{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Ops Runbooks for Fields This is the operational runbook project for the AH product (codename fields). It is used for detailing and controlling the common processes that Ops perform on a daily basis. To view this repository, use your LDAP credentials and log in to https://runbook.ops.acquia.com . To set-up your local machine to view documentation locally and run the appropriate syntax and linting tests run ./setmeup.sh in the root of your repo's directory. Tests can be run locally by running make style_check in the root of this repository. For contributing to this repo => Contribution For policy and general information => Operations Home For departmental information => Ops Employee Resources Topics Escalation Procedures Incident Response Secondary Response Ops Infrastructure Realm Management Standard Maintenance Kanban Tickets Ops Reference & Training Runbook Metadocs","title":"Welcome to Ops Runbooks for Fields"},{"location":"#welcome-to-ops-runbooks-for-fields","text":"This is the operational runbook project for the AH product (codename fields). It is used for detailing and controlling the common processes that Ops perform on a daily basis. To view this repository, use your LDAP credentials and log in to https://runbook.ops.acquia.com . To set-up your local machine to view documentation locally and run the appropriate syntax and linting tests run ./setmeup.sh in the root of your repo's directory. Tests can be run locally by running make style_check in the root of this repository. For contributing to this repo => Contribution For policy and general information => Operations Home For departmental information => Ops Employee Resources","title":"Welcome to Ops Runbooks for Fields"},{"location":"#topics","text":"Escalation Procedures Incident Response Secondary Response Ops Infrastructure Realm Management Standard Maintenance Kanban Tickets Ops Reference & Training Runbook Metadocs","title":"Topics"},{"location":"toc/","text":"Table of Contents Auto-generated index that can be used for browser based search. ah-config-iptables_locked ah-config-iptables locked Resolution ah-critical Master AH_CRITICAL Duplicate Volumes Finding The Duplicate Volumes Removing A Duplicate Volume ah-resource-mon * [Resolution](./incident_response/ah-resource-mon.md#resolution) alerts_pagerduty_outage How to Survive During a Pagerduty Outage Ops Tickets Tools to find issues Ops-emergencyperfmon Alerts Procmail Log backup_check Backup Check General Information About Backup Tasks and Runs Tasks Runs General troubleshooting local-fs-cluster fs-cluster db-cluster Next Steps Further Debugging Overdue Backups Reinstalling the ah-task-server gem to fix broken symlinks after a Fields release Hung TCP connections Duplicate volume ids blocked_fcw_run Blocked Fields Config Web Run alert Response check_auditd Check Auditd Agent Response Investigate Root Cause Restore Auditd Service check_clamav As a first step Check if the server has clamd configured Check the status of the service Health check Troubleshooting check_filesystem_fencing Check Filesystem Fencing alert Response check_gluster_transport_endpoint_error Check Gluster Transport endpoint error Response Site-wide gluster remount Server-specific gluster remount Advanced Troubleshooting Gluster 3.0 Gluster 3.4 Last Resort: Build a new FS Cluster check_perfmon_data_is_recent Check perfmon data is recent Automation Manual Resolution Verify sites start getting checked check_possible_hung_tasks Check Possible Hung Tasks Response Anything that DOES NOT involve a data transfer Database and file copies (copy, migrate, etc.) Check for rebooted/relaunched remote servers Check for Data Transfer Check for Disk Full Kill the Task check_ssl_certificate Check SSL Certificate Resolution critical_service_port_revoked Critical Service Port Revoked What to Do Communicate with the Incident Response team Log into the AWS Console Fix the Issue db_binlogs MySQL binary log troubleshooting Out of disk space Verify the problem Verify the cause Multi-region database servers Non-clustered database servers Clustered database servers Binary log corruption Binary log missing dead_backup_tasks Dead Backup Tasks Resolution debugging_php Debugging PHP Tools strace PHP-FPM Logs disk_partitions Disk Partitions Alert Resolution multiregion (passive) servers bastion servers RA Servers CDE (CD Environment) servers SVN servers for /vol/ebs1 for /vol/backup-ebs Ephemeral volumes Handle deleted files consuming space Gluster Volumes Gluster - Common Gluster - ACE Backup Volumes Common Database Volumes Warnings Operations is not allowed to purge data without customer consent (except for binlogs) Operations is not allowed to move tables or databases to alternate storage (ephemeral, gluster, ramdisk, etc.) Database - Common Database - ACE Database - ACP Misc Volumes Mon - /opt/nagios-tmpfs Master - /etc/puppet/versions Stats - /vol/ebs1/ or /vol/backup-ebs/ perf-mon.acquia.com - root fs (/) disk_writable Disk Writable Alert Determine if inode usage has been exceeeded Determine whether its an impaired volume Response Inode Usage exceeded Impaired Volume CDE (CD Environment) servers elb_issues ELB Issues Resolution Debugging ELB issues Adding and Removing ELBs from monitoring Removing an ELB from monitoring Adding an ELB back to monitoring fix-missing-glusterd_vol-file Fix missing glusterd.vol file THIS IS FOR GLUSTER 3.4 ONLY gluster-not-split-brain Not Split-brain (Gluster 3.4) Configuration Daemon (glusterd) Doesn't Start Remediation Network Issues Fields Data Issues Data Issues on Gluster 3.4 Run the diagnostic option Based on the diagnose output choose the option to repair the cluster gluster-troubleshooting * [FS Node](./incident_response/gluster-troubleshooting.md#fs-node) * [Client Node](./incident_response/gluster-troubleshooting.md#client-node) fsdbmesh * [Action](./incident_response/host_alert/fsdbmesh.md#action) * [Clean up](./incident_response/host_alert/fsdbmesh.md#clean-up) master Master Down Triage Find the master Reboot / Relaunch Nagstamon index_ping_not_initiated Sum Invocations LessThanThreshold 2.0 for FunctionName InitiateIndexCheck instance_management_acp ACP Instance Management Manual Volume Resizes maintenance_past_due Maintenance Past Due Resolution malicious_high_traffic_hosts Blocking Crawlers and Malicious High-Traffic Hosts Synopsis Identification (Know Thy Enemy) SumoLogic Logstream, GoAccess , Site-traffic and site-trafficbyuseragent Detection (Inspect Thy Enemy) Verification (Question Thy Enemy) Mitigation (Slay Thy Enemy) A word on blocking methodologies Criteria for when to block via VCL or iptables Blocking an IP or IP Range Blocking via .htaccess (Not Preferred anymore) Blocking via Varnish (Not Recommended) Block Connections using iptables (Recommended for OPS) Blocking an Useragent Block Connections using iptables Verify Post-Block (Gloat Upon Thy Enemy's Grave) mon_server_host_count Mon Server Host Count Check if the server has host monitored more than 250 Resolution Scenario 1: You get the output showing all the other mon servers from the region and their corresponding monitored Hosts Count Example output Scenario 2: There are no other mon servers in the region and you need to provision a new mon server monitoring_audit Monitoring Audit Resolution multiregion_rsync_verification MultiRegion Rsync Verification Resolution mysql_available MySQL Available Response No Seconds Behind Master MySQL Daemon Crash / Not Running Replication Is NULL Missing ops-mon User mysql_debian_sys_maint MySQL Debian Sys Maint alert Response Caveat mysql_failover MySQL Failover Response Clean Up Background mysql_replication_lag MySQL replication lag Diagnosing a replication problem Resolution for replication conflicts / split-brain Resolution for manually stopped replication Resolution for replication is running but falling behind Resolution for other replication problems Missing first binary log Corruption in the binary log Active server stopped writing binary logs Replication is still broken nagios_configuration Nagios Configuration Response nginx_config_test NGINX Configtest Resolution TLS/SSL Error Server_names_hash error Verification nxephem_nginx Nxephem Nginx Configtest Procedure out_of_memory_errors Out Of Memory (OOM) errors Summary Background Investigation Remediation - Customer Hardware Remediation - Infrastructure Post-Remediation perf_url_mon Perf URL Mon Alert Response Notification to Support Initial Triage Escalation Common Scenarios Customer-Inflicted AWS-Inflicted Acquia-Inflicted Example Scenarios General Load Web Tier High Load DB Layer High Load FS Tier High Load External Calls pupgov Pupgov Alerts Runbook Table of Contents Custom Index Ping Check Index Alert Handling Master 404 and Slave 404 Master 200 and Slave 404 Master 404 and Slave 200 Master 200 and Slave 5xx Master 5xx and Slave 200 499 Error Tomcat Out of Memory Response Manually rotating the log file ELB Metrics Additional troubleshooting Upsizing Escalations puppet_agent_disabled Puppet Agent Disabled alert Response Enabling/Disabling Masterless Puppet puppet_agent_run_status Puppet Agent Run Status Response search_index_mon Search Core Index Alerts Disabling the Core Index Checks Meta-monitoring Information Gathering Alert Handling Index not deployed (slave_code=404 & master_code=404) Index missing on slave (slave_code=404 & master_code=200) Index missing on master (slave_code=200 & master_code=404) Slave is erroring (slave_code=5xx & master_code=200) Master is erroring (slave_code=200 & master_code=5xx) Index failing on rake rebuild with boot- core already exists 499 status code Impaired Search Instances Other Troubleshooting and Resolution Procedures services_check Services Check Resolution Triage the Service Restart the Service Verify Services and Follow-up site_capacity Site Capacity alert Cause Thresholds CRITICAL: Server is full SVN Servers Staging Servers Important Note Shared Non-RA Staging Servers (Automated) Shared Non-RA Staging Servers (Manual) Shared RA Staging Servers (Automated) Shared RA Staging Servers (Manual) BAL Servers Provision Shared Balancers UNKNOWN: Could not find number of sites tomcat_memory_check Tomcat Memory Check alert Response Manually rotating the log file tomcat_running Tomcat Running alert Response triage_unresponsive_servers Triage unresponsive ACE, ACP, ACSF, Network, trex and [WMG/UMG]Gardens servers NOTE: for auditing purposes it is absolutely crucial to document all resolution steps carried out in a JIRA ticket Initial steps Determine if the server is accessible Determine the instance status from AWS Rebooting Clean up tungsten_latency Tungsten Latency Resolution tungsten_online Tungsten Online tungsten_troubleshooting Troubleshooting Tungsten Common Problems Offline Tunnel configuration files missing Error: unexpected seqno Split brain Seqno -1 & State Is ONLINE Seqno -1 & State Is OFFLINE:ERROR unmonitored_sites_check Unmonitored Site Check alert Resolution varnish_http Check Varnish HTTP Resolution vpn_connection VPN Connection Resolution vpn_mon Name of Alert Resolution web_audit Web Audit Resolution Review status Search recent JIRA and Chat activity Enabling/Disabling the host 181_release 1.81 Hosting Release Procedure Optional steps Disabling the puppet agent Re-enabling the puppet agent Verification acquiamail Acquiamail.acquia.com Dump Restore Overview Procedure acsf_deprovision Site Factory Sitegroup Deprovisioning Preparation Usage Examples and Useful Some-Liners Usage of acsf-sitegroupterminate List sitegroups List sites List servers List sites on servers Deprovisioning Suspension Termination add_custom_proxy_conf Add a custom Mod-Proxy file to a Site Enabling mod_proxy Step Ticket Requirements Testing on a dedicated staging Review Deploy once the change has been hotfixed Done add_remove_site_mon Add/Remove Sites to/from Monitoring Monitoring Sites - ACE Add ACE site to monitoring Remove ACE site from monitoring Monitoring URLs - Site Factory Add ACSF site to monitoring Remove ACSF site from monitoring Monitoring Sites - ACP & Network Add site to monitoring Remove site from monitoring add_remove_webs_from_rotation Add/Remove Webs From Rotation Overview Web Rotation Status Web Service Status Pre-Flight Checks Procedures Disabling/Removing Disabling Web Service for single OR multiple hosts Disabling Web Rotation on a single host, single site Disabling Web Rotation on multiple hosts, single site Enabling/Adding Enabling Web Service for single OR multiple hosts Enabling Web Rotation on a single host, single site Enabling Web Rotation on multiple hosts, single site add_user Bastion Provisioning Gather Required Information Approval Choosing a Username Granting Access to Bastion Provisioning a user EXAMPLE: Bastion ONLY EXAMPLE: ACE,ACP production access Confirm that User Can Log In Test Log-in ahrabot Modify the list of bastion users that can sudo ahrabot arbitrary_phpini_settings Arbitrary php.ini settings Changing php.ini settings Adding or changing arbitrary directives Removing arbitrary directives bastion_access Bastion Access User Changes Updating a user's SSH key Changing a user's group Adding a user to an additional stage bastion_troubleshooting Troubleshooting When a User Just Can't Log In When a User Gets Locked Out after successful previous logins bulk_site_move Bulk Site Move Preparation Procedure Variables Home directory copy commands Important Note Site Move Verification Post Steps bulk_site_php_edits Bulk Site PHP Edits Preparation Procedure Verification capacity-limit Edge Cluster Capacity limit Capacity Limit Reached for Non-RA Environments Capacity Limit Reached for RA Environments change_balancers_on_existing_environment Change balancers on existing environment Information ELB Configuration VPC Placement SSL Requirements Tag Validation and Migration Custom VCL Requirements Procedures change_db_password Site Database Password Change Changing Credentials clamav ClamAV Daemon Enabling Tunables Disabling code_checkout_failures Code Checkout Failures Incorrect VCS path Clean checkout configuring_hsd_for_sites HSD (Higher Site Density) To check if hsd is enabled for particular site To enable hsd To disable hsd core_dumps Enable Coredumps for Capturing PHP Segfaults Managing Coredumps Enabling Disabling Coredump Analysis Preparing Analysing Interpreting A Sample Backtrace create_test_balancer Create a test balancer Preparation Procedure Operation Extend the duration of a test balancer before its deprovision Verify if a site has test balancers Monitoring Known bugs custom_tungsten_settings Custom Tungsten Settings Configure-service Static Configuration Files Replication Filter dedicated_to_dedicated Dedicated To Dedicated Hardware Allocation Pre-Assignment Assigning Balancers Post-Assignment dedicated_to_shared Dedicated to Shared Pre-work Assign Balancers Post-Assignment shared_to_dedicated Shared to Dedicated Hardware Allocation Pre-Assignment Assigning Balancers Post-Assignment shared_to_shared Shared to Shared Pre-work Assigning Balancers Post-Assignment dedicated_hypervisor Set servers to be dedicated instances Preparation Procedure Verification dedicated_memcache Dedicated Memcache About Dedicated Memcache What site-setmemcache does Procedure Memcache Service Status deploy_certificate Deploying an SSL / TLS certificate to a balancer cluster Table of Contents Determine balancers and tag Prepare Certificate chain Private key Certificates management Adding a new certificate (Both Edge Cluster and Legacy) Deploy a certificate override (Edge cluster) Deploy a certificate override (Legacy balancer) Remove a certificate override and set to default Acquia certificates (Edge cluster) Remove a certificate override and set to default Acquia certificates (Legacy balancer) Setting a default certificate (This is for entire realm) Verify deploy_test_vcl Deploy custom VCL for customer testing deprovision_search_colony Deprovision a Search Colony Prerequisites Procedure deprovision_search_farm Deprovision a Search Farm Prerequisites Procedures deprovisioning_ace Deprovisioning ACE & ACP Preparation Caveats Deprovisioning a specific site stage Deprovisioning a sitegroup Deprovisioning A Note About ACP Suspension Termination Bulk site/environment Termination deprovisioning_mail_server Deprovisoning a mail server Remove from monitoring and puppet manifest Removing DNS entries for the mail server Terminating server from Rackspace diagnostics * [Certificate Files](./kanban_tickets/diagnostics.md#certificate-files) * [Compare Cert and Key](./kanban_tickets/diagnostics.md#compare-cert-and-key) * [Compare CSR and Key](./kanban_tickets/diagnostics.md#compare-csr-and-key) * [View Certificate Information](./kanban_tickets/diagnostics.md#view-certificate-information) * [Get notBefore/notAfter (Expiration) date](./kanban_tickets/diagnostics.md#get-notbeforenotafter-expiration-date) * [Services over SSL](./kanban_tickets/diagnostics.md#services-over-ssl) * [Verify Certificate Chain](./kanban_tickets/diagnostics.md#verify-certificate-chain) * [Asynchronous Keys](./kanban_tickets/diagnostics.md#asynchronous-keys) * [Get public key from private key](./kanban_tickets/diagnostics.md#get-public-key-from-private-key) disable_tls_version Disable TLS versions Check for Shared balancers Disable TLSv1.0 only Disable TLSv1.1 Disable TLSv1.1 in Edge Clusters duplicate_certificates Duplicate Certificates Important Note How to Duplicate a Certificate edge_cluster Edge Cluster Available commands Describe available commands or one specific command Create a new Edge Cluster Delete an Edge Cluster Relaunching bals in an Edge Cluster Note View details of an existing Edge Cluster View a list of Edge Clusters on the current realm Add an environment to an existing Edge Cluster Remove an environment from an existing Edge Cluster Increase an Edge Cluster capacity by doubling its number of servers. Cannot scale more than once Important Apply a tag to an Edge Cluster Remove a tag from an Edge Cluster Migrations Manual migration of a customer from a legacy bal pair to an Edge Cluster Manual migration of a customer from an Edge Cluster to a Legacy Balancers elb_creation ELB Creation Initialize Variables For Customers For Whom We Have The Cert and Key For Customers For Whom We Do Not Have The Cert and Key email_blacklist Acquia Email Server Blacklist Removal An example of a host being \"listed\" List of mail servers according to realm Investigation A word of caution Resolution enabling_mod_proxy Enabling Mod-Proxy on a Site Required Information Procedure Documentation Custom proxy.conf file enabling_xdebug Enabling xdebug for a Site Required Information Procedure Enabling Xdebug Enabling Xdebug Remote Documentation extended_validation_certificates Extended Validation Certificates fix_livedev Fixing/Enabling livedev Identify the error Remediation generating_csrs Generating a Certificate Signing Request (CSR) Subject SSL Plus/EV CSR Generation Procedure Wildcard Plus CSR Generation UCC/EV Multi-Domain CSR Generation Using an existing key for UCC CSR Generation UCC CSR Generation Example gluster-downgrade Downgrade Gluster Version from 3.4 to 3.0 THIS PROCESS SHOULD BE USED ONLY ON GLUSTER 3.4 SERVERS Initial Variables Info Gathering Provision new FS servers and fix volumes Allocate new FS servers Add brick volumes Configure FS servers for gluster 3.0 Allocate FS cluster Fix backup vol on secondary server to 1gb Fix ebs1 volumes on both servers to 1gb Launch FS Servers Filesystem Data Transfer Create Temporary SSH key rsync from source server to destination server Web servers cutover Take webs out of rotation Re-run rysnc Disable Puppet and cron on webs Stop gluster and Unmount gluster Add webs to New FS cluster Relaunch suspended webs Remount gluster on webs check gluster for site Put webs back into rotation Restart PHP, Run FCW on webs Verification Cleanup gluster-upgrade Upgrade Gluster Version from 3.0 to 3.4 THIS PROCESS SHOULD BE USED ONLY ON GLUSTER 3.0 SERVERS Initial Variables Info Gathering Provision new FS servers and fix volumes Allocate new FS servers Add brick volumes Configure FS servers for gluster 3.4 Allocate FS cluster Fix backup vol on secondary server to 1gb Fix ebs1 volumes on both servers to 1gb Launch FS Servers Filesystem Data Transfer Create Temporary SSH key rsync from source server to destination server Web servers cutover Take webs out of rotation Re-run rysnc Disable Puppet and cron on webs Stop gluster and Unmount gluster Add webs to New FS cluster Relaunch suspended webs Remount gluster on webs check gluster for site Put webs back into rotation Restart PHP, Run FCW on webs Verification Cleanup loadtest_balancer Load Test Balancer Adding a Load Test Balancer Find a Valid Load Test Balancer Add the balancer Check the ELB Removing a Load Test Balancer logforward Log Forwarding Log Forwarding through Ops Portal Manually Enabling Log Forwarding Requirements Enable ACE ACSF Verify ACE ACSF Disable ACE ACSF Restarting Log forwarding for Sumo Logic Follow these steps when logs forwarding breaks down for customer Diagnose log forwarding for Sumo Logic Follow these steps when logs are not being forwarded to Sumo Logic Troubleshooting td-agent and New Log Forwarding issues manage_end_to_end_encryption Manage End To End Encryption Preparation Preparation: Get sitegroup, site names and servers Enable E2E Encryption Checking the E2E Installation Disable E2E Encryption Rotate E2E Encryption Keys Verifying the e2e configuration masterless_puppet Masterless Puppet How to tell if a Server is Masterless move_customer_repo move_provisioning_pointer Moving the Index Provisioning Pointer Information multi_region_failover_testing Performing a Multi-Region Failover Test Pre-Flight Set up some Variables Validate and Document that the Site is Healthy Prior to Initiating the Failover Simulate a Region Outage, at this time the TAM should instruct the customer to fail over DNS to their Secondary Region Initiate the Multi-Region Failover to the Secondary Region Begin the Multi-Region Fail-back to the Primary Region Perform Health Checks and Document the Output in the ticket multi_tier_to_full_tier Multi-tier to Full-tier Upsize Prep Maintenance Window Site Move Procedure Cleanup multi_tier_to_single_tier Multi-tier to Single-tier Downsize Traps Important Note Set Variables Gather information Verify Server Settings Add DED SERVERS back to Site/s Check Replication Manage EIPs Move EIP Clean Up End mysql-daily-replication-fix * [Daily Automated replication fix](./kanban_tickets/mysql-daily-replication-fix.md#daily-automated-replication-fix) * [Manually finding list of servers](./kanban_tickets/mysql-daily-replication-fix.md#manually-finding-list-of-servers) * [Attempting to fix the clusters](./kanban_tickets/mysql-daily-replication-fix.md#attempting-to-fix-the-clusters) mysql_audit Enabling or Disabling MySQL Auditing Enabling MySQL Auditing Disabling MySQL Auditing orphans * [Preparation](./kanban_tickets/orphans.md#preparation) * [Procedure](./kanban_tickets/orphans.md#procedure) * [Determine the orphan instance status](./kanban_tickets/orphans.md#determine-the-orphan-instance-status) * [Determine when the server was launched](./kanban_tickets/orphans.md#determine-when-the-server-was-launched) * [Devcloud](./kanban_tickets/orphans.md#devcloud) * [All Other Environments](./kanban_tickets/orphans.md#all-other-environments) * [If the orphan instance report is not showing a server name](./kanban_tickets/orphans.md#if-the-orphan-instance-report-is-not-showing-a-server-name) * [Removing orphans nodes](./kanban_tickets/orphans.md#removing-orphans-nodes) overview SSL Overview Important Note Customer-facing Documentation on docs.ccquia.com Technical details of how SSL/TLS cert chains work Ordering SSL Certificates Pre-flight Check WHOIS Types of Actions Trial Certs General Information/Process Trial Certificate FAQ point_in_time_recovery MySQL Point in Time Recovery Warning Procedure Restoring With Binlogs From Secondary Instance Restoring With Binlogs From Primary preallocating_eips_for_webs Preallocating EIPs for webs Procedure provision_ace Gather Information Provisioning With Juno Manual Provisioning of Customer Hardware Manual Provisioning of Infrastructure Hardware provision_ace_customer Provision customer hardware and sites Allocating Hardware Determine if the VPC exists or needs to be created Setting variables Region and AZs Volume Size VPC FS Cluster variables Single-Tier Multi-Tier Full-Tier Get or allocate the Bals If dedicated If customer plans to use [edge cluster bals](/kanban_tickets/edge_cluster) Get or allocate the Staging server(s) Change mntfs volume size on Gen3 instances Set HIPAA settings if applicable Get the SVN (VCS) server Set opportunity ID to the dedicated hardware Creating sites prod test dev ra Set the smtp return path for prod test and dev Provisioning prod and ra sites with different stage names tagged prod tagged ra Tagging consequences Setup FIPS - FIPS compliant stacks only FIPS server config setting Mysql version server config setting Launching Servers If Launching A DB Server Initially Should Fail NOTE Verification Add production sites to Monitoring provision_ace_dedicated_cron Dedicated Cron For Single Tier Sites provision_ace_empfree Provisioning employee free sites Find the hardware available in the requested region Bals available in the requested region Bals in us-east-1 Bals in ap-southeast-1 region SVN SERVER Create SITES Prod site test dev Enable HSD on the SITES provision_ace_infra Provision shared and infra hardware Shared SVN Shared Edge Clustered Balancers Shared Staging Shared RA servers RA within VPC Ossec servers Mon servers Backup servers provision_acp Manually Provision a DevCloud Site & Server Provision and creation Provision a dedicated SRV server Manual steps for sites creation prod dev staging ra Provisioning prod and ra sites with different stage names tagged prod tagged ra Tagging consequences Add production sites to monitoring provision_acsf Site Factory provisioning Preparation Procedure Creating additional environments Creating an ELB for the site factory Adding a \"Stack\" Adding a \"Load test environment\" Use cases Arguments needed Commands creating a load test environment for a customer provision_bastion Provisioning provision_log_server Log Servers Introduction Pre-requisites Provision Log Servers Manage A New Cluster Manage An Existing Cluster Manage Clients provision_multi_region Multi-Region Provisioning Preparation Provision the Balancers Provision a Multi-Tier-MR Cluster Provision a Full-Tier-MR Cluster Create the site Customize and tune the Cluster Launch the cluster Install Tungsten Setup File Replication Add the site to monitoring Verification provision_search_colony Provisioning a Search Colony Allocate and launch load balancers Create the site Configure the site Create the ELB Create the CNAME in AWS Route53 Add the colony to the Governor provision_search_farm Provision a Search Farm First time preparation Sizing Deploying an extractor Solr version Allocate and launch servers Determine names Example Create and configure sites Extra: If you are deploying Solr 4 provision_site Site Provision By Realm Tiers provisioning_a_fedramp_site_with_acquia_shield Provision FedRAMP Customer Site with Acquia Cloud Shield Allocating Hardware Create the VPC Setting variables Region and AZs Volume Size VPC FS Cluster variables Single-Tier Multi-Tier Full-Tier Allocate the Bals Allocate the Staging server(s) Change mntfs volume size on Gen3 instances Set HIPAA settings if applicable Get the SVN (VCS) server Set opportunity ID to the dedicated hardware Creating sites prod test dev ra Set the smtp return path for prod test and dev Setup FIPS FIPS server config setting Mysql version server config setting Launching Servers If Launching A DB Server Initially Should Fail NOTE Verification SAML Support Enable the Network Boundary for the VPC Create an ELB Add production sites to Monitoring provisioning_a_fedramp_site_without_acquia_shield Provision FedRAMP Customer Site without Acquia Cloud Shield Allocating Hardware Create the VPC Setting variables Region and AZs Volume Size VPC FS Cluster variables Single-Tier Multi-Tier Full-Tier Allocate the Bals Allocate the Staging server(s) Change mntfs volume size on Gen3 instances Set HIPAA settings if applicable Get the SVN (VCS) server Set opportunity ID to the dedicated hardware Creating sites prod test dev ra Set the smtp return path for prod test and dev Setup FIPS FIPS server config setting MySQL version server config setting Launching Servers If Launching A DB Server Initially Should Fail NOTE Verification SAML Support Create an ELB Add production sites to Monitoring provisioning_mail_server Provisioning a mail server for Acquia Hosting Platform Cloning an existing mail server DNS Management Configuring the new mail server Testing the new mail server Replacing mail server with new server Adding the mail server to monitoring Adding the mail server in mxtoolbox for blacklist monitoring puppet_master Generating and updating the root CA cert for puppet master Change directory to ssl path Setup steps Remove old newcert.pem from last time Check config Create/Set file \"index.txt\" Create/Set file \"serial\" Create/Set file \"openssl.cnf\" Create directory \"newcerts\" if it does not exist Generate csr and cert Get CA password Generate csr Generate pem Check newcert.pem looks normal relative to ca.pem Verify the new cert Choose a server to verify At this point, make a backup of the current cert Reload Apache Test that puppet runs on the master and the new CA is cached Test that puppet runs on an arbitrary server Choose a server to test Now we need to move the current ca on all clients in the stage regenerate_netrcs Regenerating netrc Credentials Summary WARNINGS Procedure Ahops Ahsupport releasing_domains Site Domains Management Usage Checking domains for old site Removing domain from old site Adding domain to new site Real-life Example remove_user Deprovision User Access Bastion access Ops-Puppet Fields AWS renewing_certificates Renewing SSL Certificates Preface Important Note Procedure renewing_puppet_master_cert Renewing SSL cert for puppet master Steps to renew puppet master SSL cert resize_volumes_bastion Modify volumes on bastions manually Preparatory steps Gather volume information and create a backup snapshot Creating and attaching the volume Formatting the file system Copy data: rsync method Maintenance window steps Swap the volumes once the data transfer is complete restore_snapshot_on_new_hardware Restore Snapshots on New Hardware (ACE) Restore DB from backup Restore files from backup Unmount the snapshot volumes after restoring everything restore_volumes Restore Volume Backups Procedure Set the Variables Find the backup to be used for restore Mounting (Not ACSF DB) Mounting ACSF DB Communication Cleanup (Not ACSF DB) Cleanup (ACSF DB) Restore Repo revert_ssl Restoring an Acquia-Managed SSL Cert How to revert certificates for LEGACY BALANCERS How to revert certificates for EDGE CLUSTERS root_cause_analysis Root Cause Analysis Process Copy the Template Perform the RCA Request Feedback/Approval search_index_migration Search Index Migration Gathering information Risks and Customer Notification Procedures Same Colony Different Colony, Same Region Different Colony, Different Region Moving the index WITHOUT the data Moving the index WITH the data secondary_db_cluster Provisioning of single-region secondary database cluster Preparation Procedure Verification self_service_ssl Self-service SSL (on ELBs) Important Note Enabling Self-Service SSL Location of the CSR, cert, and key Support-Specified Certificate Path Pre-Existing Certificates on Bals Pre-Existing Certificate on ELBs Debugging SSL on ELBs Adding Certs to ELBs Manually or Updating an Existing ELB Cert single_tier_to_multi_tier Single-tier to Multi-tier Upsize Traps Set Variables Existing Webs Gather information AMI Types and Constrained AZs Start the Workflow Adding New EIPs Important Note After Workflow: Memcache Account Management Dealsheet single_tier_to_multi_tier_manual Single-tier to Multi-tier Upsize Traps Set Variables Existing Webs Gather information Create Provision New Webs Cluster New Webs Add Webs to Site/s Verify Server Settings Launch New Webs Post Launch Manage EIPs Check Replication Move EIP Clean Up End Account Management Dealsheet site_audit Performing a Site Audit Converting to Gen2 Downsizing / Upsizing clusters Bal Layer Cache Layer Web Layer DB Layer FS Layer Customer Renewals Additional Docroots Summary/Recommendations of Audit site_move Site Move VPC ODE/CDE instructions Site Factory Preparation Procedure Important Note Syncing Data Prior to Downtime Same Region Variables Home directory copy commands Site Move - Same region Different Regions Variables - Different regions Home directory copy commands multi-region Site Move - Different region Verification Recovery Cleanup sni_ssl SNI Certificates (deployed to bals) Some SNI concepts (for information purposes - can be skipped) SNI features in fields Uploading new certificate/key pair and activating it for use with SNI Changing active cert/key pair for a site which has multiple cert/key pairs availabile for SNI Making an SNI key/pair 'inactive' for disabling SNI Deleting an SNI key/pair 'inactive' for a site ssl_acm AWS Certificate Manager Requesting A Certificate Deploying an ACM Certificate staging_single_tier_to_multi_tier_manual Staging Single Tier to Multi-tier Upsize Traps Set Variables Existing Webs Gather information Create Provision New Webs Cluster New Webs Add Webs to Site/s Verify Server Settings Launch New Webs Post Launch Manage EIPs Move EIP Clean Up End Account Management Dealsheet svn_server_certificates SVN Server Certificates automated Test VCL Deployment - Automated Review the VCL PR CREATE a VCL test bal from an initial request UPDATE a test VCL on an existing VCL test balancer DESTROY a test VCL balancer manual Test VCL Deployment - MANUAL Review the VCL PR Set Up Some Variables Provision a Test Balancer Set up the Test Balancer Deploy the Test VCL to the Test Balancer troubleshooting_bastion Troubleshooting When a User Just Can't Log In When a User Gets Locked Out after successful previous logins troubleshooting_yubikey Troubleshooting Yubikey When a User Just Can't Log In with Yubikey Resources on Confluence Installation steps for Yubikey Download yk_bastion_init tool Command to run after installation When a User Gets Locked Out after Three Attempts When a User Gets Permission denied (publickey) while connecting bastion unblocking_email_service Unblock Email Sending for a Customer Investigation Resolution update_colony_certificate Update Search Colony Certificate Get ELB for Colony Get Certificate Info Deploy cert to ELB verify_extractor Search Extractor Determining Whether a javaephem is an Extractor Test Procedure Remediation vpc_deprovision Deprovision a VPC Preparation Procedure Verification vpc_network_boundaries VPC Network Boundaries Notes on Shield behavior Provisioning a VPC Network Boundary Preparing to create Registering the Network Boundary Deregistering a VPC Network Boundary Preparing to deregister Deregistering the Network Boundary Inspecting existing Network Boundaries Listing all the Network Boundaries in a realm Viewing the details of a Network Boundary vpc_provision Provision a VPC Preparation Procedure FedRAMP Verification vpc_vpn_deprovision Deprovision a Shield VPN Preparation Procedure Verification vpc_vpn_management Updating Shield VPNs Add a route Preparation for route addition Procedure for route addition Verification of route addition Remove a route Preparation for route removal Procedure for route removal Verification of route removal vpc_vpn_provision Provisioning a Shield VPN Preparation Procedure Verification wildcard_certificates Wildcard Certificates Important Note Wildcard Management for Customers Combining Wildcard Certificates and UCCs Wildcard Management for Acquia How to handle Duplicates on a Wildcard Certificate Creating a duplicate under an existing Wildcard Certificate A Note On Transmitting \"Secured\" Information alerts alerts.ops.acquia.com Overview of Services Relaunching Preparation Relaunch gordon_deploy OPS-Gordon Deployment Building ops-gordon Test the Deploy gordon_prod_issues OPS-Gordon Production Troubleshooting Alert-Function Timed Out Alert-Function Error Rate oneoffs General Information About One-Off Servers Access Relaunching One-Offs Preparation Relaunch perfmon perf-mon.ops.acquia.com Overview of Services Relaunching Preparation Relaunch deploy_secrets_masterless Deploying secrets with Masterless Puppet Keys scp * [How to use](./ops_reference/scp.md#how-to-use) audit_data_backup Audit Data Backup Log Set filename variable Create Server List Data Backup Logs Clock SCP audit_iptables_sgroups Audit IPtables Security Groups Set filename variable Create Server List NGINX IPTABLES Security Groups SCP audit_services_protocols_ports Audit Services Protocols Ports Set filename variable Create Server List NETSTAT Systemctl SCP audit_sudoers Audit Sudoers Set filename variable Create Server List SUDOERS SCP audit_user_access User Access Audit Set filename variable Tooling to generate the report: admin-userreport Bastion YubiKey Access List mntfs-volume-reaping Reaping of Unused /mnt EBS Volumes Step 1: Switch to required stage in Bastion Step 2: Create directory to store interim files used for reaping Step 3: Find volumes that are tagged with ah_terminated Step 4: List the volumes that are tagged with ah_terminated Step 5: Reap the /mnt mounting unsued volumes that are tagged with ah_terminated mysql_restarts MySQL Restart Mass Process Servers with no replication One-off Procedure Servers with replication Preparation Procedure Cleanup patching Mass patching Preparation Ensure hosts have enough free inodes on root filesystem Patching search Restart services if OpenSSL was updated Verification backup Reboot Backup Servers Prerequisites Procedure balancer Balancer Mass Reboots / Relaunches General Information Procedure Important Notes Preparation Reboot / Relaunch Balancers Standard Balancers Singleton Balancers Non-Standard Balancers cplane Control Plane Non-Customer-Impacting Hosts: dns , ossec , stats , log Rebooting or Relaunching DNS ( dns ) Rebooting or Relaunching OSSEC ( ossec ) Rebooting or Relaunching STATS ( stats ) Rebooting or Relaunching LOG ( log ) Rebooting or Relaunching Monitoring Hosts ( mon , monui , sitemon ) Customer-Impacting Hosts: svn Rebooting or Relaunching SVN Hosts ( svn ) custom_servers Custom servers ( custom ) databases Database Mass Reboot/Relaunch General Information Procedure Important Notes Preparation Reboot or Relaunch Database Clusters Cleanup Workflow Errors fs Filesystem Server Mass Reboot/Relaunch Preparation Important Note Ensure Gluster Mounts Reboot/Relaunch FS Servers Cleanup Workflow errors manual_databases Databases (dbmaster, ded, fsdb) Summary manual_fs Filesystem Server Mass Reboot/Relaunch - Manual Preparation Ensure Gluster Mounts Reboot/Relaunch FS Servers Cleanup manual_webs Manual Reboot or Relaunch Webs( api , web ) Procedure - Web non_ha Customer Non-HA Servers ( free , srv , staging , api ) task Task Servers Prerequisites Procedure tungsten Multiregion Database Mass Reboot/Relaunch Overview Procedure Important Notes Preparation Reboot Secondary Multiregion Databases Failover to Secondary Multiregion Databases Reboot Primary Multiregion Databases Failover to Primary Multiregion Databases Cleanup webs Webs ( web ) Important Note workflow_errors Dealing with Workflow errors Retry Workflow Aborting a workflow Important Note Some Specific Workflow Fixes SSH Disconnect Gluster Failed Workflow Launch Task Times Out Workflow Hit Ruby Threading Bug Workflow Hit Invalid VCS Path provision_new_region Provision New Region Init Preparation Procedure Import the public key into the new region Create the shared vpc Launch a mon Launch a dns Launch a log cluster Launch a ossec Launch a svn Launch a shared production bal pair and a shared non-production bal pair - ACE only Launch a shared staging server - ACE only reboot_balancers Reboot Bals Using Workflow Variable setup Reboot bals reboot_master Reboot a Master Find the master Rebooting Post Reboot reboot_search Mass Rebooting Search Servers Prequisites Patching Rebooting All Servers Rebooting All Servers By Region Rebooting a Subset of Servers Rebooting the Master Troubleshooting Disabling monitoring failed Squelching of index checks failed Server patching fails Server reboot failed Server fails to register with the Governor Rake rebuild fails Index unsquelch fails Re-enabling monitoring fails Reboot command errors out rebooting_relaunching Mass Rebooting and Relaunching Procedure Overview Table of Contents IMPORTANT NOTES The bulk-reboot Workflow Monitoring Tasks and Workflows Important Note Credentials Scheduling maintenance for AMI type Change OS Upgrades Preparation Rebooting or Relaunching CPLANE ( dns , ossec , stats , log , svn ) Customer Non-HA Servers ( free , srv , staging , api ) Balancers ( bal ) Databases ( ded , fsdb , dbmaster ) Filesystem-only servers ( fs ) Tungsten Multiregion servers ( fsdbmesh , dbmesh ) Webs ( managed , web ) Custom servers ( custom ) Search Servers ( nxephem , javasrv , javaephem ) Dealing with Workflow errors Auditing TODO: Check version of kernel and important packages updated. relaunch Relaunch Instances Pre-Relaunch Steps Web Class (ded,managed,staging,web) FS Class (ded,fs,fsdb,fsdbmesh,staging) DB Class (ded,fsdb,fsdbmesh,dbmaster) Relaunching Procedures Relaunching Failed Instances Normal Relaunch Task Relaunch Local Relaunch Forced Relaunch Post checks after successful relaunch(Mandatory) relaunch_backup Backup Server Relaunch Bugs Backup Credentials Rogue EBS Volumes relaunch_balancers Relaunch Bals Using Workflow Variable setup Relaunch bals relaunch_master Relaunch a Master Setting up the variables Prepare for relaunch Relaunch Post relaunch Terminating the old master Rollback relaunch and switch back to previous master relaunch_master_manual Relaunch a Master (manual process) Find the master Relaunch During Relaunch Post Relaunch relaunch_search Mass Relaunching Search Servers Relaunching All Servers by Region Relaunching a Subset of Servers Notes site_config_changes Bulk config settings changes Procedure Verification volume_relaunch_fix Volume Relaunch Fix Applicable Situations Diagnosing the condition Workaround Cleanup contribution Welcome to Contributing to Ops Runbooks for Fields Guidelines Main Topics Contributing Workflow Local Development Setup (Automated) Setup (Manual) Reviewing Shortcutting Linting Labels Approved style Ops Runbook (Fields) Style Guide Install and Use Rules file The Standard Verbiage Headings Lists Ordered Unordered Code in lists Variables Standard Variables Common Reserved Variables Coding cpu_wait Diagnosing CPU Wait problems Tools to Identify CPU Wait SignalFX vmstat ps iostat lsof strace Responses Balancers Webs FS DB db_error_lock_wait_timeout MySQL lock_wait_timeout errors Background Optional: Verify how many processes are waiting Finding the long-running transaction Finding the PHP process Report to Support disable_acp_sales Disable DevCloud Purchases Procedure Alternate Procedure dump_restore_all Dump Restore All Tungsten Hosts Procedure Dump The DB Prepare Bad Hosts For The DR Restore The DB Restore Replication dump_restore_single Dump Restore A Single Tungsten Slave Procedure Dump The DB Restore The DB Restore Replication dump_restore_workflow MySQL Dump Restore Workflow Preparation Ensure there is no replication lag on either server Make sure there is enough space on the ephemeral volume Verify that replication is set up Starting the workflow Important Note Required parameter --method Optional parameter --path Standard workflow parameters Verify replication Trouble shooting fencing * [Enable fence](./secondary_response/fencing.md#enable-fence) * [Enable on Single server](./secondary_response/fencing.md#enable-on-single-server) * [Enable on AZ](./secondary_response/fencing.md#enable-on-az) * [Disable fence](./secondary_response/fencing.md#disable-fence) * [Disable on Single server](./secondary_response/fencing.md#disable-on-single-server) * [Disable on AZ](./secondary_response/fencing.md#disable-on-az) fix-1970-timestamps Fix 1970 timestamps for files THIS IS FOR GLUSTER 3.0 ONLY Gather Information Remediation 1 Remediation 2 Remediation 3 impaired_server_relaunch Relaunching impaired servers Pre-checks Web Servers FS Servers DB servers Balancers Search servers Diagnosing problems with relaunch and force relaunch mysql_service_issue_during_volume_resize Fix MySQL service issue occured during volume resize Important Note Setting up the variables Lock replication to the GOOD_DB_SERVER Attach last known/working DB volume on BAD_DB_SERVER Let's Sync the old data after mounting old DB volume on BAD_DB_SERVER Start MySQL Service Resume the Workflow Check replication Status Initiate Dump Restore Umount the old volume and remove the folder from $BAD_DB_SERVER Detach the volume from $BAD_DB_SERVER mysql_startup_failures MySQL Startup Failure Troubleshooting InnoDB File unknown read returned OS error 71 Problem Description for File (unknown) error Fix for File (unknown) error You have to start mysqld with tc-heuristic-recover switch to commit or rollback pending transactions Problem Description for --tc-heuristic-recover error Fix for --tc-heuristic-recover error pt-kill * [READ THIS FIRST](./secondary_response/pt-kill.md#read-this-first) * [Investigation](./secondary_response/pt-kill.md#investigation) * [Example pt-kill Command](./secondary_response/pt-kill.md#example-pt-kill-command) reduce_sf_mysql_disk_usage Reduce Site Factory MySQL Disk Usage Warning Procedure Variables Prep Begin on Secondary Repeat on Primary replacing-brick-volumes * [Initial Variables](./secondary_response/replacing-brick-volumes.md#initial-variables) * [Remove the old (corrupt) brick](./secondary_response/replacing-brick-volumes.md#remove-the-old-corrupt-brick) * [Relaunch the server to setup a new brick](./secondary_response/replacing-brick-volumes.md#relaunch-the-server-to-setup-a-new-brick) * [If all is fine delete the aws volume](./secondary_response/replacing-brick-volumes.md#if-all-is-fine-delete-the-aws-volume) replacing-bricks Replacing Gluster Bricks THIS IS FOR GLUSTER 3.4 ONLY Stop Gluster and other services Remove the old (corrupt) brick directory Recover Volume ID Start Gluster Heal the brick Force-mounting the brick Verify success Start Gluster Client & Cron search_disk_partitions Search Disk Partitions Alert Initialize Confirm that the indexes directory is filling its partition Remediation Move indexes that should not be deployed Determine if a customer is over their limit Move the largest index Emergency Upsize split-brain * [Init](./secondary_response/split-brain.md#init) * [Resolution](./secondary_response/split-brain.md#resolution) * [Heal and Check](./secondary_response/split-brain.md#heal-and-check) * [Clean up](./secondary_response/split-brain.md#clean-up) tungsten_administration General Administration Check Consistency Check Status Dump Restore Missing Peers Properties Files Resetting Tungsten User Privileges Send Heartbeat State Overview Tungsten Slave Resync How To Use It Trim Log Files Binlogs Info Logs Total Wipe/Reinstallation Of Tungsten Verifying Replication With Checksumming xtrabackup Xtrabackup Dump Restore Pre Restoring MySQL data from dbmaster-A to dbmaster-B Prepare XtraBackup snapshot Copy snapshot and prepare passive master Restore replication Reset replication to restored passive master Verify replication Clean up az_migration AZ Migration Preparatory Work Variables (prep) Procedure (prep) Important Note Monitor Snapshot Progress Maintenance Window Procedure for Servers without Volumes (web) Important Note Procedure for Servers with Volumes Confirm ELB AZ Configuration is Correct when migrating Bals Monitor Snapshot Progress az_migration_manual Manual AZ Migration Preparatory Work Variables (prep) Procedure (prep) Wait for completion Maintenance Window Procedure for Servers without Volumes (web) Procedure for Servers with Volumes az_migration_manual_volume_m AZ Migration (xvdm) Variables Maintenance Window Procedure Post Launch az_migration_manual_volume_mn AZ Migration (xvdm xvdn) Variables Maintenance Window Procedure Post Launch az_migration_manual_volume_mno AZ Migration (xvdm xvdn xvdo) Variables Maintenance Window Procedure Post Launch az_migration_manual_volume_no AZ Migration (xvdn xvdo) Variables Maintenance Window Procedure Post Launch fedramp_relaunch Relaunching into FedRAMP compliance VPC Site Factory site layout Prep Maintenance Validate Maintenance Relaunch Into VPC fips-140-2 FIPS 140-2 compliant instance management Reporting issues References fips_check Check whether a server is already FIPS compliant Check kernel release Check package pin Check mysql version on DB servers fips_disable Disable FIPS Disable FIPS on a server Bulk disable FIPS on servers fips_enable Enable FIPS Enable FIPS on a server Bulk enable FIPS on servers Bulk relaunch servers fips_migrate_db Enable FIPS on DB servers fips_mysql_upgrade Upgrading mysql tier to be FIPS 140-2 compliant Pre-requisites (must be known before you begin) Gathering a list of servers Create lists of database servers for the customer Verify the MySQL Versions before starting Find all active and passive database servers Upgrade database servers to use FIPS compliant mysql version Verification step Suspend, Enable FIPS, Relaunch to New VPC fips_provision FIPS 140-2 compliant server provisioning moving_a_fedramp_site_with_acquia_shield Moving a FedRAMP Site with Acquia Cloud Shield Requirements VPC Site Factory site layout Provisioning New Hardware Preparation Procedure Important Note Syncing Data Prior to Downtime Variables Home directory copy commands Site Move Verification IPv6 Support TLSv1.2 Support Network Boundaries Site Factory post-steps Recovery moving_a_fedramp_site_without_acquia_shield Moving a FedRAMP Site without Acquia Cloud Shield Requirements VPC Site Factory site layout Provisioning New Hardware Preparation Procedure Important Note Syncing Data Prior to Downtime Varriables Migrating EIP of dedicated bals - PLEASE READ THIS CAREFULLY Home directory copy commands Site Move Create an ELB Verification IPv6 Support TLSv1.2 Support Site Factory post-steps Recovery relaunch_bastion Relaunching Rebooting Pre-Flight Check Suspending Launching Post Relaunch Setup Fields Ops-misc Ops-API (Otto) Ahrabot Ahopsbot AHT AWS CLI ops-incidents Restore the crontab Unison Sync Cleanup Notification replace_volumes Replacing a Bad Volume Manually Diagnosing a Bad Volume Repairing the File System Replacing the Volume with a Snapshot resize_volumes Resize volumes Emergency upsize guidelines (ACE & ACSF only) Gluster Prep Dumps Preparatory steps Create and attach the new volume Copy data: rsync method Important Note Copy data: XFS dump-restore method Important Note No data copy: no_data_migration method Maintenance window steps Volume and service specifics MySQL volumes (xvdm) Backup (xvdn) Gluster (xvdo) Mntfs (xvdb) Livedev-enabled sites Troubleshooting Reset XFS dump-restore Gluster 3.4 ID Volume Cleanup resize_volumes_manual Resize volumes manually Emergency upsize guidelines (ACE & ACSF only) Gluster Prep Dumps Preparatory steps Create and attach the new volume Format and mount the new volume Copy data: rsync method Copy data: XFS dump-restore method Maintenance window steps Volume and service specifics MySQL volumes (sdm) Backup (sdn) Gluster (sdo) Troubleshooting Reset XFS dump-restore Gluster 3.4 ID Deleting a volume Volume Cleanup toc Table of Contents * ah-config-iptables_locked * ah-critical * ah-resource-mon * alerts_pagerduty_outage * backup_check * blocked_fcw_run * check_auditd * check_clamav * check_filesystem_fencing * check_gluster_transport_endpoint_error * check_perfmon_data_is_recent * check_possible_hung_tasks * check_ssl_certificate * critical_service_port_revoked * db_binlogs * dead_backup_tasks * debugging_php * disk_partitions * disk_writable * elb_issues * fix-missing-glusterd_vol-file * gluster-not-split-brain * gluster-troubleshooting * fsdbmesh * master * index_old * index_ping_not_initiated * instance_management_acp * maintenance_past_due * malicious_high_traffic_hosts * mon_server_host_count * monitoring_audit * multiregion_rsync_verification * mysql_available * mysql_debian_sys_maint * mysql_failover * mysql_replication_lag * nagios_configuration * nginx_config_test * nxephem_nginx * out_of_memory_errors * perf_url_mon * pupgov * puppet_agent_disabled * puppet_agent_run_status * search_index_mon * services_check * site_capacity * tomcat_memory_check * tomcat_running * triage_unresponsive_servers * tungsten_latency * tungsten_online * tungsten_troubleshooting * unmonitored_sites_check * varnish_http * vpn_connection * vpn_mon * web_audit * index_new * 181_release * acquiamail * acsf_deprovision * add_custom_proxy_conf * add_remove_site_mon * add_remove_webs_from_rotation * add_user * ahrabot * arbitrary_phpini_settings * bastion_access * bastion_troubleshooting * bulk_site_move * bulk_site_php_edits * capacity-limit * change_balancers_on_existing_environment * change_db_password * clamav * code_checkout_failures * configuring_hsd_for_sites * core_dumps * create_test_balancer * custom_tungsten_settings * dedicated_to_dedicated * dedicated_to_shared * shared_to_dedicated * shared_to_shared * dedicated_hypervisor * dedicated_memcache * deploy_certificate * deploy_test_vcl * deprovision_search_colony * deprovision_search_farm * deprovisioning_ace * deprovisioning_mail_server * diagnostics * disable_tls_version * duplicate_certificates * edge_cluster * elb_creation * email_blacklist * enabling_mod_proxy * enabling_xdebug * extended_validation_certificates * fix_livedev * generating_csrs * gluster-downgrade * gluster-upgrade * index_old * loadtest_balancer * logforward * manage_end_to_end_encryption * masterless_puppet * move_customer_repo * move_provisioning_pointer * multi_region_failover_testing * multi_tier_to_full_tier * multi_tier_to_single_tier * mysql-daily-replication-fix * mysql_audit * orphans * overview * point_in_time_recovery * preallocating_eips_for_webs * provision_ace * provision_ace_customer * provision_ace_dedicated_cron * provision_ace_dedicated_memcache * provision_ace_empfree * provision_ace_infra * provision_acp * provision_acsf * provision_bastion * provision_log_server * provision_multi_region * provision_search_colony * provision_search_farm * provision_site * provisioning_a_fedramp_site_with_acquia_shield * provisioning_a_fedramp_site_without_acquia_shield * provisioning_mail_server * puppet_master * regenerate_netrcs * releasing_domains * remove_user * renewing_certificates * renewing_puppet_master_cert * resize_volumes_bastion * restore_snapshot_on_new_hardware * restore_volumes * revert_ssl * root_cause_analysis * search_index_migration * secondary_db_cluster * self_service_ssl * single_tier_to_multi_tier * single_tier_to_multi_tier_manual * site_audit * site_move * sni_ssl * ssl_acm * staging_single_tier_to_multi_tier_manual * svn_server_certificates * automated * manual * troubleshooting_bastion * troubleshooting_yubikey * unblocking_email_service * update_colony_certificate * verify_extractor * vpc_deprovision * vpc_network_boundaries * vpc_provision * vpc_vpn_deprovision * vpc_vpn_management * vpc_vpn_provision * wildcard_certificates * alerts * gordon_deploy * gordon_prod_issues * index_old * oneoffs * perfmon * deploy_secrets_masterless * index_old * scp * audit_data_backup * audit_iptables_sgroups * audit_services_protocols_ports * audit_sudoers * audit_user_access * index_old * mntfs-volume-reaping * mysql_restarts * patching * backup * balancer * cplane * custom_servers * databases * fs * manual_databases * manual_fs * manual_webs * non_ha * task * tungsten * webs * workflow_errors * provision_new_region * reboot_balancers * reboot_master * reboot_old * reboot_search * rebooting_relaunching * relaunch * relaunch_backup * relaunch_balancers * relaunch_master * relaunch_master_manual * relaunch_search * site_config_changes * volume_relaunch_fix * contribution * index_old * style * cpu_wait * db_error_lock_wait_timeout * disable_acp_sales * dump_restore_all * dump_restore_single * dump_restore_workflow * fencing * fix-1970-timestamps * impaired_server_relaunch * index_old * mysql_service_issue_during_volume_resize * mysql_startup_failures * pt-kill * reduce_sf_mysql_disk_usage * replacing-brick-volumes * replacing-bricks * search_disk_partitions * split-brain * tungsten_administration * xtrabackup * az_migration * az_migration_manual * az_migration_manual_volume_m * az_migration_manual_volume_mn * az_migration_manual_volume_mno * az_migration_manual_volume_no * fedramp_relaunch * fips-140-2 * fips_check * fips_disable * fips_enable * fips_migrate_db * fips_mysql_upgrade * fips_provision * index_old * moving_a_fedramp_site_with_acquia_shield * moving_a_fedramp_site_without_acquia_shield * relaunch_bastion * replace_volumes * resize_volumes * resize_volumes_manual * services_overview * ssh_between_servers * strace services_overview Overview of Common Services A Note About Log Analysis System Logs Primary Services Varnish Nginx Apache PHP-FPM Memcached MySQL Gluster Tungsten Secondary Services ah-socketd collectd cron exim4 Nagios ossec pt-heartbeat ssh_between_servers SSHing Between Servers sv-rsyncfile Key Forwarding Temporary SSH Key strace Using strace Basic strace Usage Interpreting strace Output","title":"Table of Contents"},{"location":"toc/#table-of-contents","text":"Auto-generated index that can be used for browser based search.","title":"Table of Contents"},{"location":"toc/#ah-config-iptables_locked","text":"ah-config-iptables locked Resolution","title":"ah-config-iptables_locked"},{"location":"toc/#ah-critical","text":"Master AH_CRITICAL Duplicate Volumes Finding The Duplicate Volumes Removing A Duplicate Volume","title":"ah-critical"},{"location":"toc/#ah-resource-mon","text":"* [Resolution](./incident_response/ah-resource-mon.md#resolution)","title":"ah-resource-mon"},{"location":"toc/#alerts_pagerduty_outage","text":"How to Survive During a Pagerduty Outage Ops Tickets Tools to find issues Ops-emergencyperfmon Alerts Procmail Log","title":"alerts_pagerduty_outage"},{"location":"toc/#backup_check","text":"Backup Check General Information About Backup Tasks and Runs Tasks Runs General troubleshooting local-fs-cluster fs-cluster db-cluster Next Steps Further Debugging Overdue Backups Reinstalling the ah-task-server gem to fix broken symlinks after a Fields release Hung TCP connections Duplicate volume ids","title":"backup_check"},{"location":"toc/#blocked_fcw_run","text":"Blocked Fields Config Web Run alert Response","title":"blocked_fcw_run"},{"location":"toc/#check_auditd","text":"Check Auditd Agent Response Investigate Root Cause Restore Auditd Service","title":"check_auditd"},{"location":"toc/#check_clamav","text":"As a first step Check if the server has clamd configured Check the status of the service Health check Troubleshooting","title":"check_clamav"},{"location":"toc/#check_filesystem_fencing","text":"Check Filesystem Fencing alert Response","title":"check_filesystem_fencing"},{"location":"toc/#check_gluster_transport_endpoint_error","text":"Check Gluster Transport endpoint error Response Site-wide gluster remount Server-specific gluster remount Advanced Troubleshooting Gluster 3.0 Gluster 3.4 Last Resort: Build a new FS Cluster","title":"check_gluster_transport_endpoint_error"},{"location":"toc/#check_perfmon_data_is_recent","text":"Check perfmon data is recent Automation Manual Resolution Verify sites start getting checked","title":"check_perfmon_data_is_recent"},{"location":"toc/#check_possible_hung_tasks","text":"Check Possible Hung Tasks Response Anything that DOES NOT involve a data transfer Database and file copies (copy, migrate, etc.) Check for rebooted/relaunched remote servers Check for Data Transfer Check for Disk Full Kill the Task","title":"check_possible_hung_tasks"},{"location":"toc/#check_ssl_certificate","text":"Check SSL Certificate Resolution","title":"check_ssl_certificate"},{"location":"toc/#critical_service_port_revoked","text":"Critical Service Port Revoked What to Do Communicate with the Incident Response team Log into the AWS Console Fix the Issue","title":"critical_service_port_revoked"},{"location":"toc/#db_binlogs","text":"MySQL binary log troubleshooting Out of disk space Verify the problem Verify the cause Multi-region database servers Non-clustered database servers Clustered database servers Binary log corruption Binary log missing","title":"db_binlogs"},{"location":"toc/#dead_backup_tasks","text":"Dead Backup Tasks Resolution","title":"dead_backup_tasks"},{"location":"toc/#debugging_php","text":"Debugging PHP Tools strace PHP-FPM Logs","title":"debugging_php"},{"location":"toc/#disk_partitions","text":"Disk Partitions Alert Resolution multiregion (passive) servers bastion servers RA Servers CDE (CD Environment) servers SVN servers for /vol/ebs1 for /vol/backup-ebs Ephemeral volumes Handle deleted files consuming space Gluster Volumes Gluster - Common Gluster - ACE Backup Volumes Common Database Volumes Warnings Operations is not allowed to purge data without customer consent (except for binlogs) Operations is not allowed to move tables or databases to alternate storage (ephemeral, gluster, ramdisk, etc.) Database - Common Database - ACE Database - ACP Misc Volumes Mon - /opt/nagios-tmpfs Master - /etc/puppet/versions Stats - /vol/ebs1/ or /vol/backup-ebs/ perf-mon.acquia.com - root fs (/)","title":"disk_partitions"},{"location":"toc/#disk_writable","text":"Disk Writable Alert Determine if inode usage has been exceeeded Determine whether its an impaired volume Response Inode Usage exceeded Impaired Volume CDE (CD Environment) servers","title":"disk_writable"},{"location":"toc/#elb_issues","text":"ELB Issues Resolution Debugging ELB issues Adding and Removing ELBs from monitoring Removing an ELB from monitoring Adding an ELB back to monitoring","title":"elb_issues"},{"location":"toc/#fix-missing-glusterd_vol-file","text":"Fix missing glusterd.vol file THIS IS FOR GLUSTER 3.4 ONLY","title":"fix-missing-glusterd_vol-file"},{"location":"toc/#gluster-not-split-brain","text":"Not Split-brain (Gluster 3.4) Configuration Daemon (glusterd) Doesn't Start Remediation Network Issues Fields Data Issues Data Issues on Gluster 3.4 Run the diagnostic option Based on the diagnose output choose the option to repair the cluster","title":"gluster-not-split-brain"},{"location":"toc/#gluster-troubleshooting","text":"* [FS Node](./incident_response/gluster-troubleshooting.md#fs-node) * [Client Node](./incident_response/gluster-troubleshooting.md#client-node)","title":"gluster-troubleshooting"},{"location":"toc/#fsdbmesh","text":"* [Action](./incident_response/host_alert/fsdbmesh.md#action) * [Clean up](./incident_response/host_alert/fsdbmesh.md#clean-up)","title":"fsdbmesh"},{"location":"toc/#master","text":"Master Down Triage Find the master Reboot / Relaunch Nagstamon","title":"master"},{"location":"toc/#index_ping_not_initiated","text":"Sum Invocations LessThanThreshold 2.0 for FunctionName InitiateIndexCheck","title":"index_ping_not_initiated"},{"location":"toc/#instance_management_acp","text":"ACP Instance Management Manual Volume Resizes","title":"instance_management_acp"},{"location":"toc/#maintenance_past_due","text":"Maintenance Past Due Resolution","title":"maintenance_past_due"},{"location":"toc/#malicious_high_traffic_hosts","text":"Blocking Crawlers and Malicious High-Traffic Hosts Synopsis Identification (Know Thy Enemy) SumoLogic Logstream, GoAccess , Site-traffic and site-trafficbyuseragent Detection (Inspect Thy Enemy) Verification (Question Thy Enemy) Mitigation (Slay Thy Enemy) A word on blocking methodologies Criteria for when to block via VCL or iptables Blocking an IP or IP Range Blocking via .htaccess (Not Preferred anymore) Blocking via Varnish (Not Recommended) Block Connections using iptables (Recommended for OPS) Blocking an Useragent Block Connections using iptables Verify Post-Block (Gloat Upon Thy Enemy's Grave)","title":"malicious_high_traffic_hosts"},{"location":"toc/#mon_server_host_count","text":"Mon Server Host Count Check if the server has host monitored more than 250 Resolution Scenario 1: You get the output showing all the other mon servers from the region and their corresponding monitored Hosts Count Example output Scenario 2: There are no other mon servers in the region and you need to provision a new mon server","title":"mon_server_host_count"},{"location":"toc/#monitoring_audit","text":"Monitoring Audit Resolution","title":"monitoring_audit"},{"location":"toc/#multiregion_rsync_verification","text":"MultiRegion Rsync Verification Resolution","title":"multiregion_rsync_verification"},{"location":"toc/#mysql_available","text":"MySQL Available Response No Seconds Behind Master MySQL Daemon Crash / Not Running Replication Is NULL Missing ops-mon User","title":"mysql_available"},{"location":"toc/#mysql_debian_sys_maint","text":"MySQL Debian Sys Maint alert Response Caveat","title":"mysql_debian_sys_maint"},{"location":"toc/#mysql_failover","text":"MySQL Failover Response Clean Up Background","title":"mysql_failover"},{"location":"toc/#mysql_replication_lag","text":"MySQL replication lag Diagnosing a replication problem Resolution for replication conflicts / split-brain Resolution for manually stopped replication Resolution for replication is running but falling behind Resolution for other replication problems Missing first binary log Corruption in the binary log Active server stopped writing binary logs Replication is still broken","title":"mysql_replication_lag"},{"location":"toc/#nagios_configuration","text":"Nagios Configuration Response","title":"nagios_configuration"},{"location":"toc/#nginx_config_test","text":"NGINX Configtest Resolution TLS/SSL Error Server_names_hash error Verification","title":"nginx_config_test"},{"location":"toc/#nxephem_nginx","text":"Nxephem Nginx Configtest Procedure","title":"nxephem_nginx"},{"location":"toc/#out_of_memory_errors","text":"Out Of Memory (OOM) errors Summary Background Investigation Remediation - Customer Hardware Remediation - Infrastructure Post-Remediation","title":"out_of_memory_errors"},{"location":"toc/#perf_url_mon","text":"Perf URL Mon Alert Response Notification to Support Initial Triage Escalation Common Scenarios Customer-Inflicted AWS-Inflicted Acquia-Inflicted Example Scenarios General Load Web Tier High Load DB Layer High Load FS Tier High Load External Calls","title":"perf_url_mon"},{"location":"toc/#pupgov","text":"Pupgov Alerts Runbook Table of Contents Custom Index Ping Check Index Alert Handling Master 404 and Slave 404 Master 200 and Slave 404 Master 404 and Slave 200 Master 200 and Slave 5xx Master 5xx and Slave 200 499 Error Tomcat Out of Memory Response Manually rotating the log file ELB Metrics Additional troubleshooting Upsizing Escalations","title":"pupgov"},{"location":"toc/#puppet_agent_disabled","text":"Puppet Agent Disabled alert Response Enabling/Disabling Masterless Puppet","title":"puppet_agent_disabled"},{"location":"toc/#puppet_agent_run_status","text":"Puppet Agent Run Status Response","title":"puppet_agent_run_status"},{"location":"toc/#search_index_mon","text":"Search Core Index Alerts Disabling the Core Index Checks Meta-monitoring Information Gathering Alert Handling Index not deployed (slave_code=404 & master_code=404) Index missing on slave (slave_code=404 & master_code=200) Index missing on master (slave_code=200 & master_code=404) Slave is erroring (slave_code=5xx & master_code=200) Master is erroring (slave_code=200 & master_code=5xx) Index failing on rake rebuild with boot- core already exists 499 status code Impaired Search Instances Other Troubleshooting and Resolution Procedures","title":"search_index_mon"},{"location":"toc/#services_check","text":"Services Check Resolution Triage the Service Restart the Service Verify Services and Follow-up","title":"services_check"},{"location":"toc/#site_capacity","text":"Site Capacity alert Cause Thresholds CRITICAL: Server is full SVN Servers Staging Servers Important Note Shared Non-RA Staging Servers (Automated) Shared Non-RA Staging Servers (Manual) Shared RA Staging Servers (Automated) Shared RA Staging Servers (Manual) BAL Servers Provision Shared Balancers UNKNOWN: Could not find number of sites","title":"site_capacity"},{"location":"toc/#tomcat_memory_check","text":"Tomcat Memory Check alert Response Manually rotating the log file","title":"tomcat_memory_check"},{"location":"toc/#tomcat_running","text":"Tomcat Running alert Response","title":"tomcat_running"},{"location":"toc/#triage_unresponsive_servers","text":"Triage unresponsive ACE, ACP, ACSF, Network, trex and [WMG/UMG]Gardens servers NOTE: for auditing purposes it is absolutely crucial to document all resolution steps carried out in a JIRA ticket Initial steps Determine if the server is accessible Determine the instance status from AWS Rebooting Clean up","title":"triage_unresponsive_servers"},{"location":"toc/#tungsten_latency","text":"Tungsten Latency Resolution","title":"tungsten_latency"},{"location":"toc/#tungsten_online","text":"Tungsten Online","title":"tungsten_online"},{"location":"toc/#tungsten_troubleshooting","text":"Troubleshooting Tungsten Common Problems Offline Tunnel configuration files missing Error: unexpected seqno Split brain Seqno -1 & State Is ONLINE Seqno -1 & State Is OFFLINE:ERROR","title":"tungsten_troubleshooting"},{"location":"toc/#unmonitored_sites_check","text":"Unmonitored Site Check alert Resolution","title":"unmonitored_sites_check"},{"location":"toc/#varnish_http","text":"Check Varnish HTTP Resolution","title":"varnish_http"},{"location":"toc/#vpn_connection","text":"VPN Connection Resolution","title":"vpn_connection"},{"location":"toc/#vpn_mon","text":"Name of Alert Resolution","title":"vpn_mon"},{"location":"toc/#web_audit","text":"Web Audit Resolution Review status Search recent JIRA and Chat activity Enabling/Disabling the host","title":"web_audit"},{"location":"toc/#181_release","text":"1.81 Hosting Release Procedure Optional steps Disabling the puppet agent Re-enabling the puppet agent Verification","title":"181_release"},{"location":"toc/#acquiamail","text":"Acquiamail.acquia.com Dump Restore Overview Procedure","title":"acquiamail"},{"location":"toc/#acsf_deprovision","text":"Site Factory Sitegroup Deprovisioning Preparation Usage Examples and Useful Some-Liners Usage of acsf-sitegroupterminate List sitegroups List sites List servers List sites on servers Deprovisioning Suspension Termination","title":"acsf_deprovision"},{"location":"toc/#add_custom_proxy_conf","text":"Add a custom Mod-Proxy file to a Site Enabling mod_proxy Step Ticket Requirements Testing on a dedicated staging Review Deploy once the change has been hotfixed Done","title":"add_custom_proxy_conf"},{"location":"toc/#add_remove_site_mon","text":"Add/Remove Sites to/from Monitoring Monitoring Sites - ACE Add ACE site to monitoring Remove ACE site from monitoring Monitoring URLs - Site Factory Add ACSF site to monitoring Remove ACSF site from monitoring Monitoring Sites - ACP & Network Add site to monitoring Remove site from monitoring","title":"add_remove_site_mon"},{"location":"toc/#add_remove_webs_from_rotation","text":"Add/Remove Webs From Rotation Overview Web Rotation Status Web Service Status Pre-Flight Checks Procedures Disabling/Removing Disabling Web Service for single OR multiple hosts Disabling Web Rotation on a single host, single site Disabling Web Rotation on multiple hosts, single site Enabling/Adding Enabling Web Service for single OR multiple hosts Enabling Web Rotation on a single host, single site Enabling Web Rotation on multiple hosts, single site","title":"add_remove_webs_from_rotation"},{"location":"toc/#add_user","text":"Bastion Provisioning Gather Required Information Approval Choosing a Username Granting Access to Bastion Provisioning a user EXAMPLE: Bastion ONLY EXAMPLE: ACE,ACP production access Confirm that User Can Log In Test Log-in","title":"add_user"},{"location":"toc/#ahrabot","text":"Modify the list of bastion users that can sudo ahrabot","title":"ahrabot"},{"location":"toc/#arbitrary_phpini_settings","text":"Arbitrary php.ini settings Changing php.ini settings Adding or changing arbitrary directives Removing arbitrary directives","title":"arbitrary_phpini_settings"},{"location":"toc/#bastion_access","text":"Bastion Access User Changes Updating a user's SSH key Changing a user's group Adding a user to an additional stage","title":"bastion_access"},{"location":"toc/#bastion_troubleshooting","text":"Troubleshooting When a User Just Can't Log In When a User Gets Locked Out after successful previous logins","title":"bastion_troubleshooting"},{"location":"toc/#bulk_site_move","text":"Bulk Site Move Preparation Procedure Variables Home directory copy commands Important Note Site Move Verification Post Steps","title":"bulk_site_move"},{"location":"toc/#bulk_site_php_edits","text":"Bulk Site PHP Edits Preparation Procedure Verification","title":"bulk_site_php_edits"},{"location":"toc/#capacity-limit","text":"Edge Cluster Capacity limit Capacity Limit Reached for Non-RA Environments Capacity Limit Reached for RA Environments","title":"capacity-limit"},{"location":"toc/#change_balancers_on_existing_environment","text":"Change balancers on existing environment Information ELB Configuration VPC Placement SSL Requirements Tag Validation and Migration Custom VCL Requirements Procedures","title":"change_balancers_on_existing_environment"},{"location":"toc/#change_db_password","text":"Site Database Password Change Changing Credentials","title":"change_db_password"},{"location":"toc/#clamav","text":"ClamAV Daemon Enabling Tunables Disabling","title":"clamav"},{"location":"toc/#code_checkout_failures","text":"Code Checkout Failures Incorrect VCS path Clean checkout","title":"code_checkout_failures"},{"location":"toc/#configuring_hsd_for_sites","text":"HSD (Higher Site Density) To check if hsd is enabled for particular site To enable hsd To disable hsd","title":"configuring_hsd_for_sites"},{"location":"toc/#core_dumps","text":"Enable Coredumps for Capturing PHP Segfaults Managing Coredumps Enabling Disabling Coredump Analysis Preparing Analysing Interpreting A Sample Backtrace","title":"core_dumps"},{"location":"toc/#create_test_balancer","text":"Create a test balancer Preparation Procedure Operation Extend the duration of a test balancer before its deprovision Verify if a site has test balancers Monitoring Known bugs","title":"create_test_balancer"},{"location":"toc/#custom_tungsten_settings","text":"Custom Tungsten Settings Configure-service Static Configuration Files Replication Filter","title":"custom_tungsten_settings"},{"location":"toc/#dedicated_to_dedicated","text":"Dedicated To Dedicated Hardware Allocation Pre-Assignment Assigning Balancers Post-Assignment","title":"dedicated_to_dedicated"},{"location":"toc/#dedicated_to_shared","text":"Dedicated to Shared Pre-work Assign Balancers Post-Assignment","title":"dedicated_to_shared"},{"location":"toc/#shared_to_dedicated","text":"Shared to Dedicated Hardware Allocation Pre-Assignment Assigning Balancers Post-Assignment","title":"shared_to_dedicated"},{"location":"toc/#shared_to_shared","text":"Shared to Shared Pre-work Assigning Balancers Post-Assignment","title":"shared_to_shared"},{"location":"toc/#dedicated_hypervisor","text":"Set servers to be dedicated instances Preparation Procedure Verification","title":"dedicated_hypervisor"},{"location":"toc/#dedicated_memcache","text":"Dedicated Memcache About Dedicated Memcache What site-setmemcache does Procedure Memcache Service Status","title":"dedicated_memcache"},{"location":"toc/#deploy_certificate","text":"Deploying an SSL / TLS certificate to a balancer cluster Table of Contents Determine balancers and tag Prepare Certificate chain Private key Certificates management Adding a new certificate (Both Edge Cluster and Legacy) Deploy a certificate override (Edge cluster) Deploy a certificate override (Legacy balancer) Remove a certificate override and set to default Acquia certificates (Edge cluster) Remove a certificate override and set to default Acquia certificates (Legacy balancer) Setting a default certificate (This is for entire realm) Verify","title":"deploy_certificate"},{"location":"toc/#deploy_test_vcl","text":"Deploy custom VCL for customer testing","title":"deploy_test_vcl"},{"location":"toc/#deprovision_search_colony","text":"Deprovision a Search Colony Prerequisites Procedure","title":"deprovision_search_colony"},{"location":"toc/#deprovision_search_farm","text":"Deprovision a Search Farm Prerequisites Procedures","title":"deprovision_search_farm"},{"location":"toc/#deprovisioning_ace","text":"Deprovisioning ACE & ACP Preparation Caveats Deprovisioning a specific site stage Deprovisioning a sitegroup Deprovisioning A Note About ACP Suspension Termination Bulk site/environment Termination","title":"deprovisioning_ace"},{"location":"toc/#deprovisioning_mail_server","text":"Deprovisoning a mail server Remove from monitoring and puppet manifest Removing DNS entries for the mail server Terminating server from Rackspace","title":"deprovisioning_mail_server"},{"location":"toc/#diagnostics","text":"* [Certificate Files](./kanban_tickets/diagnostics.md#certificate-files) * [Compare Cert and Key](./kanban_tickets/diagnostics.md#compare-cert-and-key) * [Compare CSR and Key](./kanban_tickets/diagnostics.md#compare-csr-and-key) * [View Certificate Information](./kanban_tickets/diagnostics.md#view-certificate-information) * [Get notBefore/notAfter (Expiration) date](./kanban_tickets/diagnostics.md#get-notbeforenotafter-expiration-date) * [Services over SSL](./kanban_tickets/diagnostics.md#services-over-ssl) * [Verify Certificate Chain](./kanban_tickets/diagnostics.md#verify-certificate-chain) * [Asynchronous Keys](./kanban_tickets/diagnostics.md#asynchronous-keys) * [Get public key from private key](./kanban_tickets/diagnostics.md#get-public-key-from-private-key)","title":"diagnostics"},{"location":"toc/#disable_tls_version","text":"Disable TLS versions Check for Shared balancers Disable TLSv1.0 only Disable TLSv1.1 Disable TLSv1.1 in Edge Clusters","title":"disable_tls_version"},{"location":"toc/#duplicate_certificates","text":"Duplicate Certificates Important Note How to Duplicate a Certificate","title":"duplicate_certificates"},{"location":"toc/#edge_cluster","text":"Edge Cluster Available commands Describe available commands or one specific command Create a new Edge Cluster Delete an Edge Cluster Relaunching bals in an Edge Cluster Note View details of an existing Edge Cluster View a list of Edge Clusters on the current realm Add an environment to an existing Edge Cluster Remove an environment from an existing Edge Cluster Increase an Edge Cluster capacity by doubling its number of servers. Cannot scale more than once Important Apply a tag to an Edge Cluster Remove a tag from an Edge Cluster Migrations Manual migration of a customer from a legacy bal pair to an Edge Cluster Manual migration of a customer from an Edge Cluster to a Legacy Balancers","title":"edge_cluster"},{"location":"toc/#elb_creation","text":"ELB Creation Initialize Variables For Customers For Whom We Have The Cert and Key For Customers For Whom We Do Not Have The Cert and Key","title":"elb_creation"},{"location":"toc/#email_blacklist","text":"Acquia Email Server Blacklist Removal An example of a host being \"listed\" List of mail servers according to realm Investigation A word of caution Resolution","title":"email_blacklist"},{"location":"toc/#enabling_mod_proxy","text":"Enabling Mod-Proxy on a Site Required Information Procedure Documentation Custom proxy.conf file","title":"enabling_mod_proxy"},{"location":"toc/#enabling_xdebug","text":"Enabling xdebug for a Site Required Information Procedure Enabling Xdebug Enabling Xdebug Remote Documentation","title":"enabling_xdebug"},{"location":"toc/#extended_validation_certificates","text":"Extended Validation Certificates","title":"extended_validation_certificates"},{"location":"toc/#fix_livedev","text":"Fixing/Enabling livedev Identify the error Remediation","title":"fix_livedev"},{"location":"toc/#generating_csrs","text":"Generating a Certificate Signing Request (CSR) Subject SSL Plus/EV CSR Generation Procedure Wildcard Plus CSR Generation UCC/EV Multi-Domain CSR Generation Using an existing key for UCC CSR Generation UCC CSR Generation Example","title":"generating_csrs"},{"location":"toc/#gluster-downgrade","text":"Downgrade Gluster Version from 3.4 to 3.0 THIS PROCESS SHOULD BE USED ONLY ON GLUSTER 3.4 SERVERS Initial Variables Info Gathering Provision new FS servers and fix volumes Allocate new FS servers Add brick volumes Configure FS servers for gluster 3.0 Allocate FS cluster Fix backup vol on secondary server to 1gb Fix ebs1 volumes on both servers to 1gb Launch FS Servers Filesystem Data Transfer Create Temporary SSH key rsync from source server to destination server Web servers cutover Take webs out of rotation Re-run rysnc Disable Puppet and cron on webs Stop gluster and Unmount gluster Add webs to New FS cluster Relaunch suspended webs Remount gluster on webs check gluster for site Put webs back into rotation Restart PHP, Run FCW on webs Verification Cleanup","title":"gluster-downgrade"},{"location":"toc/#gluster-upgrade","text":"Upgrade Gluster Version from 3.0 to 3.4 THIS PROCESS SHOULD BE USED ONLY ON GLUSTER 3.0 SERVERS Initial Variables Info Gathering Provision new FS servers and fix volumes Allocate new FS servers Add brick volumes Configure FS servers for gluster 3.4 Allocate FS cluster Fix backup vol on secondary server to 1gb Fix ebs1 volumes on both servers to 1gb Launch FS Servers Filesystem Data Transfer Create Temporary SSH key rsync from source server to destination server Web servers cutover Take webs out of rotation Re-run rysnc Disable Puppet and cron on webs Stop gluster and Unmount gluster Add webs to New FS cluster Relaunch suspended webs Remount gluster on webs check gluster for site Put webs back into rotation Restart PHP, Run FCW on webs Verification Cleanup","title":"gluster-upgrade"},{"location":"toc/#loadtest_balancer","text":"Load Test Balancer Adding a Load Test Balancer Find a Valid Load Test Balancer Add the balancer Check the ELB Removing a Load Test Balancer","title":"loadtest_balancer"},{"location":"toc/#logforward","text":"Log Forwarding Log Forwarding through Ops Portal Manually Enabling Log Forwarding Requirements Enable ACE ACSF Verify ACE ACSF Disable ACE ACSF Restarting Log forwarding for Sumo Logic Follow these steps when logs forwarding breaks down for customer Diagnose log forwarding for Sumo Logic Follow these steps when logs are not being forwarded to Sumo Logic Troubleshooting td-agent and New Log Forwarding issues","title":"logforward"},{"location":"toc/#manage_end_to_end_encryption","text":"Manage End To End Encryption Preparation Preparation: Get sitegroup, site names and servers Enable E2E Encryption Checking the E2E Installation Disable E2E Encryption Rotate E2E Encryption Keys Verifying the e2e configuration","title":"manage_end_to_end_encryption"},{"location":"toc/#masterless_puppet","text":"Masterless Puppet How to tell if a Server is Masterless","title":"masterless_puppet"},{"location":"toc/#move_customer_repo","text":"","title":"move_customer_repo"},{"location":"toc/#move_provisioning_pointer","text":"Moving the Index Provisioning Pointer Information","title":"move_provisioning_pointer"},{"location":"toc/#multi_region_failover_testing","text":"Performing a Multi-Region Failover Test Pre-Flight Set up some Variables Validate and Document that the Site is Healthy Prior to Initiating the Failover Simulate a Region Outage, at this time the TAM should instruct the customer to fail over DNS to their Secondary Region Initiate the Multi-Region Failover to the Secondary Region Begin the Multi-Region Fail-back to the Primary Region Perform Health Checks and Document the Output in the ticket","title":"multi_region_failover_testing"},{"location":"toc/#multi_tier_to_full_tier","text":"Multi-tier to Full-tier Upsize Prep Maintenance Window Site Move Procedure Cleanup","title":"multi_tier_to_full_tier"},{"location":"toc/#multi_tier_to_single_tier","text":"Multi-tier to Single-tier Downsize Traps Important Note Set Variables Gather information Verify Server Settings Add DED SERVERS back to Site/s Check Replication Manage EIPs Move EIP Clean Up End","title":"multi_tier_to_single_tier"},{"location":"toc/#mysql-daily-replication-fix","text":"* [Daily Automated replication fix](./kanban_tickets/mysql-daily-replication-fix.md#daily-automated-replication-fix) * [Manually finding list of servers](./kanban_tickets/mysql-daily-replication-fix.md#manually-finding-list-of-servers) * [Attempting to fix the clusters](./kanban_tickets/mysql-daily-replication-fix.md#attempting-to-fix-the-clusters)","title":"mysql-daily-replication-fix"},{"location":"toc/#mysql_audit","text":"Enabling or Disabling MySQL Auditing Enabling MySQL Auditing Disabling MySQL Auditing","title":"mysql_audit"},{"location":"toc/#orphans","text":"* [Preparation](./kanban_tickets/orphans.md#preparation) * [Procedure](./kanban_tickets/orphans.md#procedure) * [Determine the orphan instance status](./kanban_tickets/orphans.md#determine-the-orphan-instance-status) * [Determine when the server was launched](./kanban_tickets/orphans.md#determine-when-the-server-was-launched) * [Devcloud](./kanban_tickets/orphans.md#devcloud) * [All Other Environments](./kanban_tickets/orphans.md#all-other-environments) * [If the orphan instance report is not showing a server name](./kanban_tickets/orphans.md#if-the-orphan-instance-report-is-not-showing-a-server-name) * [Removing orphans nodes](./kanban_tickets/orphans.md#removing-orphans-nodes)","title":"orphans"},{"location":"toc/#overview","text":"SSL Overview Important Note Customer-facing Documentation on docs.ccquia.com Technical details of how SSL/TLS cert chains work Ordering SSL Certificates Pre-flight Check WHOIS Types of Actions Trial Certs General Information/Process Trial Certificate FAQ","title":"overview"},{"location":"toc/#point_in_time_recovery","text":"MySQL Point in Time Recovery Warning Procedure Restoring With Binlogs From Secondary Instance Restoring With Binlogs From Primary","title":"point_in_time_recovery"},{"location":"toc/#preallocating_eips_for_webs","text":"Preallocating EIPs for webs Procedure","title":"preallocating_eips_for_webs"},{"location":"toc/#provision_ace","text":"Gather Information Provisioning With Juno Manual Provisioning of Customer Hardware Manual Provisioning of Infrastructure Hardware","title":"provision_ace"},{"location":"toc/#provision_ace_customer","text":"Provision customer hardware and sites Allocating Hardware Determine if the VPC exists or needs to be created Setting variables Region and AZs Volume Size VPC FS Cluster variables Single-Tier Multi-Tier Full-Tier Get or allocate the Bals If dedicated If customer plans to use [edge cluster bals](/kanban_tickets/edge_cluster) Get or allocate the Staging server(s) Change mntfs volume size on Gen3 instances Set HIPAA settings if applicable Get the SVN (VCS) server Set opportunity ID to the dedicated hardware Creating sites prod test dev ra Set the smtp return path for prod test and dev Provisioning prod and ra sites with different stage names tagged prod tagged ra Tagging consequences Setup FIPS - FIPS compliant stacks only FIPS server config setting Mysql version server config setting Launching Servers If Launching A DB Server Initially Should Fail NOTE Verification Add production sites to Monitoring","title":"provision_ace_customer"},{"location":"toc/#provision_ace_dedicated_cron","text":"Dedicated Cron For Single Tier Sites","title":"provision_ace_dedicated_cron"},{"location":"toc/#provision_ace_empfree","text":"Provisioning employee free sites Find the hardware available in the requested region Bals available in the requested region Bals in us-east-1 Bals in ap-southeast-1 region SVN SERVER Create SITES Prod site test dev Enable HSD on the SITES","title":"provision_ace_empfree"},{"location":"toc/#provision_ace_infra","text":"Provision shared and infra hardware Shared SVN Shared Edge Clustered Balancers Shared Staging Shared RA servers RA within VPC Ossec servers Mon servers Backup servers","title":"provision_ace_infra"},{"location":"toc/#provision_acp","text":"Manually Provision a DevCloud Site & Server Provision and creation Provision a dedicated SRV server Manual steps for sites creation prod dev staging ra Provisioning prod and ra sites with different stage names tagged prod tagged ra Tagging consequences Add production sites to monitoring","title":"provision_acp"},{"location":"toc/#provision_acsf","text":"Site Factory provisioning Preparation Procedure Creating additional environments Creating an ELB for the site factory Adding a \"Stack\" Adding a \"Load test environment\" Use cases Arguments needed Commands creating a load test environment for a customer","title":"provision_acsf"},{"location":"toc/#provision_bastion","text":"Provisioning","title":"provision_bastion"},{"location":"toc/#provision_log_server","text":"Log Servers Introduction Pre-requisites Provision Log Servers Manage A New Cluster Manage An Existing Cluster Manage Clients","title":"provision_log_server"},{"location":"toc/#provision_multi_region","text":"Multi-Region Provisioning Preparation Provision the Balancers Provision a Multi-Tier-MR Cluster Provision a Full-Tier-MR Cluster Create the site Customize and tune the Cluster Launch the cluster Install Tungsten Setup File Replication Add the site to monitoring Verification","title":"provision_multi_region"},{"location":"toc/#provision_search_colony","text":"Provisioning a Search Colony Allocate and launch load balancers Create the site Configure the site Create the ELB Create the CNAME in AWS Route53 Add the colony to the Governor","title":"provision_search_colony"},{"location":"toc/#provision_search_farm","text":"Provision a Search Farm First time preparation Sizing Deploying an extractor Solr version Allocate and launch servers Determine names Example Create and configure sites Extra: If you are deploying Solr 4","title":"provision_search_farm"},{"location":"toc/#provision_site","text":"Site Provision By Realm Tiers","title":"provision_site"},{"location":"toc/#provisioning_a_fedramp_site_with_acquia_shield","text":"Provision FedRAMP Customer Site with Acquia Cloud Shield Allocating Hardware Create the VPC Setting variables Region and AZs Volume Size VPC FS Cluster variables Single-Tier Multi-Tier Full-Tier Allocate the Bals Allocate the Staging server(s) Change mntfs volume size on Gen3 instances Set HIPAA settings if applicable Get the SVN (VCS) server Set opportunity ID to the dedicated hardware Creating sites prod test dev ra Set the smtp return path for prod test and dev Setup FIPS FIPS server config setting Mysql version server config setting Launching Servers If Launching A DB Server Initially Should Fail NOTE Verification SAML Support Enable the Network Boundary for the VPC Create an ELB Add production sites to Monitoring","title":"provisioning_a_fedramp_site_with_acquia_shield"},{"location":"toc/#provisioning_a_fedramp_site_without_acquia_shield","text":"Provision FedRAMP Customer Site without Acquia Cloud Shield Allocating Hardware Create the VPC Setting variables Region and AZs Volume Size VPC FS Cluster variables Single-Tier Multi-Tier Full-Tier Allocate the Bals Allocate the Staging server(s) Change mntfs volume size on Gen3 instances Set HIPAA settings if applicable Get the SVN (VCS) server Set opportunity ID to the dedicated hardware Creating sites prod test dev ra Set the smtp return path for prod test and dev Setup FIPS FIPS server config setting MySQL version server config setting Launching Servers If Launching A DB Server Initially Should Fail NOTE Verification SAML Support Create an ELB Add production sites to Monitoring","title":"provisioning_a_fedramp_site_without_acquia_shield"},{"location":"toc/#provisioning_mail_server","text":"Provisioning a mail server for Acquia Hosting Platform Cloning an existing mail server DNS Management Configuring the new mail server Testing the new mail server Replacing mail server with new server Adding the mail server to monitoring Adding the mail server in mxtoolbox for blacklist monitoring","title":"provisioning_mail_server"},{"location":"toc/#puppet_master","text":"Generating and updating the root CA cert for puppet master Change directory to ssl path Setup steps Remove old newcert.pem from last time Check config Create/Set file \"index.txt\" Create/Set file \"serial\" Create/Set file \"openssl.cnf\" Create directory \"newcerts\" if it does not exist Generate csr and cert Get CA password Generate csr Generate pem Check newcert.pem looks normal relative to ca.pem Verify the new cert Choose a server to verify At this point, make a backup of the current cert Reload Apache Test that puppet runs on the master and the new CA is cached Test that puppet runs on an arbitrary server Choose a server to test Now we need to move the current ca on all clients in the stage","title":"puppet_master"},{"location":"toc/#regenerate_netrcs","text":"Regenerating netrc Credentials Summary WARNINGS Procedure Ahops Ahsupport","title":"regenerate_netrcs"},{"location":"toc/#releasing_domains","text":"Site Domains Management Usage Checking domains for old site Removing domain from old site Adding domain to new site Real-life Example","title":"releasing_domains"},{"location":"toc/#remove_user","text":"Deprovision User Access Bastion access Ops-Puppet Fields AWS","title":"remove_user"},{"location":"toc/#renewing_certificates","text":"Renewing SSL Certificates Preface Important Note Procedure","title":"renewing_certificates"},{"location":"toc/#renewing_puppet_master_cert","text":"Renewing SSL cert for puppet master Steps to renew puppet master SSL cert","title":"renewing_puppet_master_cert"},{"location":"toc/#resize_volumes_bastion","text":"Modify volumes on bastions manually Preparatory steps Gather volume information and create a backup snapshot Creating and attaching the volume Formatting the file system Copy data: rsync method Maintenance window steps Swap the volumes once the data transfer is complete","title":"resize_volumes_bastion"},{"location":"toc/#restore_snapshot_on_new_hardware","text":"Restore Snapshots on New Hardware (ACE) Restore DB from backup Restore files from backup Unmount the snapshot volumes after restoring everything","title":"restore_snapshot_on_new_hardware"},{"location":"toc/#restore_volumes","text":"Restore Volume Backups Procedure Set the Variables Find the backup to be used for restore Mounting (Not ACSF DB) Mounting ACSF DB Communication Cleanup (Not ACSF DB) Cleanup (ACSF DB) Restore Repo","title":"restore_volumes"},{"location":"toc/#revert_ssl","text":"Restoring an Acquia-Managed SSL Cert How to revert certificates for LEGACY BALANCERS How to revert certificates for EDGE CLUSTERS","title":"revert_ssl"},{"location":"toc/#root_cause_analysis","text":"Root Cause Analysis Process Copy the Template Perform the RCA Request Feedback/Approval","title":"root_cause_analysis"},{"location":"toc/#search_index_migration","text":"Search Index Migration Gathering information Risks and Customer Notification Procedures Same Colony Different Colony, Same Region Different Colony, Different Region Moving the index WITHOUT the data Moving the index WITH the data","title":"search_index_migration"},{"location":"toc/#secondary_db_cluster","text":"Provisioning of single-region secondary database cluster Preparation Procedure Verification","title":"secondary_db_cluster"},{"location":"toc/#self_service_ssl","text":"Self-service SSL (on ELBs) Important Note Enabling Self-Service SSL Location of the CSR, cert, and key Support-Specified Certificate Path Pre-Existing Certificates on Bals Pre-Existing Certificate on ELBs Debugging SSL on ELBs Adding Certs to ELBs Manually or Updating an Existing ELB Cert","title":"self_service_ssl"},{"location":"toc/#single_tier_to_multi_tier","text":"Single-tier to Multi-tier Upsize Traps Set Variables Existing Webs Gather information AMI Types and Constrained AZs Start the Workflow Adding New EIPs Important Note After Workflow: Memcache Account Management Dealsheet","title":"single_tier_to_multi_tier"},{"location":"toc/#single_tier_to_multi_tier_manual","text":"Single-tier to Multi-tier Upsize Traps Set Variables Existing Webs Gather information Create Provision New Webs Cluster New Webs Add Webs to Site/s Verify Server Settings Launch New Webs Post Launch Manage EIPs Check Replication Move EIP Clean Up End Account Management Dealsheet","title":"single_tier_to_multi_tier_manual"},{"location":"toc/#site_audit","text":"Performing a Site Audit Converting to Gen2 Downsizing / Upsizing clusters Bal Layer Cache Layer Web Layer DB Layer FS Layer Customer Renewals Additional Docroots Summary/Recommendations of Audit","title":"site_audit"},{"location":"toc/#site_move","text":"Site Move VPC ODE/CDE instructions Site Factory Preparation Procedure Important Note Syncing Data Prior to Downtime Same Region Variables Home directory copy commands Site Move - Same region Different Regions Variables - Different regions Home directory copy commands multi-region Site Move - Different region Verification Recovery Cleanup","title":"site_move"},{"location":"toc/#sni_ssl","text":"SNI Certificates (deployed to bals) Some SNI concepts (for information purposes - can be skipped) SNI features in fields Uploading new certificate/key pair and activating it for use with SNI Changing active cert/key pair for a site which has multiple cert/key pairs availabile for SNI Making an SNI key/pair 'inactive' for disabling SNI Deleting an SNI key/pair 'inactive' for a site","title":"sni_ssl"},{"location":"toc/#ssl_acm","text":"AWS Certificate Manager Requesting A Certificate Deploying an ACM Certificate","title":"ssl_acm"},{"location":"toc/#staging_single_tier_to_multi_tier_manual","text":"Staging Single Tier to Multi-tier Upsize Traps Set Variables Existing Webs Gather information Create Provision New Webs Cluster New Webs Add Webs to Site/s Verify Server Settings Launch New Webs Post Launch Manage EIPs Move EIP Clean Up End Account Management Dealsheet","title":"staging_single_tier_to_multi_tier_manual"},{"location":"toc/#svn_server_certificates","text":"SVN Server Certificates","title":"svn_server_certificates"},{"location":"toc/#automated","text":"Test VCL Deployment - Automated Review the VCL PR CREATE a VCL test bal from an initial request UPDATE a test VCL on an existing VCL test balancer DESTROY a test VCL balancer","title":"automated"},{"location":"toc/#manual","text":"Test VCL Deployment - MANUAL Review the VCL PR Set Up Some Variables Provision a Test Balancer Set up the Test Balancer Deploy the Test VCL to the Test Balancer","title":"manual"},{"location":"toc/#troubleshooting_bastion","text":"Troubleshooting When a User Just Can't Log In When a User Gets Locked Out after successful previous logins","title":"troubleshooting_bastion"},{"location":"toc/#troubleshooting_yubikey","text":"Troubleshooting Yubikey When a User Just Can't Log In with Yubikey Resources on Confluence Installation steps for Yubikey Download yk_bastion_init tool Command to run after installation When a User Gets Locked Out after Three Attempts When a User Gets Permission denied (publickey) while connecting bastion","title":"troubleshooting_yubikey"},{"location":"toc/#unblocking_email_service","text":"Unblock Email Sending for a Customer Investigation Resolution","title":"unblocking_email_service"},{"location":"toc/#update_colony_certificate","text":"Update Search Colony Certificate Get ELB for Colony Get Certificate Info Deploy cert to ELB","title":"update_colony_certificate"},{"location":"toc/#verify_extractor","text":"Search Extractor Determining Whether a javaephem is an Extractor Test Procedure Remediation","title":"verify_extractor"},{"location":"toc/#vpc_deprovision","text":"Deprovision a VPC Preparation Procedure Verification","title":"vpc_deprovision"},{"location":"toc/#vpc_network_boundaries","text":"VPC Network Boundaries Notes on Shield behavior Provisioning a VPC Network Boundary Preparing to create Registering the Network Boundary Deregistering a VPC Network Boundary Preparing to deregister Deregistering the Network Boundary Inspecting existing Network Boundaries Listing all the Network Boundaries in a realm Viewing the details of a Network Boundary","title":"vpc_network_boundaries"},{"location":"toc/#vpc_provision","text":"Provision a VPC Preparation Procedure FedRAMP Verification","title":"vpc_provision"},{"location":"toc/#vpc_vpn_deprovision","text":"Deprovision a Shield VPN Preparation Procedure Verification","title":"vpc_vpn_deprovision"},{"location":"toc/#vpc_vpn_management","text":"Updating Shield VPNs Add a route Preparation for route addition Procedure for route addition Verification of route addition Remove a route Preparation for route removal Procedure for route removal Verification of route removal","title":"vpc_vpn_management"},{"location":"toc/#vpc_vpn_provision","text":"Provisioning a Shield VPN Preparation Procedure Verification","title":"vpc_vpn_provision"},{"location":"toc/#wildcard_certificates","text":"Wildcard Certificates Important Note Wildcard Management for Customers Combining Wildcard Certificates and UCCs Wildcard Management for Acquia How to handle Duplicates on a Wildcard Certificate Creating a duplicate under an existing Wildcard Certificate A Note On Transmitting \"Secured\" Information","title":"wildcard_certificates"},{"location":"toc/#alerts","text":"alerts.ops.acquia.com Overview of Services Relaunching Preparation Relaunch","title":"alerts"},{"location":"toc/#gordon_deploy","text":"OPS-Gordon Deployment Building ops-gordon Test the Deploy","title":"gordon_deploy"},{"location":"toc/#gordon_prod_issues","text":"OPS-Gordon Production Troubleshooting Alert-Function Timed Out Alert-Function Error Rate","title":"gordon_prod_issues"},{"location":"toc/#oneoffs","text":"General Information About One-Off Servers Access Relaunching One-Offs Preparation Relaunch","title":"oneoffs"},{"location":"toc/#perfmon","text":"perf-mon.ops.acquia.com Overview of Services Relaunching Preparation Relaunch","title":"perfmon"},{"location":"toc/#deploy_secrets_masterless","text":"Deploying secrets with Masterless Puppet Keys","title":"deploy_secrets_masterless"},{"location":"toc/#scp","text":"* [How to use](./ops_reference/scp.md#how-to-use)","title":"scp"},{"location":"toc/#audit_data_backup","text":"Audit Data Backup Log Set filename variable Create Server List Data Backup Logs Clock SCP","title":"audit_data_backup"},{"location":"toc/#audit_iptables_sgroups","text":"Audit IPtables Security Groups Set filename variable Create Server List NGINX IPTABLES Security Groups SCP","title":"audit_iptables_sgroups"},{"location":"toc/#audit_services_protocols_ports","text":"Audit Services Protocols Ports Set filename variable Create Server List NETSTAT Systemctl SCP","title":"audit_services_protocols_ports"},{"location":"toc/#audit_sudoers","text":"Audit Sudoers Set filename variable Create Server List SUDOERS SCP","title":"audit_sudoers"},{"location":"toc/#audit_user_access","text":"User Access Audit Set filename variable Tooling to generate the report: admin-userreport Bastion YubiKey Access List","title":"audit_user_access"},{"location":"toc/#mntfs-volume-reaping","text":"Reaping of Unused /mnt EBS Volumes Step 1: Switch to required stage in Bastion Step 2: Create directory to store interim files used for reaping Step 3: Find volumes that are tagged with ah_terminated Step 4: List the volumes that are tagged with ah_terminated Step 5: Reap the /mnt mounting unsued volumes that are tagged with ah_terminated","title":"mntfs-volume-reaping"},{"location":"toc/#mysql_restarts","text":"MySQL Restart Mass Process Servers with no replication One-off Procedure Servers with replication Preparation Procedure Cleanup","title":"mysql_restarts"},{"location":"toc/#patching","text":"Mass patching Preparation Ensure hosts have enough free inodes on root filesystem Patching search Restart services if OpenSSL was updated Verification","title":"patching"},{"location":"toc/#backup","text":"Reboot Backup Servers Prerequisites Procedure","title":"backup"},{"location":"toc/#balancer","text":"Balancer Mass Reboots / Relaunches General Information Procedure Important Notes Preparation Reboot / Relaunch Balancers Standard Balancers Singleton Balancers Non-Standard Balancers","title":"balancer"},{"location":"toc/#cplane","text":"Control Plane Non-Customer-Impacting Hosts: dns , ossec , stats , log Rebooting or Relaunching DNS ( dns ) Rebooting or Relaunching OSSEC ( ossec ) Rebooting or Relaunching STATS ( stats ) Rebooting or Relaunching LOG ( log ) Rebooting or Relaunching Monitoring Hosts ( mon , monui , sitemon ) Customer-Impacting Hosts: svn Rebooting or Relaunching SVN Hosts ( svn )","title":"cplane"},{"location":"toc/#custom_servers","text":"Custom servers ( custom )","title":"custom_servers"},{"location":"toc/#databases","text":"Database Mass Reboot/Relaunch General Information Procedure Important Notes Preparation Reboot or Relaunch Database Clusters Cleanup Workflow Errors","title":"databases"},{"location":"toc/#fs","text":"Filesystem Server Mass Reboot/Relaunch Preparation Important Note Ensure Gluster Mounts Reboot/Relaunch FS Servers Cleanup Workflow errors","title":"fs"},{"location":"toc/#manual_databases","text":"Databases (dbmaster, ded, fsdb) Summary","title":"manual_databases"},{"location":"toc/#manual_fs","text":"Filesystem Server Mass Reboot/Relaunch - Manual Preparation Ensure Gluster Mounts Reboot/Relaunch FS Servers Cleanup","title":"manual_fs"},{"location":"toc/#manual_webs","text":"Manual Reboot or Relaunch Webs( api , web ) Procedure - Web","title":"manual_webs"},{"location":"toc/#non_ha","text":"Customer Non-HA Servers ( free , srv , staging , api )","title":"non_ha"},{"location":"toc/#task","text":"Task Servers Prerequisites Procedure","title":"task"},{"location":"toc/#tungsten","text":"Multiregion Database Mass Reboot/Relaunch Overview Procedure Important Notes Preparation Reboot Secondary Multiregion Databases Failover to Secondary Multiregion Databases Reboot Primary Multiregion Databases Failover to Primary Multiregion Databases Cleanup","title":"tungsten"},{"location":"toc/#webs","text":"Webs ( web ) Important Note","title":"webs"},{"location":"toc/#workflow_errors","text":"Dealing with Workflow errors Retry Workflow Aborting a workflow Important Note Some Specific Workflow Fixes SSH Disconnect Gluster Failed Workflow Launch Task Times Out Workflow Hit Ruby Threading Bug Workflow Hit Invalid VCS Path","title":"workflow_errors"},{"location":"toc/#provision_new_region","text":"Provision New Region Init Preparation Procedure Import the public key into the new region Create the shared vpc Launch a mon Launch a dns Launch a log cluster Launch a ossec Launch a svn Launch a shared production bal pair and a shared non-production bal pair - ACE only Launch a shared staging server - ACE only","title":"provision_new_region"},{"location":"toc/#reboot_balancers","text":"Reboot Bals Using Workflow Variable setup Reboot bals","title":"reboot_balancers"},{"location":"toc/#reboot_master","text":"Reboot a Master Find the master Rebooting Post Reboot","title":"reboot_master"},{"location":"toc/#reboot_search","text":"Mass Rebooting Search Servers Prequisites Patching Rebooting All Servers Rebooting All Servers By Region Rebooting a Subset of Servers Rebooting the Master Troubleshooting Disabling monitoring failed Squelching of index checks failed Server patching fails Server reboot failed Server fails to register with the Governor Rake rebuild fails Index unsquelch fails Re-enabling monitoring fails Reboot command errors out","title":"reboot_search"},{"location":"toc/#rebooting_relaunching","text":"Mass Rebooting and Relaunching Procedure Overview Table of Contents IMPORTANT NOTES The bulk-reboot Workflow Monitoring Tasks and Workflows Important Note Credentials Scheduling maintenance for AMI type Change OS Upgrades Preparation Rebooting or Relaunching CPLANE ( dns , ossec , stats , log , svn ) Customer Non-HA Servers ( free , srv , staging , api ) Balancers ( bal ) Databases ( ded , fsdb , dbmaster ) Filesystem-only servers ( fs ) Tungsten Multiregion servers ( fsdbmesh , dbmesh ) Webs ( managed , web ) Custom servers ( custom ) Search Servers ( nxephem , javasrv , javaephem ) Dealing with Workflow errors Auditing TODO: Check version of kernel and important packages updated.","title":"rebooting_relaunching"},{"location":"toc/#relaunch","text":"Relaunch Instances Pre-Relaunch Steps Web Class (ded,managed,staging,web) FS Class (ded,fs,fsdb,fsdbmesh,staging) DB Class (ded,fsdb,fsdbmesh,dbmaster) Relaunching Procedures Relaunching Failed Instances Normal Relaunch Task Relaunch Local Relaunch Forced Relaunch Post checks after successful relaunch(Mandatory)","title":"relaunch"},{"location":"toc/#relaunch_backup","text":"Backup Server Relaunch Bugs Backup Credentials Rogue EBS Volumes","title":"relaunch_backup"},{"location":"toc/#relaunch_balancers","text":"Relaunch Bals Using Workflow Variable setup Relaunch bals","title":"relaunch_balancers"},{"location":"toc/#relaunch_master","text":"Relaunch a Master Setting up the variables Prepare for relaunch Relaunch Post relaunch Terminating the old master Rollback relaunch and switch back to previous master","title":"relaunch_master"},{"location":"toc/#relaunch_master_manual","text":"Relaunch a Master (manual process) Find the master Relaunch During Relaunch Post Relaunch","title":"relaunch_master_manual"},{"location":"toc/#relaunch_search","text":"Mass Relaunching Search Servers Relaunching All Servers by Region Relaunching a Subset of Servers Notes","title":"relaunch_search"},{"location":"toc/#site_config_changes","text":"Bulk config settings changes Procedure Verification","title":"site_config_changes"},{"location":"toc/#volume_relaunch_fix","text":"Volume Relaunch Fix Applicable Situations Diagnosing the condition Workaround Cleanup","title":"volume_relaunch_fix"},{"location":"toc/#contribution","text":"Welcome to Contributing to Ops Runbooks for Fields Guidelines Main Topics Contributing Workflow Local Development Setup (Automated) Setup (Manual) Reviewing Shortcutting Linting Labels Approved","title":"contribution"},{"location":"toc/#style","text":"Ops Runbook (Fields) Style Guide Install and Use Rules file The Standard Verbiage Headings Lists Ordered Unordered Code in lists Variables Standard Variables Common Reserved Variables Coding","title":"style"},{"location":"toc/#cpu_wait","text":"Diagnosing CPU Wait problems Tools to Identify CPU Wait SignalFX vmstat ps iostat lsof strace Responses Balancers Webs FS DB","title":"cpu_wait"},{"location":"toc/#db_error_lock_wait_timeout","text":"MySQL lock_wait_timeout errors Background Optional: Verify how many processes are waiting Finding the long-running transaction Finding the PHP process Report to Support","title":"db_error_lock_wait_timeout"},{"location":"toc/#disable_acp_sales","text":"Disable DevCloud Purchases Procedure Alternate Procedure","title":"disable_acp_sales"},{"location":"toc/#dump_restore_all","text":"Dump Restore All Tungsten Hosts Procedure Dump The DB Prepare Bad Hosts For The DR Restore The DB Restore Replication","title":"dump_restore_all"},{"location":"toc/#dump_restore_single","text":"Dump Restore A Single Tungsten Slave Procedure Dump The DB Restore The DB Restore Replication","title":"dump_restore_single"},{"location":"toc/#dump_restore_workflow","text":"MySQL Dump Restore Workflow Preparation Ensure there is no replication lag on either server Make sure there is enough space on the ephemeral volume Verify that replication is set up Starting the workflow Important Note Required parameter --method Optional parameter --path Standard workflow parameters Verify replication Trouble shooting","title":"dump_restore_workflow"},{"location":"toc/#fencing","text":"* [Enable fence](./secondary_response/fencing.md#enable-fence) * [Enable on Single server](./secondary_response/fencing.md#enable-on-single-server) * [Enable on AZ](./secondary_response/fencing.md#enable-on-az) * [Disable fence](./secondary_response/fencing.md#disable-fence) * [Disable on Single server](./secondary_response/fencing.md#disable-on-single-server) * [Disable on AZ](./secondary_response/fencing.md#disable-on-az)","title":"fencing"},{"location":"toc/#fix-1970-timestamps","text":"Fix 1970 timestamps for files THIS IS FOR GLUSTER 3.0 ONLY Gather Information Remediation 1 Remediation 2 Remediation 3","title":"fix-1970-timestamps"},{"location":"toc/#impaired_server_relaunch","text":"Relaunching impaired servers Pre-checks Web Servers FS Servers DB servers Balancers Search servers Diagnosing problems with relaunch and force relaunch","title":"impaired_server_relaunch"},{"location":"toc/#mysql_service_issue_during_volume_resize","text":"Fix MySQL service issue occured during volume resize Important Note Setting up the variables Lock replication to the GOOD_DB_SERVER Attach last known/working DB volume on BAD_DB_SERVER Let's Sync the old data after mounting old DB volume on BAD_DB_SERVER Start MySQL Service Resume the Workflow Check replication Status Initiate Dump Restore Umount the old volume and remove the folder from $BAD_DB_SERVER Detach the volume from $BAD_DB_SERVER","title":"mysql_service_issue_during_volume_resize"},{"location":"toc/#mysql_startup_failures","text":"MySQL Startup Failure Troubleshooting InnoDB File unknown read returned OS error 71 Problem Description for File (unknown) error Fix for File (unknown) error You have to start mysqld with tc-heuristic-recover switch to commit or rollback pending transactions Problem Description for --tc-heuristic-recover error Fix for --tc-heuristic-recover error","title":"mysql_startup_failures"},{"location":"toc/#pt-kill","text":"* [READ THIS FIRST](./secondary_response/pt-kill.md#read-this-first) * [Investigation](./secondary_response/pt-kill.md#investigation) * [Example pt-kill Command](./secondary_response/pt-kill.md#example-pt-kill-command)","title":"pt-kill"},{"location":"toc/#reduce_sf_mysql_disk_usage","text":"Reduce Site Factory MySQL Disk Usage Warning Procedure Variables Prep Begin on Secondary Repeat on Primary","title":"reduce_sf_mysql_disk_usage"},{"location":"toc/#replacing-brick-volumes","text":"* [Initial Variables](./secondary_response/replacing-brick-volumes.md#initial-variables) * [Remove the old (corrupt) brick](./secondary_response/replacing-brick-volumes.md#remove-the-old-corrupt-brick) * [Relaunch the server to setup a new brick](./secondary_response/replacing-brick-volumes.md#relaunch-the-server-to-setup-a-new-brick) * [If all is fine delete the aws volume](./secondary_response/replacing-brick-volumes.md#if-all-is-fine-delete-the-aws-volume)","title":"replacing-brick-volumes"},{"location":"toc/#replacing-bricks","text":"Replacing Gluster Bricks THIS IS FOR GLUSTER 3.4 ONLY Stop Gluster and other services Remove the old (corrupt) brick directory Recover Volume ID Start Gluster Heal the brick Force-mounting the brick Verify success Start Gluster Client & Cron","title":"replacing-bricks"},{"location":"toc/#search_disk_partitions","text":"Search Disk Partitions Alert Initialize Confirm that the indexes directory is filling its partition Remediation Move indexes that should not be deployed Determine if a customer is over their limit Move the largest index Emergency Upsize","title":"search_disk_partitions"},{"location":"toc/#split-brain","text":"* [Init](./secondary_response/split-brain.md#init) * [Resolution](./secondary_response/split-brain.md#resolution) * [Heal and Check](./secondary_response/split-brain.md#heal-and-check) * [Clean up](./secondary_response/split-brain.md#clean-up)","title":"split-brain"},{"location":"toc/#tungsten_administration","text":"General Administration Check Consistency Check Status Dump Restore Missing Peers Properties Files Resetting Tungsten User Privileges Send Heartbeat State Overview Tungsten Slave Resync How To Use It Trim Log Files Binlogs Info Logs Total Wipe/Reinstallation Of Tungsten Verifying Replication With Checksumming","title":"tungsten_administration"},{"location":"toc/#xtrabackup","text":"Xtrabackup Dump Restore Pre Restoring MySQL data from dbmaster-A to dbmaster-B Prepare XtraBackup snapshot Copy snapshot and prepare passive master Restore replication Reset replication to restored passive master Verify replication Clean up","title":"xtrabackup"},{"location":"toc/#az_migration","text":"AZ Migration Preparatory Work Variables (prep) Procedure (prep) Important Note Monitor Snapshot Progress Maintenance Window Procedure for Servers without Volumes (web) Important Note Procedure for Servers with Volumes Confirm ELB AZ Configuration is Correct when migrating Bals Monitor Snapshot Progress","title":"az_migration"},{"location":"toc/#az_migration_manual","text":"Manual AZ Migration Preparatory Work Variables (prep) Procedure (prep) Wait for completion Maintenance Window Procedure for Servers without Volumes (web) Procedure for Servers with Volumes","title":"az_migration_manual"},{"location":"toc/#az_migration_manual_volume_m","text":"AZ Migration (xvdm) Variables Maintenance Window Procedure Post Launch","title":"az_migration_manual_volume_m"},{"location":"toc/#az_migration_manual_volume_mn","text":"AZ Migration (xvdm xvdn) Variables Maintenance Window Procedure Post Launch","title":"az_migration_manual_volume_mn"},{"location":"toc/#az_migration_manual_volume_mno","text":"AZ Migration (xvdm xvdn xvdo) Variables Maintenance Window Procedure Post Launch","title":"az_migration_manual_volume_mno"},{"location":"toc/#az_migration_manual_volume_no","text":"AZ Migration (xvdn xvdo) Variables Maintenance Window Procedure Post Launch","title":"az_migration_manual_volume_no"},{"location":"toc/#fedramp_relaunch","text":"Relaunching into FedRAMP compliance VPC Site Factory site layout Prep Maintenance Validate Maintenance Relaunch Into VPC","title":"fedramp_relaunch"},{"location":"toc/#fips-140-2","text":"FIPS 140-2 compliant instance management Reporting issues References","title":"fips-140-2"},{"location":"toc/#fips_check","text":"Check whether a server is already FIPS compliant Check kernel release Check package pin Check mysql version on DB servers","title":"fips_check"},{"location":"toc/#fips_disable","text":"Disable FIPS Disable FIPS on a server Bulk disable FIPS on servers","title":"fips_disable"},{"location":"toc/#fips_enable","text":"Enable FIPS Enable FIPS on a server Bulk enable FIPS on servers Bulk relaunch servers","title":"fips_enable"},{"location":"toc/#fips_migrate_db","text":"Enable FIPS on DB servers","title":"fips_migrate_db"},{"location":"toc/#fips_mysql_upgrade","text":"Upgrading mysql tier to be FIPS 140-2 compliant Pre-requisites (must be known before you begin) Gathering a list of servers Create lists of database servers for the customer Verify the MySQL Versions before starting Find all active and passive database servers Upgrade database servers to use FIPS compliant mysql version Verification step Suspend, Enable FIPS, Relaunch to New VPC","title":"fips_mysql_upgrade"},{"location":"toc/#fips_provision","text":"FIPS 140-2 compliant server provisioning","title":"fips_provision"},{"location":"toc/#moving_a_fedramp_site_with_acquia_shield","text":"Moving a FedRAMP Site with Acquia Cloud Shield Requirements VPC Site Factory site layout Provisioning New Hardware Preparation Procedure Important Note Syncing Data Prior to Downtime Variables Home directory copy commands Site Move Verification IPv6 Support TLSv1.2 Support Network Boundaries Site Factory post-steps Recovery","title":"moving_a_fedramp_site_with_acquia_shield"},{"location":"toc/#moving_a_fedramp_site_without_acquia_shield","text":"Moving a FedRAMP Site without Acquia Cloud Shield Requirements VPC Site Factory site layout Provisioning New Hardware Preparation Procedure Important Note Syncing Data Prior to Downtime Varriables Migrating EIP of dedicated bals - PLEASE READ THIS CAREFULLY Home directory copy commands Site Move Create an ELB Verification IPv6 Support TLSv1.2 Support Site Factory post-steps Recovery","title":"moving_a_fedramp_site_without_acquia_shield"},{"location":"toc/#relaunch_bastion","text":"Relaunching Rebooting Pre-Flight Check Suspending Launching Post Relaunch Setup Fields Ops-misc Ops-API (Otto) Ahrabot Ahopsbot AHT AWS CLI ops-incidents Restore the crontab Unison Sync Cleanup Notification","title":"relaunch_bastion"},{"location":"toc/#replace_volumes","text":"Replacing a Bad Volume Manually Diagnosing a Bad Volume Repairing the File System Replacing the Volume with a Snapshot","title":"replace_volumes"},{"location":"toc/#resize_volumes","text":"Resize volumes Emergency upsize guidelines (ACE & ACSF only) Gluster Prep Dumps Preparatory steps Create and attach the new volume Copy data: rsync method Important Note Copy data: XFS dump-restore method Important Note No data copy: no_data_migration method Maintenance window steps Volume and service specifics MySQL volumes (xvdm) Backup (xvdn) Gluster (xvdo) Mntfs (xvdb) Livedev-enabled sites Troubleshooting Reset XFS dump-restore Gluster 3.4 ID Volume Cleanup","title":"resize_volumes"},{"location":"toc/#resize_volumes_manual","text":"Resize volumes manually Emergency upsize guidelines (ACE & ACSF only) Gluster Prep Dumps Preparatory steps Create and attach the new volume Format and mount the new volume Copy data: rsync method Copy data: XFS dump-restore method Maintenance window steps Volume and service specifics MySQL volumes (sdm) Backup (sdn) Gluster (sdo) Troubleshooting Reset XFS dump-restore Gluster 3.4 ID Deleting a volume Volume Cleanup","title":"resize_volumes_manual"},{"location":"toc/#toc","text":"Table of Contents * ah-config-iptables_locked * ah-critical * ah-resource-mon * alerts_pagerduty_outage * backup_check * blocked_fcw_run * check_auditd * check_clamav * check_filesystem_fencing * check_gluster_transport_endpoint_error * check_perfmon_data_is_recent * check_possible_hung_tasks * check_ssl_certificate * critical_service_port_revoked * db_binlogs * dead_backup_tasks * debugging_php * disk_partitions * disk_writable * elb_issues * fix-missing-glusterd_vol-file * gluster-not-split-brain * gluster-troubleshooting * fsdbmesh * master * index_old * index_ping_not_initiated * instance_management_acp * maintenance_past_due * malicious_high_traffic_hosts * mon_server_host_count * monitoring_audit * multiregion_rsync_verification * mysql_available * mysql_debian_sys_maint * mysql_failover * mysql_replication_lag * nagios_configuration * nginx_config_test * nxephem_nginx * out_of_memory_errors * perf_url_mon * pupgov * puppet_agent_disabled * puppet_agent_run_status * search_index_mon * services_check * site_capacity * tomcat_memory_check * tomcat_running * triage_unresponsive_servers * tungsten_latency * tungsten_online * tungsten_troubleshooting * unmonitored_sites_check * varnish_http * vpn_connection * vpn_mon * web_audit * index_new * 181_release * acquiamail * acsf_deprovision * add_custom_proxy_conf * add_remove_site_mon * add_remove_webs_from_rotation * add_user * ahrabot * arbitrary_phpini_settings * bastion_access * bastion_troubleshooting * bulk_site_move * bulk_site_php_edits * capacity-limit * change_balancers_on_existing_environment * change_db_password * clamav * code_checkout_failures * configuring_hsd_for_sites * core_dumps * create_test_balancer * custom_tungsten_settings * dedicated_to_dedicated * dedicated_to_shared * shared_to_dedicated * shared_to_shared * dedicated_hypervisor * dedicated_memcache * deploy_certificate * deploy_test_vcl * deprovision_search_colony * deprovision_search_farm * deprovisioning_ace * deprovisioning_mail_server * diagnostics * disable_tls_version * duplicate_certificates * edge_cluster * elb_creation * email_blacklist * enabling_mod_proxy * enabling_xdebug * extended_validation_certificates * fix_livedev * generating_csrs * gluster-downgrade * gluster-upgrade * index_old * loadtest_balancer * logforward * manage_end_to_end_encryption * masterless_puppet * move_customer_repo * move_provisioning_pointer * multi_region_failover_testing * multi_tier_to_full_tier * multi_tier_to_single_tier * mysql-daily-replication-fix * mysql_audit * orphans * overview * point_in_time_recovery * preallocating_eips_for_webs * provision_ace * provision_ace_customer * provision_ace_dedicated_cron * provision_ace_dedicated_memcache * provision_ace_empfree * provision_ace_infra * provision_acp * provision_acsf * provision_bastion * provision_log_server * provision_multi_region * provision_search_colony * provision_search_farm * provision_site * provisioning_a_fedramp_site_with_acquia_shield * provisioning_a_fedramp_site_without_acquia_shield * provisioning_mail_server * puppet_master * regenerate_netrcs * releasing_domains * remove_user * renewing_certificates * renewing_puppet_master_cert * resize_volumes_bastion * restore_snapshot_on_new_hardware * restore_volumes * revert_ssl * root_cause_analysis * search_index_migration * secondary_db_cluster * self_service_ssl * single_tier_to_multi_tier * single_tier_to_multi_tier_manual * site_audit * site_move * sni_ssl * ssl_acm * staging_single_tier_to_multi_tier_manual * svn_server_certificates * automated * manual * troubleshooting_bastion * troubleshooting_yubikey * unblocking_email_service * update_colony_certificate * verify_extractor * vpc_deprovision * vpc_network_boundaries * vpc_provision * vpc_vpn_deprovision * vpc_vpn_management * vpc_vpn_provision * wildcard_certificates * alerts * gordon_deploy * gordon_prod_issues * index_old * oneoffs * perfmon * deploy_secrets_masterless * index_old * scp * audit_data_backup * audit_iptables_sgroups * audit_services_protocols_ports * audit_sudoers * audit_user_access * index_old * mntfs-volume-reaping * mysql_restarts * patching * backup * balancer * cplane * custom_servers * databases * fs * manual_databases * manual_fs * manual_webs * non_ha * task * tungsten * webs * workflow_errors * provision_new_region * reboot_balancers * reboot_master * reboot_old * reboot_search * rebooting_relaunching * relaunch * relaunch_backup * relaunch_balancers * relaunch_master * relaunch_master_manual * relaunch_search * site_config_changes * volume_relaunch_fix * contribution * index_old * style * cpu_wait * db_error_lock_wait_timeout * disable_acp_sales * dump_restore_all * dump_restore_single * dump_restore_workflow * fencing * fix-1970-timestamps * impaired_server_relaunch * index_old * mysql_service_issue_during_volume_resize * mysql_startup_failures * pt-kill * reduce_sf_mysql_disk_usage * replacing-brick-volumes * replacing-bricks * search_disk_partitions * split-brain * tungsten_administration * xtrabackup * az_migration * az_migration_manual * az_migration_manual_volume_m * az_migration_manual_volume_mn * az_migration_manual_volume_mno * az_migration_manual_volume_no * fedramp_relaunch * fips-140-2 * fips_check * fips_disable * fips_enable * fips_migrate_db * fips_mysql_upgrade * fips_provision * index_old * moving_a_fedramp_site_with_acquia_shield * moving_a_fedramp_site_without_acquia_shield * relaunch_bastion * replace_volumes * resize_volumes * resize_volumes_manual * services_overview * ssh_between_servers * strace","title":"toc"},{"location":"toc/#services_overview","text":"Overview of Common Services A Note About Log Analysis System Logs Primary Services Varnish Nginx Apache PHP-FPM Memcached MySQL Gluster Tungsten Secondary Services ah-socketd collectd cron exim4 Nagios ossec pt-heartbeat","title":"services_overview"},{"location":"toc/#ssh_between_servers","text":"SSHing Between Servers sv-rsyncfile Key Forwarding Temporary SSH Key","title":"ssh_between_servers"},{"location":"toc/#strace","text":"Using strace Basic strace Usage Interpreting strace Output","title":"strace"},{"location":"escalation_procedures/","text":"","title":"Index"},{"location":"incident_response/","text":"Alerts by Check Name ah-config-iptables_locked ah-config-iptables locked Resolution ah-critical Master AH_CRITICAL Duplicate Volumes Finding The Duplicate Volumes Removing A Duplicate Volume ah-resource-mon * [Resolution](./ah-resource-mon.md#resolution) alerts_pagerduty_outage How to Survive During a Pagerduty Outage Ops Tickets Tools to find issues Ops-emergencyperfmon Alerts Procmail Log backup_check Backup Check General Information About Backup Tasks and Runs Tasks Runs General troubleshooting local-fs-cluster fs-cluster db-cluster Next Steps Further Debugging Overdue Backups Reinstalling the ah-task-server gem to fix broken symlinks after a Fields release Hung TCP connections Duplicate volume ids blocked_fcw_run Blocked Fields Config Web Run alert Response check_auditd Check Auditd Agent Response Investigate Root Cause Restore Auditd Service check_clamav As a first step Check if the server has clamd configured Check the status of the service Health check Troubleshooting check_filesystem_fencing Check Filesystem Fencing alert Response check_gluster_transport_endpoint_error Check Gluster Transport endpoint error Response Site-wide gluster remount Server-specific gluster remount Advanced Troubleshooting Gluster 3.0 Gluster 3.4 Last Resort: Build a new FS Cluster check_perfmon_data_is_recent Check perfmon data is recent Automation Manual Resolution Verify sites start getting checked check_possible_hung_tasks Check Possible Hung Tasks Response Anything that DOES NOT involve a data transfer Database and file copies (copy, migrate, etc.) Check for rebooted/relaunched remote servers Check for Data Transfer Check for Disk Full Kill the Task check_ssl_certificate Check SSL Certificate Resolution critical_service_port_revoked Critical Service Port Revoked What to Do Communicate with the Incident Response team Log into the AWS Console Fix the Issue db_binlogs MySQL binary log troubleshooting Out of disk space Verify the problem Verify the cause Multi-region database servers Non-clustered database servers Clustered database servers Binary log corruption Binary log missing dead_backup_tasks Dead Backup Tasks Resolution debugging_php Debugging PHP Tools strace PHP-FPM Logs disk_partitions Disk Partitions Alert Resolution multiregion (passive) servers bastion servers RA Servers CDE (CD Environment) servers SVN servers for /vol/ebs1 for /vol/backup-ebs Ephemeral volumes Handle deleted files consuming space Gluster Volumes Gluster - Common Gluster - ACE Backup Volumes Common Database Volumes Warnings Operations is not allowed to purge data without customer consent (except for binlogs) Operations is not allowed to move tables or databases to alternate storage (ephemeral, gluster, ramdisk, etc.) Database - Common Database - ACE Database - ACP Misc Volumes Mon - /opt/nagios-tmpfs Master - /etc/puppet/versions Stats - /vol/ebs1/ or /vol/backup-ebs/ perf-mon.acquia.com - root fs (/) disk_writable Disk Writable Alert Determine if inode usage has been exceeeded Determine whether its an impaired volume Response Inode Usage exceeded Impaired Volume CDE (CD Environment) servers elb_issues ELB Issues Resolution Debugging ELB issues Adding and Removing ELBs from monitoring Removing an ELB from monitoring Adding an ELB back to monitoring fix-missing-glusterd_vol-file Fix missing glusterd.vol file THIS IS FOR GLUSTER 3.4 ONLY gluster-not-split-brain Not Split-brain (Gluster 3.4) Configuration Daemon (glusterd) Doesn't Start Remediation Network Issues Fields Data Issues Data Issues on Gluster 3.4 Run the diagnostic option Based on the diagnose output choose the option to repair the cluster gluster-troubleshooting * [FS Node](./gluster-troubleshooting.md#fs-node) * [Client Node](./gluster-troubleshooting.md#client-node) fsdbmesh * [Action](./host_alert/fsdbmesh.md#action) * [Clean up](./host_alert/fsdbmesh.md#clean-up) master Master Down Triage Find the master Reboot / Relaunch Nagstamon index_ping_not_initiated Sum Invocations LessThanThreshold 2.0 for FunctionName InitiateIndexCheck instance_management_acp ACP Instance Management Manual Volume Resizes maintenance_past_due Maintenance Past Due Resolution malicious_high_traffic_hosts Blocking Crawlers and Malicious High-Traffic Hosts Synopsis Identification (Know Thy Enemy) SumoLogic Logstream, GoAccess , Site-traffic and site-trafficbyuseragent Detection (Inspect Thy Enemy) Verification (Question Thy Enemy) Mitigation (Slay Thy Enemy) A word on blocking methodologies Criteria for when to block via VCL or iptables Blocking an IP or IP Range Blocking via .htaccess (Not Preferred anymore) Blocking via Varnish (Not Recommended) Block Connections using iptables (Recommended for OPS) Blocking an Useragent Block Connections using iptables Verify Post-Block (Gloat Upon Thy Enemy's Grave) mon_server_host_count Mon Server Host Count Check if the server has host monitored more than 250 Resolution Scenario 1: You get the output showing all the other mon servers from the region and their corresponding monitored Hosts Count Example output Scenario 2: There are no other mon servers in the region and you need to provision a new mon server monitoring_audit Monitoring Audit Resolution multiregion_rsync_verification MultiRegion Rsync Verification Resolution mysql_available MySQL Available Response No Seconds Behind Master MySQL Daemon Crash / Not Running Replication Is NULL Missing ops-mon User mysql_debian_sys_maint MySQL Debian Sys Maint alert Response Caveat mysql_failover MySQL Failover Response Clean Up Background mysql_replication_lag MySQL replication lag Diagnosing a replication problem Resolution for replication conflicts / split-brain Resolution for manually stopped replication Resolution for replication is running but falling behind Resolution for other replication problems Missing first binary log Corruption in the binary log Active server stopped writing binary logs Replication is still broken nagios_configuration Nagios Configuration Response nginx_config_test NGINX Configtest Resolution TLS/SSL Error Server_names_hash error Verification nxephem_nginx Nxephem Nginx Configtest Procedure out_of_memory_errors Out Of Memory (OOM) errors Summary Background Investigation Remediation - Customer Hardware Remediation - Infrastructure Post-Remediation perf_url_mon Perf URL Mon Alert Response Notification to Support Initial Triage Escalation Common Scenarios Customer-Inflicted AWS-Inflicted Acquia-Inflicted Example Scenarios General Load Web Tier High Load DB Layer High Load FS Tier High Load External Calls pupgov Pupgov Alerts Runbook Table of Contents Custom Index Ping Check Index Alert Handling Master 404 and Slave 404 Master 200 and Slave 404 Master 404 and Slave 200 Master 200 and Slave 5xx Master 5xx and Slave 200 499 Error Tomcat Out of Memory Response Manually rotating the log file ELB Metrics Additional troubleshooting Upsizing Escalations puppet_agent_disabled Puppet Agent Disabled alert Response Enabling/Disabling Masterless Puppet puppet_agent_run_status Puppet Agent Run Status Response search_index_mon Search Core Index Alerts Disabling the Core Index Checks Meta-monitoring Information Gathering Alert Handling Index not deployed (slave_code=404 & master_code=404) Index missing on slave (slave_code=404 & master_code=200) Index missing on master (slave_code=200 & master_code=404) Slave is erroring (slave_code=5xx & master_code=200) Master is erroring (slave_code=200 & master_code=5xx) Index failing on rake rebuild with boot- core already exists 499 status code Impaired Search Instances Other Troubleshooting and Resolution Procedures services_check Services Check Resolution Triage the Service Restart the Service Verify Services and Follow-up site_capacity Site Capacity alert Cause Thresholds CRITICAL: Server is full SVN Servers Staging Servers Important Note Shared Non-RA Staging Servers (Automated) Shared Non-RA Staging Servers (Manual) Shared RA Staging Servers (Automated) Shared RA Staging Servers (Manual) BAL Servers Provision Shared Balancers UNKNOWN: Could not find number of sites tomcat_memory_check Tomcat Memory Check alert Response Manually rotating the log file tomcat_running Tomcat Running alert Response triage_unresponsive_servers Triage unresponsive ACE, ACP, ACSF, Network, trex and [WMG/UMG]Gardens servers NOTE: for auditing purposes it is absolutely crucial to document all resolution steps carried out in a JIRA ticket Initial steps Determine if the server is accessible Determine the instance status from AWS Rebooting Clean up tungsten_latency Tungsten Latency Resolution tungsten_online Tungsten Online tungsten_troubleshooting Troubleshooting Tungsten Common Problems Offline Tunnel configuration files missing Error: unexpected seqno Split brain Seqno -1 & State Is ONLINE Seqno -1 & State Is OFFLINE:ERROR unmonitored_sites_check Unmonitored Site Check alert Resolution varnish_http Check Varnish HTTP Resolution vpn_connection VPN Connection Resolution vpn_mon Name of Alert Resolution web_audit Web Audit Resolution Review status Search recent JIRA and Chat activity Enabling/Disabling the host Impaired Server Relaunch Relaunching impaired servers Pre-checks Web Servers FS Servers DB servers Balancers Search servers Node servers Nodebal Servers Diagnosing problems with relaunch and force relaunch Node.js server memory nearing threashold Diagnostics Remediation Node.js Degraded stack Node.js Degraded stack alert","title":"Alerts by Check Name"},{"location":"incident_response/#alerts-by-check-name","text":"","title":"Alerts by Check Name"},{"location":"incident_response/#ah-config-iptables_locked","text":"ah-config-iptables locked Resolution","title":"ah-config-iptables_locked"},{"location":"incident_response/#ah-critical","text":"Master AH_CRITICAL Duplicate Volumes Finding The Duplicate Volumes Removing A Duplicate Volume","title":"ah-critical"},{"location":"incident_response/#ah-resource-mon","text":"* [Resolution](./ah-resource-mon.md#resolution)","title":"ah-resource-mon"},{"location":"incident_response/#alerts_pagerduty_outage","text":"How to Survive During a Pagerduty Outage Ops Tickets Tools to find issues Ops-emergencyperfmon Alerts Procmail Log","title":"alerts_pagerduty_outage"},{"location":"incident_response/#backup_check","text":"Backup Check General Information About Backup Tasks and Runs Tasks Runs General troubleshooting local-fs-cluster fs-cluster db-cluster Next Steps Further Debugging Overdue Backups Reinstalling the ah-task-server gem to fix broken symlinks after a Fields release Hung TCP connections Duplicate volume ids","title":"backup_check"},{"location":"incident_response/#blocked_fcw_run","text":"Blocked Fields Config Web Run alert Response","title":"blocked_fcw_run"},{"location":"incident_response/#check_auditd","text":"Check Auditd Agent Response Investigate Root Cause Restore Auditd Service","title":"check_auditd"},{"location":"incident_response/#check_clamav","text":"As a first step Check if the server has clamd configured Check the status of the service Health check Troubleshooting","title":"check_clamav"},{"location":"incident_response/#check_filesystem_fencing","text":"Check Filesystem Fencing alert Response","title":"check_filesystem_fencing"},{"location":"incident_response/#check_gluster_transport_endpoint_error","text":"Check Gluster Transport endpoint error Response Site-wide gluster remount Server-specific gluster remount Advanced Troubleshooting Gluster 3.0 Gluster 3.4 Last Resort: Build a new FS Cluster","title":"check_gluster_transport_endpoint_error"},{"location":"incident_response/#check_perfmon_data_is_recent","text":"Check perfmon data is recent Automation Manual Resolution Verify sites start getting checked","title":"check_perfmon_data_is_recent"},{"location":"incident_response/#check_possible_hung_tasks","text":"Check Possible Hung Tasks Response Anything that DOES NOT involve a data transfer Database and file copies (copy, migrate, etc.) Check for rebooted/relaunched remote servers Check for Data Transfer Check for Disk Full Kill the Task","title":"check_possible_hung_tasks"},{"location":"incident_response/#check_ssl_certificate","text":"Check SSL Certificate Resolution","title":"check_ssl_certificate"},{"location":"incident_response/#critical_service_port_revoked","text":"Critical Service Port Revoked What to Do Communicate with the Incident Response team Log into the AWS Console Fix the Issue","title":"critical_service_port_revoked"},{"location":"incident_response/#db_binlogs","text":"MySQL binary log troubleshooting Out of disk space Verify the problem Verify the cause Multi-region database servers Non-clustered database servers Clustered database servers Binary log corruption Binary log missing","title":"db_binlogs"},{"location":"incident_response/#dead_backup_tasks","text":"Dead Backup Tasks Resolution","title":"dead_backup_tasks"},{"location":"incident_response/#debugging_php","text":"Debugging PHP Tools strace PHP-FPM Logs","title":"debugging_php"},{"location":"incident_response/#disk_partitions","text":"Disk Partitions Alert Resolution multiregion (passive) servers bastion servers RA Servers CDE (CD Environment) servers SVN servers for /vol/ebs1 for /vol/backup-ebs Ephemeral volumes Handle deleted files consuming space Gluster Volumes Gluster - Common Gluster - ACE Backup Volumes Common Database Volumes Warnings Operations is not allowed to purge data without customer consent (except for binlogs) Operations is not allowed to move tables or databases to alternate storage (ephemeral, gluster, ramdisk, etc.) Database - Common Database - ACE Database - ACP Misc Volumes Mon - /opt/nagios-tmpfs Master - /etc/puppet/versions Stats - /vol/ebs1/ or /vol/backup-ebs/ perf-mon.acquia.com - root fs (/)","title":"disk_partitions"},{"location":"incident_response/#disk_writable","text":"Disk Writable Alert Determine if inode usage has been exceeeded Determine whether its an impaired volume Response Inode Usage exceeded Impaired Volume CDE (CD Environment) servers","title":"disk_writable"},{"location":"incident_response/#elb_issues","text":"ELB Issues Resolution Debugging ELB issues Adding and Removing ELBs from monitoring Removing an ELB from monitoring Adding an ELB back to monitoring","title":"elb_issues"},{"location":"incident_response/#fix-missing-glusterd_vol-file","text":"Fix missing glusterd.vol file THIS IS FOR GLUSTER 3.4 ONLY","title":"fix-missing-glusterd_vol-file"},{"location":"incident_response/#gluster-not-split-brain","text":"Not Split-brain (Gluster 3.4) Configuration Daemon (glusterd) Doesn't Start Remediation Network Issues Fields Data Issues Data Issues on Gluster 3.4 Run the diagnostic option Based on the diagnose output choose the option to repair the cluster","title":"gluster-not-split-brain"},{"location":"incident_response/#gluster-troubleshooting","text":"* [FS Node](./gluster-troubleshooting.md#fs-node) * [Client Node](./gluster-troubleshooting.md#client-node)","title":"gluster-troubleshooting"},{"location":"incident_response/#fsdbmesh","text":"* [Action](./host_alert/fsdbmesh.md#action) * [Clean up](./host_alert/fsdbmesh.md#clean-up)","title":"fsdbmesh"},{"location":"incident_response/#master","text":"Master Down Triage Find the master Reboot / Relaunch Nagstamon","title":"master"},{"location":"incident_response/#index_ping_not_initiated","text":"Sum Invocations LessThanThreshold 2.0 for FunctionName InitiateIndexCheck","title":"index_ping_not_initiated"},{"location":"incident_response/#instance_management_acp","text":"ACP Instance Management Manual Volume Resizes","title":"instance_management_acp"},{"location":"incident_response/#maintenance_past_due","text":"Maintenance Past Due Resolution","title":"maintenance_past_due"},{"location":"incident_response/#malicious_high_traffic_hosts","text":"Blocking Crawlers and Malicious High-Traffic Hosts Synopsis Identification (Know Thy Enemy) SumoLogic Logstream, GoAccess , Site-traffic and site-trafficbyuseragent Detection (Inspect Thy Enemy) Verification (Question Thy Enemy) Mitigation (Slay Thy Enemy) A word on blocking methodologies Criteria for when to block via VCL or iptables Blocking an IP or IP Range Blocking via .htaccess (Not Preferred anymore) Blocking via Varnish (Not Recommended) Block Connections using iptables (Recommended for OPS) Blocking an Useragent Block Connections using iptables Verify Post-Block (Gloat Upon Thy Enemy's Grave)","title":"malicious_high_traffic_hosts"},{"location":"incident_response/#mon_server_host_count","text":"Mon Server Host Count Check if the server has host monitored more than 250 Resolution Scenario 1: You get the output showing all the other mon servers from the region and their corresponding monitored Hosts Count Example output Scenario 2: There are no other mon servers in the region and you need to provision a new mon server","title":"mon_server_host_count"},{"location":"incident_response/#monitoring_audit","text":"Monitoring Audit Resolution","title":"monitoring_audit"},{"location":"incident_response/#multiregion_rsync_verification","text":"MultiRegion Rsync Verification Resolution","title":"multiregion_rsync_verification"},{"location":"incident_response/#mysql_available","text":"MySQL Available Response No Seconds Behind Master MySQL Daemon Crash / Not Running Replication Is NULL Missing ops-mon User","title":"mysql_available"},{"location":"incident_response/#mysql_debian_sys_maint","text":"MySQL Debian Sys Maint alert Response Caveat","title":"mysql_debian_sys_maint"},{"location":"incident_response/#mysql_failover","text":"MySQL Failover Response Clean Up Background","title":"mysql_failover"},{"location":"incident_response/#mysql_replication_lag","text":"MySQL replication lag Diagnosing a replication problem Resolution for replication conflicts / split-brain Resolution for manually stopped replication Resolution for replication is running but falling behind Resolution for other replication problems Missing first binary log Corruption in the binary log Active server stopped writing binary logs Replication is still broken","title":"mysql_replication_lag"},{"location":"incident_response/#nagios_configuration","text":"Nagios Configuration Response","title":"nagios_configuration"},{"location":"incident_response/#nginx_config_test","text":"NGINX Configtest Resolution TLS/SSL Error Server_names_hash error Verification","title":"nginx_config_test"},{"location":"incident_response/#nxephem_nginx","text":"Nxephem Nginx Configtest Procedure","title":"nxephem_nginx"},{"location":"incident_response/#out_of_memory_errors","text":"Out Of Memory (OOM) errors Summary Background Investigation Remediation - Customer Hardware Remediation - Infrastructure Post-Remediation","title":"out_of_memory_errors"},{"location":"incident_response/#perf_url_mon","text":"Perf URL Mon Alert Response Notification to Support Initial Triage Escalation Common Scenarios Customer-Inflicted AWS-Inflicted Acquia-Inflicted Example Scenarios General Load Web Tier High Load DB Layer High Load FS Tier High Load External Calls","title":"perf_url_mon"},{"location":"incident_response/#pupgov","text":"Pupgov Alerts Runbook Table of Contents Custom Index Ping Check Index Alert Handling Master 404 and Slave 404 Master 200 and Slave 404 Master 404 and Slave 200 Master 200 and Slave 5xx Master 5xx and Slave 200 499 Error Tomcat Out of Memory Response Manually rotating the log file ELB Metrics Additional troubleshooting Upsizing Escalations","title":"pupgov"},{"location":"incident_response/#puppet_agent_disabled","text":"Puppet Agent Disabled alert Response Enabling/Disabling Masterless Puppet","title":"puppet_agent_disabled"},{"location":"incident_response/#puppet_agent_run_status","text":"Puppet Agent Run Status Response","title":"puppet_agent_run_status"},{"location":"incident_response/#search_index_mon","text":"Search Core Index Alerts Disabling the Core Index Checks Meta-monitoring Information Gathering Alert Handling Index not deployed (slave_code=404 & master_code=404) Index missing on slave (slave_code=404 & master_code=200) Index missing on master (slave_code=200 & master_code=404) Slave is erroring (slave_code=5xx & master_code=200) Master is erroring (slave_code=200 & master_code=5xx) Index failing on rake rebuild with boot- core already exists 499 status code Impaired Search Instances Other Troubleshooting and Resolution Procedures","title":"search_index_mon"},{"location":"incident_response/#services_check","text":"Services Check Resolution Triage the Service Restart the Service Verify Services and Follow-up","title":"services_check"},{"location":"incident_response/#site_capacity","text":"Site Capacity alert Cause Thresholds CRITICAL: Server is full SVN Servers Staging Servers Important Note Shared Non-RA Staging Servers (Automated) Shared Non-RA Staging Servers (Manual) Shared RA Staging Servers (Automated) Shared RA Staging Servers (Manual) BAL Servers Provision Shared Balancers UNKNOWN: Could not find number of sites","title":"site_capacity"},{"location":"incident_response/#tomcat_memory_check","text":"Tomcat Memory Check alert Response Manually rotating the log file","title":"tomcat_memory_check"},{"location":"incident_response/#tomcat_running","text":"Tomcat Running alert Response","title":"tomcat_running"},{"location":"incident_response/#triage_unresponsive_servers","text":"Triage unresponsive ACE, ACP, ACSF, Network, trex and [WMG/UMG]Gardens servers NOTE: for auditing purposes it is absolutely crucial to document all resolution steps carried out in a JIRA ticket Initial steps Determine if the server is accessible Determine the instance status from AWS Rebooting Clean up","title":"triage_unresponsive_servers"},{"location":"incident_response/#tungsten_latency","text":"Tungsten Latency Resolution","title":"tungsten_latency"},{"location":"incident_response/#tungsten_online","text":"Tungsten Online","title":"tungsten_online"},{"location":"incident_response/#tungsten_troubleshooting","text":"Troubleshooting Tungsten Common Problems Offline Tunnel configuration files missing Error: unexpected seqno Split brain Seqno -1 & State Is ONLINE Seqno -1 & State Is OFFLINE:ERROR","title":"tungsten_troubleshooting"},{"location":"incident_response/#unmonitored_sites_check","text":"Unmonitored Site Check alert Resolution","title":"unmonitored_sites_check"},{"location":"incident_response/#varnish_http","text":"Check Varnish HTTP Resolution","title":"varnish_http"},{"location":"incident_response/#vpn_connection","text":"VPN Connection Resolution","title":"vpn_connection"},{"location":"incident_response/#vpn_mon","text":"Name of Alert Resolution","title":"vpn_mon"},{"location":"incident_response/#web_audit","text":"Web Audit Resolution Review status Search recent JIRA and Chat activity Enabling/Disabling the host","title":"web_audit"},{"location":"incident_response/#impaired-server-relaunch","text":"Relaunching impaired servers Pre-checks Web Servers FS Servers DB servers Balancers Search servers Node servers Nodebal Servers Diagnosing problems with relaunch and force relaunch","title":"Impaired Server Relaunch"},{"location":"incident_response/#nodejs-server-memory-nearing-threashold","text":"Diagnostics Remediation","title":"Node.js server memory nearing threashold"},{"location":"incident_response/#nodejs-degraded-stack","text":"Node.js Degraded stack alert","title":"Node.js Degraded stack"},{"location":"incident_response/Node.js-server-memory-nearing-threashold/","text":"Node.js server memory nearing threashold This alert was created as a proactive step to notify support team when node.js runtime memory utilization nears saturation. Node process need to be restarted to prevent node.js runtime from saturating and stop accepting new requests due to high memory utilization and maxing open file descriptor count. It was identified in CL-53102 . This alert is mainly for one customer due to the fact that they are not able to close the connections. Customer is working on a fix for it but it may take a while. Diagnostics Check memory utilization of the stack being alerted for in signalfx . Change the stack ID with the one you receive in the alert. Currently, the alert will trigger when memory usage goes beyond 3.3 GB out of 4 GB memory system available. Remediation In the alert, you will see Host value see this ticket for example. Login to that server and run the following commands: ps -ef|grep '/next start' sudo systemctl list-units|grep node-prod It will list out the Node.js services for the customer - restart all the services displayed using the following command: sudo systemctl restart #NODE_SERVICE.service Here is the example: [cloudservicesprod|hosting-prod:prod] ~/fields/1.145$ fssh node-38784 FIPS mode initialized vikaskrishnia@node-38784:~$ #Identify running node runtime processes vikaskrishnia@node-38784:~$ ps -ef|grep '/next start' vikaskr+ 6686 6602 0 07:52 pts/4 00:00:00 grep /next start vfdotco+ 16893 16892 2 Jun15 ? 00:28:34 node /mnt/www/artifacts/vfdotcomnode.prod/73303/node_modules/.bin/next start -p 12212 vfdotco+ 17924 17923 2 Jun15 ? 00:29:07 node /mnt/www/artifacts/vfdotcomnode.prod/73303/node_modules/.bin/next start -p 12213 vikaskrishnia@node-38784:~$ #List and Restart node service vikaskrishnia@node-38784:~$ sudo systemctl list-units|grep node-prod vfdotcomnode-prod-12212.service loaded active running NodeJS Service for vfdotcomnode.prod vfdotcomnode-prod-12213.service loaded active running NodeJS Service for vfdotcomnode.prod vikaskrishnia@node-38784:~$ vikaskrishnia@node-38784:~$ sudo systemctl restart vfdotcomnode-prod-12212.service vikaskrishnia@node-38784:~$ sudo systemctl restart vfdotcomnode-prod-12213.service If you face any issue with - escalate to Node.js team using the ops-portal and select the component as Node.JS Hosting. For critical escalations take approval from Ops managers as per SOP. However, this particular incident is not a critical issue so raise non-urgent escalation if the steps doesn't resolve the issue.","title":"Node.js server memory nearing threashold"},{"location":"incident_response/Node.js-server-memory-nearing-threashold/#nodejs-server-memory-nearing-threashold","text":"This alert was created as a proactive step to notify support team when node.js runtime memory utilization nears saturation. Node process need to be restarted to prevent node.js runtime from saturating and stop accepting new requests due to high memory utilization and maxing open file descriptor count. It was identified in CL-53102 . This alert is mainly for one customer due to the fact that they are not able to close the connections. Customer is working on a fix for it but it may take a while.","title":"Node.js server memory nearing threashold"},{"location":"incident_response/Node.js-server-memory-nearing-threashold/#diagnostics","text":"Check memory utilization of the stack being alerted for in signalfx . Change the stack ID with the one you receive in the alert. Currently, the alert will trigger when memory usage goes beyond 3.3 GB out of 4 GB memory system available.","title":"Diagnostics"},{"location":"incident_response/Node.js-server-memory-nearing-threashold/#remediation","text":"In the alert, you will see Host value see this ticket for example. Login to that server and run the following commands: ps -ef|grep '/next start' sudo systemctl list-units|grep node-prod It will list out the Node.js services for the customer - restart all the services displayed using the following command: sudo systemctl restart #NODE_SERVICE.service Here is the example: [cloudservicesprod|hosting-prod:prod] ~/fields/1.145$ fssh node-38784 FIPS mode initialized vikaskrishnia@node-38784:~$ #Identify running node runtime processes vikaskrishnia@node-38784:~$ ps -ef|grep '/next start' vikaskr+ 6686 6602 0 07:52 pts/4 00:00:00 grep /next start vfdotco+ 16893 16892 2 Jun15 ? 00:28:34 node /mnt/www/artifacts/vfdotcomnode.prod/73303/node_modules/.bin/next start -p 12212 vfdotco+ 17924 17923 2 Jun15 ? 00:29:07 node /mnt/www/artifacts/vfdotcomnode.prod/73303/node_modules/.bin/next start -p 12213 vikaskrishnia@node-38784:~$ #List and Restart node service vikaskrishnia@node-38784:~$ sudo systemctl list-units|grep node-prod vfdotcomnode-prod-12212.service loaded active running NodeJS Service for vfdotcomnode.prod vfdotcomnode-prod-12213.service loaded active running NodeJS Service for vfdotcomnode.prod vikaskrishnia@node-38784:~$ vikaskrishnia@node-38784:~$ sudo systemctl restart vfdotcomnode-prod-12212.service vikaskrishnia@node-38784:~$ sudo systemctl restart vfdotcomnode-prod-12213.service If you face any issue with - escalate to Node.js team using the ops-portal and select the component as Node.JS Hosting. For critical escalations take approval from Ops managers as per SOP. However, this particular incident is not a critical issue so raise non-urgent escalation if the steps doesn't resolve the issue.","title":"Remediation"},{"location":"incident_response/Node.js_degradeded_stack/","text":"Node.js Degraded stack alert This alert gets triggered when one or more instances from a Node.js stack goes down. It could happen if the instance gets impaired from AWS or if the memory usage on servers goes high due to unplanned event and causing the server to go unresponsive. Usually - this alert will be triggered along with Host down alert but sometimes - it may get triggered along with multiple other alerts (for example server being unresponsive). Verify the system and instance status from AWS using the following command: STACK_ID= #This value will be available in alert/ticket ah-server status $(ah-stack status --stack-id=${STACK_ID} | grep node | awk '{print $2}' | paste -sd,) If you see any server showing as impaired, then follow the impaired server relaunch runbook to relaunch the server(s). If the status from AWS is showing as passed, then verify you are able to access the servers using the following command: fpdsh -l $(ah-stack status --stack-id=${STACK_ID} | grep node | awk '{print $2}' | paste -sd,) -c uptime If you see any server being unresponsive, reboot the server using ah-server reboot $SERVER -i command. If the issue doesn't get resolved or the stack is healthy but still alerting, escalate the issue to Cloud Node team using the portal form and select Node.js Hosting as component.","title":"Node.js Degraded stack alert"},{"location":"incident_response/Node.js_degradeded_stack/#nodejs-degraded-stack-alert","text":"This alert gets triggered when one or more instances from a Node.js stack goes down. It could happen if the instance gets impaired from AWS or if the memory usage on servers goes high due to unplanned event and causing the server to go unresponsive. Usually - this alert will be triggered along with Host down alert but sometimes - it may get triggered along with multiple other alerts (for example server being unresponsive). Verify the system and instance status from AWS using the following command: STACK_ID= #This value will be available in alert/ticket ah-server status $(ah-stack status --stack-id=${STACK_ID} | grep node | awk '{print $2}' | paste -sd,) If you see any server showing as impaired, then follow the impaired server relaunch runbook to relaunch the server(s). If the status from AWS is showing as passed, then verify you are able to access the servers using the following command: fpdsh -l $(ah-stack status --stack-id=${STACK_ID} | grep node | awk '{print $2}' | paste -sd,) -c uptime If you see any server being unresponsive, reboot the server using ah-server reboot $SERVER -i command. If the issue doesn't get resolved or the stack is healthy but still alerting, escalate the issue to Cloud Node team using the portal form and select Node.js Hosting as component.","title":"Node.js Degraded stack alert"},{"location":"incident_response/ah-config-iptables_locked/","text":"ah-config-iptables locked This alert means that ah-config-iptables has been locked/blocked from running via the /var/acquia/no-config-iptables lockfile being generated. Resolution Log in to the alerting server. Check ah-runbook on the server to see if it was disabled intentionally. ah-runbook Search JIRA for the server name and sort by created date (descending). SERVER= echo \"https://backlog.acquia.com/issues/?jql=text%20~%20%22%5C%22${SERVER}%5C%22%22%20ORDER%20BY%20created%20DESC\" If the JIRA ticket mentioned in ah-runbook , the puppet agent disabled message, or the above JIRA search does not indicate that iptables should still be blocked, revert the change and note it in the related OP. rm /var/acquia/no-config-iptables ah-config-hosts ah-config-iptables","title":"ah-config-iptables locked"},{"location":"incident_response/ah-config-iptables_locked/#ah-config-iptables-locked","text":"This alert means that ah-config-iptables has been locked/blocked from running via the /var/acquia/no-config-iptables lockfile being generated.","title":"ah-config-iptables locked"},{"location":"incident_response/ah-config-iptables_locked/#resolution","text":"Log in to the alerting server. Check ah-runbook on the server to see if it was disabled intentionally. ah-runbook Search JIRA for the server name and sort by created date (descending). SERVER= echo \"https://backlog.acquia.com/issues/?jql=text%20~%20%22%5C%22${SERVER}%5C%22%22%20ORDER%20BY%20created%20DESC\" If the JIRA ticket mentioned in ah-runbook , the puppet agent disabled message, or the above JIRA search does not indicate that iptables should still be blocked, revert the change and note it in the related OP. rm /var/acquia/no-config-iptables ah-config-hosts ah-config-iptables","title":"Resolution"},{"location":"incident_response/ah-critical/","text":"Master AH_CRITICAL Duplicate Volumes Sample output: CRITICAL - (6) Nov 19 00:52:05 master drupal: https://master.e.prod.f.e2a.us:48443--pipe--1447894325--pipe--10.30.238.16--pipe--/authrpc.php?caller=master&method=create.backup.runs&whoami=/usr/local/bin/backup-create-runs&cache=01c5a1a6fee2d767647362f3286bf66cbc9d465d917259eb8f3b8e7289c44e70--pipe--AH_CRITICAL: Exception when scheduling backup run for task 6744: find.one(volume, \\ [ ':ebs_id': =>: ':vol-35bf91c5':, ':ec2_region': =>: ':eu-west-1': ]): \\ 2 found request_id=\"-\" Finding The Duplicate Volumes Set a var. This is the AWS EBS volume ID, for example vol-1234abcd : EBS_ID= Find the duplicate volumes and the server's name: fssh master \"sudo mysql -BNe \\\" \\ SELECT id, server_id FROM acquia_fields_volume \\ WHERE ebs_id='${EBS_ID}'\\\" fields_master\" \\ 2>/dev/null >${OPSTMP}/${EBS_ID}.dupe while read line; do volume=(${line}) [[ ${volume[1]} -gt 0 ]] \\ && echo \"server: $(ah-server list %-${volume[1]})\" \\ || echo \"server: ${volume[1]}\" ah-volume get ${volume[0]} echo done < ${OPSTMP}/${EBS_ID}.dupe Search Jira. Duplicate volumes are nearly always resultant from human error. echo \"https://backlog.acquia.com/issues/?jql=project%20%3D%20OP%20AND%20text%20~%20%22\\%22${EBS_ID}\\%22%22\" Escalate to a T2 as this requires master DB edits. Removing A Duplicate Volume WARNING! Master db edits are dangerous. The chance of you performing a 'delete where true' is very real and will cause a difficult sev0 to explain. You will be praised if you ask for someone to supervise the commands you execute, but only if you ask before execution. fssh to the master and create a backup of the volume table first. fssh master sudo mysqldump -cK --single-transaction fields_master \\ acquia_fields_volume \\ | gzip -c >/mnt/tmp/$USER-acquia_fields_volume-$(date +%s).sql.gz find the offending volume by selecting the id from the acquia_fields_volume table. Verify that the server_id is in fact zero and that this is the volume you need to delete. Please ask for confirmation before proceeding from this step ID= sudo mysql -e \"SELECT * FROM acquia_fields_volume \\ WHERE id=${ID}\\G\" fields_master This command deletes the offending record and then should return zero rows. If your terminal has timed out DO NOT CONTINUE , you will have to re-define ID . sudo mysql -e \"DELETE FROM acquia_fields_volume WHERE id=${ID}; \\ SELECT * FROM acquia_fields_volume WHERE id=${ID}\" fields_master","title":"Master AH_CRITICAL"},{"location":"incident_response/ah-critical/#master-ah_critical","text":"","title":"Master AH_CRITICAL"},{"location":"incident_response/ah-critical/#duplicate-volumes","text":"Sample output: CRITICAL - (6) Nov 19 00:52:05 master drupal: https://master.e.prod.f.e2a.us:48443--pipe--1447894325--pipe--10.30.238.16--pipe--/authrpc.php?caller=master&method=create.backup.runs&whoami=/usr/local/bin/backup-create-runs&cache=01c5a1a6fee2d767647362f3286bf66cbc9d465d917259eb8f3b8e7289c44e70--pipe--AH_CRITICAL: Exception when scheduling backup run for task 6744: find.one(volume, \\ [ ':ebs_id': =>: ':vol-35bf91c5':, ':ec2_region': =>: ':eu-west-1': ]): \\ 2 found request_id=\"-\"","title":"Duplicate Volumes"},{"location":"incident_response/ah-critical/#finding-the-duplicate-volumes","text":"Set a var. This is the AWS EBS volume ID, for example vol-1234abcd : EBS_ID= Find the duplicate volumes and the server's name: fssh master \"sudo mysql -BNe \\\" \\ SELECT id, server_id FROM acquia_fields_volume \\ WHERE ebs_id='${EBS_ID}'\\\" fields_master\" \\ 2>/dev/null >${OPSTMP}/${EBS_ID}.dupe while read line; do volume=(${line}) [[ ${volume[1]} -gt 0 ]] \\ && echo \"server: $(ah-server list %-${volume[1]})\" \\ || echo \"server: ${volume[1]}\" ah-volume get ${volume[0]} echo done < ${OPSTMP}/${EBS_ID}.dupe Search Jira. Duplicate volumes are nearly always resultant from human error. echo \"https://backlog.acquia.com/issues/?jql=project%20%3D%20OP%20AND%20text%20~%20%22\\%22${EBS_ID}\\%22%22\" Escalate to a T2 as this requires master DB edits.","title":"Finding The Duplicate Volumes"},{"location":"incident_response/ah-critical/#removing-a-duplicate-volume","text":"WARNING! Master db edits are dangerous. The chance of you performing a 'delete where true' is very real and will cause a difficult sev0 to explain. You will be praised if you ask for someone to supervise the commands you execute, but only if you ask before execution. fssh to the master and create a backup of the volume table first. fssh master sudo mysqldump -cK --single-transaction fields_master \\ acquia_fields_volume \\ | gzip -c >/mnt/tmp/$USER-acquia_fields_volume-$(date +%s).sql.gz find the offending volume by selecting the id from the acquia_fields_volume table. Verify that the server_id is in fact zero and that this is the volume you need to delete. Please ask for confirmation before proceeding from this step ID= sudo mysql -e \"SELECT * FROM acquia_fields_volume \\ WHERE id=${ID}\\G\" fields_master This command deletes the offending record and then should return zero rows. If your terminal has timed out DO NOT CONTINUE , you will have to re-define ID . sudo mysql -e \"DELETE FROM acquia_fields_volume WHERE id=${ID}; \\ SELECT * FROM acquia_fields_volume WHERE id=${ID}\" fields_master","title":"Removing A Duplicate Volume"},{"location":"incident_response/ah-resource-mon/","text":"ah-resource-mon ah-resource-mon describes resource limits on a per-AWS-account basis. This means that when a \"resource\" in a given AWS account approaches 90% of a specified resource limit, the service alerts. Resolution In the body of the service alert as listed on ops-mon-2 you will find the service name whose limit requires a request to AWS Support to increase for the given AWS account. Do not downtime the alert! Create a JIRA ticket describing the limit currently impacted. Log into the AWS Console for the impacted AWS account. Click \"Support\" in the upper-right, then \"Support Center\". Open an AWS Support ticket by clicking \"Create Case\". Select \"Service Limit Increase\". Select the corresponding \"Limit Type\". Select the corresponding \"Region\" impacted by the alert. Select the corresponding \"Resource Type\". Provide an integer value that is increased by around 25% over the current limit specified in the alert body (the number after the slash). Under \"Use Case Description\", enter the following: \"We are using over 90% of our quota and expect to expand in this region.\" Select \"Web\" as the contact method and click \"Submit\". Copy the URL and ticket number to the JIRA ticket and create a link by clicking \"More\", then clicking \"Link\".","title":"ah-resource-mon"},{"location":"incident_response/ah-resource-mon/#ah-resource-mon","text":"ah-resource-mon describes resource limits on a per-AWS-account basis. This means that when a \"resource\" in a given AWS account approaches 90% of a specified resource limit, the service alerts.","title":"ah-resource-mon"},{"location":"incident_response/ah-resource-mon/#resolution","text":"In the body of the service alert as listed on ops-mon-2 you will find the service name whose limit requires a request to AWS Support to increase for the given AWS account. Do not downtime the alert! Create a JIRA ticket describing the limit currently impacted. Log into the AWS Console for the impacted AWS account. Click \"Support\" in the upper-right, then \"Support Center\". Open an AWS Support ticket by clicking \"Create Case\". Select \"Service Limit Increase\". Select the corresponding \"Limit Type\". Select the corresponding \"Region\" impacted by the alert. Select the corresponding \"Resource Type\". Provide an integer value that is increased by around 25% over the current limit specified in the alert body (the number after the slash). Under \"Use Case Description\", enter the following: \"We are using over 90% of our quota and expect to expand in this region.\" Select \"Web\" as the contact method and click \"Submit\". Copy the URL and ticket number to the JIRA ticket and create a link by clicking \"More\", then clicking \"Link\".","title":"Resolution"},{"location":"incident_response/alerts_pagerduty_outage/","text":"How to Survive During a Pagerduty Outage If Pagerduty has an outage while you are on call, it can feel like you are left in the dark, there are no alerts coming in and you don't know what's down or not and have to rely on customer reporting to find site outages. Here are some tools to help you keep on top of issues during a Pagerduty outage. Ops Tickets Without pagerduty incidents to go off of, ops-incidents will not be able to create OP tickets for you. This means you will need to create the tickets yourself, manually. You can occasionally make use of ops-portal templates like \"Request Investigation\" to make this faster, but mostly you will have to do it yourself. The important ticket traits to hit when quickly creating an OP ticket are: It should be an OP, and the ticket type should be Incident. Set the component as accurately as you can (performance/availability is a good default for site outages). Make sure the sitegroup and hosting realm are set correctly. Tools to find issues The tools listed below will give you some options for finding alerts that are not going to Pagerduty during an outage. Ops-emergencyperfmon There is a tool in ops-misc called ops-emergencyperfmon . It only works for prod, due to hard-coding. It will run in a loop and curl all sites in prod every minute, and tell you about any that are failing. This may return false alarms, so make sure you check whether or not the sites it returns are actually down. Example output from this tool: [cloudservicesprod|hosting-prod:prod] ~/perf-mon$ ops-emergencyperfmon Making sure you have perf-mon checkout: Updating: Warning: Permanently added 'github.com,192.30.253.113' (RSA) to the list of known hosts. Already up-to-date. Warning: Permanently added 'github.com,192.30.253.112' (RSA) to the list of known hosts. Already up-to-date. Monitoring 2115 Sites from ~/perf-mon/perf-mon/data/mc_sites.txt This will loop each 60 seconds and curl all sites. ----------------------------- ERROR > sitename: lifespan ----------------------------- ERROR > sitename: syscointranet ----------------------------- ERROR > sitename: stpeteclearwater Connection: keep-alive1c-9112-11e8-aed1-0ad0e3905bbc Alerts Procmail Log Even if Pagerduty is not sending you alerts, the mailer that creates the alert emails in the first place is still sending the emails. You can tail the procmail log with the ops-procmailalerts tool. This will show you the email headers of all the alerts that would be going to pagerduty. ops-procmailalerts It will have output that looks like this: [cloudservicesprod|hosting-prod:prod] ~/ops-misc$ ops-procmailalerts Warning: Permanently added 'alerts.ops.acquia.com,54.163.252.39' (ECDSA) to the list of known hosts. 07/27/18-16:17:25 Subject: Alert: staging-23163.prod is DOWN or UNRESPONSIVE 07/27/18-16:17:25 Subject: ** PROBLEM Service Alert: ah-jira-mon/Sev1/Sev0 Issues is CRITICAL ** 07/27/18-16:17:25 Subject: ** PROBLEM Service Alert: staging-16693.prod/Disk Partitions is CRITI","title":"How to Survive During a Pagerduty Outage"},{"location":"incident_response/alerts_pagerduty_outage/#how-to-survive-during-a-pagerduty-outage","text":"If Pagerduty has an outage while you are on call, it can feel like you are left in the dark, there are no alerts coming in and you don't know what's down or not and have to rely on customer reporting to find site outages. Here are some tools to help you keep on top of issues during a Pagerduty outage.","title":"How to Survive During a Pagerduty Outage"},{"location":"incident_response/alerts_pagerduty_outage/#ops-tickets","text":"Without pagerduty incidents to go off of, ops-incidents will not be able to create OP tickets for you. This means you will need to create the tickets yourself, manually. You can occasionally make use of ops-portal templates like \"Request Investigation\" to make this faster, but mostly you will have to do it yourself. The important ticket traits to hit when quickly creating an OP ticket are: It should be an OP, and the ticket type should be Incident. Set the component as accurately as you can (performance/availability is a good default for site outages). Make sure the sitegroup and hosting realm are set correctly.","title":"Ops Tickets"},{"location":"incident_response/alerts_pagerduty_outage/#tools-to-find-issues","text":"The tools listed below will give you some options for finding alerts that are not going to Pagerduty during an outage.","title":"Tools to find issues"},{"location":"incident_response/alerts_pagerduty_outage/#ops-emergencyperfmon","text":"There is a tool in ops-misc called ops-emergencyperfmon . It only works for prod, due to hard-coding. It will run in a loop and curl all sites in prod every minute, and tell you about any that are failing. This may return false alarms, so make sure you check whether or not the sites it returns are actually down. Example output from this tool: [cloudservicesprod|hosting-prod:prod] ~/perf-mon$ ops-emergencyperfmon Making sure you have perf-mon checkout: Updating: Warning: Permanently added 'github.com,192.30.253.113' (RSA) to the list of known hosts. Already up-to-date. Warning: Permanently added 'github.com,192.30.253.112' (RSA) to the list of known hosts. Already up-to-date. Monitoring 2115 Sites from ~/perf-mon/perf-mon/data/mc_sites.txt This will loop each 60 seconds and curl all sites. ----------------------------- ERROR > sitename: lifespan ----------------------------- ERROR > sitename: syscointranet ----------------------------- ERROR > sitename: stpeteclearwater Connection: keep-alive1c-9112-11e8-aed1-0ad0e3905bbc","title":"Ops-emergencyperfmon"},{"location":"incident_response/alerts_pagerduty_outage/#alerts-procmail-log","text":"Even if Pagerduty is not sending you alerts, the mailer that creates the alert emails in the first place is still sending the emails. You can tail the procmail log with the ops-procmailalerts tool. This will show you the email headers of all the alerts that would be going to pagerduty. ops-procmailalerts It will have output that looks like this: [cloudservicesprod|hosting-prod:prod] ~/ops-misc$ ops-procmailalerts Warning: Permanently added 'alerts.ops.acquia.com,54.163.252.39' (ECDSA) to the list of known hosts. 07/27/18-16:17:25 Subject: Alert: staging-23163.prod is DOWN or UNRESPONSIVE 07/27/18-16:17:25 Subject: ** PROBLEM Service Alert: ah-jira-mon/Sev1/Sev0 Issues is CRITICAL ** 07/27/18-16:17:25 Subject: ** PROBLEM Service Alert: staging-16693.prod/Disk Partitions is CRITI","title":"Alerts Procmail Log"},{"location":"incident_response/backup_check/","text":"Backup Check General Information About Backup Tasks and Runs Tasks When a host is provisioned in Acquia Cloud, if that host has backups as part of its manifest in the hosting code base, the Hosting API will create runs in the acquia_fields_backup_runs table on the Hosting API for tasks that have a frequency greater than 0. Runs A backup \"run\" is a UID similar to a \"hosting task\" in the hosting code base, except that runs are only visible to the backup system and its associated tools. Backup automation keeps track of EBS volume snapshots, MySQL database backups, and other associated data through the run UIDs, and marks them and rotates them appropriately as defined in the code-base. The backup system retains the following backups: 4 \"hourly\" backups 7 \"daily\" backups 4 \"weekly\" backups 3 \"monthly\" backups When a run completes, it is marked as done . When a run fails or does not complete, it is marked as not_done . Using the not_done run IDs should make finding problems easier. General troubleshooting Backups can fail for a variety of reasons, including TCP connections being interrupted due to instance reboots/relaunches, volume problems relating to xfs_io locks, and duplicate volumes. Please review each of the sections below when you are checking out this alert. To begin: On the bastion, run ah-backup list-overdue-tasks to see which backups are overdue. cluster_id s in the list (in the below example: id=4092 ) need to be investigated. [cloudservicesdev|hosting-prod:prod] ~/fields/1.99$ ah-backup list-overdue-tasks task, id: 8213, cluster_type: fs-cluster, cluster_id: 4092, frequency: 3600, last_backup_age: 13 hours, 33 minutes, 29 seconds task, id: 8228, cluster_type: db-cluster, cluster_id: 4039, frequency: 3600, last_backup_age: 13 hours, 33 minutes, 29 seconds [cloudservicesdev|devcloud:devcloud] ~/fields/1.99$ ah-backup list-overdue-tasks task, id: 6799, cluster_type: local-fs-cluster, cluster_id: 6358, frequency: 3600, last_backup_age: 8 hours, 54 minutes, 10 seconds Review the necessary section below relating to the cluster_type mentioned above. local-fs-cluster ah-backup list-overdue-tasks will have local-fs-cluster backups for srv , api , and free host types. The cluster_type will denote such. task, id: 6799, cluster_type: local-fs-cluster, cluster_id: 6358, frequency: 3600 last_backup_age: 8 hours, 54 minutes, 10 seconds For these cluster types, cluster_id translates to server id. Look up the server id using the cluster_id listed in the output above. CLUSTER_ID= ah-server list % -w id=$CLUSTER_ID fs-cluster Look up the server ids using the cluster id CLUSTER_ID= ah-server list % -w fs_cluster_id=$CLUSTER_ID db-cluster Use the db-cluster tool from ops-misc to find the associated server. CLUSTER_ID= db-cluster $CLUSTER_ID Next Steps After determining the server(s) in-question, use ah-backup list-runs to figure out what runs are marked as not_done . ah-backup list-runs $SERVER Using the run id of the most recent run that has not completed, you can reach out to all the backup servers in the given stage and grep through /var/log/ahbackup* for run information. BACKUP_RUN_ID= backup-whyfail $BACKUP_RUN_ID Usually, backup runs will report some kind of ERROR string. Use this to continue debugging the issue. $ backup-whyfail 94289076 backup-1264: /var/log/ahbackup2:[2016-01-03 18:55:08] Backup run ID ... backup-1264: /var/log/ahbackup2:[2016-01-03 18:55:08] Backup run ID ... backup-1264: /var/log/ahbackup2:[2016-01-03 18:55:12] Backup run ... backup-1264: /var/log/ahbackup2:[2016-01-03 18:55:12] ERROR: ... Example: If you see \"connection closed by remote host\" or \"timeout during....\", the server is likely unresponsive and you need to reboot the server: backup-4113: /var/log/ahbackup2:[2017-05-03 16:30:51] ERROR: Exception for backup run 78642145: Exception when unfreezing volume 1120830: connection closed by remote host (ahbot@free-6225.devcloud.hosting.acquia.com:40506) backup-5786: /var/log/ahbackup2:[2017-05-03 15:47:46] ERROR: Exception for backup run 161614338: timeout during server version negotiating (ahbot@staging-17917.prod.hosting.acquia.com:40506) Example: If you see \"Lock attempt timed out\", there is likely a long running transaction on the database. You will need to investigate and possibly kill the transaction, with customer's permission: backup-30: /var/log/ahbackup:[2017-04-28 21:07:13] ERROR: Exception for backup run 160865716: Lock attempt timed out after 30 seconds: could not run '/usr/local/sbin/ah-lock-db' on remote host staging-14362.prod.hosting.acquia.com Example: There are no failed backups in not_done state, but no backups have successfully run in 8+ hours. Check the backup tasks: ah-backup list-tasks $SERVER The output that you want to see here is a frequency of 3600, and a next_action_time that is in the future. If frequency is set to any value other than 3600, and there are no volume resize workflows pending or running on the server, correct it. ah-backup edit-tasks ${SERVER} -a -s frequency=3600 Further Debugging Overdue Backups The following information may be useful if you still cannot find the reason backups are failing. If you are unable to determine the problem, please escalate to another Ops team member. Run backup-fixoverdue ( CL-10459 ): $ backup-fixoverdue Finding stuck backup processes in prod and analysing... backup-5786 Proc Age: 62 hours ruby 3864 root IPv4 TCP backup-5786:40074->ded-12826:40506 (ESTABLISHED) Due to the size of some volumes a backup can take many hours to complete Please do not kill a task unless you are 100% certain there is an issue. Kill pid 3864? (y/N): fssh to each server in the output and check out the uptime (example process illustrated in OP-63505 ) vs. the Proc Age listed in the output of backup-fixoverdue . If the uptime of the host is lower than the Proc Age , kill the backup. If the uptime is longer than the Proc Age , proceed with the below sections. Reinstalling the ah-task-server gem to fix broken symlinks after a Fields release Overdue backups can also be caused by symlinks not being put into place properly after a Fields release. If this is the case, you'll likely see log messages about ah-task-server not being found or gems that are missing. If you'd like to see the currently installed version of the task server on a particular backup server, run: sudo dpkg -l | grep ah-task-server | awk '{print \\$3}' To see the currently installed version across all backup servers, run: fpdsh -r $REGION -p 1 -l $(ah-server list backup% | tr '\\n' ',') -c \"sudo dpkg -l | grep ah-task-server | awk '{print \\$3}'\" To reinstall the current version of the task server on the backup servers, uninstall ahbackup and re-install the existing task server version: sudo gem uninstall -a ahbackup sudo apt-get install --reinstall ah-task-server=$(sudo dpkg -l | grep ah-task-server | awk '{print \\$3}') If you'd like to use fpdsh to do this across multiple backup servers in a realm, you can use the following commands. First, check to make sure the backup servers that are not working are the same ones you'd be modifying with fpdsh : ah-server list backup% | tr '\\n' ',' Then, run the reinstall commands: fpdsh -r $REGION -p 1 -l $(ah-server list backup% | tr '\\n' ',') -c \"sudo gem uninstall -a ahbackup\" fpdsh -r $REGION -p 1 -l $(ah-server list backup% | tr '\\n' ',') -c \"sudo apt-get install --reinstall ah-task-server=$(sudo dpkg -l | grep ah-task-server | awk '{print \\$3}')\" Hung TCP connections Backups can hang forever on TCP connections. The backup-fixoverdue script finds them and gives you the option to kill them. Log in to the server and check netstat -pant output for connections of the same type described in the output of backup-fixoverdue . If a connection is not present (or if the host was rebooted in the middle of a backup run) as described in the tool output, kill the pid. If a connection is present, check /var/log/daemon.log to see if a volume is currently \"frozen\" or if it is in the process of being unfrozen. PIDs are listed in the log output and can be inspected via strace . Duplicate volume ids Duplicate volume IDs are covered in the ah_critical/master alert page.","title":"Backup Check"},{"location":"incident_response/backup_check/#backup-check","text":"","title":"Backup Check"},{"location":"incident_response/backup_check/#general-information-about-backup-tasks-and-runs","text":"","title":"General Information About Backup Tasks and Runs"},{"location":"incident_response/backup_check/#tasks","text":"When a host is provisioned in Acquia Cloud, if that host has backups as part of its manifest in the hosting code base, the Hosting API will create runs in the acquia_fields_backup_runs table on the Hosting API for tasks that have a frequency greater than 0.","title":"Tasks"},{"location":"incident_response/backup_check/#runs","text":"A backup \"run\" is a UID similar to a \"hosting task\" in the hosting code base, except that runs are only visible to the backup system and its associated tools. Backup automation keeps track of EBS volume snapshots, MySQL database backups, and other associated data through the run UIDs, and marks them and rotates them appropriately as defined in the code-base. The backup system retains the following backups: 4 \"hourly\" backups 7 \"daily\" backups 4 \"weekly\" backups 3 \"monthly\" backups When a run completes, it is marked as done . When a run fails or does not complete, it is marked as not_done . Using the not_done run IDs should make finding problems easier.","title":"Runs"},{"location":"incident_response/backup_check/#general-troubleshooting","text":"Backups can fail for a variety of reasons, including TCP connections being interrupted due to instance reboots/relaunches, volume problems relating to xfs_io locks, and duplicate volumes. Please review each of the sections below when you are checking out this alert. To begin: On the bastion, run ah-backup list-overdue-tasks to see which backups are overdue. cluster_id s in the list (in the below example: id=4092 ) need to be investigated. [cloudservicesdev|hosting-prod:prod] ~/fields/1.99$ ah-backup list-overdue-tasks task, id: 8213, cluster_type: fs-cluster, cluster_id: 4092, frequency: 3600, last_backup_age: 13 hours, 33 minutes, 29 seconds task, id: 8228, cluster_type: db-cluster, cluster_id: 4039, frequency: 3600, last_backup_age: 13 hours, 33 minutes, 29 seconds [cloudservicesdev|devcloud:devcloud] ~/fields/1.99$ ah-backup list-overdue-tasks task, id: 6799, cluster_type: local-fs-cluster, cluster_id: 6358, frequency: 3600, last_backup_age: 8 hours, 54 minutes, 10 seconds Review the necessary section below relating to the cluster_type mentioned above.","title":"General troubleshooting"},{"location":"incident_response/backup_check/#local-fs-cluster","text":"ah-backup list-overdue-tasks will have local-fs-cluster backups for srv , api , and free host types. The cluster_type will denote such. task, id: 6799, cluster_type: local-fs-cluster, cluster_id: 6358, frequency: 3600 last_backup_age: 8 hours, 54 minutes, 10 seconds For these cluster types, cluster_id translates to server id. Look up the server id using the cluster_id listed in the output above. CLUSTER_ID= ah-server list % -w id=$CLUSTER_ID","title":"local-fs-cluster"},{"location":"incident_response/backup_check/#fs-cluster","text":"Look up the server ids using the cluster id CLUSTER_ID= ah-server list % -w fs_cluster_id=$CLUSTER_ID","title":"fs-cluster"},{"location":"incident_response/backup_check/#db-cluster","text":"Use the db-cluster tool from ops-misc to find the associated server. CLUSTER_ID= db-cluster $CLUSTER_ID","title":"db-cluster"},{"location":"incident_response/backup_check/#next-steps","text":"After determining the server(s) in-question, use ah-backup list-runs to figure out what runs are marked as not_done . ah-backup list-runs $SERVER Using the run id of the most recent run that has not completed, you can reach out to all the backup servers in the given stage and grep through /var/log/ahbackup* for run information. BACKUP_RUN_ID= backup-whyfail $BACKUP_RUN_ID Usually, backup runs will report some kind of ERROR string. Use this to continue debugging the issue. $ backup-whyfail 94289076 backup-1264: /var/log/ahbackup2:[2016-01-03 18:55:08] Backup run ID ... backup-1264: /var/log/ahbackup2:[2016-01-03 18:55:08] Backup run ID ... backup-1264: /var/log/ahbackup2:[2016-01-03 18:55:12] Backup run ... backup-1264: /var/log/ahbackup2:[2016-01-03 18:55:12] ERROR: ... Example: If you see \"connection closed by remote host\" or \"timeout during....\", the server is likely unresponsive and you need to reboot the server: backup-4113: /var/log/ahbackup2:[2017-05-03 16:30:51] ERROR: Exception for backup run 78642145: Exception when unfreezing volume 1120830: connection closed by remote host (ahbot@free-6225.devcloud.hosting.acquia.com:40506) backup-5786: /var/log/ahbackup2:[2017-05-03 15:47:46] ERROR: Exception for backup run 161614338: timeout during server version negotiating (ahbot@staging-17917.prod.hosting.acquia.com:40506) Example: If you see \"Lock attempt timed out\", there is likely a long running transaction on the database. You will need to investigate and possibly kill the transaction, with customer's permission: backup-30: /var/log/ahbackup:[2017-04-28 21:07:13] ERROR: Exception for backup run 160865716: Lock attempt timed out after 30 seconds: could not run '/usr/local/sbin/ah-lock-db' on remote host staging-14362.prod.hosting.acquia.com Example: There are no failed backups in not_done state, but no backups have successfully run in 8+ hours. Check the backup tasks: ah-backup list-tasks $SERVER The output that you want to see here is a frequency of 3600, and a next_action_time that is in the future. If frequency is set to any value other than 3600, and there are no volume resize workflows pending or running on the server, correct it. ah-backup edit-tasks ${SERVER} -a -s frequency=3600","title":"Next Steps"},{"location":"incident_response/backup_check/#further-debugging-overdue-backups","text":"The following information may be useful if you still cannot find the reason backups are failing. If you are unable to determine the problem, please escalate to another Ops team member. Run backup-fixoverdue ( CL-10459 ): $ backup-fixoverdue Finding stuck backup processes in prod and analysing... backup-5786 Proc Age: 62 hours ruby 3864 root IPv4 TCP backup-5786:40074->ded-12826:40506 (ESTABLISHED) Due to the size of some volumes a backup can take many hours to complete Please do not kill a task unless you are 100% certain there is an issue. Kill pid 3864? (y/N): fssh to each server in the output and check out the uptime (example process illustrated in OP-63505 ) vs. the Proc Age listed in the output of backup-fixoverdue . If the uptime of the host is lower than the Proc Age , kill the backup. If the uptime is longer than the Proc Age , proceed with the below sections.","title":"Further Debugging Overdue Backups"},{"location":"incident_response/backup_check/#reinstalling-the-ah-task-server-gem-to-fix-broken-symlinks-after-a-fields-release","text":"Overdue backups can also be caused by symlinks not being put into place properly after a Fields release. If this is the case, you'll likely see log messages about ah-task-server not being found or gems that are missing. If you'd like to see the currently installed version of the task server on a particular backup server, run: sudo dpkg -l | grep ah-task-server | awk '{print \\$3}' To see the currently installed version across all backup servers, run: fpdsh -r $REGION -p 1 -l $(ah-server list backup% | tr '\\n' ',') -c \"sudo dpkg -l | grep ah-task-server | awk '{print \\$3}'\" To reinstall the current version of the task server on the backup servers, uninstall ahbackup and re-install the existing task server version: sudo gem uninstall -a ahbackup sudo apt-get install --reinstall ah-task-server=$(sudo dpkg -l | grep ah-task-server | awk '{print \\$3}') If you'd like to use fpdsh to do this across multiple backup servers in a realm, you can use the following commands. First, check to make sure the backup servers that are not working are the same ones you'd be modifying with fpdsh : ah-server list backup% | tr '\\n' ',' Then, run the reinstall commands: fpdsh -r $REGION -p 1 -l $(ah-server list backup% | tr '\\n' ',') -c \"sudo gem uninstall -a ahbackup\" fpdsh -r $REGION -p 1 -l $(ah-server list backup% | tr '\\n' ',') -c \"sudo apt-get install --reinstall ah-task-server=$(sudo dpkg -l | grep ah-task-server | awk '{print \\$3}')\"","title":"Reinstalling the ah-task-server gem to fix broken symlinks after a Fields release"},{"location":"incident_response/backup_check/#hung-tcp-connections","text":"Backups can hang forever on TCP connections. The backup-fixoverdue script finds them and gives you the option to kill them. Log in to the server and check netstat -pant output for connections of the same type described in the output of backup-fixoverdue . If a connection is not present (or if the host was rebooted in the middle of a backup run) as described in the tool output, kill the pid. If a connection is present, check /var/log/daemon.log to see if a volume is currently \"frozen\" or if it is in the process of being unfrozen. PIDs are listed in the log output and can be inspected via strace .","title":"Hung TCP connections"},{"location":"incident_response/backup_check/#duplicate-volume-ids","text":"Duplicate volume IDs are covered in the ah_critical/master alert page.","title":"Duplicate volume ids"},{"location":"incident_response/blocked_fcw_run/","text":"Blocked Fields Config Web Run alert This alert means that a fields-config-web.php lock has been in place longer than 3600 seconds. sudo /usr/lib/nagios/plugins/check_stale_fcweb 3600 Response Determine if FCW is either stuck or long-running due to checking out many repos. If the FCW is stuck, then kill the process and run FCW again. sudo kill $(cat /var/run/acquia_fields_config_web.lock) sudo fields-config-web.php","title":"Blocked Fields Config Web Run alert"},{"location":"incident_response/blocked_fcw_run/#blocked-fields-config-web-run-alert","text":"This alert means that a fields-config-web.php lock has been in place longer than 3600 seconds. sudo /usr/lib/nagios/plugins/check_stale_fcweb 3600","title":"Blocked Fields Config Web Run alert"},{"location":"incident_response/blocked_fcw_run/#response","text":"Determine if FCW is either stuck or long-running due to checking out many repos. If the FCW is stuck, then kill the process and run FCW again. sudo kill $(cat /var/run/acquia_fields_config_web.lock) sudo fields-config-web.php","title":"Response"},{"location":"incident_response/check_auditd/","text":"Check Auditd Agent The Auditd agent is not active and running unless enable_auditd flag is turned on. This flag is maintained in fields. Read the fields archictecture docs for more information. There is no customer impact if auditd service goes down. This only affects the ossec parsers from successfully alerting on certain system auditing events. There will be no alerts/errors found within ossec logs either. NOTE: check_services only checks for the auditd service if enable_auditd flag is turned on. Response Investigate Root Cause There are two known scenarios under which Auditd may not be running: Resource starvation causing Auditd agent to crash (I.e. high network, high cpu, disk space utilization, etc.) Auditd agent is disabled Do the following to identify and respond to the scenario appropriately: Check the server's uptime and resource graphs and identify any constrained or unusual resource statistics in the past 24 hours (CPU, memory, disk space, disk I/O, network utilization, etc.): SERVER= sv-up ${SERVER} sv-dbdash ${SERVER} Example: [cloudservicesprod|hosting-prod:prod] ~/fields/1.107$ SERVER=ded-1990 [cloudservicesprod|hosting-prod:prod] ~/fields/1.108$ sv-up ${SERVER} Warning: Permanently added '[ded-1990.prod.hosting.acquia.com]:40506,[50.16.11.79]:40506' (RSA) to the list of known hosts. 20:25:25 up 38 days, 14:13, 0 users, load average: 0.04, 0.15, 0.14 Thu Jun 7 20:25:25 UTC 2018 [cloudservicesprod|hosting-prod:prod] ~/fields/1.107$ sv-dbdash ${SERVER} https://app.signalfx.com/#/dashboard/C_jL5ehAgAA?startTime=-12h&endTime=Now&density=4&variables%5B%5D=Instances%3D&sources%5B%5D=host:%5B%22ded-1990.prod.hosting.acquia.com%22%5D [cloudservicesprod|hosting-prod:prod] ~/fields/1.107$ If any resource starvation is observed, resolve the problem and restart auditd . Check for any JIRA tickets related to the agent being disabled. If it is tracked or done due to some part of critical issue, please request the flag enable_auditd to be turned off instead, as this will disable service check too. Do not turn off this flag without first consulting the SecEng team. For any issues not listed here, please follow SecEng escalation procedure or contact sec-eng@acquia.com Restore Auditd Service If auditd is not running but should be, restart the agent: service auditd restart","title":"Check Auditd Agent"},{"location":"incident_response/check_auditd/#check-auditd-agent","text":"The Auditd agent is not active and running unless enable_auditd flag is turned on. This flag is maintained in fields. Read the fields archictecture docs for more information. There is no customer impact if auditd service goes down. This only affects the ossec parsers from successfully alerting on certain system auditing events. There will be no alerts/errors found within ossec logs either. NOTE: check_services only checks for the auditd service if enable_auditd flag is turned on.","title":"Check Auditd Agent"},{"location":"incident_response/check_auditd/#response","text":"","title":"Response"},{"location":"incident_response/check_auditd/#investigate-root-cause","text":"There are two known scenarios under which Auditd may not be running: Resource starvation causing Auditd agent to crash (I.e. high network, high cpu, disk space utilization, etc.) Auditd agent is disabled Do the following to identify and respond to the scenario appropriately: Check the server's uptime and resource graphs and identify any constrained or unusual resource statistics in the past 24 hours (CPU, memory, disk space, disk I/O, network utilization, etc.): SERVER= sv-up ${SERVER} sv-dbdash ${SERVER} Example: [cloudservicesprod|hosting-prod:prod] ~/fields/1.107$ SERVER=ded-1990 [cloudservicesprod|hosting-prod:prod] ~/fields/1.108$ sv-up ${SERVER} Warning: Permanently added '[ded-1990.prod.hosting.acquia.com]:40506,[50.16.11.79]:40506' (RSA) to the list of known hosts. 20:25:25 up 38 days, 14:13, 0 users, load average: 0.04, 0.15, 0.14 Thu Jun 7 20:25:25 UTC 2018 [cloudservicesprod|hosting-prod:prod] ~/fields/1.107$ sv-dbdash ${SERVER} https://app.signalfx.com/#/dashboard/C_jL5ehAgAA?startTime=-12h&endTime=Now&density=4&variables%5B%5D=Instances%3D&sources%5B%5D=host:%5B%22ded-1990.prod.hosting.acquia.com%22%5D [cloudservicesprod|hosting-prod:prod] ~/fields/1.107$ If any resource starvation is observed, resolve the problem and restart auditd . Check for any JIRA tickets related to the agent being disabled. If it is tracked or done due to some part of critical issue, please request the flag enable_auditd to be turned off instead, as this will disable service check too. Do not turn off this flag without first consulting the SecEng team. For any issues not listed here, please follow SecEng escalation procedure or contact sec-eng@acquia.com","title":"Investigate Root Cause"},{"location":"incident_response/check_auditd/#restore-auditd-service","text":"If auditd is not running but should be, restart the agent: service auditd restart","title":"Restore Auditd Service"},{"location":"incident_response/check_clamav/","text":"As a first step Check if a reporting customer is running ClamAV as a daemon and is supported by Acquia in doing so. Only 3 customers are permitted to use ClamAV in Daemon mode: Michael Page (ACE) and WMG (Site Factory), Trex. Check if the server has clamd configured ah-server list config:puppet:clamd -w name=${SERVER} This should return the server being investigated. If not that means that Clamd is not configured on the server. Please follow instructions on how to enable ClamAV Daemon . Check the status of the service # systemctl status clamav-daemon \u25cf clamav-daemon.service - Clam AntiVirus userspace daemon Loaded: loaded (/lib/systemd/system/clamav-daemon.service; enabled; vendor preset: enabled) Drop-In: /etc/systemd/system/clamav-daemon.service.d \u2514\u2500extend.conf Active: active (running) since Wed 2018-09-05 15:14:30 UTC; 5h 44min ago Docs: man:clamd(8) man:clamd.conf(5) https://www.clamav.net/documents/ Main PID: 6278 (clamd) CGroup: /system.slice/clamav-daemon.service \u2514\u25006278 /usr/sbin/clamd --foreground=true Sep 05 15:14:44 web-29065.prod.hosting.acquia.com clamd[6278]: Wed Sep 5 15:14:44 2018 -> PDF support enabled. Sep 05 15:14:44 web-29065.prod.hosting.acquia.com clamd[6278]: Wed Sep 5 15:14:44 2018 -> SWF support enabled. Sep 05 15:14:44 web-29065.prod.hosting.acquia.com clamd[6278]: Wed Sep 5 15:14:44 2018 -> HTML support enabled. Sep 05 15:14:44 web-29065.prod.hosting.acquia.com clamd[6278]: Wed Sep 5 15:14:44 2018 -> XMLDOCS support enabled. Sep 05 15:14:44 web-29065.prod.hosting.acquia.com clamd[6278]: Wed Sep 5 15:14:44 2018 -> HWP3 support enabled. Sep 05 15:14:44 web-29065.prod.hosting.acquia.com clamd[6278]: Wed Sep 5 15:14:44 2018 -> Self checking every 3600 seconds. Sep 05 16:20:31 web-29065.prod.hosting.acquia.com clamd[6278]: Wed Sep 5 16:20:31 2018 -> SelfCheck: Database status OK. Sep 05 17:28:05 web-29065.prod.hosting.acquia.com clamd[6278]: Wed Sep 5 17:28:05 2018 -> SelfCheck: Database status OK. Sep 05 19:03:28 web-29065.prod.hosting.acquia.com clamd[6278]: Wed Sep 5 19:03:28 2018 -> SelfCheck: Database status OK. Sep 05 20:16:46 web-29065.prod.hosting.acquia.com clamd[6278]: Wed Sep 5 20:16:46 2018 -> SelfCheck: Database status OK. Logs can be found under /var/log/clamav/clamav.log . Health check Check the health of the service: # touch /tmp/yolo # clamdscan /tmp/yolo WARNING: Ignoring deprecated option AllowSupplementaryGroups at line 12 /tmp/yolo: OK ----------- SCAN SUMMARY ----------- Infected files: 0 Time: 0.000 sec (0 m 0 s)[21:06:24] root@web-29065.prod:~# clamdscan /tmp/ Check if the daemon is listening on port 3310: # /usr/lib/nagios/plugins/check_tcp -H 127.0.0.1 -p 3310 TCP OK - 0.000 second response time on 127.0.0.1 port 3310|time=0.000113s;;;0.000000;10.000000 Troubleshooting For troubleshooting for Clamd and ClamAV Daemon you can follow the following two documentations: ClamAV troubleshooting FAQ Arch linux WIKI daemon troubleshooting steps","title":"As a first step"},{"location":"incident_response/check_clamav/#as-a-first-step","text":"Check if a reporting customer is running ClamAV as a daemon and is supported by Acquia in doing so. Only 3 customers are permitted to use ClamAV in Daemon mode: Michael Page (ACE) and WMG (Site Factory), Trex.","title":"As a first step"},{"location":"incident_response/check_clamav/#check-if-the-server-has-clamd-configured","text":"ah-server list config:puppet:clamd -w name=${SERVER} This should return the server being investigated. If not that means that Clamd is not configured on the server. Please follow instructions on how to enable ClamAV Daemon .","title":"Check if the server has clamd configured"},{"location":"incident_response/check_clamav/#check-the-status-of-the-service","text":"# systemctl status clamav-daemon \u25cf clamav-daemon.service - Clam AntiVirus userspace daemon Loaded: loaded (/lib/systemd/system/clamav-daemon.service; enabled; vendor preset: enabled) Drop-In: /etc/systemd/system/clamav-daemon.service.d \u2514\u2500extend.conf Active: active (running) since Wed 2018-09-05 15:14:30 UTC; 5h 44min ago Docs: man:clamd(8) man:clamd.conf(5) https://www.clamav.net/documents/ Main PID: 6278 (clamd) CGroup: /system.slice/clamav-daemon.service \u2514\u25006278 /usr/sbin/clamd --foreground=true Sep 05 15:14:44 web-29065.prod.hosting.acquia.com clamd[6278]: Wed Sep 5 15:14:44 2018 -> PDF support enabled. Sep 05 15:14:44 web-29065.prod.hosting.acquia.com clamd[6278]: Wed Sep 5 15:14:44 2018 -> SWF support enabled. Sep 05 15:14:44 web-29065.prod.hosting.acquia.com clamd[6278]: Wed Sep 5 15:14:44 2018 -> HTML support enabled. Sep 05 15:14:44 web-29065.prod.hosting.acquia.com clamd[6278]: Wed Sep 5 15:14:44 2018 -> XMLDOCS support enabled. Sep 05 15:14:44 web-29065.prod.hosting.acquia.com clamd[6278]: Wed Sep 5 15:14:44 2018 -> HWP3 support enabled. Sep 05 15:14:44 web-29065.prod.hosting.acquia.com clamd[6278]: Wed Sep 5 15:14:44 2018 -> Self checking every 3600 seconds. Sep 05 16:20:31 web-29065.prod.hosting.acquia.com clamd[6278]: Wed Sep 5 16:20:31 2018 -> SelfCheck: Database status OK. Sep 05 17:28:05 web-29065.prod.hosting.acquia.com clamd[6278]: Wed Sep 5 17:28:05 2018 -> SelfCheck: Database status OK. Sep 05 19:03:28 web-29065.prod.hosting.acquia.com clamd[6278]: Wed Sep 5 19:03:28 2018 -> SelfCheck: Database status OK. Sep 05 20:16:46 web-29065.prod.hosting.acquia.com clamd[6278]: Wed Sep 5 20:16:46 2018 -> SelfCheck: Database status OK. Logs can be found under /var/log/clamav/clamav.log .","title":"Check the status of the service"},{"location":"incident_response/check_clamav/#health-check","text":"Check the health of the service: # touch /tmp/yolo # clamdscan /tmp/yolo WARNING: Ignoring deprecated option AllowSupplementaryGroups at line 12 /tmp/yolo: OK ----------- SCAN SUMMARY ----------- Infected files: 0 Time: 0.000 sec (0 m 0 s)[21:06:24] root@web-29065.prod:~# clamdscan /tmp/ Check if the daemon is listening on port 3310: # /usr/lib/nagios/plugins/check_tcp -H 127.0.0.1 -p 3310 TCP OK - 0.000 second response time on 127.0.0.1 port 3310|time=0.000113s;;;0.000000;10.000000","title":"Health check"},{"location":"incident_response/check_clamav/#troubleshooting","text":"For troubleshooting for Clamd and ClamAV Daemon you can follow the following two documentations: ClamAV troubleshooting FAQ Arch linux WIKI daemon troubleshooting steps","title":"Troubleshooting"},{"location":"incident_response/check_filesystem_fencing/","text":"Check Filesystem Fencing alert This alert means that gluster fence enabled for a FS_SERVER is on. sudo /usr/lib/nagios/plugins/check_fence A person has placed a fence for protection while performing work in a JIRA ticket. The fence is an IPTABLES OUTPUT rule that rejects gluster traffic. They initiated the fence with these commands. fssh $FS_SERVER sudo service glusterfs-server stop ah-filesystem fail --server $FS_SERVER Response Search JIRA for tickets on $FS_SERVER name, this alert only exists because of an persons action. Preferably contact current JIRA ticket assignee to discuss. If that is not possible, use some judgement and perform these steps to turn fencing off if JIRA ticket is closed or non-existent. Remount gluster SITE= site-fsremount $SITE If any issues with the fsremount, log into $FS_SERVER and investigate. Return the IPTABLES to defaults across the site fpdsh -t site:$SITE -p 1 -n 'web|ded|fsdb|fs|fsdbmesh|staging' -c \"sudo ah-config-iptables\"","title":"Check Filesystem Fencing alert"},{"location":"incident_response/check_filesystem_fencing/#check-filesystem-fencing-alert","text":"This alert means that gluster fence enabled for a FS_SERVER is on. sudo /usr/lib/nagios/plugins/check_fence A person has placed a fence for protection while performing work in a JIRA ticket. The fence is an IPTABLES OUTPUT rule that rejects gluster traffic. They initiated the fence with these commands. fssh $FS_SERVER sudo service glusterfs-server stop ah-filesystem fail --server $FS_SERVER","title":"Check Filesystem Fencing alert"},{"location":"incident_response/check_filesystem_fencing/#response","text":"Search JIRA for tickets on $FS_SERVER name, this alert only exists because of an persons action. Preferably contact current JIRA ticket assignee to discuss. If that is not possible, use some judgement and perform these steps to turn fencing off if JIRA ticket is closed or non-existent. Remount gluster SITE= site-fsremount $SITE If any issues with the fsremount, log into $FS_SERVER and investigate. Return the IPTABLES to defaults across the site fpdsh -t site:$SITE -p 1 -n 'web|ded|fsdb|fs|fsdbmesh|staging' -c \"sudo ah-config-iptables\"","title":"Response"},{"location":"incident_response/check_gluster_transport_endpoint_error/","text":"Check Gluster Transport endpoint error The glusterfs mount point on the local server, /mnt/gfs , is in some way impaired. This can be caused by network blips, server side issues or a dead client process. Response Determine if all servers in the site need to be remounted or just a specific server. Remounting gluster has the potential to cause an outage. Only perform a site-wide remount if all , or the majority, of gluster fs clients have the same alert. Check the site's gluster mount status. site-checkgluster $SITE If any servers report failures, use the server method below. Site-wide gluster remount Review the state of gluster across the site site-checkgluster $SITE If there has been recent maintenance or the gluster client has OOMed and you are sure that you want to remount gluster across the entire site (including hosts in passive MR regions), you can attempt to remount all hosts. site-fsremount $SITE Restart apache and FPM for the site to clear any processes that might be holding or hitting stale resources. fpdsh -t site:$SITE -n 'ded|web|staging|managed' -c 'sudo service safe-httpd restart' site-restartfpm $SITE Server-specific gluster remount Review the state of the gluster mount. fssh $SERVER df -h Remount gluster for the server sv-fsremount $SERVER If gluster remounting fails to work there are several courses of action, depending on the error and version of Gluster. Advanced Troubleshooting Gluster 3.0 Ensure glusterfsd is not in disk wait, is not I/O bound, or is not otherwise consuming excessive resources. fpdsh -t site:$SITE -n 'ded|fs|fsdb|fsdbmesh' \\ -c 'sudo ps aux | grep [g]lusterfsd' Check to see if there have been any OOMs recently. fpdsh -t site:$SITE -n 'ded|fs|fsdb|fsdbmesh' \\ -c 'sudo dmesg | grep -i oom' Run strace to see if stat() calls are taking longer than 1 second. The number at the end of each line indicates the number of seconds a particular call took. If a call takes longer than a second, this is indicative of a potential problem with glusterfsd on the gluster servers (ded, fs, fsdb, fsdbmesh, etc.) PID=$(pgrep php-fpm | sort -R | head -n1) strace -f -p $PID -s 2048 -T -e trace='stat' # Example: # [14:04:13] root@web-10881.prod:~# PID=$(pgrep php-fpm | sort -R | head -n1) # [14:04:14] root@web-10881.prod:~# strace -f -p $PID -s 2048 -T -e trace='stat' # Process 5719 attached - interrupt to quit # stat(\"(FILE)\", {st_mode=S_IFREG|0550, st_size=19894, ...}) = 0 <0.000388> Re-run fields-config-fs-server.php and fields-config-fs-client.php to ensure current configs are deployed. fpdsh -t site:$SITE -n 'ded|fs|fsdb|fsdbmesh' -c 'sudo fields-config-fs-server.php' fpdsh -t site:$SITE -n 'ded|fs|fsdb|fsdbmesh|web|staging|managed' \\ -c 'sudo fields-config-fs-client.php' Forcefully unmount gluster (twice). fpdsh -t site:$SITE -n 'ded|fs|fsdb|fsdbmesh|web|staging|managed' \\ -c 'sudo umount -f /mnt/gfs; sudo umount -f /mnt/gfs' Kill all the gluster processes that could be stalled. fpdsh -t site:$SITE -n 'ded|fs|fsdb|fsdbmesh|web|staging|managed' -c 'sudo pkill glusterfsd' Kill all the fpm processes that might be accessing the stale mount and stop apache2. fpdsh -t site:$SITE -n 'ded|web|staging|managed' \\ -c 'sudo pkill -9 \"php-fpm\"; sudo service safe-httpd stop' Restart glusterfsd on the gluster servers. fpdsh -t site:$SITE -n 'ded|fs|fsdb|fsdbmesh' -c 'sudo service glusterfs-server restart' Remount gluster. site-fsremount $SITE Restart apache2 and fpm processes. fpdsh -t site:$SITE -n 'ded|web|staging|managed' \\ -c 'sudo service safe-httpd start; \\ for i in 5.3 5.5 5.6 7.0; \\ do sudo service php-fpm-${i} restart_all; \\ done' If the issue is still not resolved, escalate to a senior member of Ops. Gluster 3.4 If ah-config-gluster fails and has the following, then there is a problem with one of the glusterfsd processes. ah-config-gluster[7058]: Mounting didn't succeed, retrying. ah-config-gluster[7058]: Mounting didn't succeed, retrying. ah-config-gluster[7058]: Mounting didn't succeed, retrying. ah-config-gluster[7058]: Mounting didn't succeed, retrying. ah-config-gluster[7058]: Mounting didn't succeed, retrying. Ensure glusterfsd is not in disk wait, is not I/O bound, or is not otherwise consuming excessive resources. fpdsh -t site:$SITE -n 'ded|fs|fsdb|fsdbmesh' \\ -c 'sudo ps aux | grep [g]lusterfsd' Check to see if there have been any OOMs recently. fpdsh -t site:$SITE -n 'ded|fs|fsdb|fsdbmesh' \\ -c 'sudo dmesg | grep -i oom' Run strace to see if stat() calls are taking longer than 1 second. The number at the end of each line indicates the number of seconds a particular call took. If a call takes longer than a second, this is indicative of a potential problem with glusterfsd on the gluster servers (ded, fs, fsdb, fsdbmesh, etc.) PID=$(pgrep php-fpm | sort -R | head -n1) strace -f -p $PID -s 2048 -T -e trace='stat' # Example: # [14:04:13] root@web-10881.prod:~# PID=$(pgrep php-fpm | sort -R | head -n1) # [14:04:14] root@web-10881.prod:~# strace -f -p $PID -s 2048 -T -e trace='stat' # Process 5719 attached - interrupt to quit # stat(\"(FILE)\", {st_mode=S_IFREG|0550, st_size=19894, ...}) = 0 <0.000388> Check to see if Gluster 3.4 has more than 1 peer listed in /var/lib/glusterd/peers/ . SITE= fpdsh -t site:${SITE} -n 'ded|fs|fsdb|fsdbmesh' \\ -c \"sudo grep -Po '[a-z]\\w+-\\w+-.*' /var/lib/glusterd/glusterd.info\" fpdsh -t site:${SITE} -n 'ded|fs|fsdb|fsdbmesh' \\ -c \"sudo find /var/lib/glusterd/peers/ -type f | sudo xargs cat\" If there are rogue UUIDs, you can move them out of the way by hand. (Example below.) $ mv -v {,../${USER}-}b70e098a-eead-4fa6-b082-d7799f660f23 `b70e098a-eead-4fa6-b082-d7799f660f23' -> `../pingram-b70e098a-eead-4fa6-b082-d7799f660f23' Re-run ah-config-gluster to ensure current configs are deployed. fpdsh -t site:$SITE -n 'ded|fs|fsdb|fsdbmesh|web|staging|managed' \\ -c 'sudo ah-config-gluster' Forcefully unmount gluster (twice). fpdsh -t site:$SITE -n 'ded|fs|fsdb|fsdbmesh|web|staging|managed' \\ -c 'sudo umount -f /mnt/gfs; sudo umount -f /mnt/gfs' Kill all the fpm processes that might be accessing the stale mount and stop apache2. fpdsh -t site:$SITE -n 'ded|web|staging|managed' \\ -c 'sudo pkill -9 \"php-fpm\"; sudo service safe-httpd stop' Restart glusterfsd on the gluster servers. On Precise: fpdsh -t site:$SITE -n 'ded|fs|fsdb|fsdbmesh' -c 'sudo service glusterfs-server restart' On Xenial: fpdsh -t site:$SITE -n 'ded|fs|fsdb|fsdbmesh' -c 'sudo systemctl restart glusterfs-server.service' Remount gluster. site-fsremount $SITE Restart apache2 and fpm processes. fpdsh -t site:$SITE -n 'ded|web|staging|managed' \\ -c 'sudo service safe-httpd start; \\ for i in 5.3 5.5 5.6 7.0; \\ do sudo service php-fpm-${i} restart_all; \\ done' If the issue is still not resolved, escalate to a senior member of Ops. Last Resort: Build a new FS Cluster This process should only be undertaken under approval from a senior Ops team member or Ops management and after all other options have been exhausted. TODO: Document this process.","title":"Check Gluster Transport endpoint error"},{"location":"incident_response/check_gluster_transport_endpoint_error/#check-gluster-transport-endpoint-error","text":"The glusterfs mount point on the local server, /mnt/gfs , is in some way impaired. This can be caused by network blips, server side issues or a dead client process.","title":"Check Gluster Transport endpoint error"},{"location":"incident_response/check_gluster_transport_endpoint_error/#response","text":"Determine if all servers in the site need to be remounted or just a specific server. Remounting gluster has the potential to cause an outage. Only perform a site-wide remount if all , or the majority, of gluster fs clients have the same alert. Check the site's gluster mount status. site-checkgluster $SITE If any servers report failures, use the server method below.","title":"Response"},{"location":"incident_response/check_gluster_transport_endpoint_error/#site-wide-gluster-remount","text":"Review the state of gluster across the site site-checkgluster $SITE If there has been recent maintenance or the gluster client has OOMed and you are sure that you want to remount gluster across the entire site (including hosts in passive MR regions), you can attempt to remount all hosts. site-fsremount $SITE Restart apache and FPM for the site to clear any processes that might be holding or hitting stale resources. fpdsh -t site:$SITE -n 'ded|web|staging|managed' -c 'sudo service safe-httpd restart' site-restartfpm $SITE","title":"Site-wide gluster remount"},{"location":"incident_response/check_gluster_transport_endpoint_error/#server-specific-gluster-remount","text":"Review the state of the gluster mount. fssh $SERVER df -h Remount gluster for the server sv-fsremount $SERVER If gluster remounting fails to work there are several courses of action, depending on the error and version of Gluster.","title":"Server-specific gluster remount"},{"location":"incident_response/check_gluster_transport_endpoint_error/#advanced-troubleshooting","text":"","title":"Advanced Troubleshooting"},{"location":"incident_response/check_gluster_transport_endpoint_error/#gluster-30","text":"Ensure glusterfsd is not in disk wait, is not I/O bound, or is not otherwise consuming excessive resources. fpdsh -t site:$SITE -n 'ded|fs|fsdb|fsdbmesh' \\ -c 'sudo ps aux | grep [g]lusterfsd' Check to see if there have been any OOMs recently. fpdsh -t site:$SITE -n 'ded|fs|fsdb|fsdbmesh' \\ -c 'sudo dmesg | grep -i oom' Run strace to see if stat() calls are taking longer than 1 second. The number at the end of each line indicates the number of seconds a particular call took. If a call takes longer than a second, this is indicative of a potential problem with glusterfsd on the gluster servers (ded, fs, fsdb, fsdbmesh, etc.) PID=$(pgrep php-fpm | sort -R | head -n1) strace -f -p $PID -s 2048 -T -e trace='stat' # Example: # [14:04:13] root@web-10881.prod:~# PID=$(pgrep php-fpm | sort -R | head -n1) # [14:04:14] root@web-10881.prod:~# strace -f -p $PID -s 2048 -T -e trace='stat' # Process 5719 attached - interrupt to quit # stat(\"(FILE)\", {st_mode=S_IFREG|0550, st_size=19894, ...}) = 0 <0.000388> Re-run fields-config-fs-server.php and fields-config-fs-client.php to ensure current configs are deployed. fpdsh -t site:$SITE -n 'ded|fs|fsdb|fsdbmesh' -c 'sudo fields-config-fs-server.php' fpdsh -t site:$SITE -n 'ded|fs|fsdb|fsdbmesh|web|staging|managed' \\ -c 'sudo fields-config-fs-client.php' Forcefully unmount gluster (twice). fpdsh -t site:$SITE -n 'ded|fs|fsdb|fsdbmesh|web|staging|managed' \\ -c 'sudo umount -f /mnt/gfs; sudo umount -f /mnt/gfs' Kill all the gluster processes that could be stalled. fpdsh -t site:$SITE -n 'ded|fs|fsdb|fsdbmesh|web|staging|managed' -c 'sudo pkill glusterfsd' Kill all the fpm processes that might be accessing the stale mount and stop apache2. fpdsh -t site:$SITE -n 'ded|web|staging|managed' \\ -c 'sudo pkill -9 \"php-fpm\"; sudo service safe-httpd stop' Restart glusterfsd on the gluster servers. fpdsh -t site:$SITE -n 'ded|fs|fsdb|fsdbmesh' -c 'sudo service glusterfs-server restart' Remount gluster. site-fsremount $SITE Restart apache2 and fpm processes. fpdsh -t site:$SITE -n 'ded|web|staging|managed' \\ -c 'sudo service safe-httpd start; \\ for i in 5.3 5.5 5.6 7.0; \\ do sudo service php-fpm-${i} restart_all; \\ done' If the issue is still not resolved, escalate to a senior member of Ops.","title":"Gluster 3.0"},{"location":"incident_response/check_gluster_transport_endpoint_error/#gluster-34","text":"If ah-config-gluster fails and has the following, then there is a problem with one of the glusterfsd processes. ah-config-gluster[7058]: Mounting didn't succeed, retrying. ah-config-gluster[7058]: Mounting didn't succeed, retrying. ah-config-gluster[7058]: Mounting didn't succeed, retrying. ah-config-gluster[7058]: Mounting didn't succeed, retrying. ah-config-gluster[7058]: Mounting didn't succeed, retrying. Ensure glusterfsd is not in disk wait, is not I/O bound, or is not otherwise consuming excessive resources. fpdsh -t site:$SITE -n 'ded|fs|fsdb|fsdbmesh' \\ -c 'sudo ps aux | grep [g]lusterfsd' Check to see if there have been any OOMs recently. fpdsh -t site:$SITE -n 'ded|fs|fsdb|fsdbmesh' \\ -c 'sudo dmesg | grep -i oom' Run strace to see if stat() calls are taking longer than 1 second. The number at the end of each line indicates the number of seconds a particular call took. If a call takes longer than a second, this is indicative of a potential problem with glusterfsd on the gluster servers (ded, fs, fsdb, fsdbmesh, etc.) PID=$(pgrep php-fpm | sort -R | head -n1) strace -f -p $PID -s 2048 -T -e trace='stat' # Example: # [14:04:13] root@web-10881.prod:~# PID=$(pgrep php-fpm | sort -R | head -n1) # [14:04:14] root@web-10881.prod:~# strace -f -p $PID -s 2048 -T -e trace='stat' # Process 5719 attached - interrupt to quit # stat(\"(FILE)\", {st_mode=S_IFREG|0550, st_size=19894, ...}) = 0 <0.000388> Check to see if Gluster 3.4 has more than 1 peer listed in /var/lib/glusterd/peers/ . SITE= fpdsh -t site:${SITE} -n 'ded|fs|fsdb|fsdbmesh' \\ -c \"sudo grep -Po '[a-z]\\w+-\\w+-.*' /var/lib/glusterd/glusterd.info\" fpdsh -t site:${SITE} -n 'ded|fs|fsdb|fsdbmesh' \\ -c \"sudo find /var/lib/glusterd/peers/ -type f | sudo xargs cat\" If there are rogue UUIDs, you can move them out of the way by hand. (Example below.) $ mv -v {,../${USER}-}b70e098a-eead-4fa6-b082-d7799f660f23 `b70e098a-eead-4fa6-b082-d7799f660f23' -> `../pingram-b70e098a-eead-4fa6-b082-d7799f660f23' Re-run ah-config-gluster to ensure current configs are deployed. fpdsh -t site:$SITE -n 'ded|fs|fsdb|fsdbmesh|web|staging|managed' \\ -c 'sudo ah-config-gluster' Forcefully unmount gluster (twice). fpdsh -t site:$SITE -n 'ded|fs|fsdb|fsdbmesh|web|staging|managed' \\ -c 'sudo umount -f /mnt/gfs; sudo umount -f /mnt/gfs' Kill all the fpm processes that might be accessing the stale mount and stop apache2. fpdsh -t site:$SITE -n 'ded|web|staging|managed' \\ -c 'sudo pkill -9 \"php-fpm\"; sudo service safe-httpd stop' Restart glusterfsd on the gluster servers. On Precise: fpdsh -t site:$SITE -n 'ded|fs|fsdb|fsdbmesh' -c 'sudo service glusterfs-server restart' On Xenial: fpdsh -t site:$SITE -n 'ded|fs|fsdb|fsdbmesh' -c 'sudo systemctl restart glusterfs-server.service' Remount gluster. site-fsremount $SITE Restart apache2 and fpm processes. fpdsh -t site:$SITE -n 'ded|web|staging|managed' \\ -c 'sudo service safe-httpd start; \\ for i in 5.3 5.5 5.6 7.0; \\ do sudo service php-fpm-${i} restart_all; \\ done' If the issue is still not resolved, escalate to a senior member of Ops.","title":"Gluster 3.4"},{"location":"incident_response/check_gluster_transport_endpoint_error/#last-resort-build-a-new-fs-cluster","text":"This process should only be undertaken under approval from a senior Ops team member or Ops management and after all other options have been exhausted. TODO: Document this process.","title":"Last Resort: Build a new FS Cluster"},{"location":"incident_response/check_perfmon_data_is_recent/","text":"Check perfmon data is recent The perf-mon server has gotten stuck and is no longer checking sites. While Ops will still be alerted about sites being down, the data used for calculating uptimes for SLAs is not being written. NOTE: Currently only Managed Cloud is monitored this way. A generic solution is on the way for all stages. Automation Automated resolution is set for this alert in the form of a Nagios event handler, so unless the automation breaks, you should never get this alert. If it ever breaks, resolve the alert manually and check /mnt/logs/nagios-kill_perf_mon_checks.log on mon3.ops-mon-2.acquia.com to determine why the automation failed and file an OPE to fix it. Manual Resolution SSH into the the perf-mon.acquia.com instance. ssh perf-mon.acquia.com Kill all check_http processes. sudo pkill check_http Verify sites start getting checked The checks get logged to /root/bin/logs/run-checks.log . Tailing that file a minute after killing the stuck check_http process and seeing \"Sucess: checks complete\" is good. sudo tail -f /root/bin/logs/run-checks.log Manually running the check that NRPE would run a minute after fixing check_http is another alternative, looking for an \"OK\" result. sudo /usr/lib/nagios/plugins/check_perfmon_data","title":"Check perfmon data is recent"},{"location":"incident_response/check_perfmon_data_is_recent/#check-perfmon-data-is-recent","text":"The perf-mon server has gotten stuck and is no longer checking sites. While Ops will still be alerted about sites being down, the data used for calculating uptimes for SLAs is not being written. NOTE: Currently only Managed Cloud is monitored this way. A generic solution is on the way for all stages.","title":"Check perfmon data is recent"},{"location":"incident_response/check_perfmon_data_is_recent/#automation","text":"Automated resolution is set for this alert in the form of a Nagios event handler, so unless the automation breaks, you should never get this alert. If it ever breaks, resolve the alert manually and check /mnt/logs/nagios-kill_perf_mon_checks.log on mon3.ops-mon-2.acquia.com to determine why the automation failed and file an OPE to fix it.","title":"Automation"},{"location":"incident_response/check_perfmon_data_is_recent/#manual-resolution","text":"SSH into the the perf-mon.acquia.com instance. ssh perf-mon.acquia.com Kill all check_http processes. sudo pkill check_http","title":"Manual Resolution"},{"location":"incident_response/check_perfmon_data_is_recent/#verify-sites-start-getting-checked","text":"The checks get logged to /root/bin/logs/run-checks.log . Tailing that file a minute after killing the stuck check_http process and seeing \"Sucess: checks complete\" is good. sudo tail -f /root/bin/logs/run-checks.log Manually running the check that NRPE would run a minute after fixing check_http is another alternative, looking for an \"OK\" result. sudo /usr/lib/nagios/plugins/check_perfmon_data","title":"Verify sites start getting checked"},{"location":"incident_response/check_possible_hung_tasks/","text":"Check Possible Hung Tasks Task processes have been running for over 24 hours, indicating the associated task is stuck, dead, or very long running. Response Get task info: TASK_SERVER= sv-stucktasks $TASK_SERVER If there are multiple task servers alerting, it may be worth grabbing them all up and handling them in one ticket: for TASK_SERVER in $(ah-server list % -w type=task status=0); \\ do sv-stucktasks $TASK_SERVER; \\ done Get task log output: fssh $TASK_SERVER \"sudo cat /mnt/acquia/task-server/$TASK_ID/output\" Tasks are handled differently by type (queue). Anything that DOES NOT involve a data transfer If the task is of type relaunch or reboot , ensure the host is online and check its status: sv-up $SERVER ah-server list ${SERVER}+ -c status If the status is anything but 0 , escalate the issue and note your findings in the OP ticket. For other non-copy or non-migration tasks, proceed to kill the task . Database and file copies (copy, migrate, etc.) When databases and files are large or poorly structured, these tasks can take a long time to complete. It is not sufficient to verify that syscalls aren't happening, kill the task, and then restart it. If you cannot verify that the data transfer is still happening or is not happening with the methods below, then the issue must be escalated. Check for rebooted/relaunched remote servers SSH to the task server and find the ssh host connections for the task: fssh $TASK_SERVER sudo su TASK_ID= PID=$(ps aux | grep $TASK_ID | awk {'print $2'}) ps --forest -f -w -s $(ps -p $PID -jf --no-header | awk '{ print $5 }') Read the ssh hosts from the ssh commands and check their uptime: fssh $HOST1 'uptime' fssh $HOST2 'uptime' Compare the boot times with the S-TIME column from the previous ps command or run the following if that time is not precise enough for a decision: ps -o lstart -p $PID If either server has rebooted since the start of the task process or the \"created\" time on the task, kill the task and note it in the OP ticket. Check for Data Transfer These methods are performed on the destination remote server. These methods can only demonstrate that the transfer is running. It is not possible to prove that the transfer is stuck, except by showing that the server has been rebooted as above. Try the following and paste the output in the ticket: Generic methods to try include: monitor the output of du and/or df for the mountpoint of interest: watch -n1 \"df $MOUNTPOINT\" watch the rx columns to verify that data is coming in: iostat -mx 1 $MOUNTPOINT For mysql transfers, we can check that statements are being fed in with: watch sudo mysqladmin processList If you are satisfied that the task is transferring data, note the task as long-running in the ticket and label the ticket with the 'handover' label. Check for Disk Full Sometimes the destination does not have sufficient space available to accept the incoming data. Check disk space utilization df -h /mnt /vol/ebs1 /mnt/brick* If the volume is 100% full, send a crit to support and kill the task: ah-task kill $TASK_ID Kill the Task Only use this as a last resort . Kill the task: ah-task kill $TASK_ID Note in the ticket that you killed the task. If the task is of type vcs-commit or ah-callback , restart it: ah-task restart $TASK_ID","title":"Check Possible Hung Tasks"},{"location":"incident_response/check_possible_hung_tasks/#check-possible-hung-tasks","text":"Task processes have been running for over 24 hours, indicating the associated task is stuck, dead, or very long running.","title":"Check Possible Hung Tasks"},{"location":"incident_response/check_possible_hung_tasks/#response","text":"Get task info: TASK_SERVER= sv-stucktasks $TASK_SERVER If there are multiple task servers alerting, it may be worth grabbing them all up and handling them in one ticket: for TASK_SERVER in $(ah-server list % -w type=task status=0); \\ do sv-stucktasks $TASK_SERVER; \\ done Get task log output: fssh $TASK_SERVER \"sudo cat /mnt/acquia/task-server/$TASK_ID/output\" Tasks are handled differently by type (queue).","title":"Response"},{"location":"incident_response/check_possible_hung_tasks/#anything-that-does-not-involve-a-data-transfer","text":"If the task is of type relaunch or reboot , ensure the host is online and check its status: sv-up $SERVER ah-server list ${SERVER}+ -c status If the status is anything but 0 , escalate the issue and note your findings in the OP ticket. For other non-copy or non-migration tasks, proceed to kill the task .","title":"Anything that DOES NOT involve a data transfer"},{"location":"incident_response/check_possible_hung_tasks/#database-and-file-copies-copy-migrate-etc","text":"When databases and files are large or poorly structured, these tasks can take a long time to complete. It is not sufficient to verify that syscalls aren't happening, kill the task, and then restart it. If you cannot verify that the data transfer is still happening or is not happening with the methods below, then the issue must be escalated.","title":"Database and file copies (copy, migrate, etc.)"},{"location":"incident_response/check_possible_hung_tasks/#check-for-rebootedrelaunched-remote-servers","text":"SSH to the task server and find the ssh host connections for the task: fssh $TASK_SERVER sudo su TASK_ID= PID=$(ps aux | grep $TASK_ID | awk {'print $2'}) ps --forest -f -w -s $(ps -p $PID -jf --no-header | awk '{ print $5 }') Read the ssh hosts from the ssh commands and check their uptime: fssh $HOST1 'uptime' fssh $HOST2 'uptime' Compare the boot times with the S-TIME column from the previous ps command or run the following if that time is not precise enough for a decision: ps -o lstart -p $PID If either server has rebooted since the start of the task process or the \"created\" time on the task, kill the task and note it in the OP ticket.","title":"Check for rebooted/relaunched remote servers"},{"location":"incident_response/check_possible_hung_tasks/#check-for-data-transfer","text":"These methods are performed on the destination remote server. These methods can only demonstrate that the transfer is running. It is not possible to prove that the transfer is stuck, except by showing that the server has been rebooted as above. Try the following and paste the output in the ticket: Generic methods to try include: monitor the output of du and/or df for the mountpoint of interest: watch -n1 \"df $MOUNTPOINT\" watch the rx columns to verify that data is coming in: iostat -mx 1 $MOUNTPOINT For mysql transfers, we can check that statements are being fed in with: watch sudo mysqladmin processList If you are satisfied that the task is transferring data, note the task as long-running in the ticket and label the ticket with the 'handover' label.","title":"Check for Data Transfer"},{"location":"incident_response/check_possible_hung_tasks/#check-for-disk-full","text":"Sometimes the destination does not have sufficient space available to accept the incoming data. Check disk space utilization df -h /mnt /vol/ebs1 /mnt/brick* If the volume is 100% full, send a crit to support and kill the task: ah-task kill $TASK_ID","title":"Check for Disk Full"},{"location":"incident_response/check_possible_hung_tasks/#kill-the-task","text":"Only use this as a last resort . Kill the task: ah-task kill $TASK_ID Note in the ticket that you killed the task. If the task is of type vcs-commit or ah-callback , restart it: ah-task restart $TASK_ID","title":"Kill the Task"},{"location":"incident_response/check_ssl_certificate/","text":"Check SSL Certificate A SSL cert is approaching its expiration date Resolution If the cert is a shared UCC or for an Acquian service then renew it. Check if the alerting cert is the default cert SITE=<site name> DEFAULT_FQDN=$(ah-site list ${SITE} --no-name -c default_fqdn) openssl s_client -connect ${DEFAULT_FQDN}:443 -showcerts \\ < /dev/null | openssl x509 -noout -text \\ | grep \"Not \\|DNS\" If the default cert is the one which is alerting, do not crit to the customer or support and resintall the certificate using the following command BALS=($(ah-server list site:${SITE} -w type=bal )) for BAL in ${BALS[@]} do ah-edge remove-balancer-default-certificate-override --server-name=${BAL} done If the custom certs are alerting, then crit to support and customer and downtime the alert Note In ACSF we proxy/followers sites. This means that all SSL hooks in HAPI will be bound to proxy site. Keep that in mind when handling certificates, if you are looking for SNI certificates use the proxy site, usually the one from prod stage. For example, if you want to check the SSL information from pwcacsf01live use pwcacsfprod instead. Check if the customer has SNI with an updated certificate and mention it in the ticket SITE= ah-site ssl show ${SITE} Check the vailidity CUSTOM_DOMAIN=<any domain hosted on the site and is in the custom cert> openssl s_client -connect ${DEFAULT_FQDN}:443 \\ -servername ${CUSTOM_DOMAIN} -showcerts < /dev/null | \\ openssl x509 -noout -text | grep \"Not \\|DNS Crit to support and customer using ssl expiration template BAL=bal-xxx OP_URL=https://backlog.acquia.com/browse/OP-xxxxx ticket-ng normal --server=$BAL \\ --template=\"Your SSL certificate is expiring soon\" \\ --jira-ticket=$OP_URL Downtime the alert for 2 weeks or a few days if it expires within 7 days. SSL_TAG= MINUTES= OP= for BAL in $(ah-server list tag:${SSL_TAG}); do sv-downtimeservice ${BAL} 'Check SSL Certificate' ${MINUTES} ${OP} done If the certificate is expired, or replaced by SNI, remove it by replacing it with the acquia default cert. Check the infrastructure the environment is on and use the proper link below, first link for legacy balancers, the second for edge clusters. Remove a certificate override (Legacy balancer) Remove a certificate override (Edge cluster) Note The later scenario, where a direct install certificate was replaced by a SNI certificate, will most likely occur in ACSF after introduction of SSL self service. Keep in mind that after the use of SSL self service, the direct install certificate will remain in the hosting site's default_fqdn which will trigger alerts for OPS. In that case, simply remove the certificate override (direct install) using the links above. Close the ticket and comment that you removed the expired cert and that they should open a new ticket if they need to replace the cert.","title":"Check SSL Certificate"},{"location":"incident_response/check_ssl_certificate/#check-ssl-certificate","text":"A SSL cert is approaching its expiration date","title":"Check SSL Certificate"},{"location":"incident_response/check_ssl_certificate/#resolution","text":"If the cert is a shared UCC or for an Acquian service then renew it. Check if the alerting cert is the default cert SITE=<site name> DEFAULT_FQDN=$(ah-site list ${SITE} --no-name -c default_fqdn) openssl s_client -connect ${DEFAULT_FQDN}:443 -showcerts \\ < /dev/null | openssl x509 -noout -text \\ | grep \"Not \\|DNS\" If the default cert is the one which is alerting, do not crit to the customer or support and resintall the certificate using the following command BALS=($(ah-server list site:${SITE} -w type=bal )) for BAL in ${BALS[@]} do ah-edge remove-balancer-default-certificate-override --server-name=${BAL} done If the custom certs are alerting, then crit to support and customer and downtime the alert Note In ACSF we proxy/followers sites. This means that all SSL hooks in HAPI will be bound to proxy site. Keep that in mind when handling certificates, if you are looking for SNI certificates use the proxy site, usually the one from prod stage. For example, if you want to check the SSL information from pwcacsf01live use pwcacsfprod instead. Check if the customer has SNI with an updated certificate and mention it in the ticket SITE= ah-site ssl show ${SITE} Check the vailidity CUSTOM_DOMAIN=<any domain hosted on the site and is in the custom cert> openssl s_client -connect ${DEFAULT_FQDN}:443 \\ -servername ${CUSTOM_DOMAIN} -showcerts < /dev/null | \\ openssl x509 -noout -text | grep \"Not \\|DNS Crit to support and customer using ssl expiration template BAL=bal-xxx OP_URL=https://backlog.acquia.com/browse/OP-xxxxx ticket-ng normal --server=$BAL \\ --template=\"Your SSL certificate is expiring soon\" \\ --jira-ticket=$OP_URL Downtime the alert for 2 weeks or a few days if it expires within 7 days. SSL_TAG= MINUTES= OP= for BAL in $(ah-server list tag:${SSL_TAG}); do sv-downtimeservice ${BAL} 'Check SSL Certificate' ${MINUTES} ${OP} done If the certificate is expired, or replaced by SNI, remove it by replacing it with the acquia default cert. Check the infrastructure the environment is on and use the proper link below, first link for legacy balancers, the second for edge clusters. Remove a certificate override (Legacy balancer) Remove a certificate override (Edge cluster) Note The later scenario, where a direct install certificate was replaced by a SNI certificate, will most likely occur in ACSF after introduction of SSL self service. Keep in mind that after the use of SSL self service, the direct install certificate will remain in the hosting site's default_fqdn which will trigger alerts for OPS. In that case, simply remove the certificate override (direct install) using the links above. Close the ticket and comment that you removed the expired cert and that they should open a new ticket if they need to replace the cert.","title":"Resolution"},{"location":"incident_response/critical_service_port_revoked/","text":"Critical Service Port Revoked There are various service ports critical to the operation of Acquia's infrastructure. An outage can occur when one of these ports is revoked during a change to a Security Group. A list of service ports considered to be critical can be found here: Authorized Ports, Protocols, and Services . AWS CloudTrail periodically sends logs to Sumo Logic, and if Sumo detects that one of these critical ports has been revoked, it will notify the Incident Response team by creating an ISI ticket and posting an alert in their Slack channel. Operations does not receieve a pagerduty alert, but the IR team's bot will post the alert to #ops-alerts in slack, letting us know which AWS account it happened in, which port was revoked, who did it, etc. For more info on how this alerting workflow works, please see the IR team's confluence page . What to Do Communicate with the Incident Response team The IR team will likely hear about the alert first, since they get paged, and will ping the on-call person in #team-ops. If any Ops actions are required, file an OP ticket and keep track of your actions there. The IR team may also choose to create a public SEC ticket. If an OP and SEC ticket are both created, link them together. Log into the AWS Console Incase the Incident Response bot doesn't give you all the necessary information, or the IR team needs more details, you can log into the AWS account in which the port was revoked and look at CloudTrail. Log into the relevant AWS account. Under Find Services on the home page, type CloudTrail and select it. Once you are on the CloudTrail page, on the left click Event history . Then filter by Event name, and search for RevokeSecurityGroupIngress . You can expand events here for more details. Click View event at the bottom to see more information on what happened, including the details on which port(s) were revoked. Fix the Issue Do not try to manually fix the issue yourself right away. You should know by now what changed and who made the change. Ping the person responsible and ask if the change was done intentionally. If they are offline, go in their team's chatroom and find someone to ask there.","title":"Critical Service Port Revoked"},{"location":"incident_response/critical_service_port_revoked/#critical-service-port-revoked","text":"There are various service ports critical to the operation of Acquia's infrastructure. An outage can occur when one of these ports is revoked during a change to a Security Group. A list of service ports considered to be critical can be found here: Authorized Ports, Protocols, and Services . AWS CloudTrail periodically sends logs to Sumo Logic, and if Sumo detects that one of these critical ports has been revoked, it will notify the Incident Response team by creating an ISI ticket and posting an alert in their Slack channel. Operations does not receieve a pagerduty alert, but the IR team's bot will post the alert to #ops-alerts in slack, letting us know which AWS account it happened in, which port was revoked, who did it, etc. For more info on how this alerting workflow works, please see the IR team's confluence page .","title":"Critical Service Port Revoked"},{"location":"incident_response/critical_service_port_revoked/#what-to-do","text":"","title":"What to Do"},{"location":"incident_response/critical_service_port_revoked/#communicate-with-the-incident-response-team","text":"The IR team will likely hear about the alert first, since they get paged, and will ping the on-call person in #team-ops. If any Ops actions are required, file an OP ticket and keep track of your actions there. The IR team may also choose to create a public SEC ticket. If an OP and SEC ticket are both created, link them together.","title":"Communicate with the Incident Response team"},{"location":"incident_response/critical_service_port_revoked/#log-into-the-aws-console","text":"Incase the Incident Response bot doesn't give you all the necessary information, or the IR team needs more details, you can log into the AWS account in which the port was revoked and look at CloudTrail. Log into the relevant AWS account. Under Find Services on the home page, type CloudTrail and select it. Once you are on the CloudTrail page, on the left click Event history . Then filter by Event name, and search for RevokeSecurityGroupIngress . You can expand events here for more details. Click View event at the bottom to see more information on what happened, including the details on which port(s) were revoked.","title":"Log into the AWS Console"},{"location":"incident_response/critical_service_port_revoked/#fix-the-issue","text":"Do not try to manually fix the issue yourself right away. You should know by now what changed and who made the change. Ping the person responsible and ask if the change was done intentionally. If they are offline, go in their team's chatroom and find someone to ask there.","title":"Fix the Issue"},{"location":"incident_response/db_binlogs/","text":"MySQL binary log troubleshooting MySQL binary logs are part of the MySQL replication mechanism. Changes on a master get stored in the binary logs which the slave then retrieves so it can execute those commands and bring the database into the same state as the master. This page describes the different problems that can occur with binary logs and how to troubleshoot them. These issues are a subset of the replication issues that can occur within MySQL on our platform. Out of disk space This is perhaps the most common problem that we see with binary logs. The volume that the binary logs are stored on fills up and MySQL can no longer write to the binary logs. MySQL will still accept new connections and certain select statements can still be executed but all writes will hang until disk space is cleared up. MySQL will check every 60 seconds if space is available to continue so even if you free up space MySQL may take up to a minute to get going again. Verify the problem The quickest way to verify that the volume is full is to run df. If this shows 20KB or less space available for the volume where the binary logs are stored, MySQL can no longer process writes. Binary logs can be stored in 2 different locations. For all clustered database servers (fsdb, ded, dbmaster, dbmesh and fsdbmesh) they are stored in /vol/ebs1/mysql (the MySQL data directory on the sdm volume) and for staging servers they are stored in /mnt/tmp/mysql (the temp table directory on ephemeral storage). Other database servers types (srv and free) do no have binary logs enabled so this issue should not occur on those server types. Alternatively you can check the end of the MySQL error log which will show the following messages. 160825 22:09:28 [ERROR] /usr/sbin/mysqld: Disk is full writing './binlog.000143' (Errcode: 28). Waiting for someone to free space... (Expect up to 60 secs delay for server to continue after freeing disk space) 160825 22:09:28 [ERROR] /usr/sbin/mysqld: Retry in 60 secs. Message reprinted in 600 secs Also verify how much space the binary logs are actually using on the volume. It is possible that the databases have grown so much that there is very little space left for the binary logs. In that case a volume upsize is the best solution. Verify the cause If the volume containing the binary logs is full this can have multiple causes. A typical cause is very high write activity by the website. The sqldash page has graphs for showing the rate at which binary logs are being filled and the total amount of disk space being used by binary logs. There is no hard rule for what an acceptable fill rate is for a website since each website is different and volume sizes are different as well but the graphs can be used to see if there has been a spike in recent activity. You can also look at the directory listing for the binary logs. In general, if a customer generates more than one 1.1GB binary file per 20 minutes there is a problem. In the example below there are only 1 or 2 minutes between each binary log file. -rw-rw---- 1 mysql mysql 1.1G Aug 26 15:49 binlog.000145 -rw-rw---- 1 mysql mysql 1.1G Aug 26 15:51 binlog.000146 -rw-rw---- 1 mysql mysql 1.1G Aug 26 15:53 binlog.000147 -rw-rw---- 1 mysql mysql 1.1G Aug 26 15:55 binlog.000148 -rw-rw---- 1 mysql mysql 1.1G Aug 26 15:57 binlog.000149 -rw-rw---- 1 mysql mysql 543M Aug 26 15:58 binlog.000150 In this case the first step should be to alert Support and have them inform the customer of the issue. This is not a platform but an application issue and something in the application is causing the writes. It is also possible that it is a spam attack. Either way, if we free up disk space and don't inform the customer the problem is almost guaranteed to come back very quickly. NOTE :Sometimes binlogs fill out quickly due to high traffic. Please examine the site traffic to look for any IP or USERAGENT hitting the site particularly hard using below commands. site-traffic $SITENAME site-trafficbyuseragent $SITENAME Block the problematic IP or USERAGENT if necessary. Multi-region database servers multi-region db cluster binlog trimming runbook Non-clustered database servers On non-clustered database servers the binary logs are located on ephemeral storage which is shared with other customer files so verify if the binary logs are the problem or the other files. If the binary logs are only 25% or less of the overall space on ephemeral storage it may make more sense to suggest an upsize to a server type with more ephemeral storage. In general you need to purge binary logs to free up space. Unfortunately MySQL needs disk space to purge binary logs. Since the binary logs are not needed for replication you can delete the oldest one and then purge the rest. Run the following command to show the current binary logs: mysql -e \"show binary logs\" Delete the lowest numbered binary log with rm: rm /mnt/tmp/mysql/binlog.N Then run the following command to purge all binary logs up till the current one: mysql -e \"purge binary logs to 'binlog.Z'\" Do not remove the current binary log as that will cause issues for MySQL. If you purge binary logs before creating space the command will just sit there and not finish until the space becomes available to complete the command. Note : Please do not purge binlogs during DB volume upsize even if the site is down. Purging binlogs during a DB volume upsize might corrupt that DB upon finishing. Clustered database servers On clustered database servers the binary logs are used for replication so removing or purging binary log files can break replication if the slave still needs to read them. For ease of explanation, we will call the server that has run of disk space server A and the other server in the database cluster server B. The first step is to verify what the current binary log is that server B is reading. Check the Relay_Master_Log_File value in the SHOW SLAVE STATUS output on server B. [20:40:59] root@fsdb-7.pvanderwal:/vol/ebs1/sb# mysql -e \"show slave status\\G\" | grep \"Relay_Master_Log_File\" Relay_Master_Log_File: binlog.000021 In this example server B is executing statements from binlog.000021 on server A so we're good to purge binary logs up to binlog.000021 on server A. Unfortunately the same problem that applies to non-clustered database servers also applies to clustered database servers which is that MySQL needs space before it can purge binary logs. However, because the binary logs are used for replication we can't just delete them. Check which binary logs there are on server A with SHOW BINARY LOGS. [20:51:15] root@fsdb-8.pvanderwal:~# mysql -e \"show binary logs\" +---------------+-----------+ | Log_name | File_size | +---------------+-----------+ | binlog.000018 | 65947381 | | binlog.000019 | 65945853 | | binlog.000020 | 65948145 | | binlog.000021 | 39692515 | +---------------+-----------+ Move one of the binary logs older than the binary log server B needs (binlog.000021) and newer than the oldest log (binlog.000018) to ephemeral storage for the time being. mv /vol/ebs1/mysql/binlog.000020 /mnt/tmp Now purge the oldest binary log. mysql -e \"purge binary logs to 'binlog.000019'\" Note : Please do not purge binlogs during DB volume upsize even if the site is down. Purging binlogs during a DB volume upsize might corrupt that DB upon finishing. Move the binary log back from ephemeral storage to the data directory and purge the remaining binary logs up to binlog.000021. mv /mnt/tmp/binlog.000020 /vol/ebs1/mysql/ mysql -e \"purge binary logs to 'binlog.000021'\" This should create enough space for the cluster to proceed. Binary log corruption Binary log missing","title":"MySQL binary log troubleshooting"},{"location":"incident_response/db_binlogs/#mysql-binary-log-troubleshooting","text":"MySQL binary logs are part of the MySQL replication mechanism. Changes on a master get stored in the binary logs which the slave then retrieves so it can execute those commands and bring the database into the same state as the master. This page describes the different problems that can occur with binary logs and how to troubleshoot them. These issues are a subset of the replication issues that can occur within MySQL on our platform.","title":"MySQL binary log troubleshooting"},{"location":"incident_response/db_binlogs/#out-of-disk-space","text":"This is perhaps the most common problem that we see with binary logs. The volume that the binary logs are stored on fills up and MySQL can no longer write to the binary logs. MySQL will still accept new connections and certain select statements can still be executed but all writes will hang until disk space is cleared up. MySQL will check every 60 seconds if space is available to continue so even if you free up space MySQL may take up to a minute to get going again.","title":"Out of disk space"},{"location":"incident_response/db_binlogs/#verify-the-problem","text":"The quickest way to verify that the volume is full is to run df. If this shows 20KB or less space available for the volume where the binary logs are stored, MySQL can no longer process writes. Binary logs can be stored in 2 different locations. For all clustered database servers (fsdb, ded, dbmaster, dbmesh and fsdbmesh) they are stored in /vol/ebs1/mysql (the MySQL data directory on the sdm volume) and for staging servers they are stored in /mnt/tmp/mysql (the temp table directory on ephemeral storage). Other database servers types (srv and free) do no have binary logs enabled so this issue should not occur on those server types. Alternatively you can check the end of the MySQL error log which will show the following messages. 160825 22:09:28 [ERROR] /usr/sbin/mysqld: Disk is full writing './binlog.000143' (Errcode: 28). Waiting for someone to free space... (Expect up to 60 secs delay for server to continue after freeing disk space) 160825 22:09:28 [ERROR] /usr/sbin/mysqld: Retry in 60 secs. Message reprinted in 600 secs Also verify how much space the binary logs are actually using on the volume. It is possible that the databases have grown so much that there is very little space left for the binary logs. In that case a volume upsize is the best solution.","title":"Verify the problem"},{"location":"incident_response/db_binlogs/#verify-the-cause","text":"If the volume containing the binary logs is full this can have multiple causes. A typical cause is very high write activity by the website. The sqldash page has graphs for showing the rate at which binary logs are being filled and the total amount of disk space being used by binary logs. There is no hard rule for what an acceptable fill rate is for a website since each website is different and volume sizes are different as well but the graphs can be used to see if there has been a spike in recent activity. You can also look at the directory listing for the binary logs. In general, if a customer generates more than one 1.1GB binary file per 20 minutes there is a problem. In the example below there are only 1 or 2 minutes between each binary log file. -rw-rw---- 1 mysql mysql 1.1G Aug 26 15:49 binlog.000145 -rw-rw---- 1 mysql mysql 1.1G Aug 26 15:51 binlog.000146 -rw-rw---- 1 mysql mysql 1.1G Aug 26 15:53 binlog.000147 -rw-rw---- 1 mysql mysql 1.1G Aug 26 15:55 binlog.000148 -rw-rw---- 1 mysql mysql 1.1G Aug 26 15:57 binlog.000149 -rw-rw---- 1 mysql mysql 543M Aug 26 15:58 binlog.000150 In this case the first step should be to alert Support and have them inform the customer of the issue. This is not a platform but an application issue and something in the application is causing the writes. It is also possible that it is a spam attack. Either way, if we free up disk space and don't inform the customer the problem is almost guaranteed to come back very quickly. NOTE :Sometimes binlogs fill out quickly due to high traffic. Please examine the site traffic to look for any IP or USERAGENT hitting the site particularly hard using below commands. site-traffic $SITENAME site-trafficbyuseragent $SITENAME Block the problematic IP or USERAGENT if necessary.","title":"Verify the cause"},{"location":"incident_response/db_binlogs/#multi-region-database-servers","text":"multi-region db cluster binlog trimming runbook","title":"Multi-region database servers"},{"location":"incident_response/db_binlogs/#non-clustered-database-servers","text":"On non-clustered database servers the binary logs are located on ephemeral storage which is shared with other customer files so verify if the binary logs are the problem or the other files. If the binary logs are only 25% or less of the overall space on ephemeral storage it may make more sense to suggest an upsize to a server type with more ephemeral storage. In general you need to purge binary logs to free up space. Unfortunately MySQL needs disk space to purge binary logs. Since the binary logs are not needed for replication you can delete the oldest one and then purge the rest. Run the following command to show the current binary logs: mysql -e \"show binary logs\" Delete the lowest numbered binary log with rm: rm /mnt/tmp/mysql/binlog.N Then run the following command to purge all binary logs up till the current one: mysql -e \"purge binary logs to 'binlog.Z'\" Do not remove the current binary log as that will cause issues for MySQL. If you purge binary logs before creating space the command will just sit there and not finish until the space becomes available to complete the command. Note : Please do not purge binlogs during DB volume upsize even if the site is down. Purging binlogs during a DB volume upsize might corrupt that DB upon finishing.","title":"Non-clustered database servers"},{"location":"incident_response/db_binlogs/#clustered-database-servers","text":"On clustered database servers the binary logs are used for replication so removing or purging binary log files can break replication if the slave still needs to read them. For ease of explanation, we will call the server that has run of disk space server A and the other server in the database cluster server B. The first step is to verify what the current binary log is that server B is reading. Check the Relay_Master_Log_File value in the SHOW SLAVE STATUS output on server B. [20:40:59] root@fsdb-7.pvanderwal:/vol/ebs1/sb# mysql -e \"show slave status\\G\" | grep \"Relay_Master_Log_File\" Relay_Master_Log_File: binlog.000021 In this example server B is executing statements from binlog.000021 on server A so we're good to purge binary logs up to binlog.000021 on server A. Unfortunately the same problem that applies to non-clustered database servers also applies to clustered database servers which is that MySQL needs space before it can purge binary logs. However, because the binary logs are used for replication we can't just delete them. Check which binary logs there are on server A with SHOW BINARY LOGS. [20:51:15] root@fsdb-8.pvanderwal:~# mysql -e \"show binary logs\" +---------------+-----------+ | Log_name | File_size | +---------------+-----------+ | binlog.000018 | 65947381 | | binlog.000019 | 65945853 | | binlog.000020 | 65948145 | | binlog.000021 | 39692515 | +---------------+-----------+ Move one of the binary logs older than the binary log server B needs (binlog.000021) and newer than the oldest log (binlog.000018) to ephemeral storage for the time being. mv /vol/ebs1/mysql/binlog.000020 /mnt/tmp Now purge the oldest binary log. mysql -e \"purge binary logs to 'binlog.000019'\" Note : Please do not purge binlogs during DB volume upsize even if the site is down. Purging binlogs during a DB volume upsize might corrupt that DB upon finishing. Move the binary log back from ephemeral storage to the data directory and purge the remaining binary logs up to binlog.000021. mv /mnt/tmp/binlog.000020 /vol/ebs1/mysql/ mysql -e \"purge binary logs to 'binlog.000021'\" This should create enough space for the cluster to proceed.","title":"Clustered database servers"},{"location":"incident_response/db_binlogs/#binary-log-corruption","text":"","title":"Binary log corruption"},{"location":"incident_response/db_binlogs/#binary-log-missing","text":"","title":"Binary log missing"},{"location":"incident_response/dead_backup_tasks/","text":"Dead Backup Tasks This alert relates directly to backup tasks in production. This alert takes a different approach to checking backups and instead checks for backups whose run times are in the past. This is indicative of a backup that has not run either due to errors or because the backup system has failed. The alert will tell you the cluster ID(s) which needs fixing. To determine the server_id, you need to run sv-deadbackups Output of sv-deadbackups Dead Backup Tasks: backup_task_ids: 16835 server_ids: 35769 backup_task_ids: 18503 server_ids: 39051 Resolution Specify SERVER_ID as provided from the output of the tool to find the server impacted. SERVER_ID= SERVER=$(ah-server list % -w id=${SERVER_ID}) Ensure there are no volume resize workflows pending or running for the impacted server. ah-workflow list volume_resize_workflow -w body~${SERVER} -c type status step_name body List out the tasks for the impacted server. ah-backup list-tasks ${SERVER} If frequency is set to any value but 3600 and there are no volume resize workflows pending or running, correct it. ah-backup edit-tasks ${SERVER} -a -s frequency=3600 If next_action_time is in the past, but the frequency is set correctly, you will need to escalate to Cloud; ops cannot modify the next_action_time on our own. ah-backup list-tasks ${SERVER} Check recent backup runs for the server in-question. Both tasks should have dates from the current day. ah-backup list-runs ${SERVER} If there is a gap between the current date and the last date of a task or run of a given cluster_type , get the id of the volume that is impacted and find the last date it was backed-up. db-cluster volumes reference /vol/ebs1 while fs-cluster references /vol/backup-ebs . VOLUME_ID can be found using sv-vollist ${SERVER} . VOLUME_ID= fpdsh -t % -n backup -c \"sudo zgrep 'volume ${VOLUME_ID}' /var/log/ahbackup-$(date +%Y%m)* || exit 0\" \\ | sort -k2 | tail If you are unable to find references to the volume in compressed logs, search logs from the current day. fpdsh -t % -n backup -c \"sudo egrep 'volume ${VOLUME_ID}' /var/log/ahbackup* || exit 0\" \\ | dshbak | tail If an error message is presented in the logs relating to the volume, log into the backup host showing the error in logs and provide that information in the OP ticket. You will possibly need to escalate to a more senior member of Ops. If no error message is presented in the logs and ah-backup list-tasks output is still showing either a zero-frequency backup or an old date, escalate to a senior member of Ops and document your findings in the OP.","title":"Dead Backup Tasks"},{"location":"incident_response/dead_backup_tasks/#dead-backup-tasks","text":"This alert relates directly to backup tasks in production. This alert takes a different approach to checking backups and instead checks for backups whose run times are in the past. This is indicative of a backup that has not run either due to errors or because the backup system has failed. The alert will tell you the cluster ID(s) which needs fixing. To determine the server_id, you need to run sv-deadbackups Output of sv-deadbackups Dead Backup Tasks: backup_task_ids: 16835 server_ids: 35769 backup_task_ids: 18503 server_ids: 39051","title":"Dead Backup Tasks"},{"location":"incident_response/dead_backup_tasks/#resolution","text":"Specify SERVER_ID as provided from the output of the tool to find the server impacted. SERVER_ID= SERVER=$(ah-server list % -w id=${SERVER_ID}) Ensure there are no volume resize workflows pending or running for the impacted server. ah-workflow list volume_resize_workflow -w body~${SERVER} -c type status step_name body List out the tasks for the impacted server. ah-backup list-tasks ${SERVER} If frequency is set to any value but 3600 and there are no volume resize workflows pending or running, correct it. ah-backup edit-tasks ${SERVER} -a -s frequency=3600 If next_action_time is in the past, but the frequency is set correctly, you will need to escalate to Cloud; ops cannot modify the next_action_time on our own. ah-backup list-tasks ${SERVER} Check recent backup runs for the server in-question. Both tasks should have dates from the current day. ah-backup list-runs ${SERVER} If there is a gap between the current date and the last date of a task or run of a given cluster_type , get the id of the volume that is impacted and find the last date it was backed-up. db-cluster volumes reference /vol/ebs1 while fs-cluster references /vol/backup-ebs . VOLUME_ID can be found using sv-vollist ${SERVER} . VOLUME_ID= fpdsh -t % -n backup -c \"sudo zgrep 'volume ${VOLUME_ID}' /var/log/ahbackup-$(date +%Y%m)* || exit 0\" \\ | sort -k2 | tail If you are unable to find references to the volume in compressed logs, search logs from the current day. fpdsh -t % -n backup -c \"sudo egrep 'volume ${VOLUME_ID}' /var/log/ahbackup* || exit 0\" \\ | dshbak | tail If an error message is presented in the logs relating to the volume, log into the backup host showing the error in logs and provide that information in the OP ticket. You will possibly need to escalate to a more senior member of Ops. If no error message is presented in the logs and ah-backup list-tasks output is still showing either a zero-frequency backup or an old date, escalate to a senior member of Ops and document your findings in the OP.","title":"Resolution"},{"location":"incident_response/debugging_php/","text":"Debugging PHP Customer sites commonly experience incidents that exhibit symptoms via PHP. As Operations, it is important that we be able to diagnose and help debug PHP to improve site uptime and platform stability. PHP-FPM on our platform executes both customer and Acquia code, so Ops needs to investigate the root cause of any PHP-caused outage with a variety of tools. For example, PHP processes can time-out if a request to an external resource (such as MySQL, the file system, or another site) takes longer than 660 seconds. As of 1.102, any such time-out will print to the site's fpm-error.log . Tools strace If PHP is experiencing problems, identifying the most time-consuming system calls can often provide insight into why. strace can help provide some insight here. This is the most important tool to use any time you find the need to restart PHP-FPM for a customer. If the customer or our engineering teams are going to fix the problem that caused PHP-FPM to become stuck, they need to know what PHP was doing when it happened. PHP-FPM Logs Each web server for any customer site has a dedicated directory into which they put logs relevant to their site code. These logs can provide insight into problems with customer code, configuration settings, or traffic analysis. You can find these logs in /var/log/sites/${SITENAME}/logs/${WEB_NAME}/ . Some of the logs in this directory can be quite large, depending on what modules the customer is using and traffic levels. Not all errors in these logs are relevant, so be careful how you interpret the contents of these log files. The following log files, may be useful to read if you suspect a problem with a specific site. Some of the more common and useful error messages found in each log are described to help with recognizing relevant errors. Please note that this list is not exhaustive of the logs, the potential errors found in the logs, or the potential root causes of any particular error. php-errors.log : Memcache instance could not be initialized : Raised if PHP cannot talk to memcache This may be a sign that the memcache_service_status setting for a site's servers are improperly configured, or that the memcache service needs to be restarted for some reason. PHP Fatal error : This could indicate several problems including (but not limited to): misconfigured memcache_service_status , missing customer modules, bad customer code, file system problems, networking problems, etc. fpm-error.log : server reached max_children setting : Raised when a site is forking too many FPM processes. This is sometimes a sign the customer is underprovisioned. Fatal Error Zend OPcache cannot allocate buffer for interned strings : Raised when FPM hits a soft memory limit This may be an indication that php.ini:opcache.interned_strings_buffer is not properly configured. drupal-watchdog.log : Generally very spammy, approach with caution Illegal offset type in dmemcache_get_multi : May indicate problems with memcache or memory consumption in general.","title":"Debugging PHP"},{"location":"incident_response/debugging_php/#debugging-php","text":"Customer sites commonly experience incidents that exhibit symptoms via PHP. As Operations, it is important that we be able to diagnose and help debug PHP to improve site uptime and platform stability. PHP-FPM on our platform executes both customer and Acquia code, so Ops needs to investigate the root cause of any PHP-caused outage with a variety of tools. For example, PHP processes can time-out if a request to an external resource (such as MySQL, the file system, or another site) takes longer than 660 seconds. As of 1.102, any such time-out will print to the site's fpm-error.log .","title":"Debugging PHP"},{"location":"incident_response/debugging_php/#tools","text":"","title":"Tools"},{"location":"incident_response/debugging_php/#strace","text":"If PHP is experiencing problems, identifying the most time-consuming system calls can often provide insight into why. strace can help provide some insight here. This is the most important tool to use any time you find the need to restart PHP-FPM for a customer. If the customer or our engineering teams are going to fix the problem that caused PHP-FPM to become stuck, they need to know what PHP was doing when it happened.","title":"strace"},{"location":"incident_response/debugging_php/#php-fpm-logs","text":"Each web server for any customer site has a dedicated directory into which they put logs relevant to their site code. These logs can provide insight into problems with customer code, configuration settings, or traffic analysis. You can find these logs in /var/log/sites/${SITENAME}/logs/${WEB_NAME}/ . Some of the logs in this directory can be quite large, depending on what modules the customer is using and traffic levels. Not all errors in these logs are relevant, so be careful how you interpret the contents of these log files. The following log files, may be useful to read if you suspect a problem with a specific site. Some of the more common and useful error messages found in each log are described to help with recognizing relevant errors. Please note that this list is not exhaustive of the logs, the potential errors found in the logs, or the potential root causes of any particular error. php-errors.log : Memcache instance could not be initialized : Raised if PHP cannot talk to memcache This may be a sign that the memcache_service_status setting for a site's servers are improperly configured, or that the memcache service needs to be restarted for some reason. PHP Fatal error : This could indicate several problems including (but not limited to): misconfigured memcache_service_status , missing customer modules, bad customer code, file system problems, networking problems, etc. fpm-error.log : server reached max_children setting : Raised when a site is forking too many FPM processes. This is sometimes a sign the customer is underprovisioned. Fatal Error Zend OPcache cannot allocate buffer for interned strings : Raised when FPM hits a soft memory limit This may be an indication that php.ini:opcache.interned_strings_buffer is not properly configured. drupal-watchdog.log : Generally very spammy, approach with caution Illegal offset type in dmemcache_get_multi : May indicate problems with memcache or memory consumption in general.","title":"PHP-FPM Logs"},{"location":"incident_response/disk_partitions/","text":"Disk Partitions Alert This alert indicates that a volume for the specified server greater than or equal to 95% full. /usr/lib/nagios/plugins/check_disk -X proc -X sysfs -X tmpfs -X devpts \\ -X securityfs -X fuse.glusterfs -w 10% -c 5% Resolution Run df -h to determine which volumes are over the threshold. Include the full output of this command in the ticket. Verify that the volumes are not obviously incorrectly sized: For infrastructure that is not specific to any customer, ensure that the volumes were correctly sized according to the docs for provisioning them. This includes but is not limited to: devcloud bals prod shared bals svn servers Ensure that the /dev/sdn volume is the same size as the /dev/sdo volume attached to the instance for servers on which Acquia backups run: For any HA pair that hosts Gluster, only the server with the lowest-number brick any non-HA server that has a file storage partition, namely staging and srv Run sv-vollist $SERVER to verify that the fields master is consistent with the state of the EBS volumes and the EC2 instance involved, ie an upsize is not in progress and/or was not completed incorrectly. Depending on the volume, different actions need to be taken. See the following sections. multiregion (passive) servers No zendesk ticket is needed for passive fs or fsdbmesh servers filling up. Verify the ah-mrrsync cron is present and determine what server it is running on by looking at the server_id column ah-site cron2 list --site-name=${SITENAME} | grep /usr/local/sbin/ah-mrrsync Log into the server listed in the cron fssh ${CRON_WEB} sudo -i screen -S rsync_delete su - ${SITENAME} Copy the ah-mrrsync script to /tmp cat /usr/local/sbin/ah-mrrsync | sed 's/--verbose/--verbose --delete/' \\ > /tmp/ah-mrrsync && chmod +x /tmp/ah-mrrsync Kill any existing ah-mrrsync / rsync processes pgrep -lf ah-mrrsync Run the script /tmp/ah-mrrsync ${SITENAME} Note :If the script runs for longer than an hour, please investigate why it's taking long time. eg. the rsync script might not been running automatically. bastion servers No zendesk ticket is needed for bastion servers filling up. Need Sudo access on bastion to perform below cleanups Verify the /mnt/tmp/ahsupportbot folder and delete cron.sh-bastion files older than 30 days find /mnt/tmp/ahsupportbot -type f -iname 'cron.sh-bastion*' -mtime +30 -delete Verify the /mnt/tmp/ folder and delete log-analysis files older than 30 days find /mnt/tmp -type f -iname 'log-analysis*' -mtime +30 -delete Take a look at disk usage by user's home directories, identify top 10 User's consuming disk space. du -sh /vol/ebs1/home/* | sort -hr | head -n10 This command may run for several minutes. (you can also run ncdu -x /vol/ebs1/home/ it will scan the entire directories and list all the directories by usage. but here we are only interested in top 10 users.) Ping concern person in the ticket requesting to clean their unused files. RA Servers No zendesk ticket is needed for RA servers filling up. Ping \"@Acquia RA\" in the jira ticket to get their attention, and follow these cleanup steps: /mnt/gfs/sitename.ra/backups/ can be deleted if it is eating space /mnt/gfs/sitename.ra/sites/default/files/sitename can be deleted if it is eating space /mnt/gfs or brick*/home/sitename/sitename-svn can be deleted if it is eating space If /mnt/gfs/sitename.ra/livedev/sitename is the problem, this can be cleared out as well, but RA should be notified since this means an possibly currently running update will fail. This is not a problem as RA can restart the process, RA just needs to know. Large repo directories can also be cleared. RA-Up can always redeploy the repo on the next update. It is important to ping @Acquia RA OR start a 'subscription issue' type ticket in the RA project. RA will contact the client to reduce the size of the repo. CDE (CD Environment) servers No zendesk ticket is needed for CDE volumes filling up. Escalate the issue to the CDE team. CDE servers can be identified by the ode tag. Escalate the issue to the CDE team SVN servers Name Device Mount point Database /dev/xvdm /vol/ebs1 Backup /dev/xvdn /vol/backup-ebs for /vol/ebs1 If the volume with customer repos (/vol/ebs1) alerts for disk space, the issue can often be solved by running git garbage collection (described below). If that does not work, a manual upsize of the volume is necessary. The most expedient approach is to selectively run git gc on some of the repos on the server. While a post-commit hook tries to run git gc on customer repos automatically, it leaves room for improvement, and many gigabytes can often be reclaimed. To start with, take a look at disk usage by repo: For /vol/ebs1: du -sh /vol/ebs1/home/* | sort -h This command may run for several minutes. Because garbage collection involves writing temporary files while running, disk space usage will temporarily increase , so if the disk is very full, larger repos may not have enough space to complete initially. Therefore, it is generally necessary to start with smaller repos and work towards the largest ones. Garbage collection is performed by navigating into one of the repos in the list from du and running git gc . This may take several minutes. It is also possible to script this for all repositories on the server, but be warned that this can run for more than an hour: screen cd VOLUME_THAT_ALERTED # /vol/ebs1/home if on /vol/ebs1 find . -name '*.git' -type d | xargs -P1 -I {} -n 1 git -C {} gc If this fails to bring usage below the alerting threshold, the volume will have to be manually upsized . The disk upsize workflow does not work for svn servers. If at any point you run into trouble or need guidance, page the Pandora Team , using the \"Version Control\" component. It is much better to page early than to allow a disk to fill completely and lead to downtime. for /vol/backup-ebs We should run the backup script 'ah-backup-vcs' manually to sync the data to their backup volume. This script works for svn servers similarly as 'fields-backup-fileserver.php' script works for other servers. We should also take a look at disk usage by repo: For /vol/backup-ebs: du -sh --exclude *.tar.gz /vol/backup-ebs/* | sort -h If ah-backup-vcs does not give back enough space for backup volume (/vol/ebs1 and /vol/backup-ebs/ should have comparable space usage), then we should run the following command to get space back on /vol/backup-ebs/: cd /vol/backup-ebs for i in $(ls | grep -v tar.gz) ; do echo $i/$i.git ; $(cd $i/$i.git && git gc) ; done Ephemeral volumes Name Device Mount point Root volume /dev/xvda / Secondary ephemeral volume /dev/xvdb /mnt/ Note :In case of high root volume usage try apt autoremove -y to remove old packages before trying other stuff to solve the issue. Determine where the space is being used. Keep in mind that other volumes are mounted within each of the mount points. Using -x with du should ignore the other volumes. MOUNTPOINT= du --max-depth 2 -x -h $MOUNTPOINT | sort -rhk 1,1 | head If there is a large file in /var/mail , it is likely improperly configured cron. Find the offending address, crit support with this address, and truncate the file. grep '^To:' /var/mail/$FILE | uniq -c echo -n \"\" > /var/mail/$FILE If there is a large file in /tmp , verify the customer placed it there, crit support that the customer is not using /mnt/tmp, and move the file to /mnt/tmp . ls -l $FILE mv /tmp/$FILE /mnt/tmp/ Note : We shouldn't delete any data from '/mnt/tmp' directory without customer's approval. Also it's not recommended to delete an entire directory under '/mnt/tmp', but if we have to clear out an entire '/mnt/tmp' or '/mnt/tmp/site_name' with customer's approval, specifically file '.contained_tmp' (present under /mnt/tmp/site_name), then we may need to start the socket service manually in that case. If a server has ODE sites (tag ode is present on them), then escalate to CDE team without any delay. If there is a large amount of logs in /mnt/logs ( /var/log symlinks here), delete logs older than a week, delete logs that have been shipped to S3, and force a log rotation. sv-rotatelog $SERVER Use below legacy manual log rotation steps for Search Servers find /mnt/log/ -iname '*.gz' -mtime +7 -delete find /mnt/log/ -iname '*.gz' -perm -1000 -delete screen logrotate -f /etc/logrotate.conf Special case : If Varnish and / or nginx logs on a balancer running on Gen2 hardware have needed to be deleted before (check Jira), emergency upsize the balancer pair to the next cheapest Gen2 instance with more ephemeral storage. File a deal sheet ticket against the AM project by clicking on me. If /mnt/site-delete-backups is found to be consuming more space, delete backup files (in the format 'task-sitegroup-delete-*.gz) older than 7 days. find /mnt/site-delete-backups/ -type f \\( -iname \"task-site*\" -a -iname \"*gz\" \\) -mtime +7 -delete In ACSF, if /mnt/tmp is filling up, do not delete the theme directories. You can run git gc to try to compact some space. Theme directories are located in /mnt/tmp/<sitegroup>.<env>/theme_repo . Customer approval required for this action . If /mnt/www/repo is consuming more space, find the SVN server hosting the customer's repo, note the space consumed by repo on the SVN, then go to the repo directory and run git garbage collection command. SITEGROUP= du -sh /vol/ebs1/home/${SITEGROUP} cd /vol/ebs1/home/${SITEGROUP}/${SITEGROUP}.git git gc --aggressive Check the disk usage again for repo and if there is any change then run FCW on the site. site-fcw <sitename.stage> Also, check if twig cache is consuming more space using the following command and make sure to create a customer facing Zendesk ticket: fpdsh -t site:${SITENAME} -n 'web|ded|staging' -c \"sudo find /mnt/tmp -maxdepth 3 -type d -iname 'twig' -exec du -sh {} For a single server, use the following commands instead: SERVER= fssh $SERVER \"sudo find /mnt/tmp -maxdepth 3 -type d -iname 'twig' -exec du -sh {} +\" If customer approves or is unresponsive and volume is full - confirm with support and clean up twig cache using the following command (set the variable SITENAME with the site name, and run the following command with appropriate set of web/ded/staging). The command below for web servers : fpdsh -t site:${SITENAME} -n web -c \"sudo find /mnt/tmp/${SITENAME}/php_storage/twig -type f -mtime 2 -delete\" NOTE: If it takes long time to cleanup, probably it is better to relaunch the web instead or upsize /mnt volume if needed. In other cases, you need to investigate and determine a cause and resolution on your own. Keep in mind that these volumes are recreated from scratch on relaunch. Handle deleted files consuming space Sometimes, a running process can keep hold of deleted/moved files and the disk space is consumed even though the actual usage is less. This can usually be checked by the difference between du and df command for a given volume. Following commands can be used to verify deleted files are consuming space: lsof +aL1 $MOUNTPOINT or find /proc/*/fd -ls 2> /dev/null | grep '(deleted)' | grep $MOUNTPOINT Once verified that deleted files are consuming space, the space can be reclaimed using the following command: truncate -s 0 /proc/xxx/fd/yyy Note : Be careful while truncating the file descriptors as the process may be holding it up and could cause some issues. This can be used to cleanup space consumed by log files or temporary files. Gluster Volumes Gluster - Common Name Device Mountpoint Gluster (brick) /dev/xvdo /mnt/brickXXX/ Gluster (client) /etc/glusterfs/glusterfs-client.vol /mnt/gfs/ Determine what is taking up the most space. Run du against the gluster brick for greater read performance. MOUNTPOINT=/mnt/brickXXX/ du -h --max-depth=2 $MOUNTPOINT --exclude=.glusterfs | sort -rhk 1,1 | head Crit support with this data. Determine if anything can be removed by consulting the sections below. Downtime the alert for one to three days. Use your judgment and disk usage graphs to determine the growth rate. Primarily focus on 'Days to Fill' graph. Please do not downtime an alert to come out of downtime during someone's weekend on-call shift. sv-diskusage $SERVER sv-downtimeservice $SERVER \"Disk Partitions\" $((60*24*$DAYS)) \\ \"$JIRA_TICKET - $MOUNTPOINT XX%.\" Add an entry to the Handover Document about the downtime. Gluster - ACE Never modify anything directly on the Gluster brick. Always use the client mount. These volumes contain customer data . There are a limited set of files that are okay to delete, but be extra careful when deleting files, and never delete customer files . If any sites have been moved off of this server, then cleanup stale data. After performing a site move, site data gets renamed on the source server to the following: /mnt/gfs/SITENAME-MOVED-task-TASKID. Verify that the site was properly moved by searching in Jira and checking the destination servers. Clean up the moved sites files. rm -rf /mnt/gfs/SITENAME-MOVED-task-TASKID If the guidelines for emergency upsizing are met, perform an emergency upsize to the next supported size. Remember to file a deal sheet ticket against the AM project by clicking on me. Otherwise, the customer will need to delete something or request an upsize. Submit a crit and downtime as normal. Backup Volumes Common Name Device Mount point Backup /dev/xvdm /vol/backup-ebs The backup rsync that /vol/backup-ebs the volume will not to complete if the volume reaches 100% full. In the event that that backup volume fills, then we need to run the backup rsync with the --delete-before command. Copy the backup script to a new location. cp /usr/local/sbin/fields-backup-fileserver.php . Modify the rsync to use --delete-before and confirm. vim fields-backup-fileserver.php diff -u /usr/local/sbin/fields-backup-fileserver.php fields-backup-fileserver.php Run the new backup rsync with --delete-before in a screen. screen ./fields-backup-fileserver.php Database Volumes Warnings Operations is not allowed to purge data without customer consent (except for binlogs) The primary reason Operations is not allowed to purge data without customer consent is because each customer's application is different and may be using databases in unexpected ways. Without knowing the application intimately, Operations can inadvertently introduce additional complexity to an application or cause downtime. Operations is not allowed to move tables or databases to alternate storage (ephemeral, gluster, ramdisk, etc.) There are several reasons why Operations is not allowed to move tables or databases to alternate storage: Gluster Using Gluster for table/database storage is not advisable. Gluster's daemon would see the new file and replicate it to the other peer, potentially leading to further complexity or even one or both gluster volumes becoming full. Ephemeral Ephemeral storage does not survive a relaunch. It may be \"faster\" than EBS but in the event that the instance fails (which is a common occurrence on AWS' platform), the data would be lost. Ramdisk Again, it may be \"faster\" than EBS but in the event that the instance fails (which is a common occurrence on AWS' platform), the data would be lost. Additionally, this is an unsupported operation on Acquia's platform. Database - Common Name Device Mount point Database /dev/xvdm /vol/ebs1/ Determine what is taking up the most space. du -h --max-depth=2 $MOUNTPOINT | sort -rhk 1,1 | head Crit support with this data. Downtime the alert for one to three days. Use your judgement and disk usage graphs to determine the growth rate. Primarily focus on 'Days to Fill' graph. Please do not downtime an alert to come out of downtime during someone's weekend on-call shift. sv-diskusage $SERVER sv-downtimeservice $SERVER \"Disk Partitions\" $((60*24*$DAYS)) \\ \"$JIRA_TICKET - $MOUNTPOINT XX%.\" Add an entry to the Handover Document about the downtime. Database - ACE If any sites have been moved off of this server, then cleanup stale data. After performing a site move, site data gets renamed on the source server to the following: /vol/ebs1/mysql/SITENAME-MOVED-task-TASKID. Verify that the site was properly moved by searching in Jira and checking the destination servers. Ensure the databases have been dropped from MySQL. cd /vol/ebs1/mysql; \\ for FILE in ${SITENAME}*MOVED*; \\ do DB=`echo $FILE|cut -f1 -d\\-` ; \\ mysql -e \"DROP DATABASE IF EXISTS $DB\" ; \\ rm -rf $FILE; \\ unset DB; \\ done Clean up the moved sites files. rm -rf /vol/ebs1/mysql/SITENAME-MOVED-task-TASKID If the guidelines for emergency upsizing are met, perform an emergency upsize to the next supported size. Remember to file a deal sheet ticket against the AM project by clicking on me. Otherwise, the customer will need to delete something or request an upsize. Submit a crit and downtime as normal. If you notice that there is a large amount of binlogs filling up the Database volume, then you can purge binlogs in order to temporarily create room. Note that binlogs being generated quickly normally indicate that there are underlying issues somewhere else in the stack. Ensure both DB's are in sync. ah-db-cluster status $DBMASTERA Get the current binlog position of the slave. fssh $DBMASTERB \"sudo mysql -e 'show slave status\\G'\"|grep binlog Purge the binlogs on the master up to BINLOG_NUMBER -1. fssh $DBMASTERA sudo su - mysql purge binary logs to 'binlog.000123'; Verify disk usage. Sometimes binlogs fill out quickly due to high traffic. Please examine the site traffic to look for any IP or USERAGENT hitting the site particularly hard using below commands. site-traffic $SITENAME site-trafficbyuseragent $SITENAME Block the problematic IP or USERAGENT if necessary. Database - ACSF First check the files and directories consuming most of the space on the DB volume. fssh $DBMASTERA sudo su - du -max -h /vol/ebs1/mysql | sort -hr | head -20 If ibdata is consuming most of the disk space then proceed with this link. Reduce Mysql disk usage for ACSF/Site Factory else if you need to upsize the volume then follow this link. Resize DB volume Database - ACP We do not perform emergency upsizes in ACP. Follow the Common procedure. Misc Volumes Acquia managed infrastructure that may cause a disk partitions alert: Mon - /opt/nagios-tmpfs Restart the nagios service. sudo service nagios restart Master - /etc/puppet/versions Find all currently-used versions. ah-server list % -c hosting_version --no-name | sort | uniq On the Master, remove all but the currently-used versions of fields found in the above command. cd /etc/puppet/versions rm -rf $OLD_VERSIONS Remove any entries under the VERSIONS section of /etc/puppet/puppet.conf that correlate with the versions of fields that you removed from the master. Stats - /vol/ebs1/ or /vol/backup-ebs/ Check to see if it's carbon-cache logs. du -shx /vol/ebs1/gfs/graphite/storage/log/carbon-cache/carbon-cache-a If the directory size is large, purge it. find /vol/ebs1/gfs/graphite/storage/log/carbon-cache/carbon-cache-a -name \"*.log*\" -mtime +30 -delete Make sure to clean-up the backup volume as well. find /vol/backup-ebs/gfs/graphite/storage/log/carbon-cache/carbon-cache-a -name \"*.log*\" -mtime +30 -delete perf-mon.acquia.com - root fs (/) Determine which directory is using the most space. du -sh /* --block-size=M | sort -nr | head Rotate logs. logrotate -f /etc/logrotate.conf If sufficient space has not been freed, remove archived files from /var/log/acquia/ one at a time starting with oldest first. cd /var/log/acquia/ find . -name \"*.gz\" -type f -printf '%T+ %p\\n' | sort | head rm FILE Escalate to Senior Ops if this does not resolve the problem.","title":"Disk Partitions Alert"},{"location":"incident_response/disk_partitions/#disk-partitions-alert","text":"This alert indicates that a volume for the specified server greater than or equal to 95% full. /usr/lib/nagios/plugins/check_disk -X proc -X sysfs -X tmpfs -X devpts \\ -X securityfs -X fuse.glusterfs -w 10% -c 5%","title":"Disk Partitions Alert"},{"location":"incident_response/disk_partitions/#resolution","text":"Run df -h to determine which volumes are over the threshold. Include the full output of this command in the ticket. Verify that the volumes are not obviously incorrectly sized: For infrastructure that is not specific to any customer, ensure that the volumes were correctly sized according to the docs for provisioning them. This includes but is not limited to: devcloud bals prod shared bals svn servers Ensure that the /dev/sdn volume is the same size as the /dev/sdo volume attached to the instance for servers on which Acquia backups run: For any HA pair that hosts Gluster, only the server with the lowest-number brick any non-HA server that has a file storage partition, namely staging and srv Run sv-vollist $SERVER to verify that the fields master is consistent with the state of the EBS volumes and the EC2 instance involved, ie an upsize is not in progress and/or was not completed incorrectly. Depending on the volume, different actions need to be taken. See the following sections.","title":"Resolution"},{"location":"incident_response/disk_partitions/#multiregion-passive-servers","text":"No zendesk ticket is needed for passive fs or fsdbmesh servers filling up. Verify the ah-mrrsync cron is present and determine what server it is running on by looking at the server_id column ah-site cron2 list --site-name=${SITENAME} | grep /usr/local/sbin/ah-mrrsync Log into the server listed in the cron fssh ${CRON_WEB} sudo -i screen -S rsync_delete su - ${SITENAME} Copy the ah-mrrsync script to /tmp cat /usr/local/sbin/ah-mrrsync | sed 's/--verbose/--verbose --delete/' \\ > /tmp/ah-mrrsync && chmod +x /tmp/ah-mrrsync Kill any existing ah-mrrsync / rsync processes pgrep -lf ah-mrrsync Run the script /tmp/ah-mrrsync ${SITENAME} Note :If the script runs for longer than an hour, please investigate why it's taking long time. eg. the rsync script might not been running automatically.","title":"multiregion (passive) servers"},{"location":"incident_response/disk_partitions/#bastion-servers","text":"No zendesk ticket is needed for bastion servers filling up. Need Sudo access on bastion to perform below cleanups Verify the /mnt/tmp/ahsupportbot folder and delete cron.sh-bastion files older than 30 days find /mnt/tmp/ahsupportbot -type f -iname 'cron.sh-bastion*' -mtime +30 -delete Verify the /mnt/tmp/ folder and delete log-analysis files older than 30 days find /mnt/tmp -type f -iname 'log-analysis*' -mtime +30 -delete Take a look at disk usage by user's home directories, identify top 10 User's consuming disk space. du -sh /vol/ebs1/home/* | sort -hr | head -n10 This command may run for several minutes. (you can also run ncdu -x /vol/ebs1/home/ it will scan the entire directories and list all the directories by usage. but here we are only interested in top 10 users.) Ping concern person in the ticket requesting to clean their unused files.","title":"bastion servers"},{"location":"incident_response/disk_partitions/#ra-servers","text":"No zendesk ticket is needed for RA servers filling up. Ping \"@Acquia RA\" in the jira ticket to get their attention, and follow these cleanup steps: /mnt/gfs/sitename.ra/backups/ can be deleted if it is eating space /mnt/gfs/sitename.ra/sites/default/files/sitename can be deleted if it is eating space /mnt/gfs or brick*/home/sitename/sitename-svn can be deleted if it is eating space If /mnt/gfs/sitename.ra/livedev/sitename is the problem, this can be cleared out as well, but RA should be notified since this means an possibly currently running update will fail. This is not a problem as RA can restart the process, RA just needs to know. Large repo directories can also be cleared. RA-Up can always redeploy the repo on the next update. It is important to ping @Acquia RA OR start a 'subscription issue' type ticket in the RA project. RA will contact the client to reduce the size of the repo.","title":"RA Servers"},{"location":"incident_response/disk_partitions/#cde-cd-environment-servers","text":"No zendesk ticket is needed for CDE volumes filling up. Escalate the issue to the CDE team. CDE servers can be identified by the ode tag. Escalate the issue to the CDE team","title":"CDE (CD Environment) servers"},{"location":"incident_response/disk_partitions/#svn-servers","text":"Name Device Mount point Database /dev/xvdm /vol/ebs1 Backup /dev/xvdn /vol/backup-ebs","title":"SVN servers"},{"location":"incident_response/disk_partitions/#for-volebs1","text":"If the volume with customer repos (/vol/ebs1) alerts for disk space, the issue can often be solved by running git garbage collection (described below). If that does not work, a manual upsize of the volume is necessary. The most expedient approach is to selectively run git gc on some of the repos on the server. While a post-commit hook tries to run git gc on customer repos automatically, it leaves room for improvement, and many gigabytes can often be reclaimed. To start with, take a look at disk usage by repo: For /vol/ebs1: du -sh /vol/ebs1/home/* | sort -h This command may run for several minutes. Because garbage collection involves writing temporary files while running, disk space usage will temporarily increase , so if the disk is very full, larger repos may not have enough space to complete initially. Therefore, it is generally necessary to start with smaller repos and work towards the largest ones. Garbage collection is performed by navigating into one of the repos in the list from du and running git gc . This may take several minutes. It is also possible to script this for all repositories on the server, but be warned that this can run for more than an hour: screen cd VOLUME_THAT_ALERTED # /vol/ebs1/home if on /vol/ebs1 find . -name '*.git' -type d | xargs -P1 -I {} -n 1 git -C {} gc If this fails to bring usage below the alerting threshold, the volume will have to be manually upsized . The disk upsize workflow does not work for svn servers. If at any point you run into trouble or need guidance, page the Pandora Team , using the \"Version Control\" component. It is much better to page early than to allow a disk to fill completely and lead to downtime.","title":"for /vol/ebs1"},{"location":"incident_response/disk_partitions/#for-volbackup-ebs","text":"We should run the backup script 'ah-backup-vcs' manually to sync the data to their backup volume. This script works for svn servers similarly as 'fields-backup-fileserver.php' script works for other servers. We should also take a look at disk usage by repo: For /vol/backup-ebs: du -sh --exclude *.tar.gz /vol/backup-ebs/* | sort -h If ah-backup-vcs does not give back enough space for backup volume (/vol/ebs1 and /vol/backup-ebs/ should have comparable space usage), then we should run the following command to get space back on /vol/backup-ebs/: cd /vol/backup-ebs for i in $(ls | grep -v tar.gz) ; do echo $i/$i.git ; $(cd $i/$i.git && git gc) ; done","title":"for /vol/backup-ebs"},{"location":"incident_response/disk_partitions/#ephemeral-volumes","text":"Name Device Mount point Root volume /dev/xvda / Secondary ephemeral volume /dev/xvdb /mnt/ Note :In case of high root volume usage try apt autoremove -y to remove old packages before trying other stuff to solve the issue. Determine where the space is being used. Keep in mind that other volumes are mounted within each of the mount points. Using -x with du should ignore the other volumes. MOUNTPOINT= du --max-depth 2 -x -h $MOUNTPOINT | sort -rhk 1,1 | head If there is a large file in /var/mail , it is likely improperly configured cron. Find the offending address, crit support with this address, and truncate the file. grep '^To:' /var/mail/$FILE | uniq -c echo -n \"\" > /var/mail/$FILE If there is a large file in /tmp , verify the customer placed it there, crit support that the customer is not using /mnt/tmp, and move the file to /mnt/tmp . ls -l $FILE mv /tmp/$FILE /mnt/tmp/ Note : We shouldn't delete any data from '/mnt/tmp' directory without customer's approval. Also it's not recommended to delete an entire directory under '/mnt/tmp', but if we have to clear out an entire '/mnt/tmp' or '/mnt/tmp/site_name' with customer's approval, specifically file '.contained_tmp' (present under /mnt/tmp/site_name), then we may need to start the socket service manually in that case. If a server has ODE sites (tag ode is present on them), then escalate to CDE team without any delay. If there is a large amount of logs in /mnt/logs ( /var/log symlinks here), delete logs older than a week, delete logs that have been shipped to S3, and force a log rotation. sv-rotatelog $SERVER Use below legacy manual log rotation steps for Search Servers find /mnt/log/ -iname '*.gz' -mtime +7 -delete find /mnt/log/ -iname '*.gz' -perm -1000 -delete screen logrotate -f /etc/logrotate.conf Special case : If Varnish and / or nginx logs on a balancer running on Gen2 hardware have needed to be deleted before (check Jira), emergency upsize the balancer pair to the next cheapest Gen2 instance with more ephemeral storage. File a deal sheet ticket against the AM project by clicking on me. If /mnt/site-delete-backups is found to be consuming more space, delete backup files (in the format 'task-sitegroup-delete-*.gz) older than 7 days. find /mnt/site-delete-backups/ -type f \\( -iname \"task-site*\" -a -iname \"*gz\" \\) -mtime +7 -delete In ACSF, if /mnt/tmp is filling up, do not delete the theme directories. You can run git gc to try to compact some space. Theme directories are located in /mnt/tmp/<sitegroup>.<env>/theme_repo . Customer approval required for this action . If /mnt/www/repo is consuming more space, find the SVN server hosting the customer's repo, note the space consumed by repo on the SVN, then go to the repo directory and run git garbage collection command. SITEGROUP= du -sh /vol/ebs1/home/${SITEGROUP} cd /vol/ebs1/home/${SITEGROUP}/${SITEGROUP}.git git gc --aggressive Check the disk usage again for repo and if there is any change then run FCW on the site. site-fcw <sitename.stage> Also, check if twig cache is consuming more space using the following command and make sure to create a customer facing Zendesk ticket: fpdsh -t site:${SITENAME} -n 'web|ded|staging' -c \"sudo find /mnt/tmp -maxdepth 3 -type d -iname 'twig' -exec du -sh {} For a single server, use the following commands instead: SERVER= fssh $SERVER \"sudo find /mnt/tmp -maxdepth 3 -type d -iname 'twig' -exec du -sh {} +\" If customer approves or is unresponsive and volume is full - confirm with support and clean up twig cache using the following command (set the variable SITENAME with the site name, and run the following command with appropriate set of web/ded/staging). The command below for web servers : fpdsh -t site:${SITENAME} -n web -c \"sudo find /mnt/tmp/${SITENAME}/php_storage/twig -type f -mtime 2 -delete\" NOTE: If it takes long time to cleanup, probably it is better to relaunch the web instead or upsize /mnt volume if needed. In other cases, you need to investigate and determine a cause and resolution on your own. Keep in mind that these volumes are recreated from scratch on relaunch.","title":"Ephemeral volumes"},{"location":"incident_response/disk_partitions/#handle-deleted-files-consuming-space","text":"Sometimes, a running process can keep hold of deleted/moved files and the disk space is consumed even though the actual usage is less. This can usually be checked by the difference between du and df command for a given volume. Following commands can be used to verify deleted files are consuming space: lsof +aL1 $MOUNTPOINT or find /proc/*/fd -ls 2> /dev/null | grep '(deleted)' | grep $MOUNTPOINT Once verified that deleted files are consuming space, the space can be reclaimed using the following command: truncate -s 0 /proc/xxx/fd/yyy Note : Be careful while truncating the file descriptors as the process may be holding it up and could cause some issues. This can be used to cleanup space consumed by log files or temporary files.","title":"Handle deleted files consuming space"},{"location":"incident_response/disk_partitions/#gluster-volumes","text":"","title":"Gluster Volumes"},{"location":"incident_response/disk_partitions/#gluster-common","text":"Name Device Mountpoint Gluster (brick) /dev/xvdo /mnt/brickXXX/ Gluster (client) /etc/glusterfs/glusterfs-client.vol /mnt/gfs/ Determine what is taking up the most space. Run du against the gluster brick for greater read performance. MOUNTPOINT=/mnt/brickXXX/ du -h --max-depth=2 $MOUNTPOINT --exclude=.glusterfs | sort -rhk 1,1 | head Crit support with this data. Determine if anything can be removed by consulting the sections below. Downtime the alert for one to three days. Use your judgment and disk usage graphs to determine the growth rate. Primarily focus on 'Days to Fill' graph. Please do not downtime an alert to come out of downtime during someone's weekend on-call shift. sv-diskusage $SERVER sv-downtimeservice $SERVER \"Disk Partitions\" $((60*24*$DAYS)) \\ \"$JIRA_TICKET - $MOUNTPOINT XX%.\" Add an entry to the Handover Document about the downtime.","title":"Gluster - Common"},{"location":"incident_response/disk_partitions/#gluster-ace","text":"Never modify anything directly on the Gluster brick. Always use the client mount. These volumes contain customer data . There are a limited set of files that are okay to delete, but be extra careful when deleting files, and never delete customer files . If any sites have been moved off of this server, then cleanup stale data. After performing a site move, site data gets renamed on the source server to the following: /mnt/gfs/SITENAME-MOVED-task-TASKID. Verify that the site was properly moved by searching in Jira and checking the destination servers. Clean up the moved sites files. rm -rf /mnt/gfs/SITENAME-MOVED-task-TASKID If the guidelines for emergency upsizing are met, perform an emergency upsize to the next supported size. Remember to file a deal sheet ticket against the AM project by clicking on me. Otherwise, the customer will need to delete something or request an upsize. Submit a crit and downtime as normal.","title":"Gluster - ACE"},{"location":"incident_response/disk_partitions/#backup-volumes","text":"","title":"Backup Volumes"},{"location":"incident_response/disk_partitions/#common","text":"Name Device Mount point Backup /dev/xvdm /vol/backup-ebs The backup rsync that /vol/backup-ebs the volume will not to complete if the volume reaches 100% full. In the event that that backup volume fills, then we need to run the backup rsync with the --delete-before command. Copy the backup script to a new location. cp /usr/local/sbin/fields-backup-fileserver.php . Modify the rsync to use --delete-before and confirm. vim fields-backup-fileserver.php diff -u /usr/local/sbin/fields-backup-fileserver.php fields-backup-fileserver.php Run the new backup rsync with --delete-before in a screen. screen ./fields-backup-fileserver.php","title":"Common"},{"location":"incident_response/disk_partitions/#database-volumes","text":"","title":"Database Volumes"},{"location":"incident_response/disk_partitions/#warnings","text":"","title":"Warnings"},{"location":"incident_response/disk_partitions/#operations-is-not-allowed-to-purge-data-without-customer-consent-except-for-binlogs","text":"The primary reason Operations is not allowed to purge data without customer consent is because each customer's application is different and may be using databases in unexpected ways. Without knowing the application intimately, Operations can inadvertently introduce additional complexity to an application or cause downtime.","title":"Operations is not allowed to purge data without customer consent (except for binlogs)"},{"location":"incident_response/disk_partitions/#operations-is-not-allowed-to-move-tables-or-databases-to-alternate-storage-ephemeral-gluster-ramdisk-etc","text":"There are several reasons why Operations is not allowed to move tables or databases to alternate storage: Gluster Using Gluster for table/database storage is not advisable. Gluster's daemon would see the new file and replicate it to the other peer, potentially leading to further complexity or even one or both gluster volumes becoming full. Ephemeral Ephemeral storage does not survive a relaunch. It may be \"faster\" than EBS but in the event that the instance fails (which is a common occurrence on AWS' platform), the data would be lost. Ramdisk Again, it may be \"faster\" than EBS but in the event that the instance fails (which is a common occurrence on AWS' platform), the data would be lost. Additionally, this is an unsupported operation on Acquia's platform.","title":"Operations is not allowed to move tables or databases to alternate storage (ephemeral, gluster, ramdisk, etc.)"},{"location":"incident_response/disk_partitions/#database-common","text":"Name Device Mount point Database /dev/xvdm /vol/ebs1/ Determine what is taking up the most space. du -h --max-depth=2 $MOUNTPOINT | sort -rhk 1,1 | head Crit support with this data. Downtime the alert for one to three days. Use your judgement and disk usage graphs to determine the growth rate. Primarily focus on 'Days to Fill' graph. Please do not downtime an alert to come out of downtime during someone's weekend on-call shift. sv-diskusage $SERVER sv-downtimeservice $SERVER \"Disk Partitions\" $((60*24*$DAYS)) \\ \"$JIRA_TICKET - $MOUNTPOINT XX%.\" Add an entry to the Handover Document about the downtime.","title":"Database - Common"},{"location":"incident_response/disk_partitions/#database-ace","text":"If any sites have been moved off of this server, then cleanup stale data. After performing a site move, site data gets renamed on the source server to the following: /vol/ebs1/mysql/SITENAME-MOVED-task-TASKID. Verify that the site was properly moved by searching in Jira and checking the destination servers. Ensure the databases have been dropped from MySQL. cd /vol/ebs1/mysql; \\ for FILE in ${SITENAME}*MOVED*; \\ do DB=`echo $FILE|cut -f1 -d\\-` ; \\ mysql -e \"DROP DATABASE IF EXISTS $DB\" ; \\ rm -rf $FILE; \\ unset DB; \\ done Clean up the moved sites files. rm -rf /vol/ebs1/mysql/SITENAME-MOVED-task-TASKID If the guidelines for emergency upsizing are met, perform an emergency upsize to the next supported size. Remember to file a deal sheet ticket against the AM project by clicking on me. Otherwise, the customer will need to delete something or request an upsize. Submit a crit and downtime as normal. If you notice that there is a large amount of binlogs filling up the Database volume, then you can purge binlogs in order to temporarily create room. Note that binlogs being generated quickly normally indicate that there are underlying issues somewhere else in the stack. Ensure both DB's are in sync. ah-db-cluster status $DBMASTERA Get the current binlog position of the slave. fssh $DBMASTERB \"sudo mysql -e 'show slave status\\G'\"|grep binlog Purge the binlogs on the master up to BINLOG_NUMBER -1. fssh $DBMASTERA sudo su - mysql purge binary logs to 'binlog.000123'; Verify disk usage. Sometimes binlogs fill out quickly due to high traffic. Please examine the site traffic to look for any IP or USERAGENT hitting the site particularly hard using below commands. site-traffic $SITENAME site-trafficbyuseragent $SITENAME Block the problematic IP or USERAGENT if necessary.","title":"Database - ACE"},{"location":"incident_response/disk_partitions/#database-acsf","text":"First check the files and directories consuming most of the space on the DB volume. fssh $DBMASTERA sudo su - du -max -h /vol/ebs1/mysql | sort -hr | head -20 If ibdata is consuming most of the disk space then proceed with this link. Reduce Mysql disk usage for ACSF/Site Factory else if you need to upsize the volume then follow this link. Resize DB volume","title":"Database - ACSF"},{"location":"incident_response/disk_partitions/#database-acp","text":"We do not perform emergency upsizes in ACP. Follow the Common procedure.","title":"Database - ACP"},{"location":"incident_response/disk_partitions/#misc-volumes","text":"Acquia managed infrastructure that may cause a disk partitions alert:","title":"Misc Volumes"},{"location":"incident_response/disk_partitions/#mon-optnagios-tmpfs","text":"Restart the nagios service. sudo service nagios restart","title":"Mon - /opt/nagios-tmpfs"},{"location":"incident_response/disk_partitions/#master-etcpuppetversions","text":"Find all currently-used versions. ah-server list % -c hosting_version --no-name | sort | uniq On the Master, remove all but the currently-used versions of fields found in the above command. cd /etc/puppet/versions rm -rf $OLD_VERSIONS Remove any entries under the VERSIONS section of /etc/puppet/puppet.conf that correlate with the versions of fields that you removed from the master.","title":"Master - /etc/puppet/versions"},{"location":"incident_response/disk_partitions/#stats-volebs1-or-volbackup-ebs","text":"Check to see if it's carbon-cache logs. du -shx /vol/ebs1/gfs/graphite/storage/log/carbon-cache/carbon-cache-a If the directory size is large, purge it. find /vol/ebs1/gfs/graphite/storage/log/carbon-cache/carbon-cache-a -name \"*.log*\" -mtime +30 -delete Make sure to clean-up the backup volume as well. find /vol/backup-ebs/gfs/graphite/storage/log/carbon-cache/carbon-cache-a -name \"*.log*\" -mtime +30 -delete","title":"Stats - /vol/ebs1/ or /vol/backup-ebs/"},{"location":"incident_response/disk_partitions/#perf-monacquiacom-root-fs","text":"Determine which directory is using the most space. du -sh /* --block-size=M | sort -nr | head Rotate logs. logrotate -f /etc/logrotate.conf If sufficient space has not been freed, remove archived files from /var/log/acquia/ one at a time starting with oldest first. cd /var/log/acquia/ find . -name \"*.gz\" -type f -printf '%T+ %p\\n' | sort | head rm FILE Escalate to Senior Ops if this does not resolve the problem.","title":"perf-mon.acquia.com - root fs (/)"},{"location":"incident_response/disk_writable/","text":"Disk Writable Alert This alert means one of the instance's ephemeral volumes is impaired or that there are no more free inodes on the partition. $ sudo /usr/lib/nagios/plugins/check_disk_writable CRITICAL: Ephemeral partition(s) are not writable Determine if inode usage has been exceeeded You can check to see if inode usage has been exceeded with the df command $ sudo df -Thi /mnt Filesystem Type Inodes IUsed IFree IUse% Mounted on /dev/xvdb ext3 2.4M 1.8M 606K 75% /mnt Determine whether its an impaired volume You can verify that the volume is unwriteable by trying to create a file in root or /mnt . $ touch /tmp/newfile $ touch /mnt/tmp/newfile touch: cannot touch `/mnt/tmp/newfile': Read-only file system You may also find IO errors in the output of the dmesg command $ dmesg [6008884.192452] end_request: I/O error, dev sda1, sector 11104536 Response Inode Usage exceeded If Inode usage has been exceeded notify Support for file cleanup. If clean up is not an option, the server should be upsized to an instance type which has higher inode capacity. Note : Unless the inode fill up is due to logs or temporary files, relaunch for a temporary fix will be very messy and could fail even with hacky workarounds so relaunch is not advisable. Impaired Volume If the volume is impaired then relaunch the server CDE (CD Environment) servers No zendesk ticket is needed for CDE volumes running out of inodes. Escalate the issue to the CDE team. CDE servers can be identified by the ode tag. Escalate the issue to the CDE team","title":"Disk Writable Alert"},{"location":"incident_response/disk_writable/#disk-writable-alert","text":"This alert means one of the instance's ephemeral volumes is impaired or that there are no more free inodes on the partition. $ sudo /usr/lib/nagios/plugins/check_disk_writable CRITICAL: Ephemeral partition(s) are not writable","title":"Disk Writable Alert"},{"location":"incident_response/disk_writable/#determine-if-inode-usage-has-been-exceeeded","text":"You can check to see if inode usage has been exceeded with the df command $ sudo df -Thi /mnt Filesystem Type Inodes IUsed IFree IUse% Mounted on /dev/xvdb ext3 2.4M 1.8M 606K 75% /mnt","title":"Determine if inode usage has been exceeeded"},{"location":"incident_response/disk_writable/#determine-whether-its-an-impaired-volume","text":"You can verify that the volume is unwriteable by trying to create a file in root or /mnt . $ touch /tmp/newfile $ touch /mnt/tmp/newfile touch: cannot touch `/mnt/tmp/newfile': Read-only file system You may also find IO errors in the output of the dmesg command $ dmesg [6008884.192452] end_request: I/O error, dev sda1, sector 11104536","title":"Determine whether its an impaired volume"},{"location":"incident_response/disk_writable/#response","text":"","title":"Response"},{"location":"incident_response/disk_writable/#inode-usage-exceeded","text":"If Inode usage has been exceeded notify Support for file cleanup. If clean up is not an option, the server should be upsized to an instance type which has higher inode capacity. Note : Unless the inode fill up is due to logs or temporary files, relaunch for a temporary fix will be very messy and could fail even with hacky workarounds so relaunch is not advisable.","title":"Inode Usage exceeded"},{"location":"incident_response/disk_writable/#impaired-volume","text":"If the volume is impaired then relaunch the server","title":"Impaired Volume"},{"location":"incident_response/disk_writable/#cde-cd-environment-servers","text":"No zendesk ticket is needed for CDE volumes running out of inodes. Escalate the issue to the CDE team. CDE servers can be identified by the ode tag. Escalate the issue to the CDE team","title":"CDE (CD Environment) servers"},{"location":"incident_response/elb_issues/","text":"ELB Issues This alert checks Trusted Advisor per account to make sure all ELBs are fault tolerant. Resolution Find the ELB issue alert in check_MK on ops-mon-2 OR You can log into ops-mon-2 (from bastion or localhost if connected to acquia VPN) and run the following command as nagios user ssh $USER@ops-mon-2.acquia.com sudo su - nagios HOSTING_STAGE=[acquia-internal|devcloud|hosting-production|gardens-production|wmg-egardens|umg-egardens|search-service] /usr/local/nagios/libexec/check_elbs -f ${HOSTING_STAGE} You can also find the ELBs that are having issues by using following aws command on bastions. Do note that this will also show elbs that have been removed from monitoring aws support describe-trusted-advisor-check-result --check-id iqdCTZKCUp --region us-east-1 --query 'result.sort_by(flaggedResources[?status!=`ok`],&metadata[2])[].metadata' --output table Click on the alert and look at the long output of check plugin to get the list of issues Resolve the reason listed for each ELB Refresh the Trusted Advisor ELB check aws support refresh-trusted-advisor-check --check-id iqdCTZKCUp \\ --region us-east-1 If the check does not resolve after an hour you may have to login to the AWS console to run refresh for the ELB check. Debugging ELB issues To find the ELB associated with a specific site you need the site id. The site id is the number after the stage name so if the ELB name is mc-1234-987654 the site id is 1234 or if the ELB name in the network realm is nw-175-1178700611 the site id is 175. We can also get the sitename associated with the ELBs using below: REGION= aws elb describe-load-balancers --load-balancer-names mc-xxxx mc-yyyy --query 'LoadBalancerDescriptions[].HealthCheck.Target' --region $REGION where mc-xxxx mc-yyyy are the names of the ELBs. Sitename obtained from both should be same. ELB_NAME=mc-1234 SITE_ID=1234 ah-site list % -w id=$SITE_ID site-elbdescribe $SITENAME Adding and Removing ELBs from monitoring In some cases the ELB is being used for VCL testing or Load Testing. Removing an ELB from monitoring Add the ops_removed_from_monitoring tag REGION= JIRA_TICKET= ELB_NAME= aws elb add-tags --load-balancer-name $ELB_NAME \\ --tags Key=ops_removed_from_monitoring,Value=${JIRA_TICKET} \\ --region $REGION Adding an ELB back to monitoring Remove the ops_removed_from_monitoring tag REGION= JIRA_TICKET= ELB_NAME= aws elb remove-tags --load-balancer-name $ELB_NAME \\ --tags ops_removed_from_monitoring \\ --region $REGION","title":"ELB Issues"},{"location":"incident_response/elb_issues/#elb-issues","text":"This alert checks Trusted Advisor per account to make sure all ELBs are fault tolerant.","title":"ELB Issues"},{"location":"incident_response/elb_issues/#resolution","text":"Find the ELB issue alert in check_MK on ops-mon-2 OR You can log into ops-mon-2 (from bastion or localhost if connected to acquia VPN) and run the following command as nagios user ssh $USER@ops-mon-2.acquia.com sudo su - nagios HOSTING_STAGE=[acquia-internal|devcloud|hosting-production|gardens-production|wmg-egardens|umg-egardens|search-service] /usr/local/nagios/libexec/check_elbs -f ${HOSTING_STAGE} You can also find the ELBs that are having issues by using following aws command on bastions. Do note that this will also show elbs that have been removed from monitoring aws support describe-trusted-advisor-check-result --check-id iqdCTZKCUp --region us-east-1 --query 'result.sort_by(flaggedResources[?status!=`ok`],&metadata[2])[].metadata' --output table Click on the alert and look at the long output of check plugin to get the list of issues Resolve the reason listed for each ELB Refresh the Trusted Advisor ELB check aws support refresh-trusted-advisor-check --check-id iqdCTZKCUp \\ --region us-east-1 If the check does not resolve after an hour you may have to login to the AWS console to run refresh for the ELB check.","title":"Resolution"},{"location":"incident_response/elb_issues/#debugging-elb-issues","text":"To find the ELB associated with a specific site you need the site id. The site id is the number after the stage name so if the ELB name is mc-1234-987654 the site id is 1234 or if the ELB name in the network realm is nw-175-1178700611 the site id is 175. We can also get the sitename associated with the ELBs using below: REGION= aws elb describe-load-balancers --load-balancer-names mc-xxxx mc-yyyy --query 'LoadBalancerDescriptions[].HealthCheck.Target' --region $REGION where mc-xxxx mc-yyyy are the names of the ELBs. Sitename obtained from both should be same. ELB_NAME=mc-1234 SITE_ID=1234 ah-site list % -w id=$SITE_ID site-elbdescribe $SITENAME","title":"Debugging ELB issues"},{"location":"incident_response/elb_issues/#adding-and-removing-elbs-from-monitoring","text":"In some cases the ELB is being used for VCL testing or Load Testing.","title":"Adding and Removing ELBs from monitoring"},{"location":"incident_response/elb_issues/#removing-an-elb-from-monitoring","text":"Add the ops_removed_from_monitoring tag REGION= JIRA_TICKET= ELB_NAME= aws elb add-tags --load-balancer-name $ELB_NAME \\ --tags Key=ops_removed_from_monitoring,Value=${JIRA_TICKET} \\ --region $REGION","title":"Removing an ELB from monitoring"},{"location":"incident_response/elb_issues/#adding-an-elb-back-to-monitoring","text":"Remove the ops_removed_from_monitoring tag REGION= JIRA_TICKET= ELB_NAME= aws elb remove-tags --load-balancer-name $ELB_NAME \\ --tags ops_removed_from_monitoring \\ --region $REGION","title":"Adding an ELB back to monitoring"},{"location":"incident_response/fix-missing-glusterd_vol-file/","text":"Fix missing glusterd.vol file THIS IS FOR GLUSTER 3.4 ONLY To replace a missing glusterd.vol file (either because you tab-completed and deleted it by accident thinking it was a gluster 3.0 cluster or because the OS decided it didn't like life anymore): apt-get -o Dpkg::Options::=\"--force-confmiss\" install --reinstall glusterfs-server ah-config-gluster","title":"Fix missing glusterd.vol file"},{"location":"incident_response/fix-missing-glusterd_vol-file/#fix-missing-glusterdvol-file","text":"","title":"Fix missing glusterd.vol file"},{"location":"incident_response/fix-missing-glusterd_vol-file/#this-is-for-gluster-34-only","text":"To replace a missing glusterd.vol file (either because you tab-completed and deleted it by accident thinking it was a gluster 3.0 cluster or because the OS decided it didn't like life anymore): apt-get -o Dpkg::Options::=\"--force-confmiss\" install --reinstall glusterfs-server ah-config-gluster","title":"THIS IS FOR GLUSTER 3.4 ONLY"},{"location":"incident_response/gluster-not-split-brain/","text":"Not Split-brain This runbook details fixing sundry problems with gluster not related to discovering a split-brain. If you don't know whether you are dealing with a split-brain, run SERVER= sv-glustersplitbrainfiles $SERVER where $SERVER is any server with a brick. If you get no output or all of the afr changelogs are all 0, then you don't have a split-brain. If you get errors pertaining to network connectivity, then you may still not have a split-brain. Follow the steps below. (Gluster 3.4) Configuration Daemon (glusterd) Doesn't Start You can test for this by first checking for the presence of the configuration daemon: # pgrep -l gluster 9564 glusterd If there is no entry for glusterd, then try starting it by running sudo ah-config-gluster . If that works, then glusterd has started. Otherwise, if it fails with the following error, use the remediation steps below. ah-config-gluster[1149]: AH_CRITICAL: Aq::System::NonZeroStatusError, Command returned exit code 1: service glusterfs-server start stdout was: stderr was: Failed to get properties: Unit name ah-site-php@.socket is not valid. Job for glusterfs-server.service failed because the control process exited with error code. See \"systemctl status glusterfs-server.service\" and \"journalctl -xe\" for details. Remediation Kill any running gluster processes on the box: pkill gluster Clear existing gluster configuration: sudo tar czf gluster-config-$(date +\"%s\").tgz /var/lib/glusterd/ && \\ sudo rm -rf /var/lib/glusterd Attach the tgz containing the broken configuration to the incident ticket. Set up gluster: sudo ah-config-gluster && sudo ah-config-gluster (Running ah-config-gluster twice is a workaround to account for a bug in our gluster orchestration.) Network Issues Ensure there are no obvious issues with configuration and remount gluster. You should make sure maintenance is not in progress before proceeding, as it is necessary to partition the cluster for resolving a split brain. NODES_CSV=$(ah-server list % -w status=0 \\ fs_cluster_id=$(ah-server list $SERVER --no-name -c fs_cluster_id) | paste -sd ,) fpdsh -l $NODES_CSV -c \"sudo su -c 'ah-config-hosts; \\ rm -f /var/acquia/no-config-iptables; ah-config-iptables'\" sv-fsremount $NODES_CSV Fields Data Issues It is possible for one site to straddle many fs_clusters, though it is not meant to be allowed. If you find such a site, then update that site to use only the webs of one fs_cluster. Note that in order to preserve capacity, you may need to launch more webs in the fs_cluster you are choosing for the site to use. Data Issues on Gluster 3.4 In practice, split-brain is the only form of data corruption we see with gluster 3.0. For gluster 3.4 we have created a gluster-medic tool that should be the primary diagnose tool to be run on both the brick servers: Run the diagnostic option gluster-medic diagnose $(fqual $SERVER1) $(fqual $SERVER2) Based on the diagnose output choose the option to repair the cluster The gluster-medic repair has information on 3 options. The repair all will take longer on bigger clusters gluster-medic repair all $(fqual $SERVER1) $(fqual $SERVER2) If from diagnose you see \"Inodes are mismatched\" entries try to run this command a couple of times until they are fixed. It attempts to validate and repair all file entries with mismatched inodes between the brick and .glusterfs/ paths gluster-medic repair inode-mismatch $(fqual $SERVER1) $(fqual $SERVER2) If from diagnose you see \"circular symlink bug\" entries try to run the following a couple of times until they are fixed gluster-medic repair symlink-loop $(fqual $SERVER1) $(fqual $SERVER2) Any of the options can take a very long time to run on large filesystems and might need to be run more than once.","title":"Not Split-brain"},{"location":"incident_response/gluster-not-split-brain/#not-split-brain","text":"This runbook details fixing sundry problems with gluster not related to discovering a split-brain. If you don't know whether you are dealing with a split-brain, run SERVER= sv-glustersplitbrainfiles $SERVER where $SERVER is any server with a brick. If you get no output or all of the afr changelogs are all 0, then you don't have a split-brain. If you get errors pertaining to network connectivity, then you may still not have a split-brain. Follow the steps below.","title":"Not Split-brain"},{"location":"incident_response/gluster-not-split-brain/#gluster-34-configuration-daemon-glusterd-doesnt-start","text":"You can test for this by first checking for the presence of the configuration daemon: # pgrep -l gluster 9564 glusterd If there is no entry for glusterd, then try starting it by running sudo ah-config-gluster . If that works, then glusterd has started. Otherwise, if it fails with the following error, use the remediation steps below. ah-config-gluster[1149]: AH_CRITICAL: Aq::System::NonZeroStatusError, Command returned exit code 1: service glusterfs-server start stdout was: stderr was: Failed to get properties: Unit name ah-site-php@.socket is not valid. Job for glusterfs-server.service failed because the control process exited with error code. See \"systemctl status glusterfs-server.service\" and \"journalctl -xe\" for details.","title":"(Gluster 3.4) Configuration Daemon (glusterd) Doesn't Start"},{"location":"incident_response/gluster-not-split-brain/#remediation","text":"Kill any running gluster processes on the box: pkill gluster Clear existing gluster configuration: sudo tar czf gluster-config-$(date +\"%s\").tgz /var/lib/glusterd/ && \\ sudo rm -rf /var/lib/glusterd Attach the tgz containing the broken configuration to the incident ticket. Set up gluster: sudo ah-config-gluster && sudo ah-config-gluster (Running ah-config-gluster twice is a workaround to account for a bug in our gluster orchestration.)","title":"Remediation"},{"location":"incident_response/gluster-not-split-brain/#network-issues","text":"Ensure there are no obvious issues with configuration and remount gluster. You should make sure maintenance is not in progress before proceeding, as it is necessary to partition the cluster for resolving a split brain. NODES_CSV=$(ah-server list % -w status=0 \\ fs_cluster_id=$(ah-server list $SERVER --no-name -c fs_cluster_id) | paste -sd ,) fpdsh -l $NODES_CSV -c \"sudo su -c 'ah-config-hosts; \\ rm -f /var/acquia/no-config-iptables; ah-config-iptables'\" sv-fsremount $NODES_CSV","title":"Network Issues"},{"location":"incident_response/gluster-not-split-brain/#fields-data-issues","text":"It is possible for one site to straddle many fs_clusters, though it is not meant to be allowed. If you find such a site, then update that site to use only the webs of one fs_cluster. Note that in order to preserve capacity, you may need to launch more webs in the fs_cluster you are choosing for the site to use.","title":"Fields Data Issues"},{"location":"incident_response/gluster-not-split-brain/#data-issues-on-gluster-34","text":"In practice, split-brain is the only form of data corruption we see with gluster 3.0. For gluster 3.4 we have created a gluster-medic tool that should be the primary diagnose tool to be run on both the brick servers:","title":"Data Issues on Gluster 3.4"},{"location":"incident_response/gluster-not-split-brain/#run-the-diagnostic-option","text":"gluster-medic diagnose $(fqual $SERVER1) $(fqual $SERVER2)","title":"Run the diagnostic option"},{"location":"incident_response/gluster-not-split-brain/#based-on-the-diagnose-output-choose-the-option-to-repair-the-cluster","text":"The gluster-medic repair has information on 3 options. The repair all will take longer on bigger clusters gluster-medic repair all $(fqual $SERVER1) $(fqual $SERVER2) If from diagnose you see \"Inodes are mismatched\" entries try to run this command a couple of times until they are fixed. It attempts to validate and repair all file entries with mismatched inodes between the brick and .glusterfs/ paths gluster-medic repair inode-mismatch $(fqual $SERVER1) $(fqual $SERVER2) If from diagnose you see \"circular symlink bug\" entries try to run the following a couple of times until they are fixed gluster-medic repair symlink-loop $(fqual $SERVER1) $(fqual $SERVER2) Any of the options can take a very long time to run on large filesystems and might need to be run more than once.","title":"Based on the diagnose output choose the option to repair the cluster"},{"location":"incident_response/gluster-troubleshooting/","text":"Gluster Troubleshooting This runbook deals with dealing with gluster issues and remedition. Run the following command and check the gluster health: site-checkgluster $SITE If the gluster is failing and/or there is a lag in gluster response time greater than or equal to 1 sec, try to remount the gluster: site-fsremount $SITE or sv-fsremount $SERVER if the gluster health is failing for a particular server. In case the remount didn't help or gives any error, try the steps given below: FS Node Check the gluster logs to find out if there is any connection error and verify network connectivity List gluster processes on the affected FS server using command ps aux | grep gluster and kill them sudo pkill -f gluster Verify there is no stale gluster process remaining using ps aux | grep gluster and kill those stale process manually. Restart glusterfs service on FS server using service glusterfs-server restart . For gluster 3.0, run sudo fields-config-fs-server.php and sudo fields-config-fs-client.php on the FS server: And for gluster 3.4, perform the following steps: First go to the second FS server, check the status of the peer and detach it by running, gluster peer status gluster peer detach $HOSTNAME_OF_FIRST_FS_SERVER Run these on the first FS server, cp /var/lib/glusterd /var/lib/glusterd.backup rm -rf /var/lib/glusterd sudo run-puppet sudo ah-config-gluster && ah-config-gluster Perform the above steps on the second FS server as well to perform a clean gluster remount. Client Node List gluster processes on the affected FS client node using command ps aux | grep gluster and kill them sudo pkill -f gluster . Verify no gluster process keeps running using ps aux | grep gluster and kill them manually. Remount the gluster on client nodes by using running fields-config-fs-client.php for gluster 3.0 and ah-config-gluster for gluster 3.4. Perform a clean php-fpm restart after remounting gluster using site-restartfpm $SITE . This is required as old stale php process may cause issue with site performance and availability. Verify the gluster health and response time is fine using site-checkgluster $SITE . Verify site checks are passing using site-checkwebs $SITE and site-check $SITE . Note: (For Gluster 3.0 only) If the gluster is stuck while running fields-config-web.php with the error server /var/acquia/glusterfs-client.vol.mounting file exists which means another process is mounting Gluster; waiting . We can rename/remove this file and run fields-config-fs-client.php and then fcw should run without errors. If this does not resolve the problem, escalate to cloud team for further troubleshooting.","title":"Gluster Troubleshooting"},{"location":"incident_response/gluster-troubleshooting/#gluster-troubleshooting","text":"This runbook deals with dealing with gluster issues and remedition. Run the following command and check the gluster health: site-checkgluster $SITE If the gluster is failing and/or there is a lag in gluster response time greater than or equal to 1 sec, try to remount the gluster: site-fsremount $SITE or sv-fsremount $SERVER if the gluster health is failing for a particular server. In case the remount didn't help or gives any error, try the steps given below:","title":"Gluster Troubleshooting"},{"location":"incident_response/gluster-troubleshooting/#fs-node","text":"Check the gluster logs to find out if there is any connection error and verify network connectivity List gluster processes on the affected FS server using command ps aux | grep gluster and kill them sudo pkill -f gluster Verify there is no stale gluster process remaining using ps aux | grep gluster and kill those stale process manually. Restart glusterfs service on FS server using service glusterfs-server restart . For gluster 3.0, run sudo fields-config-fs-server.php and sudo fields-config-fs-client.php on the FS server: And for gluster 3.4, perform the following steps: First go to the second FS server, check the status of the peer and detach it by running, gluster peer status gluster peer detach $HOSTNAME_OF_FIRST_FS_SERVER Run these on the first FS server, cp /var/lib/glusterd /var/lib/glusterd.backup rm -rf /var/lib/glusterd sudo run-puppet sudo ah-config-gluster && ah-config-gluster Perform the above steps on the second FS server as well to perform a clean gluster remount.","title":"FS Node"},{"location":"incident_response/gluster-troubleshooting/#client-node","text":"List gluster processes on the affected FS client node using command ps aux | grep gluster and kill them sudo pkill -f gluster . Verify no gluster process keeps running using ps aux | grep gluster and kill them manually. Remount the gluster on client nodes by using running fields-config-fs-client.php for gluster 3.0 and ah-config-gluster for gluster 3.4. Perform a clean php-fpm restart after remounting gluster using site-restartfpm $SITE . This is required as old stale php process may cause issue with site performance and availability. Verify the gluster health and response time is fine using site-checkgluster $SITE . Verify site checks are passing using site-checkwebs $SITE and site-check $SITE . Note: (For Gluster 3.0 only) If the gluster is stuck while running fields-config-web.php with the error server /var/acquia/glusterfs-client.vol.mounting file exists which means another process is mounting Gluster; waiting . We can rename/remove this file and run fields-config-fs-client.php and then fcw should run without errors. If this does not resolve the problem, escalate to cloud team for further troubleshooting.","title":"Client Node"},{"location":"incident_response/impaired_server_relaunch/","text":"Relaunching impaired servers Process to relaunch impaired servers depends upon the type of server. This runbook deals with handling different types of servers. Pre-checks Verify that server is impaired from AWS: ah-server status $SERVER The command should give the output similar to one below: [cloudservicesprod|hosting-prod:prod] ~/fields/1.115$ ah-server status staging-33609 staging-33609 (i-0f3d73e74482b7113): running in us-east-1c system_status impaired [{:name=>\"reachability\", :status=>\"failed\", :impaired_since=>2019-08-31 12:46:00 UTC}] instance_status impaired [{:name=>\"reachability\", :status=>\"failed\", :impaired_since=>2019-08-31 12:46:00 UTC}] If both system and instance status shows impaired then we would need to proceed with the relaunch. If only instance status is showing impaired, most of the time rebooting the instance resolves the issue. However, if the server doesn't respond within 2-3 minutes, then it may require a relaunch. web (ded,staging,web,srv) fs db balancers search node nodebal Web Servers Other than webs, servers like deds (in single tier sites), staging and srv also serves web traffic. While staging and srv are NON-HA servers and their relaunch means the sites are down while relaunching them, we need to make sure that only HA is impacted while relaunching webs or deds. If the web is serving as memcache or cron web - the process would be different. Check the server and site layout and verify the web is traffic serving web or memcache/cron web: esl2 $SITENAME If the web is serving traffic, take it out of rotation and verify site is responding sv-webdisable $SERVER site-checkwebs $SITENAME Disable memcache service on the web. Only needed on web which is serving memcache. If site has dedicated memcache and the web isn't serving as dedicated memcache server (tagged as oob only), this wouldn't be required. ah-server edit $SERVER -s memcache_service_status=1 If the impaired server is Primary DED (if automatic failover hasn't happened yet) then failover to secondary DED and lock the cluster. If the impaired server is Secondary DED then just lock the cluster to primary DED before the relaunch. To Failover dns-update $CLUSTER-ID $SECONDARY-DB To Lock ah-db-cluster lock $SERVER NOTE Make sure to failback/unlock cluster as mentioned in post relaunch steps. Suspend the server before launching as it usually fails otherwise and relaunch it: ah-server suspend $SERVER -P sv-taskrelaunch server $SERVER -m 1 Once the relaunch is finished, remount gluster and add the web back to rotation: sv-fsremount $SERVER sv-webenable $SERVER Re-enable memcache service on the web if it was disabled earlier and run fields-config-memcache: ah-server edit $SERVER -s memcache_service_status=2 site-fcm $SITENAME Verify all the services are running on the server post relaunch: sv-checkservices $SERVER Verify site is passing the checks using site-checkwebs $SITENAME . After relaunch ensure that there is no data lag between databases using ah-db-cluster status $SERVER and never forget to unlock the cluster post relaunch: To Unlock ah-db-cluster unlock $SERVER To Failback dns-update $CLUSTER-ID $PRIMARY-DB FS Servers Suspend the server and relaunch the server: ah-server suspend $SERVER -P sv-taskrelaunch server $SERVER -m 1 Make sure to remount the gluster on the site after the server gets relaunched: site-fsremount $SITENAME Verify all the services are running on the server: sv-checkservices $SERVER Verify site and gluster checks are passing post relaunch: site-checkwebs $SITENAME site-checkgluster $SITENAME DB servers Verify the DB server is primary or secondary: ah-db-cluster status $SERVER If the impaired server is Primary DB (if automatic failover hasn't happened yet) then failover to secondary DED and lock the cluster. If the impaired server is Secondary DB then just lock the cluster to primary DED before the relaunch. To Failover dns-update $CLUSTER-ID $SECONDARY-DB To Lock ah-db-cluster lock $SERVER NOTE Make sure to failback/unlock cluster as mentioned in post relaunch steps. Suspend and relaunch the server: ah-server suspend $SERVER -P sv-taskrelaunch server $SERVER -m 1 If impacted server is fsdb or ded, remount the gluster on site after the server gets relaunched: site-fsremount $SITENAME After relaunch ensure that there is no data lag between databases using ah-db-cluster status $SERVER and never forget to unlock the cluster post relaunch: To Unlock ah-db-cluster unlock $SERVER To Failback dns-update $CLUSTER-ID $PRIMARY-DB Balancers Verify the affected server is Active balancer or passive. This can be identified by checking if balancer has EIP: ah-server list $SERVER -c eip_id external_ip Failover EIP to other bal if eip_id returns a number which means impaired bal is active: ah-elastic-ip failover $IP_ADDRESS_OF_ACTIVE_BAL Suspend and relaunch the server: ah-server suspend $SERVER -P sv-taskrelaunch server $SERVER -m 1 Verify all the services are running on the server: sv-checkservices $SERVER Search servers We should create an internal zendesk ticket if either Master or Slave server get impaired. We can find the list of Site names or the number of cores with the help of 'search-site' tool and add this detail to either OP or zendesk ticket. For example: [cloudservicesdev|search-service:search-service] ~/fields/1.81$ search-site -s <search-server-name-like-javaephem-456> Usage: search-site -c <Core ID - ABCD-123456.01live.default> search-site -s <Search server name - javasrv-123 or javaephem-456> To create an internal zendesk ticket, we should select 'Multiple Sites' option while executing 'ticket crit' tool and add the subject as well as the description accordingly: [cloudservicesdev|search-service:search-service] ~/fields/1.81$ ticket crit Single Customer or Multiple Customers? 1. Single Site 2. Multiple Sites Problem Type: 2 Ticket Subject: Please fill below template and add this information in the description while submitting the zendesk ticket. Hi Support, Acquia Search services have been impacted. The information directly below is provided by the OPS team about this incident. OP ticket: [link] Who is impacted - one or multiple customers? List known customers, core ID, or indexes, etc. depending on the situation: [link] What action has OPS taken yet, if any?: [info] Actions Support can do to help, if needed: [info] Is this escalated to the AS (Acquia Search) team? If so, please link to the AS ticket in Jira: [link] Here is a link to the Support runbook for Acquia Search shared services: https://confluence.acquia.com/display/support/Search For reference, here is a link to the OPS runbook: https://runbook.ops.acquia.com/master/incident_response/search_index_mon [OPS ticket creator] Search realm doesn't support task based relaunches so it has to be done manually: ah-server suspend $SERVER ah-server launch $SERVER NOTE If suspending the server fails, check the logs and verify the ec2 instance doesn't exist in AWS. In that case, manually set the status to 1 and clear out other information from fields: aws ec2 describe-instances --instance-ids $INSTANCE_ID --region $REGION ah-server edit javasrv-589 -s ec2_id=create status=1 external_fqhn= internal_fqhn= external_ec2= internal_ec2= external_ip= internal_ip= Make sure to watch the relaunch logs and seek a confirmation of successful execution of fields-config-web.php, rake rebuild and rake cron on javasrv and javaephem. In case of failure, login into the instance and manually perform rake dance: fssh $SERVER su - ${UNIX_USERNAME} rake rebuild rake cron NOTE Unix username is based on the region. For e.g. search server in us-east-1 will have unix username useast1as. It can also be found using ah-search farm FARM_ID . Post relaunch verify the indexes are showing success: ah-search ping_farm $FARM_ID Node servers Node servers have HA architecture which means even if one server is down - customer will still be able to use the service. No customer facing ticket is required for such case. Verify the server status and check if it is impaired from AWS: ah-server status $SERVER If both instance and system status shows up as impaired - suspend and relaunch the server: ah-server suspend $SERVER ah-server launch $SERVER NOTE Task based relaunch with sv-taskrelaunch also works fine but ah-server launch is usually faster. Verify the services are up and the instane status: sv-checkservices $SERVER ah-server status $SERVER Nodebal servers Nodebal servers are similar to the bal i.e. they contain an EIP on one of the server which can be failed over to other in case of outage. No customer facing ticket is required for it. Check the server status and see if it is impaired and verify if the nodebal is active i.e have an EIP attached: ah-server status $SERVER ah-server list $SERVER -c eip external_ip ## if EIP_ID is not nil - it means it is an active Nodebal Failover the EIP to other bal: ah-elastic-ip failover $EIP ## External IP value you get from above command Relaunch the server: ah-server suspend $SERVER ah-server launch $SERVER NOTE Task based relaunch with sv-taskrelaunch also works fine but ah-server launch is usually faster. Verify the services are up and the instane status: sv-checkservices $SERVER ah-server status $SERVER Diagnosing problems with relaunch and force relaunch If the relaunch is stuck or failing for some reason, verify the launcher logs: ah-task get $TASK_ID If you see the error similar to the one below, server launch has completed but stuck on fields-config-web. Execute sv-fcwkick $SERVER manually to fix this. Once fcw completes, the task usually gets completed within couple of minutes. [2019-08-01 18:01:45] Waiting for: for all sites on server to be marked deployed If launch is failing due to puppet errors or lack or resources, try relaunching the instance with --preserve: ah-server launch $SERVER --preserve Once server is relaunched with preserve, make sure to set the status to 0 on the server to avoid it getting reaped automatically. ah-server edit $SERVER -s status=0 If you are still unable to relaunch the instance, check with senior Ops engineer before escalating the issue to Cloud.","title":"Relaunching impaired servers"},{"location":"incident_response/impaired_server_relaunch/#relaunching-impaired-servers","text":"Process to relaunch impaired servers depends upon the type of server. This runbook deals with handling different types of servers.","title":"Relaunching impaired servers"},{"location":"incident_response/impaired_server_relaunch/#pre-checks","text":"Verify that server is impaired from AWS: ah-server status $SERVER The command should give the output similar to one below: [cloudservicesprod|hosting-prod:prod] ~/fields/1.115$ ah-server status staging-33609 staging-33609 (i-0f3d73e74482b7113): running in us-east-1c system_status impaired [{:name=>\"reachability\", :status=>\"failed\", :impaired_since=>2019-08-31 12:46:00 UTC}] instance_status impaired [{:name=>\"reachability\", :status=>\"failed\", :impaired_since=>2019-08-31 12:46:00 UTC}] If both system and instance status shows impaired then we would need to proceed with the relaunch. If only instance status is showing impaired, most of the time rebooting the instance resolves the issue. However, if the server doesn't respond within 2-3 minutes, then it may require a relaunch. web (ded,staging,web,srv) fs db balancers search node nodebal","title":"Pre-checks"},{"location":"incident_response/impaired_server_relaunch/#web-servers","text":"Other than webs, servers like deds (in single tier sites), staging and srv also serves web traffic. While staging and srv are NON-HA servers and their relaunch means the sites are down while relaunching them, we need to make sure that only HA is impacted while relaunching webs or deds. If the web is serving as memcache or cron web - the process would be different. Check the server and site layout and verify the web is traffic serving web or memcache/cron web: esl2 $SITENAME If the web is serving traffic, take it out of rotation and verify site is responding sv-webdisable $SERVER site-checkwebs $SITENAME Disable memcache service on the web. Only needed on web which is serving memcache. If site has dedicated memcache and the web isn't serving as dedicated memcache server (tagged as oob only), this wouldn't be required. ah-server edit $SERVER -s memcache_service_status=1 If the impaired server is Primary DED (if automatic failover hasn't happened yet) then failover to secondary DED and lock the cluster. If the impaired server is Secondary DED then just lock the cluster to primary DED before the relaunch. To Failover dns-update $CLUSTER-ID $SECONDARY-DB To Lock ah-db-cluster lock $SERVER NOTE Make sure to failback/unlock cluster as mentioned in post relaunch steps. Suspend the server before launching as it usually fails otherwise and relaunch it: ah-server suspend $SERVER -P sv-taskrelaunch server $SERVER -m 1 Once the relaunch is finished, remount gluster and add the web back to rotation: sv-fsremount $SERVER sv-webenable $SERVER Re-enable memcache service on the web if it was disabled earlier and run fields-config-memcache: ah-server edit $SERVER -s memcache_service_status=2 site-fcm $SITENAME Verify all the services are running on the server post relaunch: sv-checkservices $SERVER Verify site is passing the checks using site-checkwebs $SITENAME . After relaunch ensure that there is no data lag between databases using ah-db-cluster status $SERVER and never forget to unlock the cluster post relaunch: To Unlock ah-db-cluster unlock $SERVER To Failback dns-update $CLUSTER-ID $PRIMARY-DB","title":"Web Servers"},{"location":"incident_response/impaired_server_relaunch/#fs-servers","text":"Suspend the server and relaunch the server: ah-server suspend $SERVER -P sv-taskrelaunch server $SERVER -m 1 Make sure to remount the gluster on the site after the server gets relaunched: site-fsremount $SITENAME Verify all the services are running on the server: sv-checkservices $SERVER Verify site and gluster checks are passing post relaunch: site-checkwebs $SITENAME site-checkgluster $SITENAME","title":"FS Servers"},{"location":"incident_response/impaired_server_relaunch/#db-servers","text":"Verify the DB server is primary or secondary: ah-db-cluster status $SERVER If the impaired server is Primary DB (if automatic failover hasn't happened yet) then failover to secondary DED and lock the cluster. If the impaired server is Secondary DB then just lock the cluster to primary DED before the relaunch. To Failover dns-update $CLUSTER-ID $SECONDARY-DB To Lock ah-db-cluster lock $SERVER NOTE Make sure to failback/unlock cluster as mentioned in post relaunch steps. Suspend and relaunch the server: ah-server suspend $SERVER -P sv-taskrelaunch server $SERVER -m 1 If impacted server is fsdb or ded, remount the gluster on site after the server gets relaunched: site-fsremount $SITENAME After relaunch ensure that there is no data lag between databases using ah-db-cluster status $SERVER and never forget to unlock the cluster post relaunch: To Unlock ah-db-cluster unlock $SERVER To Failback dns-update $CLUSTER-ID $PRIMARY-DB","title":"DB servers"},{"location":"incident_response/impaired_server_relaunch/#balancers","text":"Verify the affected server is Active balancer or passive. This can be identified by checking if balancer has EIP: ah-server list $SERVER -c eip_id external_ip Failover EIP to other bal if eip_id returns a number which means impaired bal is active: ah-elastic-ip failover $IP_ADDRESS_OF_ACTIVE_BAL Suspend and relaunch the server: ah-server suspend $SERVER -P sv-taskrelaunch server $SERVER -m 1 Verify all the services are running on the server: sv-checkservices $SERVER","title":"Balancers"},{"location":"incident_response/impaired_server_relaunch/#search-servers","text":"We should create an internal zendesk ticket if either Master or Slave server get impaired. We can find the list of Site names or the number of cores with the help of 'search-site' tool and add this detail to either OP or zendesk ticket. For example: [cloudservicesdev|search-service:search-service] ~/fields/1.81$ search-site -s <search-server-name-like-javaephem-456> Usage: search-site -c <Core ID - ABCD-123456.01live.default> search-site -s <Search server name - javasrv-123 or javaephem-456> To create an internal zendesk ticket, we should select 'Multiple Sites' option while executing 'ticket crit' tool and add the subject as well as the description accordingly: [cloudservicesdev|search-service:search-service] ~/fields/1.81$ ticket crit Single Customer or Multiple Customers? 1. Single Site 2. Multiple Sites Problem Type: 2 Ticket Subject: Please fill below template and add this information in the description while submitting the zendesk ticket. Hi Support, Acquia Search services have been impacted. The information directly below is provided by the OPS team about this incident. OP ticket: [link] Who is impacted - one or multiple customers? List known customers, core ID, or indexes, etc. depending on the situation: [link] What action has OPS taken yet, if any?: [info] Actions Support can do to help, if needed: [info] Is this escalated to the AS (Acquia Search) team? If so, please link to the AS ticket in Jira: [link] Here is a link to the Support runbook for Acquia Search shared services: https://confluence.acquia.com/display/support/Search For reference, here is a link to the OPS runbook: https://runbook.ops.acquia.com/master/incident_response/search_index_mon [OPS ticket creator] Search realm doesn't support task based relaunches so it has to be done manually: ah-server suspend $SERVER ah-server launch $SERVER NOTE If suspending the server fails, check the logs and verify the ec2 instance doesn't exist in AWS. In that case, manually set the status to 1 and clear out other information from fields: aws ec2 describe-instances --instance-ids $INSTANCE_ID --region $REGION ah-server edit javasrv-589 -s ec2_id=create status=1 external_fqhn= internal_fqhn= external_ec2= internal_ec2= external_ip= internal_ip= Make sure to watch the relaunch logs and seek a confirmation of successful execution of fields-config-web.php, rake rebuild and rake cron on javasrv and javaephem. In case of failure, login into the instance and manually perform rake dance: fssh $SERVER su - ${UNIX_USERNAME} rake rebuild rake cron NOTE Unix username is based on the region. For e.g. search server in us-east-1 will have unix username useast1as. It can also be found using ah-search farm FARM_ID . Post relaunch verify the indexes are showing success: ah-search ping_farm $FARM_ID","title":"Search servers"},{"location":"incident_response/impaired_server_relaunch/#node-servers","text":"Node servers have HA architecture which means even if one server is down - customer will still be able to use the service. No customer facing ticket is required for such case. Verify the server status and check if it is impaired from AWS: ah-server status $SERVER If both instance and system status shows up as impaired - suspend and relaunch the server: ah-server suspend $SERVER ah-server launch $SERVER NOTE Task based relaunch with sv-taskrelaunch also works fine but ah-server launch is usually faster. Verify the services are up and the instane status: sv-checkservices $SERVER ah-server status $SERVER","title":"Node servers"},{"location":"incident_response/impaired_server_relaunch/#nodebal-servers","text":"Nodebal servers are similar to the bal i.e. they contain an EIP on one of the server which can be failed over to other in case of outage. No customer facing ticket is required for it. Check the server status and see if it is impaired and verify if the nodebal is active i.e have an EIP attached: ah-server status $SERVER ah-server list $SERVER -c eip external_ip ## if EIP_ID is not nil - it means it is an active Nodebal Failover the EIP to other bal: ah-elastic-ip failover $EIP ## External IP value you get from above command Relaunch the server: ah-server suspend $SERVER ah-server launch $SERVER NOTE Task based relaunch with sv-taskrelaunch also works fine but ah-server launch is usually faster. Verify the services are up and the instane status: sv-checkservices $SERVER ah-server status $SERVER","title":"Nodebal servers"},{"location":"incident_response/impaired_server_relaunch/#diagnosing-problems-with-relaunch-and-force-relaunch","text":"If the relaunch is stuck or failing for some reason, verify the launcher logs: ah-task get $TASK_ID If you see the error similar to the one below, server launch has completed but stuck on fields-config-web. Execute sv-fcwkick $SERVER manually to fix this. Once fcw completes, the task usually gets completed within couple of minutes. [2019-08-01 18:01:45] Waiting for: for all sites on server to be marked deployed If launch is failing due to puppet errors or lack or resources, try relaunching the instance with --preserve: ah-server launch $SERVER --preserve Once server is relaunched with preserve, make sure to set the status to 0 on the server to avoid it getting reaped automatically. ah-server edit $SERVER -s status=0 If you are still unable to relaunch the instance, check with senior Ops engineer before escalating the issue to Cloud.","title":"Diagnosing problems with relaunch and force relaunch"},{"location":"incident_response/index_ping_not_initiated/","text":"Sum Invocations LessThanThreshold 2.0 for FunctionName InitiateIndexCheck This alert is triggered when the InitiateIndexCheck Lambda function is not initiated at least one time in a 15 minute window. The check is triggered by a AWS CloudWatch event that triggers every 5 minutes. Log into the AWS console for the search-service account. In the search box, type CloudWatch and hit enter, this will take you to the CloudWatch screen. From the left-navigation, click Rules which is under Events . Verify that the InitiateIndexCheck rule status is enabled. If it is not, try to determine whether or not it was consciously disabled or of this was not intended. Possible avenues to explore this question is a Jira ticket search, Slack, or email to name a few. If it is enabled, click the InitiateIndexCheck link, and then check the schedule. It should read Fixed rate of 5 minutes . If this has been changed to some other rate, please change it to the correct rate. If the check is enabled and the schedule is correct, make sure that it has the InitiateIndexCheck Lambda function as a target. If not, under Actions in the top right corner of the screen, click Edit . Then under Target select add target and set it to the InitiateIndexCheck function. If everything appears to be configured correctly and you can't determine a reason why, open a ticket with AWS support.","title":"Sum Invocations LessThanThreshold 2.0 for FunctionName InitiateIndexCheck"},{"location":"incident_response/index_ping_not_initiated/#sum-invocations-lessthanthreshold-20-for-functionname-initiateindexcheck","text":"This alert is triggered when the InitiateIndexCheck Lambda function is not initiated at least one time in a 15 minute window. The check is triggered by a AWS CloudWatch event that triggers every 5 minutes. Log into the AWS console for the search-service account. In the search box, type CloudWatch and hit enter, this will take you to the CloudWatch screen. From the left-navigation, click Rules which is under Events . Verify that the InitiateIndexCheck rule status is enabled. If it is not, try to determine whether or not it was consciously disabled or of this was not intended. Possible avenues to explore this question is a Jira ticket search, Slack, or email to name a few. If it is enabled, click the InitiateIndexCheck link, and then check the schedule. It should read Fixed rate of 5 minutes . If this has been changed to some other rate, please change it to the correct rate. If the check is enabled and the schedule is correct, make sure that it has the InitiateIndexCheck Lambda function as a target. If not, under Actions in the top right corner of the screen, click Edit . Then under Target select add target and set it to the InitiateIndexCheck function. If everything appears to be configured correctly and you can't determine a reason why, open a ticket with AWS support.","title":"Sum Invocations LessThanThreshold 2.0 for FunctionName InitiateIndexCheck"},{"location":"incident_response/instance_management_acp/","text":"ACP Instance Management Most things are automated but sometimes we have to do things manually. Note : This runbook is only valid for upsize. If you are looking for ACP volume downsize then you need to do it manually by referring this runbook Manual Volume Resizes Confirm with Support or the AM that they cannot do this through Insight Log the volumes in the Jira ticket sv-vollist $SERVER Submit the volume task using the existing EBS ID of sdm ah-task submit --site-id $SITENAME \\ --description 'Resizing disk to <size> GB' \\ --body '{\"ebs_id\":\"<ebs_id>\",\"new_size_gb\":\"<size>\"}' \\ resize-volume Wait for the task to complete and verify the new size once complete","title":"ACP Instance Management"},{"location":"incident_response/instance_management_acp/#acp-instance-management","text":"Most things are automated but sometimes we have to do things manually. Note : This runbook is only valid for upsize. If you are looking for ACP volume downsize then you need to do it manually by referring this runbook","title":"ACP Instance Management"},{"location":"incident_response/instance_management_acp/#manual-volume-resizes","text":"Confirm with Support or the AM that they cannot do this through Insight Log the volumes in the Jira ticket sv-vollist $SERVER Submit the volume task using the existing EBS ID of sdm ah-task submit --site-id $SITENAME \\ --description 'Resizing disk to <size> GB' \\ --body '{\"ebs_id\":\"<ebs_id>\",\"new_size_gb\":\"<size>\"}' \\ resize-volume Wait for the task to complete and verify the new size once complete","title":"Manual Volume Resizes"},{"location":"incident_response/maintenance_past_due/","text":"Maintenance Past Due This alert pages Ops when a scheduled maintenance window has not entered \"In Progress\" status up to 15 minutes after the scheduled start time. Resolution To resolve this: Open the PagerDuty alert in the PD Web Interface Take the OP number and find it in JIRA Find the Assignee on the OP ticket Page them about it in #Operations chat If no response is received from the assignee within 5 minutes, page Ops Management or an Ops Coordinator. If no response is received from Ops Management or an Ops Coordinator, escalate to your Hotseat-Secondary.","title":"Maintenance Past Due"},{"location":"incident_response/maintenance_past_due/#maintenance-past-due","text":"This alert pages Ops when a scheduled maintenance window has not entered \"In Progress\" status up to 15 minutes after the scheduled start time.","title":"Maintenance Past Due"},{"location":"incident_response/maintenance_past_due/#resolution","text":"To resolve this: Open the PagerDuty alert in the PD Web Interface Take the OP number and find it in JIRA Find the Assignee on the OP ticket Page them about it in #Operations chat If no response is received from the assignee within 5 minutes, page Ops Management or an Ops Coordinator. If no response is received from Ops Management or an Ops Coordinator, escalate to your Hotseat-Secondary.","title":"Resolution"},{"location":"incident_response/malicious_high_traffic_hosts/","text":"Blocking Crawlers and Malicious High-Traffic Hosts Synopsis A customer site may encounter high traffic from one or more high-traffic or malicious hosts. Generally this involves HTTP or HTTPS requests against: Varnish (bal) Nginx (bal) Apache (web/ded) Often these events result in an Acquia site becoming unavailable. This document assists in diagnosing and mitigating this scenario. Identification (Know The Enemy) Ops currently leverages a couple different technologies to stream and review incoming requests to various logs. Most tools currently key off of site rather than host or server , so be sure to take this into account when you are looking at shared infrastructure such as shared balancers or deds/webs with multiple sites deployed to them. SumoLogic A SumoLogic dashboard exists to help provide Apache access log information that includes: HTTP Response Codes HTTP Methods (GET, POST, etc.) Originating IPs (X-Forwarded-For is included) User Agents The filter button in the top right of the dashboard allows users to specify the fields site name that they wish to view apache traffic for. TODO: Document queries to take site and server names to provide data. TODO: Create dashboard(s) that will take queries of this type and visualize it. Logstream, GoAccess , Site-traffic and site-trafficbyuseragent Currently, logstream , goaccess and site-traffic are the primary tools that Ops can use to identify high-traffic hosts to a given site. logstream is used to stream logs to a temporary location (usually /mnt/tmp/ on the bastion). site-traffic tool is used by Ops to easily check if there is a malicious IP making a lot of requests on the site or a potential DDOS. It looks at the apache access logs from Sumo to get its results. site-trafficbyuseragent tool is used by Ops to easily check the top 10 Useragents, sending traffic to the site over last 60 minutes. It looks at the apache access logs from one of the active web servers and gives the information about general trend of Useragent traffic. goaccess is one of the primary tools that Ops can use to visualize log data in a way that can be read in real-time. In order to expedite the process of viewing a given site's logs, wrappers have been introduced to ops-misc that make this process easier: $ site-logstream Usage: site-logstream SITE TYPE Supported TYPE: nginx varnish apache apache-error fpm-access fpm-error $ site-goaccess Usage: site-goaccess /path/to/log/file $ site-traffic Usage: site-traffic SITE $ site-trafficbyuseragent Usage: site-trafficbyuseragent SITE site-trafficbyuseragent SERVER Detection (Inspect The Enemy) If a given IP, IP range, or User Agent is making requests at an order of magnitude larger than any other, this may likely be the culprit. Verification (Question The Enemy) To verify that this is in fact a crawler or malicious host: Contact Support to determine if the customer is doing a load test. If so, that traffic is legitimate and should be left alone. Do a reverse lookup on the IP address using whois or dig . If the IP range belongs to a known organization such as Google, Bing, or Yahoo, the customer can modify and deploy robots.txt to their docroot to mitigate this. Does the whois information for the malicious IP or IP range come from a questionable source such as China or Nigeria? Does it originate from a single datacenter such as OVH ? Inspect the HTTP requests directly from the IP or range in question. Does it include random query strings or does it appear to be attempting an exploit? Inspect varnishtop . Is there a user-agent or URL that is being requested more than any others? Discuss with support about the malicious looking IPs and Useragents ; and act on IPs and Useragents requested by support . NOTE : As noted in OPS FAQ , Ops will block up to five (5) ip addresses and/or browser user-agents one (1) time at the load balancer layer for customers with dedicated load balancers. Read OPS FAQ for details. Mitigation (Slay The Enemy) A word on blocking methodologies Blocking IP ranges via .htaccess is the recommended method of mitigation, but other methods such as VCL blocking and iptables rules are listed for historical completeness. Support has the ability via Remote Admin (RA) to modify customer .htaccess rules and block abusive IP ranges, UserAgents, and other unique identifiers of abusive traffic/requests. If at all possible, Support should be engaged first and allowed time to create the requisite rules. If the impacted customer does not have RA, is on shared hardware, and is unresponsive to Support contact, escalate to a senior Ops Team Member or Ops Management immediately. Criteria for when to block via VCL or iptables Support is unable to raise the customer or modify .htaccess directly (RA customers) Support or the customer are unable to implement a WAF such as CloudFlare, Akamai, or DOSArrest The balancers are dedicated to the specific customer impacted The abusive traffic can be effectively stopped by a single modification to VCL or iptables Blocking an IP or IP Range Blocking via .htaccess (Not Preferred anymore) Support can edit or direct customers to edit .htaccess and block IPs using AH_CLIENT_IP and REMOTE_ADDR . Customer-Facing Documentation Support Documentation on Confluence Example block: # Match a specific IP address or Range SetEnvIf AH_CLIENT_IP \"^185\\.241\\.170\\.*\" Deny_Host SetEnvIf REMOTE_ADDR \"^185\\.241\\.170\\.*\" Deny_Host Deny from env=Deny_Host Blocking via Varnish (Not Recommended) NOTE : This method of blocking is not to be used on shared balancers unless specifically approved by a member of Ops Management. NOTE: Blocking IPs does not work if a customer is using an ELB in front of an impacted domain or site , as the IP(s) of the ELB instances will be referenced in logs rather than the origin of the request(s). Gather information using varnishtop on the active balancer. Which User Agent is requesting pages? varnishtop -C -I ReqHeader:User-Agent What site is being requested? (Host) varnishtop -C -I ReqHeader:Host What is the \"Accept-Language\" of the request? varnishtop -C -I ReqHeader:Accept-Language What is the most Requested URL? varnishtop -i ReqURL Who is this request being forwarded for? (Incoming from ELBs, CDNs, etc.) varnishtop -C -I ReqHeader:X-Forwarded-For RxProtocol HTTP/1.0 (Requested HTTP Protocol) varnishtop -i RxProtocol If required, craft a VCL to block the requisite traffic via Varnish. Disable puppet on the active bal, make a note with ah-runbook , and notify Support. YOUR_USER= # your fields username, example: \"jgoin\" JIRA= MESSAGE=\"$YOUR_USER - $JIRA - disable puppet for VCL block\" puppet agent --disable \"$MESSAGE\" ah-runbook \"$MESSAGE\" Block using the method identified in the above step. # Temporary block accept-language for OP-XXXXX if (req.http.Accept-Language ~ \"zh-CN\") { std.syslog(180, \"OP-XXXXX block\"); error 404 \"Not Found\"; } # End OP-XXXXX # Temporary block user-agent for OP-XXXXX if (req.http.User-Agent ~ \"SV1\") { std.syslog(180, \"OP-XXXXX block\"); error 404 \"Not Found\"; } # End OP-XXXXX # Temporary block url for OP-XXXXX if (req.http.url ~ \"PATH\") { std.syslog(180, \"OP-XXXXX block\"); error 404 \"Not Found\"; } # End OP-XXXXX Check VCL compilation status. varnishd -C -f /etc/varnish/default.vcl If the above command exits with \"0\", RELOAD and DO NOT RESTART Varnish. service varnish reload Once the event is over, re-enable Puppet and revert your changes. puppet agent --enable puppet agent --test Block Connections using iptables (Recommended for OPS) NOTE: We can block the UA/IP if site is severly impacted and customer would be taking time to block the IP through .htaccess. Refer OPS FAQ for permitted limit of IP/UA blockings using iptables. NOTE: Blocking IPs does not work if a customer is using an ELB in front of an impacted domain or site , as the IP(s) of the ELB instances will be referenced in logs rather than the origin of the request(s). NOTE: We can block the IP's on Dedicated EDGE clusters as well using below steps. This is tested in EDGE-73 and confirmed to work on edge clusters. WARNING: Setting no-config-iptables will prevent the sites balancers talking to any web that gets relaunched. It will also prevent memcache talking to any relaunched webs that has memcache running. We have limited monitoring for this feature so it can be left on accidentally for long periods of time and cause difficult to diagnose site outages. It's recommended not to use no-config-iptables for short term blocking as the iptables rules will probably persist well enough - but it can be set to assure customers in the short term that their block will hold if they will not be doing additional blocking themselves, eg in a CDN. To ensure iptables rules persist and are not wiped out by callback tasks, touch a file. touch /var/acquia/no-config-iptables Using the information above, determine the correct method of blocking. For single IPs: iptables -I INPUT 1 -s [lol.lol.lol.lol] -j DROP For an entire IP range (CIDR block notation): iptables -I INPUT 1 -s [lol.lol.lol.lol]/24 -j DROP Execute the method of blocking determined above against the appropriate host. Check for remaining connections on the host. netstat -ta | grep [BAD_IP] If connections remain, use cutter to remove those connections. # @TODO: Remove this when CL-16933 is completed. apt-get update && apt-get install cutter -y modprobe ip_conntrack cutter [BAD_IP] In cases where the above does not remove remaining connections, block outbound connections to the bad IP or IP range as well. iptables -I OUTPUT -d [BAD_IP|BAD_IP_RANGE/24] -j DROP Verify with netstat that connections have been blocked. netstat -ta | grep [BAD_IP] If required, escalate within the Ops team to the next available senior team member. Create a TSR to clear the lock file and run ah-config-iptables . Schedule the TSR to go on the Kanban board in 24 hours. fpdsh -l $SERVERS -c 'sudo rm /var/acquia/no-config-iptables; sudo ah-config-iptables' After blocking with iptables, wait at least 5 minutes then confirm the rule is being hit. Example below: root@bal-3446.prod:~# iptables -vnL Chain INPUT (policy DROP 12 packets, 937 bytes) pkts bytes target prot opt in out source destination 0 0 DROP all -- * * 78.169.162.147 0.0.0.0/0 0 0 DROP all -- * * 78.169.162.147 0.0.0.0/0 0 0 DROP all -- * * 85.211.170.32 0.0.0.0/0 0 0 DROP all -- * * 85.211.170.32 0.0.0.0/0 In this case, none of these DROP rules have been hit (the first two columns are all zeros). So you may as well remove them fpdsh -l $SERVERS -c 'sudo rm /var/acquia/no-config-iptables; sudo ah-config-iptables' If the iptables DROP rules are being hit, leave the rule in place and create a TSR to remove the block rule after 24 hours. fpdsh -l $SERVERS -c 'sudo rm /var/acquia/no-config-iptables; sudo ah-config-iptables' Blocking an Useragent Block Connections using iptables WARNING: setting no-config-iptables will prevent the sites balancers talking to any web that gets relaunched. It will also prevent memcache talking to any relaunched webs that has memcache running. We have limited monitoring for this feature so it can be left on accidentally for long periods of time and cause difficult to diagnose site outages. It's recommended not to use no-config-iptables for short term blocking as the iptables rules will probably persist well enough - but it can be set to assure customers in the short term that their block will hold if they will not be doing additional blocking themselves, eg in a CDN Using the information derived from site-trafficbyuseragent tool and from the decision derived from discussion with support, identify the useragent to be blocked. To ensure iptables rules persist and are not wiped out by callback tasks, touch a file. touch /var/acquia/no-config-iptables NOTE: Refer OPS FAQ for permitted limit of IP/UA blockings using iptables. For each Dedicated BALANCER of the site take the following step: For each USERAGENT (to be blocked): sudo iptables -I INPUT -p tcp --dport 80 -m string --algo bm --string \"USERAGENT\" -j DROP Verify that the blocking shows up in the iptables: sudo iptables -L After blocking with iptables, wait at least 5 minutes then confirm the rule is being hit. iptables -vnL In this case, none of these DROP rules have been hit. So you may as well remove them. rm /var/acquia/no-config-iptables sudo ah-config-iptables Check the logs, to observe the drop in traffic from useragent. Confirm that the traffic from intended Useragent is not hitting the servers anymore. File a TSR for 24 hours later, to unblock the useragent by refreshing the iptables on the dedicated BALANCERS. You can mention the following command in the TSR. rm /var/acquia/no-config-iptables sudo ah-config-iptables Also mention, for the TSR executer, to verify that the blocking rule is removed from the iptables. Verify Post-Block (Gloat Upon The Enemy's Grave) Check your log streaming and monitoring tools to ensure the block was successful. Ensure the connections are gone if not ask support to block via .htaccess or Cloudflare(in case customer is using). Roll php to remove the existing connections. site-restartfpm $SITENAME Escalate to cloud if issue persists despite blocking and service restarts.","title":"Blocking Crawlers and Malicious High-Traffic Hosts"},{"location":"incident_response/malicious_high_traffic_hosts/#blocking-crawlers-and-malicious-high-traffic-hosts","text":"","title":"Blocking Crawlers and Malicious High-Traffic Hosts"},{"location":"incident_response/malicious_high_traffic_hosts/#synopsis","text":"A customer site may encounter high traffic from one or more high-traffic or malicious hosts. Generally this involves HTTP or HTTPS requests against: Varnish (bal) Nginx (bal) Apache (web/ded) Often these events result in an Acquia site becoming unavailable. This document assists in diagnosing and mitigating this scenario.","title":"Synopsis"},{"location":"incident_response/malicious_high_traffic_hosts/#identification-know-the-enemy","text":"Ops currently leverages a couple different technologies to stream and review incoming requests to various logs. Most tools currently key off of site rather than host or server , so be sure to take this into account when you are looking at shared infrastructure such as shared balancers or deds/webs with multiple sites deployed to them.","title":"Identification (Know The Enemy)"},{"location":"incident_response/malicious_high_traffic_hosts/#sumologic","text":"A SumoLogic dashboard exists to help provide Apache access log information that includes: HTTP Response Codes HTTP Methods (GET, POST, etc.) Originating IPs (X-Forwarded-For is included) User Agents The filter button in the top right of the dashboard allows users to specify the fields site name that they wish to view apache traffic for. TODO: Document queries to take site and server names to provide data. TODO: Create dashboard(s) that will take queries of this type and visualize it.","title":"SumoLogic"},{"location":"incident_response/malicious_high_traffic_hosts/#logstream-goaccess-site-traffic-and-site-trafficbyuseragent","text":"Currently, logstream , goaccess and site-traffic are the primary tools that Ops can use to identify high-traffic hosts to a given site. logstream is used to stream logs to a temporary location (usually /mnt/tmp/ on the bastion). site-traffic tool is used by Ops to easily check if there is a malicious IP making a lot of requests on the site or a potential DDOS. It looks at the apache access logs from Sumo to get its results. site-trafficbyuseragent tool is used by Ops to easily check the top 10 Useragents, sending traffic to the site over last 60 minutes. It looks at the apache access logs from one of the active web servers and gives the information about general trend of Useragent traffic. goaccess is one of the primary tools that Ops can use to visualize log data in a way that can be read in real-time. In order to expedite the process of viewing a given site's logs, wrappers have been introduced to ops-misc that make this process easier: $ site-logstream Usage: site-logstream SITE TYPE Supported TYPE: nginx varnish apache apache-error fpm-access fpm-error $ site-goaccess Usage: site-goaccess /path/to/log/file $ site-traffic Usage: site-traffic SITE $ site-trafficbyuseragent Usage: site-trafficbyuseragent SITE site-trafficbyuseragent SERVER","title":"Logstream, GoAccess , Site-traffic and site-trafficbyuseragent"},{"location":"incident_response/malicious_high_traffic_hosts/#detection-inspect-the-enemy","text":"If a given IP, IP range, or User Agent is making requests at an order of magnitude larger than any other, this may likely be the culprit.","title":"Detection (Inspect The Enemy)"},{"location":"incident_response/malicious_high_traffic_hosts/#verification-question-the-enemy","text":"To verify that this is in fact a crawler or malicious host: Contact Support to determine if the customer is doing a load test. If so, that traffic is legitimate and should be left alone. Do a reverse lookup on the IP address using whois or dig . If the IP range belongs to a known organization such as Google, Bing, or Yahoo, the customer can modify and deploy robots.txt to their docroot to mitigate this. Does the whois information for the malicious IP or IP range come from a questionable source such as China or Nigeria? Does it originate from a single datacenter such as OVH ? Inspect the HTTP requests directly from the IP or range in question. Does it include random query strings or does it appear to be attempting an exploit? Inspect varnishtop . Is there a user-agent or URL that is being requested more than any others? Discuss with support about the malicious looking IPs and Useragents ; and act on IPs and Useragents requested by support . NOTE : As noted in OPS FAQ , Ops will block up to five (5) ip addresses and/or browser user-agents one (1) time at the load balancer layer for customers with dedicated load balancers. Read OPS FAQ for details.","title":"Verification (Question The Enemy)"},{"location":"incident_response/malicious_high_traffic_hosts/#mitigation-slay-the-enemy","text":"","title":"Mitigation (Slay The Enemy)"},{"location":"incident_response/malicious_high_traffic_hosts/#a-word-on-blocking-methodologies","text":"Blocking IP ranges via .htaccess is the recommended method of mitigation, but other methods such as VCL blocking and iptables rules are listed for historical completeness. Support has the ability via Remote Admin (RA) to modify customer .htaccess rules and block abusive IP ranges, UserAgents, and other unique identifiers of abusive traffic/requests. If at all possible, Support should be engaged first and allowed time to create the requisite rules. If the impacted customer does not have RA, is on shared hardware, and is unresponsive to Support contact, escalate to a senior Ops Team Member or Ops Management immediately.","title":"A word on blocking methodologies"},{"location":"incident_response/malicious_high_traffic_hosts/#criteria-for-when-to-block-via-vcl-or-iptables","text":"Support is unable to raise the customer or modify .htaccess directly (RA customers) Support or the customer are unable to implement a WAF such as CloudFlare, Akamai, or DOSArrest The balancers are dedicated to the specific customer impacted The abusive traffic can be effectively stopped by a single modification to VCL or iptables","title":"Criteria for when to block via VCL or iptables"},{"location":"incident_response/malicious_high_traffic_hosts/#blocking-an-ip-or-ip-range","text":"","title":"Blocking an IP or IP Range"},{"location":"incident_response/malicious_high_traffic_hosts/#blocking-via-htaccess-not-preferred-anymore","text":"Support can edit or direct customers to edit .htaccess and block IPs using AH_CLIENT_IP and REMOTE_ADDR . Customer-Facing Documentation Support Documentation on Confluence Example block: # Match a specific IP address or Range SetEnvIf AH_CLIENT_IP \"^185\\.241\\.170\\.*\" Deny_Host SetEnvIf REMOTE_ADDR \"^185\\.241\\.170\\.*\" Deny_Host Deny from env=Deny_Host","title":"Blocking via .htaccess (Not Preferred anymore)"},{"location":"incident_response/malicious_high_traffic_hosts/#blocking-via-varnish-not-recommended","text":"NOTE : This method of blocking is not to be used on shared balancers unless specifically approved by a member of Ops Management. NOTE: Blocking IPs does not work if a customer is using an ELB in front of an impacted domain or site , as the IP(s) of the ELB instances will be referenced in logs rather than the origin of the request(s). Gather information using varnishtop on the active balancer. Which User Agent is requesting pages? varnishtop -C -I ReqHeader:User-Agent What site is being requested? (Host) varnishtop -C -I ReqHeader:Host What is the \"Accept-Language\" of the request? varnishtop -C -I ReqHeader:Accept-Language What is the most Requested URL? varnishtop -i ReqURL Who is this request being forwarded for? (Incoming from ELBs, CDNs, etc.) varnishtop -C -I ReqHeader:X-Forwarded-For RxProtocol HTTP/1.0 (Requested HTTP Protocol) varnishtop -i RxProtocol If required, craft a VCL to block the requisite traffic via Varnish. Disable puppet on the active bal, make a note with ah-runbook , and notify Support. YOUR_USER= # your fields username, example: \"jgoin\" JIRA= MESSAGE=\"$YOUR_USER - $JIRA - disable puppet for VCL block\" puppet agent --disable \"$MESSAGE\" ah-runbook \"$MESSAGE\" Block using the method identified in the above step. # Temporary block accept-language for OP-XXXXX if (req.http.Accept-Language ~ \"zh-CN\") { std.syslog(180, \"OP-XXXXX block\"); error 404 \"Not Found\"; } # End OP-XXXXX # Temporary block user-agent for OP-XXXXX if (req.http.User-Agent ~ \"SV1\") { std.syslog(180, \"OP-XXXXX block\"); error 404 \"Not Found\"; } # End OP-XXXXX # Temporary block url for OP-XXXXX if (req.http.url ~ \"PATH\") { std.syslog(180, \"OP-XXXXX block\"); error 404 \"Not Found\"; } # End OP-XXXXX Check VCL compilation status. varnishd -C -f /etc/varnish/default.vcl If the above command exits with \"0\", RELOAD and DO NOT RESTART Varnish. service varnish reload Once the event is over, re-enable Puppet and revert your changes. puppet agent --enable puppet agent --test","title":"Blocking via Varnish (Not Recommended)"},{"location":"incident_response/malicious_high_traffic_hosts/#block-connections-using-iptables-recommended-for-ops","text":"NOTE: We can block the UA/IP if site is severly impacted and customer would be taking time to block the IP through .htaccess. Refer OPS FAQ for permitted limit of IP/UA blockings using iptables. NOTE: Blocking IPs does not work if a customer is using an ELB in front of an impacted domain or site , as the IP(s) of the ELB instances will be referenced in logs rather than the origin of the request(s). NOTE: We can block the IP's on Dedicated EDGE clusters as well using below steps. This is tested in EDGE-73 and confirmed to work on edge clusters. WARNING: Setting no-config-iptables will prevent the sites balancers talking to any web that gets relaunched. It will also prevent memcache talking to any relaunched webs that has memcache running. We have limited monitoring for this feature so it can be left on accidentally for long periods of time and cause difficult to diagnose site outages. It's recommended not to use no-config-iptables for short term blocking as the iptables rules will probably persist well enough - but it can be set to assure customers in the short term that their block will hold if they will not be doing additional blocking themselves, eg in a CDN. To ensure iptables rules persist and are not wiped out by callback tasks, touch a file. touch /var/acquia/no-config-iptables Using the information above, determine the correct method of blocking. For single IPs: iptables -I INPUT 1 -s [lol.lol.lol.lol] -j DROP For an entire IP range (CIDR block notation): iptables -I INPUT 1 -s [lol.lol.lol.lol]/24 -j DROP Execute the method of blocking determined above against the appropriate host. Check for remaining connections on the host. netstat -ta | grep [BAD_IP] If connections remain, use cutter to remove those connections. # @TODO: Remove this when CL-16933 is completed. apt-get update && apt-get install cutter -y modprobe ip_conntrack cutter [BAD_IP] In cases where the above does not remove remaining connections, block outbound connections to the bad IP or IP range as well. iptables -I OUTPUT -d [BAD_IP|BAD_IP_RANGE/24] -j DROP Verify with netstat that connections have been blocked. netstat -ta | grep [BAD_IP] If required, escalate within the Ops team to the next available senior team member. Create a TSR to clear the lock file and run ah-config-iptables . Schedule the TSR to go on the Kanban board in 24 hours. fpdsh -l $SERVERS -c 'sudo rm /var/acquia/no-config-iptables; sudo ah-config-iptables' After blocking with iptables, wait at least 5 minutes then confirm the rule is being hit. Example below: root@bal-3446.prod:~# iptables -vnL Chain INPUT (policy DROP 12 packets, 937 bytes) pkts bytes target prot opt in out source destination 0 0 DROP all -- * * 78.169.162.147 0.0.0.0/0 0 0 DROP all -- * * 78.169.162.147 0.0.0.0/0 0 0 DROP all -- * * 85.211.170.32 0.0.0.0/0 0 0 DROP all -- * * 85.211.170.32 0.0.0.0/0 In this case, none of these DROP rules have been hit (the first two columns are all zeros). So you may as well remove them fpdsh -l $SERVERS -c 'sudo rm /var/acquia/no-config-iptables; sudo ah-config-iptables' If the iptables DROP rules are being hit, leave the rule in place and create a TSR to remove the block rule after 24 hours. fpdsh -l $SERVERS -c 'sudo rm /var/acquia/no-config-iptables; sudo ah-config-iptables'","title":"Block Connections using iptables (Recommended for OPS)"},{"location":"incident_response/malicious_high_traffic_hosts/#blocking-an-useragent","text":"","title":"Blocking an Useragent"},{"location":"incident_response/malicious_high_traffic_hosts/#block-connections-using-iptables","text":"WARNING: setting no-config-iptables will prevent the sites balancers talking to any web that gets relaunched. It will also prevent memcache talking to any relaunched webs that has memcache running. We have limited monitoring for this feature so it can be left on accidentally for long periods of time and cause difficult to diagnose site outages. It's recommended not to use no-config-iptables for short term blocking as the iptables rules will probably persist well enough - but it can be set to assure customers in the short term that their block will hold if they will not be doing additional blocking themselves, eg in a CDN Using the information derived from site-trafficbyuseragent tool and from the decision derived from discussion with support, identify the useragent to be blocked. To ensure iptables rules persist and are not wiped out by callback tasks, touch a file. touch /var/acquia/no-config-iptables NOTE: Refer OPS FAQ for permitted limit of IP/UA blockings using iptables. For each Dedicated BALANCER of the site take the following step: For each USERAGENT (to be blocked): sudo iptables -I INPUT -p tcp --dport 80 -m string --algo bm --string \"USERAGENT\" -j DROP Verify that the blocking shows up in the iptables: sudo iptables -L After blocking with iptables, wait at least 5 minutes then confirm the rule is being hit. iptables -vnL In this case, none of these DROP rules have been hit. So you may as well remove them. rm /var/acquia/no-config-iptables sudo ah-config-iptables Check the logs, to observe the drop in traffic from useragent. Confirm that the traffic from intended Useragent is not hitting the servers anymore. File a TSR for 24 hours later, to unblock the useragent by refreshing the iptables on the dedicated BALANCERS. You can mention the following command in the TSR. rm /var/acquia/no-config-iptables sudo ah-config-iptables Also mention, for the TSR executer, to verify that the blocking rule is removed from the iptables.","title":"Block Connections using iptables"},{"location":"incident_response/malicious_high_traffic_hosts/#verify-post-block-gloat-upon-the-enemys-grave","text":"Check your log streaming and monitoring tools to ensure the block was successful. Ensure the connections are gone if not ask support to block via .htaccess or Cloudflare(in case customer is using). Roll php to remove the existing connections. site-restartfpm $SITENAME Escalate to cloud if issue persists despite blocking and service restarts.","title":"Verify Post-Block (Gloat Upon The Enemy's Grave)"},{"location":"incident_response/mon_server_host_count/","text":"Mon Server Host Count The Mon Sever Host Count check appears for a nagios server , when the number of hosts monitored by a nagios server instance increases more than 250 hosts . Check if the server has host monitored more than 250 Get the mon server ID from mon instance mentioned in alert e.g in mon-xyzmn \"id=xyzmn\" Run below command to check whether the monitored hosts are more than 250 ah-server list % -w status=0 mon_server_id=xyzmn |wc -l If output is greater than 250 proceed with the resolution as mentioned below. Resolution For resolution of this alert we need to move monitored host from alerting mon server to the mon server which is monitoring host below 250. Specify the Host as mentioned in the ticket SERVER= mon-moveactive ${SERVER} This will show you whether the server is active or not and do you want to proceed . Press enter here: mon-xyzmn is active. Press Enter to change the active mon and move overflow servers / Ctrl-C to wuss out: There are two scenarios possible here : Scenario 1: You get the output showing all the other mon servers from the region and their corresponding monitored Hosts Count 0. mon-xxxx: pp 1. mon-yyyy: ff Please select a mon to make active [0..1]: Select the server which has least number of monitored Hosts Count (represented by pp , ff in the above output) by selecting 0 or 1 . This will throw an output to the screen showing the reconfiguration of the new mon server as active and movement of the hosts to the new active mon host. Press enter whenever it asks for : Press enter to move web-aaaa from mon-15915 to mon-yyyy: Example output Adding active tag to mon-3847 Added active to mon-3847 Removing active tag from mon-15915 Removed active from mon-15915 mon-15915 is monitoring >250 servers Searching for mon servers in ap-southeast-2 with VPC ec2_classic and the tag active... Moving overflow servers... Press enter to move web-35202 from mon-15915 to mon-3847: INFO: server = web-35202 INFO: current_mon_server = mon-15915 INFO: new_mon = mon-3847 INFO: Removing web-35202 from monitoring. [2019-07-16 11:55:28] Socket opened to mon-15915.prod to downtime for 30 minutes from now. [2019-07-16 11:55:33] OK: Livestatus response in schedule_downtime: 107 INFO: Reconfiguring mon-15915. INFO: Copying RRD graphs from mon-15915 to bastion-22 to mon-3847 INFO: Setting mon-3847 for web-35202. web-35202 set mon_server_id=3847 Updated 1 servers. INFO: Reconfiguring mon-3847. INFO: Reconfiguring web-35202. INFO: Remove RRD files from mon-15915. INFO: Completed. Press enter to move web-35483 from mon-15915 to mon-3847: INFO: server = web-35483 INFO: current_mon_server = mon-15915 INFO: new_mon = mon-3847 INFO: Removing web-35483 from monitoring. [2019-07-16 11:57:19] Socket opened to mon-15915.prod to downtime for 30 minutes from now. [2019-07-16 11:57:24] OK: Livestatus response in schedule_downtime: 107 INFO: Reconfiguring mon-15915. INFO: Copying RRD graphs from mon-15915 to bastion-22 to mon-3847 INFO: Setting mon-3847 for web-35483. web-35483 set mon_server_id=3847 Updated 1 servers. INFO: Reconfiguring mon-3847. INFO: Reconfiguring web-35483. INFO: Remove RRD files from mon-15915. INFO: Completed. Press enter to move web-35484 from mon-15915 to mon-3847: INFO: server = web-35484 INFO: current_mon_server = mon-15915 INFO: new_mon = mon-3847 INFO: Removing web-35484 from monitoring. [2019-07-16 11:58:14] Socket opened to mon-15915.prod to downtime for 30 minutes from now. [2019-07-16 11:58:42] OK: Livestatus response in schedule_downtime: 107 INFO: Reconfiguring mon-15915. INFO: Copying RRD graphs from mon-15915 to bastion-22 to mon-3847 INFO: Setting mon-3847 for web-35484. web-35483 Scenario 2: There are no other mon servers in the region and you need to provision a new mon server There are no other mon servers in this region to make active. Please spin another mon instance Mon server provisioning runbook . Prep steps before provisioning new mon instance: 1. Find the relevant information about the current mon server and set the variables. ah-server list ${SERVER} -c status ami_type ec2_id vpc_id ec2_availability_zone ec2_region REGION= Set an availability zone other than the availability zone of $SERVER. AZ= Set VPC ID , if not nil. VPC_ID= Allocate and launch the new Mon Server. Add VPC_ID ,if relevant, to the allocation command. NOTE: --mon-server is given the value (in the command below) of any other mon server in the region , which can monitor the new mon server. For this we will use our ${SERVER} ah-server allocate mon --ami-type c4.large --region ${REGION} \\ --avail-zone ${AZ} --primary-volume-size 100 \\ --secondary-volume-size 1 --mon-server ${SERVER} The above command will give you the new Mon server name. Set NEW_SERVER variable: NEW_SERVER= ah-server launch $NEW_SERVER Once the server is launched go back to step of mon-moveactive and complete the migration of hosts to new Mon server. mon-moveactive ${SERVER}","title":"Mon Server Host Count"},{"location":"incident_response/mon_server_host_count/#mon-server-host-count","text":"The Mon Sever Host Count check appears for a nagios server , when the number of hosts monitored by a nagios server instance increases more than 250 hosts .","title":"Mon Server Host Count"},{"location":"incident_response/mon_server_host_count/#check-if-the-server-has-host-monitored-more-than-250","text":"Get the mon server ID from mon instance mentioned in alert e.g in mon-xyzmn \"id=xyzmn\" Run below command to check whether the monitored hosts are more than 250 ah-server list % -w status=0 mon_server_id=xyzmn |wc -l If output is greater than 250 proceed with the resolution as mentioned below.","title":"Check if the server has host monitored more than 250"},{"location":"incident_response/mon_server_host_count/#resolution","text":"For resolution of this alert we need to move monitored host from alerting mon server to the mon server which is monitoring host below 250. Specify the Host as mentioned in the ticket SERVER= mon-moveactive ${SERVER} This will show you whether the server is active or not and do you want to proceed . Press enter here: mon-xyzmn is active. Press Enter to change the active mon and move overflow servers / Ctrl-C to wuss out: There are two scenarios possible here :","title":"Resolution"},{"location":"incident_response/mon_server_host_count/#scenario-1-you-get-the-output-showing-all-the-other-mon-servers-from-the-region-and-their-corresponding-monitored-hosts-count","text":"0. mon-xxxx: pp 1. mon-yyyy: ff Please select a mon to make active [0..1]: Select the server which has least number of monitored Hosts Count (represented by pp , ff in the above output) by selecting 0 or 1 . This will throw an output to the screen showing the reconfiguration of the new mon server as active and movement of the hosts to the new active mon host. Press enter whenever it asks for : Press enter to move web-aaaa from mon-15915 to mon-yyyy:","title":"Scenario 1: You get the output showing all the other mon servers from the region and their corresponding monitored Hosts Count"},{"location":"incident_response/mon_server_host_count/#example-output","text":"Adding active tag to mon-3847 Added active to mon-3847 Removing active tag from mon-15915 Removed active from mon-15915 mon-15915 is monitoring >250 servers Searching for mon servers in ap-southeast-2 with VPC ec2_classic and the tag active... Moving overflow servers... Press enter to move web-35202 from mon-15915 to mon-3847: INFO: server = web-35202 INFO: current_mon_server = mon-15915 INFO: new_mon = mon-3847 INFO: Removing web-35202 from monitoring. [2019-07-16 11:55:28] Socket opened to mon-15915.prod to downtime for 30 minutes from now. [2019-07-16 11:55:33] OK: Livestatus response in schedule_downtime: 107 INFO: Reconfiguring mon-15915. INFO: Copying RRD graphs from mon-15915 to bastion-22 to mon-3847 INFO: Setting mon-3847 for web-35202. web-35202 set mon_server_id=3847 Updated 1 servers. INFO: Reconfiguring mon-3847. INFO: Reconfiguring web-35202. INFO: Remove RRD files from mon-15915. INFO: Completed. Press enter to move web-35483 from mon-15915 to mon-3847: INFO: server = web-35483 INFO: current_mon_server = mon-15915 INFO: new_mon = mon-3847 INFO: Removing web-35483 from monitoring. [2019-07-16 11:57:19] Socket opened to mon-15915.prod to downtime for 30 minutes from now. [2019-07-16 11:57:24] OK: Livestatus response in schedule_downtime: 107 INFO: Reconfiguring mon-15915. INFO: Copying RRD graphs from mon-15915 to bastion-22 to mon-3847 INFO: Setting mon-3847 for web-35483. web-35483 set mon_server_id=3847 Updated 1 servers. INFO: Reconfiguring mon-3847. INFO: Reconfiguring web-35483. INFO: Remove RRD files from mon-15915. INFO: Completed. Press enter to move web-35484 from mon-15915 to mon-3847: INFO: server = web-35484 INFO: current_mon_server = mon-15915 INFO: new_mon = mon-3847 INFO: Removing web-35484 from monitoring. [2019-07-16 11:58:14] Socket opened to mon-15915.prod to downtime for 30 minutes from now. [2019-07-16 11:58:42] OK: Livestatus response in schedule_downtime: 107 INFO: Reconfiguring mon-15915. INFO: Copying RRD graphs from mon-15915 to bastion-22 to mon-3847 INFO: Setting mon-3847 for web-35484. web-35483","title":"Example output"},{"location":"incident_response/mon_server_host_count/#scenario-2-there-are-no-other-mon-servers-in-the-region-and-you-need-to-provision-a-new-mon-server","text":"There are no other mon servers in this region to make active. Please spin another mon instance Mon server provisioning runbook . Prep steps before provisioning new mon instance: 1. Find the relevant information about the current mon server and set the variables. ah-server list ${SERVER} -c status ami_type ec2_id vpc_id ec2_availability_zone ec2_region REGION= Set an availability zone other than the availability zone of $SERVER. AZ= Set VPC ID , if not nil. VPC_ID= Allocate and launch the new Mon Server. Add VPC_ID ,if relevant, to the allocation command. NOTE: --mon-server is given the value (in the command below) of any other mon server in the region , which can monitor the new mon server. For this we will use our ${SERVER} ah-server allocate mon --ami-type c4.large --region ${REGION} \\ --avail-zone ${AZ} --primary-volume-size 100 \\ --secondary-volume-size 1 --mon-server ${SERVER} The above command will give you the new Mon server name. Set NEW_SERVER variable: NEW_SERVER= ah-server launch $NEW_SERVER Once the server is launched go back to step of mon-moveactive and complete the migration of hosts to new Mon server. mon-moveactive ${SERVER}","title":"Scenario 2: There are no other mon servers in the region and you need to provision a new mon server"},{"location":"incident_response/monitoring_audit/","text":"Monitoring Audit The Monitoring Audit check on master hosts determines if server(s) are currently out of monitoring and alerts if so. Resolution In the body of the service alert you will find the list of servers that are not in monitoring. Do not downtime the alert! First check JIRA why the server is out of monitoring. If the server has been relaunched recently then add it into monitoring. sv-monenable $SERVER If the server has been removed from monitoring intentionally by any Ops member then add the monitor_suppress tag to skip the monitoring audit check. ah-server tag add ${SERVER} -t monitor_suppress For any known alerting services on servers put in monitoring, resolve if actionable; otherwise follow the downtime procedure .","title":"Monitoring Audit"},{"location":"incident_response/monitoring_audit/#monitoring-audit","text":"The Monitoring Audit check on master hosts determines if server(s) are currently out of monitoring and alerts if so.","title":"Monitoring Audit"},{"location":"incident_response/monitoring_audit/#resolution","text":"In the body of the service alert you will find the list of servers that are not in monitoring. Do not downtime the alert! First check JIRA why the server is out of monitoring. If the server has been relaunched recently then add it into monitoring. sv-monenable $SERVER If the server has been removed from monitoring intentionally by any Ops member then add the monitor_suppress tag to skip the monitoring audit check. ah-server tag add ${SERVER} -t monitor_suppress For any known alerting services on servers put in monitoring, resolve if actionable; otherwise follow the downtime procedure .","title":"Resolution"},{"location":"incident_response/monthly_eip_audit/","text":"Handling monthly EIP audit tickets EIP's doesn't cost us money as long as those are associated with a running instance. However, AWS charges amount if there are unused EIP's left in allocated state. To save the cost for those unused EIPs, we perform monthly audit for unused EIP's. A recurring ticket has been setup for this purpose. Auditing EIP's in field We need to run the following command to audit the EIP's which are available in fields but not present in AWS: audit-realm-eips audit_fields If any EIP is stuck in fields but not present in AWS, then run the commands the tool provides to cleanup them. Audit EIP's in AWS The purpose of this is to release EIP's which are unused and hasn't been released from AWS yet. To audit EIP's unused but available in AWS, execute the following command: audit-realm-eips audit_aws Before releasing an EIP using the commands generated by tool above, we need to ensure following things: Verify that the EIP didn't come from a recent deprovision ticket for which TSR ticket is pending. If it was part of recent deprovision, link the TSR ticket which will release the EIP once the hardware gets completely terminated. Identify if the EIP belongs to a customer server or non-customer server (internal servers) and verify the server no longer exists or needed. If For VPC IP, we get an EIP Allocation ID. For documentation purposes, get the EIP using the command below and comment in the JIRA ticket: ALLOCATION_ID= REGION= aws ec2 describe-addresses --allocation-ids $ALLOCATION_ID --region $REGION Once we have validated the EIP is not going to be released and is stale - run the commands generated by the tool for those EIP's and release them back to AWS.","title":"Handling monthly EIP audit tickets"},{"location":"incident_response/monthly_eip_audit/#handling-monthly-eip-audit-tickets","text":"EIP's doesn't cost us money as long as those are associated with a running instance. However, AWS charges amount if there are unused EIP's left in allocated state. To save the cost for those unused EIPs, we perform monthly audit for unused EIP's. A recurring ticket has been setup for this purpose.","title":"Handling monthly EIP audit tickets"},{"location":"incident_response/monthly_eip_audit/#auditing-eips-in-field","text":"We need to run the following command to audit the EIP's which are available in fields but not present in AWS: audit-realm-eips audit_fields If any EIP is stuck in fields but not present in AWS, then run the commands the tool provides to cleanup them.","title":"Auditing EIP's in field"},{"location":"incident_response/monthly_eip_audit/#audit-eips-in-aws","text":"The purpose of this is to release EIP's which are unused and hasn't been released from AWS yet. To audit EIP's unused but available in AWS, execute the following command: audit-realm-eips audit_aws Before releasing an EIP using the commands generated by tool above, we need to ensure following things: Verify that the EIP didn't come from a recent deprovision ticket for which TSR ticket is pending. If it was part of recent deprovision, link the TSR ticket which will release the EIP once the hardware gets completely terminated. Identify if the EIP belongs to a customer server or non-customer server (internal servers) and verify the server no longer exists or needed. If For VPC IP, we get an EIP Allocation ID. For documentation purposes, get the EIP using the command below and comment in the JIRA ticket: ALLOCATION_ID= REGION= aws ec2 describe-addresses --allocation-ids $ALLOCATION_ID --region $REGION Once we have validated the EIP is not going to be released and is stale - run the commands generated by the tool for those EIP's and release them back to AWS.","title":"Audit EIP's in AWS"},{"location":"incident_response/multiregion_rsync_verification/","text":"MultiRegion Rsync Verification /usr/local/sbin/ah-mrrsync has been running longer than 3600 seconds (1 hour). This is generally due to a large number of files changed/uploaded by the customer recently to their gluster mount, which then must be rsynced from the active region to the passive region to all fsdbmesh-% servers. Resolution If it runs over 2 hours or so, it should definitely be investigated. Log into the first web in the active region and strace the active rsync process and make sure it is copying files. It's more than likely that the customer has too many files to stat so rsync is taking a very long time. If the fsdbmesh have standard volumes, you can make an OPS ICR ticket to move them to SSD (gp3) volumes.","title":"MultiRegion Rsync Verification"},{"location":"incident_response/multiregion_rsync_verification/#multiregion-rsync-verification","text":"/usr/local/sbin/ah-mrrsync has been running longer than 3600 seconds (1 hour). This is generally due to a large number of files changed/uploaded by the customer recently to their gluster mount, which then must be rsynced from the active region to the passive region to all fsdbmesh-% servers.","title":"MultiRegion Rsync Verification"},{"location":"incident_response/multiregion_rsync_verification/#resolution","text":"If it runs over 2 hours or so, it should definitely be investigated. Log into the first web in the active region and strace the active rsync process and make sure it is copying files. It's more than likely that the customer has too many files to stat so rsync is taking a very long time. If the fsdbmesh have standard volumes, you can make an OPS ICR ticket to move them to SSD (gp3) volumes.","title":"Resolution"},{"location":"incident_response/mysql_available/","text":"MySQL Available There are several causes of this alert: Slave IO: Yes Slave SQL: No Seconds Behind Master: (null) MySQL daemon has crashed Replication is NULL The ops-mon user is missing Response If the server is part of a replicating DB cluster it is advised to lock the database to the active server with ah-db-cluster lock . No Seconds Behind Master This alert may be present on both DB hosts in a cluster. This is indicative of a replication error on the slave. Review the slave status: mysql -e \"show slave status\\G\" You may see output containing something like this: Last_SQL_Error: Error 'Duplicate entry 'theme_registry:runtime:mittr:cache' for key 'PRIMARY'' on query. Default database: 'techreview'. Query: 'INSERT INTO semaphore (name, value, expire) VALUES ('theme_registry:runtime:mittr:cache', '546650415696f5b6e05448.94845938', '1452733934.6442')' If this error, or similar, is present on both servers it means that the DB split brained - webs wrote the same or similar queries to both servers. This can happen just before DNS is updated to failover the DB. If the error query is for a cache table, then we skip it with the slave resync tool: mysql-slave-resync.pl Gather more info from the hosts that failed the DB over site-dbfailed $SITE SSH to the host that updated dns and review /var/log/daemon.log MySQL Daemon Crash / Not Running These points are intended as guidance for things to look at. When in doubt or in need of assistance, please escalate as a downed MySQL server is very bad. MySQL logs error messages to a file on /vol/ebs1: view /var/lib/mysql/$(hostname).err Check the volume usage: df -h /vol/ebs1 WARNING : Do not relaunch an instance if the MySQL service is failing to start, as the launch will always fail due to puppet errors. Replication Is NULL If you see an error like this one: Last_IO_Error: error connecting to master \\ 'root@host-xxx.stage.hosting.acquia.com:3306' \\ - retry-time: 60 retries: 86400 You will need to run ah-config-iptables on both MySQL servers. Missing ops-mon User Discover if the user does not exist: mysql [(none)]> use mysql Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A mysql [mysql]> select user,host from user; +------------------+----------------------------------+ | user | host | +------------------+----------------------------------+ | <sitename> | % | | root | % | | slave | % | | root | 127.0.0.1 | | root | ::1 | | <sitename> | ded-2352 | | root | ded-2352.prod.hosting.acquia.com | | debian-sys-maint | localhost | | <sitename> | localhost | | root | localhost | +------------------+----------------------------------+ 10 rows in set (0.00 sec) Add the user to MySQL mysql -e \"grant Replication Client on *.* to 'ops-mon'@'localhost' \\ identified by 'm0n1t0r1ng';\" Verify the user now exists: mysql [(none)]> use mysql Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A mysql [mysql]> select user,host from user; +------------------+----------------------------------+ | user | host | +------------------+----------------------------------+ | <sitename> | % | | root | % | | slave | % | | root | 127.0.0.1 | | root | ::1 | | <sitename> | ded-2352 | | root | ded-2352.prod.hosting.acquia.com | | debian-sys-maint | localhost | | <sitename> | localhost | | ops-mon | localhost | | root | localhost | +------------------+----------------------------------+ 10 rows in set (0.00 sec)","title":"MySQL Available"},{"location":"incident_response/mysql_available/#mysql-available","text":"There are several causes of this alert: Slave IO: Yes Slave SQL: No Seconds Behind Master: (null) MySQL daemon has crashed Replication is NULL The ops-mon user is missing","title":"MySQL Available"},{"location":"incident_response/mysql_available/#response","text":"If the server is part of a replicating DB cluster it is advised to lock the database to the active server with ah-db-cluster lock .","title":"Response"},{"location":"incident_response/mysql_available/#no-seconds-behind-master","text":"This alert may be present on both DB hosts in a cluster. This is indicative of a replication error on the slave. Review the slave status: mysql -e \"show slave status\\G\" You may see output containing something like this: Last_SQL_Error: Error 'Duplicate entry 'theme_registry:runtime:mittr:cache' for key 'PRIMARY'' on query. Default database: 'techreview'. Query: 'INSERT INTO semaphore (name, value, expire) VALUES ('theme_registry:runtime:mittr:cache', '546650415696f5b6e05448.94845938', '1452733934.6442')' If this error, or similar, is present on both servers it means that the DB split brained - webs wrote the same or similar queries to both servers. This can happen just before DNS is updated to failover the DB. If the error query is for a cache table, then we skip it with the slave resync tool: mysql-slave-resync.pl Gather more info from the hosts that failed the DB over site-dbfailed $SITE SSH to the host that updated dns and review /var/log/daemon.log","title":"No Seconds Behind Master"},{"location":"incident_response/mysql_available/#mysql-daemon-crash-not-running","text":"These points are intended as guidance for things to look at. When in doubt or in need of assistance, please escalate as a downed MySQL server is very bad. MySQL logs error messages to a file on /vol/ebs1: view /var/lib/mysql/$(hostname).err Check the volume usage: df -h /vol/ebs1 WARNING : Do not relaunch an instance if the MySQL service is failing to start, as the launch will always fail due to puppet errors.","title":"MySQL Daemon Crash / Not Running"},{"location":"incident_response/mysql_available/#replication-is-null","text":"If you see an error like this one: Last_IO_Error: error connecting to master \\ 'root@host-xxx.stage.hosting.acquia.com:3306' \\ - retry-time: 60 retries: 86400 You will need to run ah-config-iptables on both MySQL servers.","title":"Replication Is NULL"},{"location":"incident_response/mysql_available/#missing-ops-mon-user","text":"Discover if the user does not exist: mysql [(none)]> use mysql Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A mysql [mysql]> select user,host from user; +------------------+----------------------------------+ | user | host | +------------------+----------------------------------+ | <sitename> | % | | root | % | | slave | % | | root | 127.0.0.1 | | root | ::1 | | <sitename> | ded-2352 | | root | ded-2352.prod.hosting.acquia.com | | debian-sys-maint | localhost | | <sitename> | localhost | | root | localhost | +------------------+----------------------------------+ 10 rows in set (0.00 sec) Add the user to MySQL mysql -e \"grant Replication Client on *.* to 'ops-mon'@'localhost' \\ identified by 'm0n1t0r1ng';\" Verify the user now exists: mysql [(none)]> use mysql Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A mysql [mysql]> select user,host from user; +------------------+----------------------------------+ | user | host | +------------------+----------------------------------+ | <sitename> | % | | root | % | | slave | % | | root | 127.0.0.1 | | root | ::1 | | <sitename> | ded-2352 | | root | ded-2352.prod.hosting.acquia.com | | debian-sys-maint | localhost | | <sitename> | localhost | | ops-mon | localhost | | root | localhost | +------------------+----------------------------------+ 10 rows in set (0.00 sec)","title":"Missing ops-mon User"},{"location":"incident_response/mysql_debian_sys_maint/","text":"MySQL Debian Sys Maint alert This alert means the debian system user does not have access to the MySQL database and can not perform certain functions. Usually occurs after an instance is relaunched. /usr/bin/sudo /usr/lib/nagios/plugins/check_debian-sys-maint Response Simply run the script to reset the password to something known, which can be done from the bastion. sv-resetdebian $SERVER Or when logged into the machine that is alerting. sudo reset-debian-password.sh Caveat The pt-heartbeat service relies on the debian system user. Sometimes the service can die if the password isn't reset and will need to be restarted on the alerting server after running one of the commands above. sudo service pt-heartbeat restart","title":"MySQL Debian Sys Maint alert"},{"location":"incident_response/mysql_debian_sys_maint/#mysql-debian-sys-maint-alert","text":"This alert means the debian system user does not have access to the MySQL database and can not perform certain functions. Usually occurs after an instance is relaunched. /usr/bin/sudo /usr/lib/nagios/plugins/check_debian-sys-maint","title":"MySQL Debian Sys Maint alert"},{"location":"incident_response/mysql_debian_sys_maint/#response","text":"Simply run the script to reset the password to something known, which can be done from the bastion. sv-resetdebian $SERVER Or when logged into the machine that is alerting. sudo reset-debian-password.sh","title":"Response"},{"location":"incident_response/mysql_debian_sys_maint/#caveat","text":"The pt-heartbeat service relies on the debian system user. Sometimes the service can die if the password isn't reset and will need to be restarted on the alerting server after running one of the commands above. sudo service pt-heartbeat restart","title":"Caveat"},{"location":"incident_response/mysql_failover/","text":"MySQL Failover This alert will trigger from a DNS server. DNS servers maintain the state of which server is active in a Database cluster. We run single DNS servers in each active region. An Operator will, as part of routine maintenance, have to make the Secondary server in a DB cluster active. This will cause an alert, so they should have notified the on alerts person. Response Run dns-fix against the alerting DNS server: If you see a message that there is no active server for the cluster, don't panic, the server is just new and has not had the active server set yet. You can safely use dns-update to set the Primary db as active. Query your colleagues to find out if this alert is part of routine maintenance. For each failed over cluster, lock the DB in place. If there has been a high traffic event that has resulted in the DB failing over, we must stop it from failing back and causing a split brain. Use ah-db-cluster to lock the active DB Work through these steps to diagnose why the cluster is running from the Secondary. Run site-dbfailed against a site that the server is configured for; this can be any site as site-dbfailed only needs to find the web servers. If you see output, verify the log timestamp. Figuring out exactly when an event happened is very important. Run sv-dbdash and alter the hours= to go further back in time if needed. To dive further, have a look at: Traffic patterns Cron frequency Recent tasks Clean Up Cleaning up a failed over DB requires guidance that differs depending on why and how the database failed over in the first place. Because of the variance in fixing this we can not easily document exactly what to do. The best course of action is to ask for assistance from a T2 Ops member to help guide you through the steps needed. These steps are a rough guide: Ensure both DBs are in sync with ah-db-cluster status If slave lag is greater than zero seconds, SSH to the lagging server and investigate the output from sudo mysql -e 'show slave status\\G' . Ask for assistance. Once you have verified that there is zero seconds of latency between both servers use ah-db-cluster to unlock the cluster. Set the Primary back to active with dns-update . Background Every 30 minutes on a DNS server fields-compare-primary-active-db.php is run. This runs through every record the DNS server is authoritative for and writes out failed over DBs, and DBs without an active master, to /var/acquia/mysql_active_primary_report.txt . Nagios executes /usr/lib/nagios/plugins/check_mysql_audit which checks the output file.","title":"MySQL Failover"},{"location":"incident_response/mysql_failover/#mysql-failover","text":"This alert will trigger from a DNS server. DNS servers maintain the state of which server is active in a Database cluster. We run single DNS servers in each active region. An Operator will, as part of routine maintenance, have to make the Secondary server in a DB cluster active. This will cause an alert, so they should have notified the on alerts person.","title":"MySQL Failover"},{"location":"incident_response/mysql_failover/#response","text":"Run dns-fix against the alerting DNS server: If you see a message that there is no active server for the cluster, don't panic, the server is just new and has not had the active server set yet. You can safely use dns-update to set the Primary db as active. Query your colleagues to find out if this alert is part of routine maintenance. For each failed over cluster, lock the DB in place. If there has been a high traffic event that has resulted in the DB failing over, we must stop it from failing back and causing a split brain. Use ah-db-cluster to lock the active DB Work through these steps to diagnose why the cluster is running from the Secondary. Run site-dbfailed against a site that the server is configured for; this can be any site as site-dbfailed only needs to find the web servers. If you see output, verify the log timestamp. Figuring out exactly when an event happened is very important. Run sv-dbdash and alter the hours= to go further back in time if needed. To dive further, have a look at: Traffic patterns Cron frequency Recent tasks","title":"Response"},{"location":"incident_response/mysql_failover/#clean-up","text":"Cleaning up a failed over DB requires guidance that differs depending on why and how the database failed over in the first place. Because of the variance in fixing this we can not easily document exactly what to do. The best course of action is to ask for assistance from a T2 Ops member to help guide you through the steps needed. These steps are a rough guide: Ensure both DBs are in sync with ah-db-cluster status If slave lag is greater than zero seconds, SSH to the lagging server and investigate the output from sudo mysql -e 'show slave status\\G' . Ask for assistance. Once you have verified that there is zero seconds of latency between both servers use ah-db-cluster to unlock the cluster. Set the Primary back to active with dns-update .","title":"Clean Up"},{"location":"incident_response/mysql_failover/#background","text":"Every 30 minutes on a DNS server fields-compare-primary-active-db.php is run. This runs through every record the DNS server is authoritative for and writes out failed over DBs, and DBs without an active master, to /var/acquia/mysql_active_primary_report.txt . Nagios executes /usr/lib/nagios/plugins/check_mysql_audit which checks the output file.","title":"Background"},{"location":"incident_response/mysql_replication_lag/","text":"MySQL replication lag This alert is caused by the MySQL replication slave being N seconds behind the master. For more information on how MySQL replication works in general and more specifically on our platform please read this article . The alert can have the following causes: Replication conflict / split-brain In this case replication is stopped with an error, usually a duplicate key error. The conflict must be resolved before replication can proceed. Replication is manually stopped In this case replication will be stopped without an error. This can be caused by a custom setting in the MySQL configuration file after a reboot/relaunch or because someone else has stopped the slave for maintenance. Replication is running but falling behind This means that replication is proceeding slower on the slave than it is on the master. If replication is not proceeding at all it is probably blocked by another process. If it's proceeding but very slowly the traffic on the master is too high. It is also possible that there is a resource problem on the slave, like a runaway process or an impaired volume. And finally, the problem could be with pt-heartbeat. If the pt-heartbeat daemon is not running correctly replication may be fine but the heartbeat table is not being updated. Other replication errors In this case replication will also be stopped with an error but it won't refer to a query failing to execute. Typical scenarios here include missing binary logs, incorrectly configured replication setup, corruption in the binary log, etc. Please follow the steps below to diagnose and the resolve the issue. If none of those help the last section describes how to escalate to a DBA. Diagnosing a replication problem The first step is to check the replication status as reported by ah-db-cluster status . ah-db-cluster status $dbserver A typical output will contain lines like this to show replication lag: pt-heartbeat lag (master -> slave) fsdb-5516 -> fsdb-5517: 0 seconds fsdb-5517 -> fsdb-5516: 0 seconds If the lag in either direction is unequal to 0 seconds the tool will check the output of the following MySQL command on the slave: show slave status\\G You can run this command manually on the slave in question to get a lot more detailed information like which binary log is currently being read and which one is being executed. Note: The lag reported by the ah-db-cluster status command results from the pt-heartbeat daemon and not from the show slave status command. If replication lag in either direction is unequal to 0 seconds ah-db-cluster will report the status of the individual replication threads (io thread and sql execution thread). Additionally, if there is an error with either of those threads, it will be in the report as well. The error is generally a clear indication of the category of problem as listed above. We also record slave lag for servers in SignalFX. Each server with replication enabled will have a mysql/seconds_behind_master entry that indicates the number of seconds that the master is behind. If no value is shown replication is stopped. Resolution for replication conflicts / split-brain Replication conflicts are fairly common and are generally caused by failovers. ah-db-cluster will report lag greater than 0 , a stopped slave SQL thread and (most likely) a duplicate key error like this: pt-heartbeat lag (master -> slave) fsdb-7 -> fsdb-8: 7 seconds, Slave SQL thread stopped: Error 'Duplicate entry '1' for key 'PRIMARY'' on query. Default database: 'acquia'. Query: 'insert into t5 (a) select 1' fsdb-8 -> fsdb-7: 0 seconds In case of a conflict on a delete query the error will not be a duplicate key error but a missing key error. The resolution is the same however. We need to run the mysql-slave-resync.pl script on the slave that has the error (fsdb-8 in the example). This script will \"resolve\" replication conflict errors by skipping over the statements that are conflicting. This does not fix the inconsistencies but does allow replication to proceed and other non-conflicting changes to be applied. [15:58:00] root@fsdb-8.pvanderwal:~# mysql-slave-resync.pl FAILED! 1062: Error 'Duplicate entry '1' for key 'PRIMARY'' on query. Default database: 'acquia'. Query: 'insert into t5 (a) select 1' Press ENTER to skip, or Ctrl-C to terminate. Seconds behind: 1258 Done! For conflicts on cache or semaphore tables the script will skip the statements automatically but for any other tables it will ask for confirmation. By default anyone in Ops can answer yes to any confirmation. This confirmation is only for very specific cases. Since cache/semaphore tables have entries that expire relatively quickly it is sometimes possible to fix the replication lag by just running mysql-slave-resync.pl but in most cases it is not. The real way to resolve a split-brain is by performing a dump-restore from the active database server to the passive and this should be the default action for a split-brain. The exception is where all conflicts are on cache/semaphore tables and they stop occurring after a short amount of time. Note: mysql-slave-resync.pl only skips over replication conflicts and takes no action otherwise. It is only useful for this particular scenario and will not do anything if replication is running. If the dump-restore fails for a reason that is not covered in the runbooks you can escalate the issue to a DBA. See the \"Replication is still broken\" section. Resolution for manually stopped replication In some cases MySQL can either be manually stopped or was prevented from starting when MySQL started. The ah-db-cluster status output will look like this: pt-heartbeat lag (master -> slave) fsdb-7 -> fsdb-8: 8 seconds, Slave IO thread stopped, Slave SQL thread stopped fsdb-8 -> fsdb-7: 0 seconds Since there is no error, verify that nobody else is working on the cluster and restart the slave with the following SQL command on the server with the stopped slave (in this example fsdb-8): start slave; It is possible that this is the result of a failed dump-restore that left the following custom MySQL setting in place: skip-slave-start=TRUE If that setting exists and there is no documentation in a JIRA ticket or an ah-runbook entry for it, it can be removed with the following command: ah-server edit $dbserver -c my.cnf:skip-slave-start= On the server itself then run: ah-config-mysql update mv /etc/mysql/conf.d/mycustom.new /etc/mysql/conf.d/mycustom.cnf It is not necessary to restart MySQL for this to take effect but the slave should still be started with start slave command. Resolution for replication is running but falling behind In this scenario the output for ah-db-cluster status won't show any errors but a fairly high value for the replication lag like this: pt-heartbeat lag (master -> slave) fsdb-7 -> fsdb-8: 516 seconds fsdb-8 -> fsdb-7: 0 seconds There are a couple of potential causes for this. The first one is that the replication thread is blocked on the slave and can't proceed until the blocking process has completed. In this case replication lag will keep going up over time linearly with the number of seconds that have passed. Typically this happens on the passive database server. Since there should not be any customer connections on the passive this is most likely caused by a daily MySQL backup or the hourly snapshot process. To verify that this is the case check in SignalFX if the MySQL data volume on the passive is busy with reads instead of writes or if there is a long-running transaction that coincides with the start of the replication lag. If either of those are true there is no immediate fix since we don't kill database backups. It might be worth investigating if the database has some very large tables and if they are cache tables, raise a ticket with Support since the backups are impairing HA. The second cause for replication lag is that the traffic on the active is higher than the replication capacity. The way to verify this is to look at the disk load on the passive database server and check the binary log throughput on the active database volume. Since different server and volume types have different replication capacities there are no fixed thresholds that we can use. Instead, go back in time in the graphs and look if the binary log throughput on the active database server changed when replication lag started going up on the passive database server. Again, there is no standard fix for this. Replication is going as fast as it can. mysql-slave-resync.pl will not do anything in this case and a dump-restore will make things worse. Investigate if the traffic on the web site has increased and raise a ticket with Support to investigate why the write pattern has increased so much. This can be caused by a customer code deployment. The third cause of increasing replication lag is caused by pt-heartbeat not running or not running correctly. In that case it will not update the heartbeat table and the ah-db-cluster status command will report replication lag even when there isn't. The best approach is to restart pt-heartbeat in this case. Run the following command on both servers. systemctl restart pt-heartbeat Optionally you can verify that pt-heartbeat is indeed updating by running the following command: mysql -e \"select * from acquia.heartbeat where server_id = @@server_id\" The ts column in the output should report the current date and time. Resolution for other replication problems We'll list the resolutions for other known problems here. If a problem is not listed here or in another section ask a DBA to document it here after the ticket has been resolved. Missing first binary log If replication has been stopped for a while and binary logs have been purged from the master, the slave can't pick up where it left off because it's missing the necessary binary logs. The output of ah-db-cluster status will look like this: pt-heartbeat lag (master -> slave) fsdb-7 -> fsdb-8: 12356 seconds, Slave IO thread stopped: Got fatal error 1236 from master when reading data from binary log: 'Could not find first log file name in binary log index file' fsdb-8 -> fsdb-7: 0 seconds Make sure the active database has no replication lag in the other direction (from the passive database server to active) and use mysql-slave-resync.pl if necessary to deal with conflicts. When the active database server is caught up do a dump-restore from the active to the passive. Corruption in the binary log If the disk for the active server is full the active server can no longer write binary logs. This can cause a partial event to be written to the binary log. If MySQL is restarted before it can finish the write it will start a new binary log but the previous binary log will end with the partial and corrupt event. Typically this will result in an error like this: Got fatal error 1236 from master when reading data from binary log: 'binlog truncated in the middle of event; consider out of disk space on master; the first event 'binlog.004136' at 567607878, the last event read from './binlog.004136' at 567607878, the last byte read from './binlog.004136' at 567607897.' There are two ways to fix this. The first and recommended way is to perform a dump-restore from the active to the passive. The second method is to manually fix the problem by skipping to the next binary log. This method can be useful if the databases are very large and the time for a dump-restore is problematic but it won't work in all cases. To manually fix replication we need to stop the slave and skip to the next binary log but before we can do that we need to verify that the log position in the error is indeed the last event in the binary log. In the case of the example error aove the binary log is binlog.004136 and last processed position is 567607878 . The binary log filein question is not on the server where the error occurred but on the other server in the cluster, ie. the replication master for this server. By running the following command for the binary log in the error message on the replication master we can see if this is the last or the next to last query in that binary log. mysqlbinlog /vol/ebs1/mysql/binlog.004136 | grep \"^# at\" | tail Example output: [20:23:38] root@fsdb-19.pvanderwal:/vol/ebs1/mysql# mysqlbinlog /vol/ebs1/mysql/binlog.000030 | grep \"^# at\" | tail Warning: mysqlbinlog: unknown variable 'loose-default-character-set=utf8' # at 41411565 # at 41411596 # at 41411684 # at 41411977 # at 41412008 # at 41412096 # at 41412389 # at 41412420 # at 41412508 # at 41412801 Every line starting with # at shows a binary log position which matches the byte position in the file. If the binlog position in the error message is indeed one of the last two last lines or the position is greater than the last line we can skip to the next binary log by running the following commands on the slave with the error. Take note that the binary log number in this command is one higher than the current binary log. The master_log_pos should always be 1 in the following command. This command needs to be executed on the server that had the error. mysql -e \"stop slave; change master to master_log_file='binlog.004137', master_log_pos=1; start slave;\" If the binary log position is lower than the last two listed events in the binary log the corruption occurred in the middle of the binary log and a dump-restore from the active to the passive is necessary. Active server stopped writing binary logs There is a setting on our platform that is being phased out that stops a server from writing binary logs when certain error conditions occur. When this condition occurs ah-db-cluster status reports the following error: pt-heartbeat lag (master -> slave) ded-23581 -> ded-23582: 4422 seconds, Slave IO thread stopped: Got fatal error 1236 from master when reading data from binary log: 'Binary log is not open' ded-23582 -> ded-23581: 0 seconds To verify the problem run the following command on the master (ded-23581 in this case): mysql [(none)]> show master status\\G Empty set (0.00 sec) If that command returns an empty set like above it verifies the problem. Make sure there is enough disk space for MySQL to write binary logs and free up space if necessary. Following that crit support that there will be a short downtime of the database server and lack of HA while we do a dump-restore. Then execute the following steps. Lock the database cluster to the active server ah-db-cluster lock <server name> Restart MySQL on active server systemctl restart mysql Perform a dump-restore from the active to the passive. If replication is broken (Not referring DB lag) between both the DB servers.Examples may differ,consult DBA if it's not for duplicates pt-heartbeat lag (master -> slave) fsdb-25305 -> fsdb-25306: 3230 seconds, Slave SQL thread stopped: Error 'Duplicate entry 'links:main-menu:page:node/596906/edit:en:1:1' for key 'PRIMARY'' on query. Default database: 'xxxxxx'. Query: 'INSER fsdb-25306 -> fsdb-25305: 3682 seconds, Slave SQL thread stopped: Error 'Duplicate entry 'admin_menu:2326:fqaOEybtsH4w6IZ-aPXbaNGqV5nw6C0z0p25TAgnVqA:en' for key 'PRIMARY'' on query. Default database: 'xxxxxxx In case if both the servers are not replicating(Not referring DB lag) then escalate this issue to DBA to fix to avoid loss of HA. This case should be updated in the runbook as well for future reference. If lag exist on both the servers due to duplicate queries then Ops need to use \"mysql-slave-resync.pl\" to skip the duplicates in order to resume replication to mitigate lag. Note: There are many reasons behind the replication lags where high IOPS is one of the reasons. In such cases, if lagging happens then it can be fixed by upsizing the DB volume which can be taken care of by Ops itself and something break, I mean if Ops are not able to establish the replication then this case must be escalated to DBA without any further due. For MR DB, the below remedy can be opted by Ops. In case if things are not established then immediately escalate this issue to DBA. The available runbook can be considered before the escalation if DR required ie. Follow the below steps, SERVER= SITENAME=$(ah-site list on:${SERVER} | head -1) SERVERTYPE=$(ah-server list ${SERVER} --no-name -c type) fpdsh -t site:$SITENAME -n $SERVERTYPE -c \"sudo ah-config-hosts\" fpdsh -t site:$SITENAME -n $SERVERTYPE -c \"sudo ah-config-iptables\" fpdsh -t site:$SITENAME -n $SERVERTYPE -c \"sudo fields-config-tungsten-peers.php\" fpdsh -t site:$SITENAME -n $SERVERTYPE -c \"sudo /etc/init.d/stunnel4 stop\" fpdsh -t site:$SITENAME -n $SERVERTYPE -c \"sudo /etc/init.d/stunnel4 start\" fpdsh -t site:$SITENAME -n $SERVERTYPE -c \"sudo service treplicator restart\" Also can use site-tungstenslaveresync funstion to skip the duplicate queries. Replication is still broken If you determined what the problem is and applied the solution (if available) and the problem persists the next step is to escalate to a DBA. Please follow the rules in Confluence for DBA escalation .","title":"MySQL replication lag"},{"location":"incident_response/mysql_replication_lag/#mysql-replication-lag","text":"This alert is caused by the MySQL replication slave being N seconds behind the master. For more information on how MySQL replication works in general and more specifically on our platform please read this article . The alert can have the following causes: Replication conflict / split-brain In this case replication is stopped with an error, usually a duplicate key error. The conflict must be resolved before replication can proceed. Replication is manually stopped In this case replication will be stopped without an error. This can be caused by a custom setting in the MySQL configuration file after a reboot/relaunch or because someone else has stopped the slave for maintenance. Replication is running but falling behind This means that replication is proceeding slower on the slave than it is on the master. If replication is not proceeding at all it is probably blocked by another process. If it's proceeding but very slowly the traffic on the master is too high. It is also possible that there is a resource problem on the slave, like a runaway process or an impaired volume. And finally, the problem could be with pt-heartbeat. If the pt-heartbeat daemon is not running correctly replication may be fine but the heartbeat table is not being updated. Other replication errors In this case replication will also be stopped with an error but it won't refer to a query failing to execute. Typical scenarios here include missing binary logs, incorrectly configured replication setup, corruption in the binary log, etc. Please follow the steps below to diagnose and the resolve the issue. If none of those help the last section describes how to escalate to a DBA.","title":"MySQL replication lag"},{"location":"incident_response/mysql_replication_lag/#diagnosing-a-replication-problem","text":"The first step is to check the replication status as reported by ah-db-cluster status . ah-db-cluster status $dbserver A typical output will contain lines like this to show replication lag: pt-heartbeat lag (master -> slave) fsdb-5516 -> fsdb-5517: 0 seconds fsdb-5517 -> fsdb-5516: 0 seconds If the lag in either direction is unequal to 0 seconds the tool will check the output of the following MySQL command on the slave: show slave status\\G You can run this command manually on the slave in question to get a lot more detailed information like which binary log is currently being read and which one is being executed. Note: The lag reported by the ah-db-cluster status command results from the pt-heartbeat daemon and not from the show slave status command. If replication lag in either direction is unequal to 0 seconds ah-db-cluster will report the status of the individual replication threads (io thread and sql execution thread). Additionally, if there is an error with either of those threads, it will be in the report as well. The error is generally a clear indication of the category of problem as listed above. We also record slave lag for servers in SignalFX. Each server with replication enabled will have a mysql/seconds_behind_master entry that indicates the number of seconds that the master is behind. If no value is shown replication is stopped.","title":"Diagnosing a replication problem"},{"location":"incident_response/mysql_replication_lag/#resolution-for-replication-conflicts-split-brain","text":"Replication conflicts are fairly common and are generally caused by failovers. ah-db-cluster will report lag greater than 0 , a stopped slave SQL thread and (most likely) a duplicate key error like this: pt-heartbeat lag (master -> slave) fsdb-7 -> fsdb-8: 7 seconds, Slave SQL thread stopped: Error 'Duplicate entry '1' for key 'PRIMARY'' on query. Default database: 'acquia'. Query: 'insert into t5 (a) select 1' fsdb-8 -> fsdb-7: 0 seconds In case of a conflict on a delete query the error will not be a duplicate key error but a missing key error. The resolution is the same however. We need to run the mysql-slave-resync.pl script on the slave that has the error (fsdb-8 in the example). This script will \"resolve\" replication conflict errors by skipping over the statements that are conflicting. This does not fix the inconsistencies but does allow replication to proceed and other non-conflicting changes to be applied. [15:58:00] root@fsdb-8.pvanderwal:~# mysql-slave-resync.pl FAILED! 1062: Error 'Duplicate entry '1' for key 'PRIMARY'' on query. Default database: 'acquia'. Query: 'insert into t5 (a) select 1' Press ENTER to skip, or Ctrl-C to terminate. Seconds behind: 1258 Done! For conflicts on cache or semaphore tables the script will skip the statements automatically but for any other tables it will ask for confirmation. By default anyone in Ops can answer yes to any confirmation. This confirmation is only for very specific cases. Since cache/semaphore tables have entries that expire relatively quickly it is sometimes possible to fix the replication lag by just running mysql-slave-resync.pl but in most cases it is not. The real way to resolve a split-brain is by performing a dump-restore from the active database server to the passive and this should be the default action for a split-brain. The exception is where all conflicts are on cache/semaphore tables and they stop occurring after a short amount of time. Note: mysql-slave-resync.pl only skips over replication conflicts and takes no action otherwise. It is only useful for this particular scenario and will not do anything if replication is running. If the dump-restore fails for a reason that is not covered in the runbooks you can escalate the issue to a DBA. See the \"Replication is still broken\" section.","title":"Resolution for replication conflicts / split-brain"},{"location":"incident_response/mysql_replication_lag/#resolution-for-manually-stopped-replication","text":"In some cases MySQL can either be manually stopped or was prevented from starting when MySQL started. The ah-db-cluster status output will look like this: pt-heartbeat lag (master -> slave) fsdb-7 -> fsdb-8: 8 seconds, Slave IO thread stopped, Slave SQL thread stopped fsdb-8 -> fsdb-7: 0 seconds Since there is no error, verify that nobody else is working on the cluster and restart the slave with the following SQL command on the server with the stopped slave (in this example fsdb-8): start slave; It is possible that this is the result of a failed dump-restore that left the following custom MySQL setting in place: skip-slave-start=TRUE If that setting exists and there is no documentation in a JIRA ticket or an ah-runbook entry for it, it can be removed with the following command: ah-server edit $dbserver -c my.cnf:skip-slave-start= On the server itself then run: ah-config-mysql update mv /etc/mysql/conf.d/mycustom.new /etc/mysql/conf.d/mycustom.cnf It is not necessary to restart MySQL for this to take effect but the slave should still be started with start slave command.","title":"Resolution for manually stopped replication"},{"location":"incident_response/mysql_replication_lag/#resolution-for-replication-is-running-but-falling-behind","text":"In this scenario the output for ah-db-cluster status won't show any errors but a fairly high value for the replication lag like this: pt-heartbeat lag (master -> slave) fsdb-7 -> fsdb-8: 516 seconds fsdb-8 -> fsdb-7: 0 seconds There are a couple of potential causes for this. The first one is that the replication thread is blocked on the slave and can't proceed until the blocking process has completed. In this case replication lag will keep going up over time linearly with the number of seconds that have passed. Typically this happens on the passive database server. Since there should not be any customer connections on the passive this is most likely caused by a daily MySQL backup or the hourly snapshot process. To verify that this is the case check in SignalFX if the MySQL data volume on the passive is busy with reads instead of writes or if there is a long-running transaction that coincides with the start of the replication lag. If either of those are true there is no immediate fix since we don't kill database backups. It might be worth investigating if the database has some very large tables and if they are cache tables, raise a ticket with Support since the backups are impairing HA. The second cause for replication lag is that the traffic on the active is higher than the replication capacity. The way to verify this is to look at the disk load on the passive database server and check the binary log throughput on the active database volume. Since different server and volume types have different replication capacities there are no fixed thresholds that we can use. Instead, go back in time in the graphs and look if the binary log throughput on the active database server changed when replication lag started going up on the passive database server. Again, there is no standard fix for this. Replication is going as fast as it can. mysql-slave-resync.pl will not do anything in this case and a dump-restore will make things worse. Investigate if the traffic on the web site has increased and raise a ticket with Support to investigate why the write pattern has increased so much. This can be caused by a customer code deployment. The third cause of increasing replication lag is caused by pt-heartbeat not running or not running correctly. In that case it will not update the heartbeat table and the ah-db-cluster status command will report replication lag even when there isn't. The best approach is to restart pt-heartbeat in this case. Run the following command on both servers. systemctl restart pt-heartbeat Optionally you can verify that pt-heartbeat is indeed updating by running the following command: mysql -e \"select * from acquia.heartbeat where server_id = @@server_id\" The ts column in the output should report the current date and time.","title":"Resolution for replication is running but falling behind"},{"location":"incident_response/mysql_replication_lag/#resolution-for-other-replication-problems","text":"We'll list the resolutions for other known problems here. If a problem is not listed here or in another section ask a DBA to document it here after the ticket has been resolved.","title":"Resolution for other replication problems"},{"location":"incident_response/mysql_replication_lag/#missing-first-binary-log","text":"If replication has been stopped for a while and binary logs have been purged from the master, the slave can't pick up where it left off because it's missing the necessary binary logs. The output of ah-db-cluster status will look like this: pt-heartbeat lag (master -> slave) fsdb-7 -> fsdb-8: 12356 seconds, Slave IO thread stopped: Got fatal error 1236 from master when reading data from binary log: 'Could not find first log file name in binary log index file' fsdb-8 -> fsdb-7: 0 seconds Make sure the active database has no replication lag in the other direction (from the passive database server to active) and use mysql-slave-resync.pl if necessary to deal with conflicts. When the active database server is caught up do a dump-restore from the active to the passive.","title":"Missing first binary log"},{"location":"incident_response/mysql_replication_lag/#corruption-in-the-binary-log","text":"If the disk for the active server is full the active server can no longer write binary logs. This can cause a partial event to be written to the binary log. If MySQL is restarted before it can finish the write it will start a new binary log but the previous binary log will end with the partial and corrupt event. Typically this will result in an error like this: Got fatal error 1236 from master when reading data from binary log: 'binlog truncated in the middle of event; consider out of disk space on master; the first event 'binlog.004136' at 567607878, the last event read from './binlog.004136' at 567607878, the last byte read from './binlog.004136' at 567607897.' There are two ways to fix this. The first and recommended way is to perform a dump-restore from the active to the passive. The second method is to manually fix the problem by skipping to the next binary log. This method can be useful if the databases are very large and the time for a dump-restore is problematic but it won't work in all cases. To manually fix replication we need to stop the slave and skip to the next binary log but before we can do that we need to verify that the log position in the error is indeed the last event in the binary log. In the case of the example error aove the binary log is binlog.004136 and last processed position is 567607878 . The binary log filein question is not on the server where the error occurred but on the other server in the cluster, ie. the replication master for this server. By running the following command for the binary log in the error message on the replication master we can see if this is the last or the next to last query in that binary log. mysqlbinlog /vol/ebs1/mysql/binlog.004136 | grep \"^# at\" | tail Example output: [20:23:38] root@fsdb-19.pvanderwal:/vol/ebs1/mysql# mysqlbinlog /vol/ebs1/mysql/binlog.000030 | grep \"^# at\" | tail Warning: mysqlbinlog: unknown variable 'loose-default-character-set=utf8' # at 41411565 # at 41411596 # at 41411684 # at 41411977 # at 41412008 # at 41412096 # at 41412389 # at 41412420 # at 41412508 # at 41412801 Every line starting with # at shows a binary log position which matches the byte position in the file. If the binlog position in the error message is indeed one of the last two last lines or the position is greater than the last line we can skip to the next binary log by running the following commands on the slave with the error. Take note that the binary log number in this command is one higher than the current binary log. The master_log_pos should always be 1 in the following command. This command needs to be executed on the server that had the error. mysql -e \"stop slave; change master to master_log_file='binlog.004137', master_log_pos=1; start slave;\" If the binary log position is lower than the last two listed events in the binary log the corruption occurred in the middle of the binary log and a dump-restore from the active to the passive is necessary.","title":"Corruption in the binary log"},{"location":"incident_response/mysql_replication_lag/#active-server-stopped-writing-binary-logs","text":"There is a setting on our platform that is being phased out that stops a server from writing binary logs when certain error conditions occur. When this condition occurs ah-db-cluster status reports the following error: pt-heartbeat lag (master -> slave) ded-23581 -> ded-23582: 4422 seconds, Slave IO thread stopped: Got fatal error 1236 from master when reading data from binary log: 'Binary log is not open' ded-23582 -> ded-23581: 0 seconds To verify the problem run the following command on the master (ded-23581 in this case): mysql [(none)]> show master status\\G Empty set (0.00 sec) If that command returns an empty set like above it verifies the problem. Make sure there is enough disk space for MySQL to write binary logs and free up space if necessary. Following that crit support that there will be a short downtime of the database server and lack of HA while we do a dump-restore. Then execute the following steps. Lock the database cluster to the active server ah-db-cluster lock <server name> Restart MySQL on active server systemctl restart mysql Perform a dump-restore from the active to the passive.","title":"Active server stopped writing binary logs"},{"location":"incident_response/mysql_replication_lag/#if-replication-is-broken-not-referring-db-lag-between-both-the-db-serversexamples-may-differconsult-dba-if-its-not-for-duplicates","text":"pt-heartbeat lag (master -> slave) fsdb-25305 -> fsdb-25306: 3230 seconds, Slave SQL thread stopped: Error 'Duplicate entry 'links:main-menu:page:node/596906/edit:en:1:1' for key 'PRIMARY'' on query. Default database: 'xxxxxx'. Query: 'INSER fsdb-25306 -> fsdb-25305: 3682 seconds, Slave SQL thread stopped: Error 'Duplicate entry 'admin_menu:2326:fqaOEybtsH4w6IZ-aPXbaNGqV5nw6C0z0p25TAgnVqA:en' for key 'PRIMARY'' on query. Default database: 'xxxxxxx In case if both the servers are not replicating(Not referring DB lag) then escalate this issue to DBA to fix to avoid loss of HA. This case should be updated in the runbook as well for future reference. If lag exist on both the servers due to duplicate queries then Ops need to use \"mysql-slave-resync.pl\" to skip the duplicates in order to resume replication to mitigate lag. Note: There are many reasons behind the replication lags where high IOPS is one of the reasons. In such cases, if lagging happens then it can be fixed by upsizing the DB volume which can be taken care of by Ops itself and something break, I mean if Ops are not able to establish the replication then this case must be escalated to DBA without any further due. For MR DB, the below remedy can be opted by Ops. In case if things are not established then immediately escalate this issue to DBA. The available runbook can be considered before the escalation if DR required ie. Follow the below steps, SERVER= SITENAME=$(ah-site list on:${SERVER} | head -1) SERVERTYPE=$(ah-server list ${SERVER} --no-name -c type) fpdsh -t site:$SITENAME -n $SERVERTYPE -c \"sudo ah-config-hosts\" fpdsh -t site:$SITENAME -n $SERVERTYPE -c \"sudo ah-config-iptables\" fpdsh -t site:$SITENAME -n $SERVERTYPE -c \"sudo fields-config-tungsten-peers.php\" fpdsh -t site:$SITENAME -n $SERVERTYPE -c \"sudo /etc/init.d/stunnel4 stop\" fpdsh -t site:$SITENAME -n $SERVERTYPE -c \"sudo /etc/init.d/stunnel4 start\" fpdsh -t site:$SITENAME -n $SERVERTYPE -c \"sudo service treplicator restart\" Also can use site-tungstenslaveresync funstion to skip the duplicate queries.","title":"If replication is broken (Not referring DB lag) between both the DB servers.Examples may differ,consult DBA if it's not for duplicates"},{"location":"incident_response/mysql_replication_lag/#replication-is-still-broken","text":"If you determined what the problem is and applied the solution (if available) and the problem persists the next step is to escalate to a DBA. Please follow the rules in Confluence for DBA escalation .","title":"Replication is still broken"},{"location":"incident_response/nagios_configuration/","text":"Nagios Configuration This alert occurs when the Nagios configuration on any of mon{1,2,3}.ops-mon-2.acquia.com is broken and causing these servers not to send us alerts. This means, among other things, that sites recently added to monitoring via site-mon or acsf-site-mon will not be monitored, while sites recently removed from monitoring will continue to alert until the configuration is fixed and Nagios is restored on the affected server. Response Identify the affected server and log into it. Use the server's fully qualified hostname for FQHN (I.e. mon1.ops-mon-2.acquia.com ): FQHN= aexternal ssh ${FQHN} If you are not able to log in, your ssh key might not be in the LEGACY_2015-02-17 branch of ops-puppet. Attempt to reload Nagios and note any errors in the output: service nagios3 reload Most commonly, Nagios will fail to start when there is an errant commit that causes the configuration to break, such as trying to add multiple sites in a single site-mon invocation, or prepending http:// the URL for ACSF sites. Nagios should tell you what line of the configuration file is causing it to error. Use that to search through ops-mon-2's git history for the bad commits and revert them. Reload Nagios and repeat until it works. If there are no errors, check for the existence of /var/run/nagioserror , which is created whenever the gitpull.sh script fails to start Nagios (this file is also what triggers this alert): ls -lah /var/run/nagioserror Run the gitpull.sh script after removing the file /tmp/gitpull.state and note its output: rm /tmp/gitpull.state /root/gitpull.sh If nagios fails to reload due to nagios config errors, checkout previous commits one by one on the local checkout of ops-mon-2 and try reloading nagios for that checkout. Repeat this step until you get to the commit from which you can reload nagios. Keep repeating the following until you have successfull nagios reload to figure out where things got broken. git checkout HEAD~1 service nagios[3] reload If gitpull.sh ran successfully, delete /var/run/nagioserror if it still exists: ls -lah /var/run/nagioserror rm /var/run/nagioserror Validate that the Nagios check runs successfully: /usr/lib/nagios/plugins/check_gitpull_error If you had to revert any git commits to fix Nagios when gitpull.sh erroed above, submit new commits to ops-mon-2 repo that won't break Nagios as appropriate and ensure that gitpull.sh runs successfully after making the changes","title":"Nagios Configuration"},{"location":"incident_response/nagios_configuration/#nagios-configuration","text":"This alert occurs when the Nagios configuration on any of mon{1,2,3}.ops-mon-2.acquia.com is broken and causing these servers not to send us alerts. This means, among other things, that sites recently added to monitoring via site-mon or acsf-site-mon will not be monitored, while sites recently removed from monitoring will continue to alert until the configuration is fixed and Nagios is restored on the affected server.","title":"Nagios Configuration"},{"location":"incident_response/nagios_configuration/#response","text":"Identify the affected server and log into it. Use the server's fully qualified hostname for FQHN (I.e. mon1.ops-mon-2.acquia.com ): FQHN= aexternal ssh ${FQHN} If you are not able to log in, your ssh key might not be in the LEGACY_2015-02-17 branch of ops-puppet. Attempt to reload Nagios and note any errors in the output: service nagios3 reload Most commonly, Nagios will fail to start when there is an errant commit that causes the configuration to break, such as trying to add multiple sites in a single site-mon invocation, or prepending http:// the URL for ACSF sites. Nagios should tell you what line of the configuration file is causing it to error. Use that to search through ops-mon-2's git history for the bad commits and revert them. Reload Nagios and repeat until it works. If there are no errors, check for the existence of /var/run/nagioserror , which is created whenever the gitpull.sh script fails to start Nagios (this file is also what triggers this alert): ls -lah /var/run/nagioserror Run the gitpull.sh script after removing the file /tmp/gitpull.state and note its output: rm /tmp/gitpull.state /root/gitpull.sh If nagios fails to reload due to nagios config errors, checkout previous commits one by one on the local checkout of ops-mon-2 and try reloading nagios for that checkout. Repeat this step until you get to the commit from which you can reload nagios. Keep repeating the following until you have successfull nagios reload to figure out where things got broken. git checkout HEAD~1 service nagios[3] reload If gitpull.sh ran successfully, delete /var/run/nagioserror if it still exists: ls -lah /var/run/nagioserror rm /var/run/nagioserror Validate that the Nagios check runs successfully: /usr/lib/nagios/plugins/check_gitpull_error If you had to revert any git commits to fix Nagios when gitpull.sh erroed above, submit new commits to ops-mon-2 repo that won't break Nagios as appropriate and ensure that gitpull.sh runs successfully after making the changes","title":"Response"},{"location":"incident_response/nginx_config_test/","text":"NGINX Configtest NOTE : if this alert is associated with a nxephem , use the nxephem Nginx runbook. This alert indicates that the Nginx config is invalid. This alert is a sev1 because it means that customers cannot add new domains. There are multiple reasons that the nginx config might be invalid. The common ones are listed below. Resolution TLS/SSL Error This error indicates something is wrong with the TLS cert. You should look in Jira to see if it was recently updated. Then revert the change or correct the issue with the cert. CRITICAL - (2) 2016/02/12 08:07:16 [emerg] 26734#0: PEM_read_bio_X509(\"/etc/ssl/certs/acquia-sites_com.pem\") failed (SSL: error:0906D066:PEM routines:PEM_read_bio:bad end line) Server_names_hash error This error indicates that you should increase nginx:server_names_hash_bucket_size to 256 CRITICAL: NGINX Configtest failed. nginx: [emerg] could not build the server_names_hash, you should increase either server_names_hash_max_size: 4096 or server_names_hash_bucket_size: 128 ah-server edit $BALS -c nginx.conf:server_names_hash_bucket_size=256 Verification Once you have resolved the issue. You can verify the alert is fixed by running the nagios check manually on the bals. bash fpdsh -l $BALS -c \"sudo /usr/lib/nagios/plugins/check_nginx_configtest\"","title":"NGINX Configtest"},{"location":"incident_response/nginx_config_test/#nginx-configtest","text":"NOTE : if this alert is associated with a nxephem , use the nxephem Nginx runbook. This alert indicates that the Nginx config is invalid. This alert is a sev1 because it means that customers cannot add new domains. There are multiple reasons that the nginx config might be invalid. The common ones are listed below.","title":"NGINX Configtest"},{"location":"incident_response/nginx_config_test/#resolution","text":"","title":"Resolution"},{"location":"incident_response/nginx_config_test/#tlsssl-error","text":"This error indicates something is wrong with the TLS cert. You should look in Jira to see if it was recently updated. Then revert the change or correct the issue with the cert. CRITICAL - (2) 2016/02/12 08:07:16 [emerg] 26734#0: PEM_read_bio_X509(\"/etc/ssl/certs/acquia-sites_com.pem\") failed (SSL: error:0906D066:PEM routines:PEM_read_bio:bad end line)","title":"TLS/SSL Error"},{"location":"incident_response/nginx_config_test/#server_names_hash-error","text":"This error indicates that you should increase nginx:server_names_hash_bucket_size to 256 CRITICAL: NGINX Configtest failed. nginx: [emerg] could not build the server_names_hash, you should increase either server_names_hash_max_size: 4096 or server_names_hash_bucket_size: 128 ah-server edit $BALS -c nginx.conf:server_names_hash_bucket_size=256","title":"Server_names_hash error"},{"location":"incident_response/nginx_config_test/#verification","text":"Once you have resolved the issue. You can verify the alert is fixed by running the nagios check manually on the bals. bash fpdsh -l $BALS -c \"sudo /usr/lib/nagios/plugins/check_nginx_configtest\"","title":"Verification"},{"location":"incident_response/nxephem_nginx/","text":"Nxephem Nginx Configtest Note: To login Search jumpboxes, follow these instructions In legacy search, Nginx is used to route Solr reads and writes to the appropriate servers. It is not uncommon for this alert to be triggered if a new index is created, and index is deleted, or an index is migrated. When this occurs, the alert is transient meaning it will resolve itself. However, on occasions the alert is triggered by a Nginx configuration file still being the repo for an unpublished index and this configuration is pointing as servers that no longer exist, that were deprovisioned. The alert message would contain the following: CRITICAL: NGINX Configtest failed. nginx: [emerg] host not found in upstream ... The remainder of this runbook will address this particular scenario. Procedure First we need to verify that the farm that is missing in the upstream config is no longer valid. To get the farm, take the host provided in the alert and drop everything after the underscore. Example, useast1ass9_search would be for farm useast1ass9 . FARM= ah-search farm $FARM The above command should have returned a 404 . If it didn't, the issue may be the transient issue. Give it a few minutes and if it doesn't clear, escalate to the search team using this procedure . Determine the colony assciated with the alerting nxephem . NXEPHEM= ah-site list on:${NXEPHEM} Log onto the nxephem that is alerting. fssh $NXEPHEM Become root and navigate to the Nginx configs directory. sudo su COLONY= cd /var/www/html/${COLONY}/nginx/server.conf.d/ Do a grep looking for any config files with the aforementioned farm in them. FARM= grep -ri $FARM . The above command will return a list of config files that contain said farm. There should be multiple entries in the affected config files. The config file sans .conf is the pertinent index. Example, AJLM-28483.conf is associated with index AJLM-28483 . For each index, determine the current state in the Governor . If the index is unpublished, then we can safely remove the config. If the index is still published, take note of the colony and farm it is assigned to in the Governor . There is a good chance that the index was migrated to a different farm and that the config is a remnant from pre-migration and can be deleted. However, if the index is published and the colony and farm match what was retrieved in relation to the alert, please escalate to search using the following procedure . Log in to the Acquia Search Governor Type the node name for the index into the Title contains textbox and click Apply . If the index has been deleted, follow this procedure to remove the config from the repo. On the nxephem run sudo fields-config-web.php . Now verify that all is good with the nxephem , execute the following on the nxephem . If it passes, then you are all good. If it still is failing the test, you will need to repeat the steps for the newly alerting farm. sudo /usr/lib/nagios/plugins/check_nginx_configtest Once the Nginx config test passes, log onto the other nxephem and run sudo fields-config-web.php .","title":"Nxephem Nginx Configtest"},{"location":"incident_response/nxephem_nginx/#nxephem-nginx-configtest","text":"Note: To login Search jumpboxes, follow these instructions In legacy search, Nginx is used to route Solr reads and writes to the appropriate servers. It is not uncommon for this alert to be triggered if a new index is created, and index is deleted, or an index is migrated. When this occurs, the alert is transient meaning it will resolve itself. However, on occasions the alert is triggered by a Nginx configuration file still being the repo for an unpublished index and this configuration is pointing as servers that no longer exist, that were deprovisioned. The alert message would contain the following: CRITICAL: NGINX Configtest failed. nginx: [emerg] host not found in upstream ... The remainder of this runbook will address this particular scenario.","title":"Nxephem Nginx Configtest"},{"location":"incident_response/nxephem_nginx/#procedure","text":"First we need to verify that the farm that is missing in the upstream config is no longer valid. To get the farm, take the host provided in the alert and drop everything after the underscore. Example, useast1ass9_search would be for farm useast1ass9 . FARM= ah-search farm $FARM The above command should have returned a 404 . If it didn't, the issue may be the transient issue. Give it a few minutes and if it doesn't clear, escalate to the search team using this procedure . Determine the colony assciated with the alerting nxephem . NXEPHEM= ah-site list on:${NXEPHEM} Log onto the nxephem that is alerting. fssh $NXEPHEM Become root and navigate to the Nginx configs directory. sudo su COLONY= cd /var/www/html/${COLONY}/nginx/server.conf.d/ Do a grep looking for any config files with the aforementioned farm in them. FARM= grep -ri $FARM . The above command will return a list of config files that contain said farm. There should be multiple entries in the affected config files. The config file sans .conf is the pertinent index. Example, AJLM-28483.conf is associated with index AJLM-28483 . For each index, determine the current state in the Governor . If the index is unpublished, then we can safely remove the config. If the index is still published, take note of the colony and farm it is assigned to in the Governor . There is a good chance that the index was migrated to a different farm and that the config is a remnant from pre-migration and can be deleted. However, if the index is published and the colony and farm match what was retrieved in relation to the alert, please escalate to search using the following procedure . Log in to the Acquia Search Governor Type the node name for the index into the Title contains textbox and click Apply . If the index has been deleted, follow this procedure to remove the config from the repo. On the nxephem run sudo fields-config-web.php . Now verify that all is good with the nxephem , execute the following on the nxephem . If it passes, then you are all good. If it still is failing the test, you will need to repeat the steps for the newly alerting farm. sudo /usr/lib/nagios/plugins/check_nginx_configtest Once the Nginx config test passes, log onto the other nxephem and run sudo fields-config-web.php .","title":"Procedure"},{"location":"incident_response/out_of_memory_errors/","text":"Out Of Memory (OOM) errors Summary OOM messages are often a result of a host that is under a significant amount of pressure to provide services. The most common host-types to OOM are (in no specific order): ded-% staging-% bal-% Other host types on the Acquia Hosting platform can OOM, but the more common of the instances that OOM are often customer hardware. Background OOMs are recorded in /var/log/kern.log and are logged with a complete process table including memory utilization information. Apr 3 08:15:48 staging-4346 kernel: php invoked oom-killer: gfp_mask=0x201da, order=0, oom_score_adj=0 Apr 3 08:15:48 staging-4346 kernel: php cpuset=/ mems_allowed=0 Apr 3 08:15:48 staging-4346 kernel: CPU: 0 PID: 12612 Comm: php Not tainted 3.13.0-112-generic #159~precise1-Ubuntu Apr 3 08:15:48 staging-4346 kernel: Hardware name: Xen HVM domU, BIOS 4.2.amazon 11/11/2016 Apr 3 08:15:48 staging-4346 kernel: 0000000000000000 ffff8803b8a3b878 ffffffff81765ce5 ffff880153423000 Apr 3 08:15:48 staging-4346 kernel: 0000000000000000 ffff8803b8a3b8c8 ffffffff8175b5a3 ffff880300000000 Apr 3 08:15:48 staging-4346 kernel: 000201da813881a8 ffff8803b5cb9800 ffff880137491800 0000000000000000 Apr 3 08:15:48 staging-4346 kernel: Call Trace: Apr 3 08:15:48 staging-4346 kernel: [<ffffffff81765ce5>] dump_stack+0x64/0x82 Apr 3 08:15:48 staging-4346 kernel: [<ffffffff8175b5a3>] dump_header+0x7e/0xbd Apr 3 08:15:48 staging-4346 kernel: [<ffffffff8175b639>] oom_kill_process.part.5+0x57/0x2fb Apr 3 08:15:48 staging-4346 kernel: [<ffffffff81160da7>] oom_kill_process+0x47/0x50 Apr 3 08:15:48 staging-4346 kernel: [<ffffffff811610e5>] out_of_memory+0x145/0x1d0 Apr 3 08:15:48 staging-4346 kernel: [<ffffffff811671a3>] __alloc_pages_nodemask+0xb43/0xc50 Apr 3 08:15:48 staging-4346 kernel: [<ffffffff811a88f2>] alloc_pages_current+0xb2/0x170 Apr 3 08:15:48 staging-4346 kernel: [<ffffffff8115d347>] __page_cache_alloc+0xb7/0xd0 Apr 3 08:15:48 staging-4346 kernel: [<ffffffff8115f18d>] filemap_fault+0x28d/0x440 Apr 3 08:15:48 staging-4346 kernel: [<ffffffff811858df>] __do_fault+0x6f/0x530 Apr 3 08:15:48 staging-4346 kernel: [<ffffffff8116c12e>] ? lru_cache_add+0xe/0x10 Apr 3 08:15:48 staging-4346 kernel: [<ffffffff81189774>] handle_pte_fault+0xa4/0x230 Apr 3 08:15:48 staging-4346 kernel: [<ffffffff81642cc5>] ? sock_recvmsg+0xc5/0xe0 Apr 3 08:15:48 staging-4346 kernel: [<ffffffff81189d0b>] __handle_mm_fault+0x1db/0x360 Apr 3 08:15:48 staging-4346 kernel: [<ffffffff81189f43>] handle_mm_fault+0xb3/0x160 Apr 3 08:15:48 staging-4346 kernel: [<ffffffff81776930>] __do_page_fault+0x1b0/0x580 Apr 3 08:15:48 staging-4346 kernel: [<ffffffff81642dce>] ? SYSC_recvfrom+0xee/0x170 Apr 3 08:15:48 staging-4346 kernel: [<ffffffff81014623>] ? __switch_to+0x173/0x500 Apr 3 08:15:48 staging-4346 kernel: [<ffffffff8176e54e>] ? __schedule+0x38e/0x720 Apr 3 08:15:48 staging-4346 kernel: [<ffffffff81776d1a>] do_page_fault+0x1a/0x70 Apr 3 08:15:48 staging-4346 kernel: [<ffffffff81772d28>] page_fault+0x28/0x30 Apr 3 08:15:48 staging-4346 kernel: Mem-Info: ... Apr 3 08:15:48 staging-4346 kernel: 73223 total pagecache pages Apr 3 08:15:48 staging-4346 kernel: 0 pages in swap cache Apr 3 08:15:48 staging-4346 kernel: Swap cache stats: add 0, delete 0, find 0/0 Apr 3 08:15:48 staging-4346 kernel: Free swap = 0kB Apr 3 08:15:48 staging-4346 kernel: Total swap = 0kB Apr 3 08:15:48 staging-4346 kernel: 3932061 pages RAM Apr 3 08:15:48 staging-4346 kernel: 0 pages HighMem/MovableOnly Apr 3 08:15:48 staging-4346 kernel: 62045 pages reserved Apr 3 08:15:48 staging-4346 kernel: [ pid ] uid tgid total_vm rss nr_ptes swapents oom_score_adj name ... Apr 3 08:15:48 staging-4346 kernel: [12534] 21876 12534 133277 52832 223 0 0 php Apr 3 08:15:48 staging-4346 kernel: [12541] 21876 12541 129561 49159 219 0 0 php Apr 3 08:15:48 staging-4346 kernel: [12545] 21876 12545 127532 47105 215 0 0 php ... Apr 3 08:15:48 staging-4346 kernel: Out of memory: Kill process 12534 (php) score 13 or sacrifice child Apr 3 08:15:48 staging-4346 kernel: Killed process 12534 (php) total-vm:533108kB, anon-rss:211260kB, file-rss:68kB Generally, a process requesting additional memory to run where the kernel reports that it is not available will invoke oom-killer , which will look for processes that do not have an \"oom score adjustment\" to prevent them from being killed, and then pass a SIGKILL to the first process that it finds to recover memory. A process that invokes oom-killer is often times not the victim of the oom-killer process, but it is possible. Sometimes this results in processes like the ones listed below to be killed: meh ah-socketd collector collectd php-fpm ... Investigation Look at stats graphs for the server reporting a service is not running. Is the server at or above 75% memory utilization over the course of a week? A month? Three months? Look at the dates of oom-killer messages recorded in /var/log/kern.log . Does it happen at a particular time of day? Does it correspond to a cron job or something similar that is customer-invoked? Look in JIRA and determine if the host has reported service failures in the past week. If so, how often? If a host has reported more than three consecutive service check failures that have been critted to the customer through Acquia Support , Ops has permission to emergency upsize a customer. Remediation - Customer Hardware Determine the next available instance size for the host. If an instance is of the c* series, use the next available c* series instance type, and the same for m* series instances. If this is for a staging server, proceed with relaunching the host to the next available instance type after sending a crit to Acquia Support . If this is a host in a single-tier cluster, upsize both instances to the new size and follow the standard Ops relaunch procedures regarding DB failover and remounting Gluster. If this is a host in a multi-tier cluster, ping #ops-team chat and ask for further input. Remediation - Infrastructure Contact #ops-team and/or escalate to a Senior Ops Engineer for further assistance. Post-Remediation If you complete an upsize of customer hardware, you must file an AM ticket for a dealsheet by visiting the following link: AM Dealsheet: Emergency Upsize","title":"Out Of Memory (OOM) errors"},{"location":"incident_response/out_of_memory_errors/#out-of-memory-oom-errors","text":"","title":"Out Of Memory (OOM) errors"},{"location":"incident_response/out_of_memory_errors/#summary","text":"OOM messages are often a result of a host that is under a significant amount of pressure to provide services. The most common host-types to OOM are (in no specific order): ded-% staging-% bal-% Other host types on the Acquia Hosting platform can OOM, but the more common of the instances that OOM are often customer hardware.","title":"Summary"},{"location":"incident_response/out_of_memory_errors/#background","text":"OOMs are recorded in /var/log/kern.log and are logged with a complete process table including memory utilization information. Apr 3 08:15:48 staging-4346 kernel: php invoked oom-killer: gfp_mask=0x201da, order=0, oom_score_adj=0 Apr 3 08:15:48 staging-4346 kernel: php cpuset=/ mems_allowed=0 Apr 3 08:15:48 staging-4346 kernel: CPU: 0 PID: 12612 Comm: php Not tainted 3.13.0-112-generic #159~precise1-Ubuntu Apr 3 08:15:48 staging-4346 kernel: Hardware name: Xen HVM domU, BIOS 4.2.amazon 11/11/2016 Apr 3 08:15:48 staging-4346 kernel: 0000000000000000 ffff8803b8a3b878 ffffffff81765ce5 ffff880153423000 Apr 3 08:15:48 staging-4346 kernel: 0000000000000000 ffff8803b8a3b8c8 ffffffff8175b5a3 ffff880300000000 Apr 3 08:15:48 staging-4346 kernel: 000201da813881a8 ffff8803b5cb9800 ffff880137491800 0000000000000000 Apr 3 08:15:48 staging-4346 kernel: Call Trace: Apr 3 08:15:48 staging-4346 kernel: [<ffffffff81765ce5>] dump_stack+0x64/0x82 Apr 3 08:15:48 staging-4346 kernel: [<ffffffff8175b5a3>] dump_header+0x7e/0xbd Apr 3 08:15:48 staging-4346 kernel: [<ffffffff8175b639>] oom_kill_process.part.5+0x57/0x2fb Apr 3 08:15:48 staging-4346 kernel: [<ffffffff81160da7>] oom_kill_process+0x47/0x50 Apr 3 08:15:48 staging-4346 kernel: [<ffffffff811610e5>] out_of_memory+0x145/0x1d0 Apr 3 08:15:48 staging-4346 kernel: [<ffffffff811671a3>] __alloc_pages_nodemask+0xb43/0xc50 Apr 3 08:15:48 staging-4346 kernel: [<ffffffff811a88f2>] alloc_pages_current+0xb2/0x170 Apr 3 08:15:48 staging-4346 kernel: [<ffffffff8115d347>] __page_cache_alloc+0xb7/0xd0 Apr 3 08:15:48 staging-4346 kernel: [<ffffffff8115f18d>] filemap_fault+0x28d/0x440 Apr 3 08:15:48 staging-4346 kernel: [<ffffffff811858df>] __do_fault+0x6f/0x530 Apr 3 08:15:48 staging-4346 kernel: [<ffffffff8116c12e>] ? lru_cache_add+0xe/0x10 Apr 3 08:15:48 staging-4346 kernel: [<ffffffff81189774>] handle_pte_fault+0xa4/0x230 Apr 3 08:15:48 staging-4346 kernel: [<ffffffff81642cc5>] ? sock_recvmsg+0xc5/0xe0 Apr 3 08:15:48 staging-4346 kernel: [<ffffffff81189d0b>] __handle_mm_fault+0x1db/0x360 Apr 3 08:15:48 staging-4346 kernel: [<ffffffff81189f43>] handle_mm_fault+0xb3/0x160 Apr 3 08:15:48 staging-4346 kernel: [<ffffffff81776930>] __do_page_fault+0x1b0/0x580 Apr 3 08:15:48 staging-4346 kernel: [<ffffffff81642dce>] ? SYSC_recvfrom+0xee/0x170 Apr 3 08:15:48 staging-4346 kernel: [<ffffffff81014623>] ? __switch_to+0x173/0x500 Apr 3 08:15:48 staging-4346 kernel: [<ffffffff8176e54e>] ? __schedule+0x38e/0x720 Apr 3 08:15:48 staging-4346 kernel: [<ffffffff81776d1a>] do_page_fault+0x1a/0x70 Apr 3 08:15:48 staging-4346 kernel: [<ffffffff81772d28>] page_fault+0x28/0x30 Apr 3 08:15:48 staging-4346 kernel: Mem-Info: ... Apr 3 08:15:48 staging-4346 kernel: 73223 total pagecache pages Apr 3 08:15:48 staging-4346 kernel: 0 pages in swap cache Apr 3 08:15:48 staging-4346 kernel: Swap cache stats: add 0, delete 0, find 0/0 Apr 3 08:15:48 staging-4346 kernel: Free swap = 0kB Apr 3 08:15:48 staging-4346 kernel: Total swap = 0kB Apr 3 08:15:48 staging-4346 kernel: 3932061 pages RAM Apr 3 08:15:48 staging-4346 kernel: 0 pages HighMem/MovableOnly Apr 3 08:15:48 staging-4346 kernel: 62045 pages reserved Apr 3 08:15:48 staging-4346 kernel: [ pid ] uid tgid total_vm rss nr_ptes swapents oom_score_adj name ... Apr 3 08:15:48 staging-4346 kernel: [12534] 21876 12534 133277 52832 223 0 0 php Apr 3 08:15:48 staging-4346 kernel: [12541] 21876 12541 129561 49159 219 0 0 php Apr 3 08:15:48 staging-4346 kernel: [12545] 21876 12545 127532 47105 215 0 0 php ... Apr 3 08:15:48 staging-4346 kernel: Out of memory: Kill process 12534 (php) score 13 or sacrifice child Apr 3 08:15:48 staging-4346 kernel: Killed process 12534 (php) total-vm:533108kB, anon-rss:211260kB, file-rss:68kB Generally, a process requesting additional memory to run where the kernel reports that it is not available will invoke oom-killer , which will look for processes that do not have an \"oom score adjustment\" to prevent them from being killed, and then pass a SIGKILL to the first process that it finds to recover memory. A process that invokes oom-killer is often times not the victim of the oom-killer process, but it is possible. Sometimes this results in processes like the ones listed below to be killed: meh ah-socketd collector collectd php-fpm ...","title":"Background"},{"location":"incident_response/out_of_memory_errors/#investigation","text":"Look at stats graphs for the server reporting a service is not running. Is the server at or above 75% memory utilization over the course of a week? A month? Three months? Look at the dates of oom-killer messages recorded in /var/log/kern.log . Does it happen at a particular time of day? Does it correspond to a cron job or something similar that is customer-invoked? Look in JIRA and determine if the host has reported service failures in the past week. If so, how often? If a host has reported more than three consecutive service check failures that have been critted to the customer through Acquia Support , Ops has permission to emergency upsize a customer.","title":"Investigation"},{"location":"incident_response/out_of_memory_errors/#remediation-customer-hardware","text":"Determine the next available instance size for the host. If an instance is of the c* series, use the next available c* series instance type, and the same for m* series instances. If this is for a staging server, proceed with relaunching the host to the next available instance type after sending a crit to Acquia Support . If this is a host in a single-tier cluster, upsize both instances to the new size and follow the standard Ops relaunch procedures regarding DB failover and remounting Gluster. If this is a host in a multi-tier cluster, ping #ops-team chat and ask for further input.","title":"Remediation - Customer Hardware"},{"location":"incident_response/out_of_memory_errors/#remediation-infrastructure","text":"Contact #ops-team and/or escalate to a Senior Ops Engineer for further assistance.","title":"Remediation - Infrastructure"},{"location":"incident_response/out_of_memory_errors/#post-remediation","text":"If you complete an upsize of customer hardware, you must file an AM ticket for a dealsheet by visiting the following link: AM Dealsheet: Emergency Upsize","title":"Post-Remediation"},{"location":"incident_response/perf_url_mon/","text":"Perf URL Mon Alert This alert indicates that a site could be down or experiencing performance issues. perf-url-mon checks the site via the URL listed below and requests ACQUIA_MONITOR . http://${SITE}.${FIELDS_STAGE}.acquia-sites.com/ACQUIA_MONITOR NOTE: The ACQUIA_MONITOR file does not bootstrap Drupal, and may potentially alert if a maintenance window is ongoing for a given site and if the DB has not been failed over correctly or is experiencing other issues. Response Notification to Support We should investigate each perf-url-mon type alert and then send an appropriate ticket to support. Steps for Initial Triage Use site-checkwebs $SITE to check if ACQUIA_MONITOR is responding or not Use site-getload $SITE to check if any server has excessive load or is unresponsive Check https://perf-mon.acquia.com/downtime.php to see how much downtime a site has (requires VPN) Alternatively use site-getdowntime $SITE from command line (ACE only) Click the SignalFx link in the Ops ticket and switch it to weekly view to see if CPU is at 100% for an excessive amount of time for any server Depending upon your findings from the above steps, send a crit to Support/Customer using the ticket crit tool on bastion Choose the '[Notification] Brief Service Interruption Detected' template if => Site is up Server load is low perf-mon.acquia.com shows no downtime except for approximately ~5 mins today and less than ~5 mins in 3-4 other past days Signalfx weekly views shows no servers at 100% CPU for the week Close the OP ticket when the crit is sent. Support may ping you in #outage channel if the customer replies to the crit asking for more information Choose the '[Notification] Brief Service Interruption Detected due to Maintenance' template if => Site is up Server load is low perf-mon.acquia.com shows no downtime except for approximately ~5 mins today and less than ~5 mins in 3-4 other past days You are aware of current maintainence happening which likely has affected this site Close the OP ticket when the crit is sent. Support may ping you in #outage channel if the customer replies to the crit asking for more information Chose 'Courtesy Investigation' template if => When checking https://perf-mon.acquia.com you notice a lot of downtime across multiple days. (Approximate guide: more than ~5 mins of downtime for ~10 or more days or more than ~10 mins of downtime for ~5 or more days) If the site is up, server load is OK, and Signalfx looks OK, close the OP ticket Otherwise, continue with the steps for the LONG OUTAGE below Copy and paste the ticket-ng link from the OP ticket or chose the 'Service Interruption Detected on your Production Environment' template if => The site is still down Server load is excessive on any server ( > 30 approximately depending on server size) Signalfx weekly view shows CPU of any server sitting at 100% the entire week Or for any other situation or if you are not sure what to chose If you send the ticket-ng link or use the 'Service Interruption Detected on your Production Environment' template, please follow the additional steps below Additional Steps for a Long Outage Use site-checkwebs to verify that ACQUIA_MONITOR is not responding Use site-getload to attempt to identify the source of potential performance bottlenecks Use site-task to check if the customer has cleared cache or pushed code in the last 24 hours Use site-dbslowqueriesandlocks to get a report of slow queries and InnoDB engine status Use aht @sitegroup.environment tr to look at recent traffic statistics from apache access logs (or use the Live Apache Metrics SumoLogic Dashboard ) to see if there was a recent traffic spike Use aht @sitegroup.environment panic --links to obtain other monitoring links that might provide you with clues as to what may be wrong Use site-traffic to check if there is a malicious IP making a lot of requests on the site or a potential DDOS. Use site-trafficbyuseragent to check if there is a malicious Useragent making lots of requests to the site Use site-getdowntime to check if the site is going down regularly and find related JIRA tickets for the root cause. Check Signalfx links in the ticket generated from ops-incidents or manually generate link using site-clusterhealth . Also, change the interval to a week or more if site has been alerting frequently. Upsize the hardware if it is repeat offender. Use aht @sitegroup.environment audit to check if any module is causing any issue. If upsize hasn't helped and the site is frequently down due to code/config issues - file an SL ticket to get attention from Support leadership. Escalation Escalating issues within Ops is documented in the Confluence document Escalating Incidents in the OE space. Common Scenarios Customer-Inflicted Clearing Varnish or Drupal cache causing more back-end requests, leading to increased load Promoting Drupal code to Prod that performs poorly Generally, this particular scenario can have an impact on the types of DB queries that are executed against the DB layer, what files are read from the filesystem, as well as what headers are emitted and processed by the Varnish caching layer (balancers). Issuing a large DB backup/import task Issuing a large Files backup/import task External calls to either external resources or to the originating site (self-calls) that are blocking PHP processes from completing AWS-Inflicted Instance retirement/instability/unavailability Service/network outages/instability Acquia-Inflicted Hardware/Sizing/Site Misconfigurations Process failures during maintenance windows, incident response, or outage recovery Tool or platform failures (bugs, service instability/unavailability, etc.) Monitoring False Alarms Accidents If a site is alerting because it was deprovisioned, find the Jira ticket where it was deprovisioned and verify whether it was intentionally deprovisioned. If so, remove it from monitoring. Otherwise, if it was deleted in error or if you are asked to restore a deleted site, you must Escalate to Cloud . Deleting a site cannot be undone by OPS. Example Scenarios General Load The best first tool to run in an outage is site-getload $SITE . It can show you what you need to look at next. [hosting-prod:prod] ~/fields/1.85$ site-getload thalesgroup bal-12025: 08:31:16 up 52 days, 8:29, 0 users, load average: 0.08, 0.09, 0.13 bal-12026: 08:31:16 up 51 days, 3:42, 0 users, load average: 0.00, 0.02, 0.05 ded-12023: 08:31:16 up 45 days, 4:38, 0 users, load average: 0.65, 0.32, 0.26 ded-12024: 08:31:16 up 45 days, 3:41, 0 users, load average: 0.77, 0.27, 0.20 In the above example, the balancers are idle as are the deds. This outage is indicative of external or code level issues. Things to check: site-externalcalls $SITE site-tailfpmerrorlog $SITE site-task $SITE Make sure web rotation and memcache configs are set appropriately for all webs in the cluster. esl2 will show each web's balancer rotation status and memcache service status. Read up on memcache for more on these statuses. site-getwebrotationstatus will show each web's serving status per site. 1000 is active, 1001 is inactive, and 1002 is deploy (the web will become active on the next successful run of fields-config-web.php ). Web Tier High Load [acquia-internal:network] ~/fields/1.85$ site-getload acquiacom bal-3: 00:50:16 up 25 days, 10:14, 0 users, load average: 0.18, 0.16, 0.20 bal-4: 00:50:16 up 25 days, 9:49, 0 users, load average: 0.00, 0.02, 0.05 fsdb-203: 00:50:16 up 24 days, 10:05, 0 users, load average: 0.06, 0.13, 0.13 fsdb-204: 00:50:16 up 24 days, 10:10, 0 users, load average: 0.03, 0.05, 0.11 web-205: 00:50:16 up 15 days, 19:37, 0 users, load average: 22.27, 14.13, 9.14 web-206: 00:50:16 up 25 days, 10:25, 0 users, load average: 21.30, 13.30, 8.33 web-245: 00:50:16 up 25 days, 10:30, 0 users, load average: 23.21, 13.18, 8.21 web-246: 00:50:16 up 25 days, 10:24, 0 users, load average: 22.10, 15.13, 10.17 In this example, only the web tier has high load. This indicates that the web tier is being overloaded with traffic that is making it past the balancer caching layer (Varnish). The low FSDB load shows that it is likely a PHP or Drupal problem or possible a Gluster issue. This may be caused by improperly-sized web servers, but could also be a crawler, a legitimate traffic spike, Gluster performance issues (typically i/o wait), or PHP code performance issues. Things to check: site-logstream and site-goaccess $streamed_log site-traffic $SITE esl2 $SITE site-elbdescribe $SITE site-task $SITE NewRelic data via aht @sitegroup.environment panic --links (if available) In the example above, aht @acquiacom.prod panic --links displays applicable links for the sitegroup. iostat -mx 1 for disk utilization (sdo/xvdo for Gluster) site-trafficbyuseragent $SITE OR site-trafficbyuseragent $SERVER If it is a crawler and the customer has an ELB, there is nothing Ops can do to assist other than to upsize the impacted tier. Support are able to create .htaccess rules to drop certain types of traffic at the apache layer if the customer has RA. This is a code-level fix and out of scope for Ops. Ops can write iptables rules on the fly, but they will not work for ELB traffic, as the origin IP will be the IP that the ELB resolves to internally. The runbook to block malicious IPs and Useragents outlines the general procedure and cautions to take. If there is something wrong with PHP do not just restart PHP! Instead, you should investigate PHP diagnostics and find out what's going wrong with it, then determine a root cause and whether it needs to be externaled to the customer or an appropriate engineering team. Once you have done that, you can restart PHP by using site-restartfpm . However, if the customer is using php-fpm-7.1 , you will need to restart it manually on each web until OP-158949 is done. DB Layer High Load [hosting-prod:prod] ~/fields/1.85$ site-getload fingovau bal-11361: 00:59:11 up 53 days, 12:15, 0 users, load average: 0.22, 0.12, 0.14 bal-11362: 00:59:11 up 53 days, 7:55, 0 users, load average: 0.00, 0.14, 0.23 fsdb-11358: 00:59:11 up 53 days, 10:47, 0 users, load average: 12.08, 9.06, 4.05 fsdb-11359: 00:59:11 up 53 days, 10:12, 0 users, load average: 0.19, 0.12, 0.14 web-11356: 00:59:11 up 53 days, 11:16, 0 users, load average: 0.10, 0.12, 0.13 web-11357: 00:59:11 up 53 days, 11:03, 0 users, load average: 0.12, 0.16, 0.14 In the above example, only the primary DB is under load. MySQL or Gluster could be extremely busy. Things to check: mytop -d mysql for long-running queries site-dbslowqueriesandlocks $SITE for a complete DB performance diagnostic (including slow queries from the last 8 hours) site-task $SITE for code deploys, DB copies, etc. ps awwwfuxx for DB backup or import processes iostat -mx 1 for disk utilization (sdm/xvdm for MySQL, sdo/xvdo for Gluster) FS Tier High Load [hosting-prod:prod] ~/fields/1.85$ site-getload mpagesig bal-3660: 01:02:15 up 53 days, 8:35, 0 users, load average: 0.13, 0.11, 0.14 bal-3661: 01:02:15 up 53 days, 8:52, 0 users, load average: 0.19, 0.14, 0.14 fsdb-3662: 01:02:15 up 53 days, 6:49, 0 users, load average: 3.56, 4.43, 3.71 fsdb-3663: 01:02:15 up 53 days, 6:39, 0 users, load average: 2.19, 3.17, 2.18 web-3664: 01:02:15 up 53 days, 6:51, 0 users, load average: 4.08, 3.98, 4.00 web-3665: 01:02:15 up 28 days, 10:52, 0 users, load average: 3.56, 3.47, 2.41 web-3666: 01:02:15 up 53 days, 6:51, 0 users, load average: 3.52, 3.46, 2.43 web-3667: 01:02:16 up 40 days, 17:36, 0 users, load average: 5.34, 4.39, 3.41 web-3668: 01:02:15 up 28 days, 10:44, 0 users, load average: 4.50, 3.52, 1.49 web-3669: 01:02:15 up 28 days, 10:44, 0 users, load average: 1.53, 4.44, 2.38 In the above example, both FSDB-class servers are experiencing high load and the webs are impacted by the same. Gluster is likely the bottleneck. Things to check: site-checkgluster $SITE (look for outliers among the return values such as high response times) site-logstream and site-goaccess $streamed_log iostat -mx 1 for disk utilization (sdo/xvdo for Gluster) External Calls [hosting-prod:prod] ~/fields/1.95$ site-externalcalls greatwolf Checking webs: (SNIP) web-9783: nweb-13399.prod.hosting.acquia.com:49398->ec2-23-23-136-70.compute-1.amazonaws.com:443 web-9783: nweb-13399.prod.hosting.acquia.com:49436->ec2-23-23-136-70.compute-1.amazonaws.com:443 web-9783: nweb-13399.prod.hosting.acquia.com:49451->ec2-23-23-136-70.compute-1.amazonaws.com:443 web-9783: nweb-13399.prod.hosting.acquia.com:49493->ec2-23-23-136-70.compute-1.amazonaws.com:443 web-9783: nweb-13399.prod.hosting.acquia.com:49474->ec2-23-23-136-70.compute-1.amazonaws.com:443 web-9783: nweb-13399.prod.hosting.acquia.com:49360->ec2-23-23-136-70.compute-1.amazonaws.com:443 web-9783: nweb-13399.prod.hosting.acquia.com:49426->ec2-23-23-136-70.compute-1.amazonaws.com:443 The webs listed above are making connections or \"calls\" to resources outside of Acquia's control and appear to be blocking. This is indicative of an external resource failure or a failure to make the resource call non-blocking in the customer's site code. There is nothing Ops can do in this scenario. Ops can attempt to identify the intended destination but cannot block them. dig on the destination (if destination is not an IP) may reveal the IP address of the destination whois on the destination (if the destinatino is an IP) may reveal ownership information for the destination such as what datacenter it belongs to, what upstream provider owns it, or if the IP is dedicated to the customer ahops-ssltool pull [DESTINATION] can pull down the SSL cert if one exists (uses openssl and assumes TCP 443) at the destination, which may provide more information","title":"Perf URL Mon Alert"},{"location":"incident_response/perf_url_mon/#perf-url-mon-alert","text":"This alert indicates that a site could be down or experiencing performance issues. perf-url-mon checks the site via the URL listed below and requests ACQUIA_MONITOR . http://${SITE}.${FIELDS_STAGE}.acquia-sites.com/ACQUIA_MONITOR NOTE: The ACQUIA_MONITOR file does not bootstrap Drupal, and may potentially alert if a maintenance window is ongoing for a given site and if the DB has not been failed over correctly or is experiencing other issues.","title":"Perf URL Mon Alert"},{"location":"incident_response/perf_url_mon/#response","text":"","title":"Response"},{"location":"incident_response/perf_url_mon/#notification-to-support","text":"We should investigate each perf-url-mon type alert and then send an appropriate ticket to support.","title":"Notification to Support"},{"location":"incident_response/perf_url_mon/#steps-for-initial-triage","text":"Use site-checkwebs $SITE to check if ACQUIA_MONITOR is responding or not Use site-getload $SITE to check if any server has excessive load or is unresponsive Check https://perf-mon.acquia.com/downtime.php to see how much downtime a site has (requires VPN) Alternatively use site-getdowntime $SITE from command line (ACE only) Click the SignalFx link in the Ops ticket and switch it to weekly view to see if CPU is at 100% for an excessive amount of time for any server","title":"Steps for Initial Triage"},{"location":"incident_response/perf_url_mon/#depending-upon-your-findings-from-the-above-steps-send-a-crit-to-supportcustomer-using-the-ticket-crit-tool-on-bastion","text":"","title":"Depending upon your findings from the above steps, send a crit to Support/Customer using the ticket crit tool on bastion"},{"location":"incident_response/perf_url_mon/#choose-the-notification-brief-service-interruption-detected-template-if","text":"Site is up Server load is low perf-mon.acquia.com shows no downtime except for approximately ~5 mins today and less than ~5 mins in 3-4 other past days Signalfx weekly views shows no servers at 100% CPU for the week Close the OP ticket when the crit is sent. Support may ping you in #outage channel if the customer replies to the crit asking for more information","title":"Choose the '[Notification] Brief Service Interruption Detected' template if =&gt;"},{"location":"incident_response/perf_url_mon/#choose-the-notification-brief-service-interruption-detected-due-to-maintenance-template-if","text":"Site is up Server load is low perf-mon.acquia.com shows no downtime except for approximately ~5 mins today and less than ~5 mins in 3-4 other past days You are aware of current maintainence happening which likely has affected this site Close the OP ticket when the crit is sent. Support may ping you in #outage channel if the customer replies to the crit asking for more information","title":"Choose the '[Notification] Brief Service Interruption Detected due to Maintenance' template if =&gt;"},{"location":"incident_response/perf_url_mon/#chose-courtesy-investigation-template-if","text":"When checking https://perf-mon.acquia.com you notice a lot of downtime across multiple days. (Approximate guide: more than ~5 mins of downtime for ~10 or more days or more than ~10 mins of downtime for ~5 or more days) If the site is up, server load is OK, and Signalfx looks OK, close the OP ticket Otherwise, continue with the steps for the LONG OUTAGE below","title":"Chose 'Courtesy Investigation' template if =&gt;"},{"location":"incident_response/perf_url_mon/#copy-and-paste-the-ticket-ng-link-from-the-op-ticket-or-chose-the-service-interruption-detected-on-your-production-environment-template-if","text":"The site is still down Server load is excessive on any server ( > 30 approximately depending on server size) Signalfx weekly view shows CPU of any server sitting at 100% the entire week Or for any other situation or if you are not sure what to chose","title":"Copy and paste the ticket-ng link from the OP ticket or chose the 'Service Interruption Detected on your Production Environment' template if =&gt;"},{"location":"incident_response/perf_url_mon/#if-you-send-the-ticket-ng-link-or-use-the-service-interruption-detected-on-your-production-environment-template-please-follow-the-additional-steps-below","text":"","title":"If you send the ticket-ng link or use the 'Service Interruption Detected on your Production Environment' template, please follow the additional steps below"},{"location":"incident_response/perf_url_mon/#additional-steps-for-a-long-outage","text":"Use site-checkwebs to verify that ACQUIA_MONITOR is not responding Use site-getload to attempt to identify the source of potential performance bottlenecks Use site-task to check if the customer has cleared cache or pushed code in the last 24 hours Use site-dbslowqueriesandlocks to get a report of slow queries and InnoDB engine status Use aht @sitegroup.environment tr to look at recent traffic statistics from apache access logs (or use the Live Apache Metrics SumoLogic Dashboard ) to see if there was a recent traffic spike Use aht @sitegroup.environment panic --links to obtain other monitoring links that might provide you with clues as to what may be wrong Use site-traffic to check if there is a malicious IP making a lot of requests on the site or a potential DDOS. Use site-trafficbyuseragent to check if there is a malicious Useragent making lots of requests to the site Use site-getdowntime to check if the site is going down regularly and find related JIRA tickets for the root cause. Check Signalfx links in the ticket generated from ops-incidents or manually generate link using site-clusterhealth . Also, change the interval to a week or more if site has been alerting frequently. Upsize the hardware if it is repeat offender. Use aht @sitegroup.environment audit to check if any module is causing any issue. If upsize hasn't helped and the site is frequently down due to code/config issues - file an SL ticket to get attention from Support leadership.","title":"Additional Steps for a Long Outage"},{"location":"incident_response/perf_url_mon/#escalation","text":"Escalating issues within Ops is documented in the Confluence document Escalating Incidents in the OE space.","title":"Escalation"},{"location":"incident_response/perf_url_mon/#common-scenarios","text":"","title":"Common Scenarios"},{"location":"incident_response/perf_url_mon/#customer-inflicted","text":"Clearing Varnish or Drupal cache causing more back-end requests, leading to increased load Promoting Drupal code to Prod that performs poorly Generally, this particular scenario can have an impact on the types of DB queries that are executed against the DB layer, what files are read from the filesystem, as well as what headers are emitted and processed by the Varnish caching layer (balancers). Issuing a large DB backup/import task Issuing a large Files backup/import task External calls to either external resources or to the originating site (self-calls) that are blocking PHP processes from completing","title":"Customer-Inflicted"},{"location":"incident_response/perf_url_mon/#aws-inflicted","text":"Instance retirement/instability/unavailability Service/network outages/instability","title":"AWS-Inflicted"},{"location":"incident_response/perf_url_mon/#acquia-inflicted","text":"Hardware/Sizing/Site Misconfigurations Process failures during maintenance windows, incident response, or outage recovery Tool or platform failures (bugs, service instability/unavailability, etc.) Monitoring False Alarms Accidents If a site is alerting because it was deprovisioned, find the Jira ticket where it was deprovisioned and verify whether it was intentionally deprovisioned. If so, remove it from monitoring. Otherwise, if it was deleted in error or if you are asked to restore a deleted site, you must Escalate to Cloud . Deleting a site cannot be undone by OPS.","title":"Acquia-Inflicted"},{"location":"incident_response/perf_url_mon/#example-scenarios","text":"","title":"Example Scenarios"},{"location":"incident_response/perf_url_mon/#general-load","text":"The best first tool to run in an outage is site-getload $SITE . It can show you what you need to look at next. [hosting-prod:prod] ~/fields/1.85$ site-getload thalesgroup bal-12025: 08:31:16 up 52 days, 8:29, 0 users, load average: 0.08, 0.09, 0.13 bal-12026: 08:31:16 up 51 days, 3:42, 0 users, load average: 0.00, 0.02, 0.05 ded-12023: 08:31:16 up 45 days, 4:38, 0 users, load average: 0.65, 0.32, 0.26 ded-12024: 08:31:16 up 45 days, 3:41, 0 users, load average: 0.77, 0.27, 0.20 In the above example, the balancers are idle as are the deds. This outage is indicative of external or code level issues. Things to check: site-externalcalls $SITE site-tailfpmerrorlog $SITE site-task $SITE Make sure web rotation and memcache configs are set appropriately for all webs in the cluster. esl2 will show each web's balancer rotation status and memcache service status. Read up on memcache for more on these statuses. site-getwebrotationstatus will show each web's serving status per site. 1000 is active, 1001 is inactive, and 1002 is deploy (the web will become active on the next successful run of fields-config-web.php ).","title":"General Load"},{"location":"incident_response/perf_url_mon/#web-tier-high-load","text":"[acquia-internal:network] ~/fields/1.85$ site-getload acquiacom bal-3: 00:50:16 up 25 days, 10:14, 0 users, load average: 0.18, 0.16, 0.20 bal-4: 00:50:16 up 25 days, 9:49, 0 users, load average: 0.00, 0.02, 0.05 fsdb-203: 00:50:16 up 24 days, 10:05, 0 users, load average: 0.06, 0.13, 0.13 fsdb-204: 00:50:16 up 24 days, 10:10, 0 users, load average: 0.03, 0.05, 0.11 web-205: 00:50:16 up 15 days, 19:37, 0 users, load average: 22.27, 14.13, 9.14 web-206: 00:50:16 up 25 days, 10:25, 0 users, load average: 21.30, 13.30, 8.33 web-245: 00:50:16 up 25 days, 10:30, 0 users, load average: 23.21, 13.18, 8.21 web-246: 00:50:16 up 25 days, 10:24, 0 users, load average: 22.10, 15.13, 10.17 In this example, only the web tier has high load. This indicates that the web tier is being overloaded with traffic that is making it past the balancer caching layer (Varnish). The low FSDB load shows that it is likely a PHP or Drupal problem or possible a Gluster issue. This may be caused by improperly-sized web servers, but could also be a crawler, a legitimate traffic spike, Gluster performance issues (typically i/o wait), or PHP code performance issues. Things to check: site-logstream and site-goaccess $streamed_log site-traffic $SITE esl2 $SITE site-elbdescribe $SITE site-task $SITE NewRelic data via aht @sitegroup.environment panic --links (if available) In the example above, aht @acquiacom.prod panic --links displays applicable links for the sitegroup. iostat -mx 1 for disk utilization (sdo/xvdo for Gluster) site-trafficbyuseragent $SITE OR site-trafficbyuseragent $SERVER If it is a crawler and the customer has an ELB, there is nothing Ops can do to assist other than to upsize the impacted tier. Support are able to create .htaccess rules to drop certain types of traffic at the apache layer if the customer has RA. This is a code-level fix and out of scope for Ops. Ops can write iptables rules on the fly, but they will not work for ELB traffic, as the origin IP will be the IP that the ELB resolves to internally. The runbook to block malicious IPs and Useragents outlines the general procedure and cautions to take. If there is something wrong with PHP do not just restart PHP! Instead, you should investigate PHP diagnostics and find out what's going wrong with it, then determine a root cause and whether it needs to be externaled to the customer or an appropriate engineering team. Once you have done that, you can restart PHP by using site-restartfpm . However, if the customer is using php-fpm-7.1 , you will need to restart it manually on each web until OP-158949 is done.","title":"Web Tier High Load"},{"location":"incident_response/perf_url_mon/#db-layer-high-load","text":"[hosting-prod:prod] ~/fields/1.85$ site-getload fingovau bal-11361: 00:59:11 up 53 days, 12:15, 0 users, load average: 0.22, 0.12, 0.14 bal-11362: 00:59:11 up 53 days, 7:55, 0 users, load average: 0.00, 0.14, 0.23 fsdb-11358: 00:59:11 up 53 days, 10:47, 0 users, load average: 12.08, 9.06, 4.05 fsdb-11359: 00:59:11 up 53 days, 10:12, 0 users, load average: 0.19, 0.12, 0.14 web-11356: 00:59:11 up 53 days, 11:16, 0 users, load average: 0.10, 0.12, 0.13 web-11357: 00:59:11 up 53 days, 11:03, 0 users, load average: 0.12, 0.16, 0.14 In the above example, only the primary DB is under load. MySQL or Gluster could be extremely busy. Things to check: mytop -d mysql for long-running queries site-dbslowqueriesandlocks $SITE for a complete DB performance diagnostic (including slow queries from the last 8 hours) site-task $SITE for code deploys, DB copies, etc. ps awwwfuxx for DB backup or import processes iostat -mx 1 for disk utilization (sdm/xvdm for MySQL, sdo/xvdo for Gluster)","title":"DB Layer High Load"},{"location":"incident_response/perf_url_mon/#fs-tier-high-load","text":"[hosting-prod:prod] ~/fields/1.85$ site-getload mpagesig bal-3660: 01:02:15 up 53 days, 8:35, 0 users, load average: 0.13, 0.11, 0.14 bal-3661: 01:02:15 up 53 days, 8:52, 0 users, load average: 0.19, 0.14, 0.14 fsdb-3662: 01:02:15 up 53 days, 6:49, 0 users, load average: 3.56, 4.43, 3.71 fsdb-3663: 01:02:15 up 53 days, 6:39, 0 users, load average: 2.19, 3.17, 2.18 web-3664: 01:02:15 up 53 days, 6:51, 0 users, load average: 4.08, 3.98, 4.00 web-3665: 01:02:15 up 28 days, 10:52, 0 users, load average: 3.56, 3.47, 2.41 web-3666: 01:02:15 up 53 days, 6:51, 0 users, load average: 3.52, 3.46, 2.43 web-3667: 01:02:16 up 40 days, 17:36, 0 users, load average: 5.34, 4.39, 3.41 web-3668: 01:02:15 up 28 days, 10:44, 0 users, load average: 4.50, 3.52, 1.49 web-3669: 01:02:15 up 28 days, 10:44, 0 users, load average: 1.53, 4.44, 2.38 In the above example, both FSDB-class servers are experiencing high load and the webs are impacted by the same. Gluster is likely the bottleneck. Things to check: site-checkgluster $SITE (look for outliers among the return values such as high response times) site-logstream and site-goaccess $streamed_log iostat -mx 1 for disk utilization (sdo/xvdo for Gluster)","title":"FS Tier High Load"},{"location":"incident_response/perf_url_mon/#external-calls","text":"[hosting-prod:prod] ~/fields/1.95$ site-externalcalls greatwolf Checking webs: (SNIP) web-9783: nweb-13399.prod.hosting.acquia.com:49398->ec2-23-23-136-70.compute-1.amazonaws.com:443 web-9783: nweb-13399.prod.hosting.acquia.com:49436->ec2-23-23-136-70.compute-1.amazonaws.com:443 web-9783: nweb-13399.prod.hosting.acquia.com:49451->ec2-23-23-136-70.compute-1.amazonaws.com:443 web-9783: nweb-13399.prod.hosting.acquia.com:49493->ec2-23-23-136-70.compute-1.amazonaws.com:443 web-9783: nweb-13399.prod.hosting.acquia.com:49474->ec2-23-23-136-70.compute-1.amazonaws.com:443 web-9783: nweb-13399.prod.hosting.acquia.com:49360->ec2-23-23-136-70.compute-1.amazonaws.com:443 web-9783: nweb-13399.prod.hosting.acquia.com:49426->ec2-23-23-136-70.compute-1.amazonaws.com:443 The webs listed above are making connections or \"calls\" to resources outside of Acquia's control and appear to be blocking. This is indicative of an external resource failure or a failure to make the resource call non-blocking in the customer's site code. There is nothing Ops can do in this scenario. Ops can attempt to identify the intended destination but cannot block them. dig on the destination (if destination is not an IP) may reveal the IP address of the destination whois on the destination (if the destinatino is an IP) may reveal ownership information for the destination such as what datacenter it belongs to, what upstream provider owns it, or if the IP is dedicated to the customer ahops-ssltool pull [DESTINATION] can pull down the SSL cert if one exists (uses openssl and assumes TCP 443) at the destination, which may provide more information","title":"External Calls"},{"location":"incident_response/pupgov/","text":"Pupgov Alerts Runbook Table of Contents Custom Ping Check Info Index Alert Handling Master 404/Slave 404 Master 200/Slave 404 Master 404/Slave 200 Master 200/Slave 5xx Master 5xx/Slave 200 Master or Slave 499 Tomcat Out of Memory pupgov-latency-check Additional Troubleshooting Upsizing Escalations Custom Index Ping Check A separate index ping check has been established for pupgov . The check like the existing index ping check is a AWS Lambda function. Unlike the regular index ping check, instead of executing every 5 minutes, it executes every 2 minutes and it is comprised of two functions: pupgov-prod-pingpup - This function is triggered by a AWS CloudWatch event every 2 minuutes. First it retrieves the list if indexes associated with the pupgov farm. It will then ping each of these indexes, if the ping should return a non-200 value or times out (5 seconds), it will publish the failed indexes to the send-to-pd AWS SNS topic ( NOTE : This topic is the same topic used by the existing index ping check ). SendToPdV1 - This function is triggered by a message being posted to the sent-to-pd AWS SNS topic. This function handles the actual sending of an alert to PD and is also shared with the default legacy index ping check. Index Alert Handling Given that this is a dedicated farm and as such, very rarely has indexes added or removed, it is not common for it to trigger an alert. Additionally, this document is specifically for a time of scheduled elevated traffic and the customer is under a code freeze, so it is highly unlikely to be adding or removing indexes. So with that it mind, more then likely the only reason you would see any index ping alerts is if one of the servers in the colony is rebooted or relaunched. Master 404 and Slave 404 Log into the Acquia Search Governor . In the textbox titled Title contains , enter the core ID (ex. AJLM-28483). From the resulting search results, click on the link pertaining to the alerting core ( NOTE : since multiple cores can be associated with an individual subscription, the search may return multiple results ). Click the \"Edit\" tab, scroll down to the bottom of the form, leave a message like \"Resaving node with no update\" and save it. Depending upon the number of cores on the farm and what EC2 region it is located in, will determine how long it will take to deploy the core, but is usually within a couple of minutes. To verify that the core was deployed, execute the following: CORE= ah-search ping $CORE Master 200 and Slave 404 Log into the slave server. fssh javaephem-702 Become the search user. sudo su - useast1as Attempt to load the core. CORE= rake client_force_reload client=${CORE} If the above results in a 500 error with a message saying that the client already exists, run a full rebuild rake rebuild If this results in a 400 error, you will need to remove the files that are already on the server and retry the reload . rm -r /var/www/html/useast1ass696m/docroot/files/indexes/${CORE} Once you have succesfully loaded the core, run the cron task. rake cron Verify it is no longer throwing a 404, from the bastion server, execute the following. CORE= ah-search ping $CORE If the ping is successful, repeat as necessary. If no more alerting cores exist, you can resolve the alert in Pager Duty. Master 404 and Slave 200 Log onto the master server. fssh javasrv-701 Become the search user. sudo su - useast1as Attempt to load the core. CORE= rake client_force_reload client=${CORE} If the above results in a 500 error with a message saying that the client already exists, run a full rebuild rake rebuild If this results in a 400 error, you will need to remove the files that are already on the server and retry the reload command. rm -r /var/www/html/useast1ass696m/docroot/files/indexes/${CORE} Once you have successfully loaded the core, run the cron task. rake cron Verify it is no longer throwing a 404 , from the bastion server, execute the following. CORE= ah-search ping $CORE If the ping is successful, repeat as necessary. If no more alerting cores exist, you can resolve the alert in Pager Duty. Master 200 and Slave 5xx Log onto master server. fssh javasrv-701 Become the search user. sudo su - useast1as Run rake rebuild. rake rebuild If you see 400 error for any of the cores, you will need to remove the existing files for each of the cores, repeating the below instructions for each core. Then re-run the rake rebuild . CORE= rm -r /var/www/html/useast1ass696m/docroot/files/indexes/${CORE} Once you get a clean rebuild run, run the cron task. rake cron Verify it is no longer throwing a 404. CORE= ah-search ping $CORE Master 5xx and Slave 200 Log onto slave server. fssh javaephem-702 Become the search user. sudo su - useast1as Run rake rebuild. rake rebuild If you see 400 error for any of the cores, you will need to remove the existing files for each of the cores, repeating the below instructions for each core. Then re-run the rake rebuild . CORE= rm -r /var/www/html/useast1ass696m/docroot/files/indexes/${CORE} Once you get a clean rebuild run, run the cron task. rake cron Verify it is no longer throwing a 404. CORE= ah-search ping $CORE 499 Error If you see a 499 status code, that indicates that the Solr index ping didn't respond in 5 seconds. This is probably a sign of an over-taxed server or a networking issue and should be investigated as such. If you see a large number of 499's for a farm, there is a good chance that the instance is impaired and will need to be relaunched; checked the status of the server. SERVER= ah-server status $SERVER Tomcat Out of Memory This alert can be triggered by two scenarios. In the first scenario, the catalina.out log has grown to such a size that the NRPE check can't process it before Nagios times out waiting for a response. This will be indicated by the Last State of the alert being UNKNOWN . The second scenario is when the check finds an OutOfMemoryError in the logs. Response If the Last State is UNKNOWN , manually run the Tomcat OOM check to make sure that we are not experiencing Tomcat OOM's in addition to the log file getting too big. /usr/lib/nagios/plugins/check_tomcat_oom If no OutOfMemoryError 's are detected, proceed to the manually rotating the log section. If OutOfMemoryError 's are detected, we will first need to determine what kind of memory issue the server is experiencing. cd /var/log/sites/$SITENAME/logs/$SERVER grep 'SEVERE.\\*java.lang.OutOfMemoryError' catalina.out If the error is java.lang.OutOfMemoryError: PermGen space or you want to check the PermGen usage, please perform the following steps Determine the Tomcat process, you will see two lines output. The line we want is the line that has Bootstrap start . jps -ml Next, display the status of the JVM, substituting PROCESSID= jstat -gcutil -h20 $PROCESSID 1000 If the P (Permgen) column number is high, for example, greater then 90, then the server is running out of Permgen space. By default, we do not configure Permgen space but instead use the default value. However, we can increase the Permgen space as follows. Get the site for the server in question. SERVER= SITE=$(ah-site list on:${SERVER}) Check to see if the Permgen space has already been configured. ah-site list $SITE -c tomcat6_java_opts:JAVA_OPTS If the Permgen space hasn't been configure, then configure it as follows: ah-site edit $SITE -c tomcat6_java_opts:JAVA_OPTS=\"-XX:PermSize=64M -XX:MaxPermSize=128M\" If the site has already been configured, increase the maximum size as the memory usage on the server allows. If the error is java.lang.OutOfMemoryError: Java heap space , the JVM is in need of more memory. It may be possible ton increase the JVM heap space, but we do not want it to exceed a certain level. Log onto the alerting server. SERVER= fssh $SERVER Determine how much memory is available. We want to take only the memory that is currently free, not including what is used for buffers or cache. free -m Take 80 percent of the value retrieved in the previous step, if the value is greater then 3072, then we can upsize the heap space. If not and the server hasn't already been upsized, the server can be upsized per the below instructions. If the server has already been upsized, escalate to the search team for further guidance. Stop Puppet sudo puppet agent --disable \"Manually upsizing heap space - DO NOT renable Puppet\" Open the Tomcat launch script for editing. sudo vi /mnt/gfs/useast1as.s696master/tomcat6/bin/control.sh Locate the memory configuration line as shown below: JAVA_OPTS=\"-server -Djava.awt.headless=true -Xms40642m -Xmx40642m\" Add an additional 2048 MB to both Xms and Xmx (Example. 40642 + 2048 = 42690) and save the file. Restart Tomcat sudo /etc/init.d/tomcat_useast1as.s696master restart Finally, to clear the alert, manually rotating the log section. Manually rotating the log file Backup catalina.out SITENAME= SERVER= cd /var/log/sites/$SITENAME/logs/$SERVER cp catalina.out /mnt/tmp/ gzip /mnt/tmp/catalina.out Truncate the log file truncate -s 0 catalina.out Verify the alert is gone /usr/lib/nagios/plugins/check_tomcat_oom ELB Metrics An AWS Lambda function has been created, pupgov-prod-pupcloudwatch which retrieves AWS CLoudWatch metrics for the pupgov ELB and sends them to SignalFX . The script is scheduled to run every 5 minutes. The metric data is being fed into a special dashboard in the Acquia Internal Services account and can be accessed via the following URL . This is the same account that houses the dashboards for the Atlassian products, so you should be able to access it. If you cannot access, please send an email to shane.vanhart@acquia.com requesting an invite to the account. Additional troubleshooting After a instance is relaunched, when a search farm has a lot of indexes with custom configuration, it will often fail the first time fields-config-web.php is executed. Try running fields-config-web.php again. sudo fields-config-web.php If you run fields-config-web.php and you see 400 errors for one or more of the indexes, do the following. Become the site user. UNIX_USERNAME= sudo su - $UNIX_USERNAME Remove the indexes that are reporting issues. rm -r /var/www/html/<SITENAME>/docroot/files/indexes/<SITENAME> Run rebuild. rake rebuild It is not uncommon that new 400 errors to appear, so it might be necessary to repeat the delete and rake step again. Once you have a clean rebuild, run the cron job. rake cron Verify that all indexes are okay, from bastion run the following: FARM_ID= ah-search ping_farm $FARM_ID If you have republished the indexes in the Governor and the rake tasks complete without issue on the effected server, take a look at the nxephem's. Log onto one of the farm's nxephems Run an nginx configuration test. sudo /etc/init.d/nginx configtest If the configtest fails, please raise a critical AS ticket and email search.admins . If the configuration test is clean, restart Nginx. sudo /etc/init.d/nginx restart Upsizing Currently, the farm is the largest tier, which is m2.4xlarge for the javasrv and javaephem . There has been some conversation about pro-actively upsizing them to i2.4xlarges . The largest supported instance type is an i2.8xlarge, if all other remedies have been exhausted and an upsize to the next instance type is believed to resolve the issue, then said upsize is approved without requiring consultation with the search team. However, if the farm has been upsized to the largest possible instance type and problems still exist, escalate to the search team using the procedures escalation procedure below. Escalations Per SOP, support should be notified of any alerts that requires action upon ops part. Escalating to the search team should be handled like any normal escalation to search. (see the Confluence How-to-get-help page )","title":"Pupgov Alerts Runbook"},{"location":"incident_response/pupgov/#pupgov-alerts-runbook","text":"","title":"Pupgov Alerts Runbook"},{"location":"incident_response/pupgov/#table-of-contents","text":"Custom Ping Check Info Index Alert Handling Master 404/Slave 404 Master 200/Slave 404 Master 404/Slave 200 Master 200/Slave 5xx Master 5xx/Slave 200 Master or Slave 499 Tomcat Out of Memory pupgov-latency-check Additional Troubleshooting Upsizing Escalations","title":"Table of Contents"},{"location":"incident_response/pupgov/#custom-index-ping-check","text":"A separate index ping check has been established for pupgov . The check like the existing index ping check is a AWS Lambda function. Unlike the regular index ping check, instead of executing every 5 minutes, it executes every 2 minutes and it is comprised of two functions: pupgov-prod-pingpup - This function is triggered by a AWS CloudWatch event every 2 minuutes. First it retrieves the list if indexes associated with the pupgov farm. It will then ping each of these indexes, if the ping should return a non-200 value or times out (5 seconds), it will publish the failed indexes to the send-to-pd AWS SNS topic ( NOTE : This topic is the same topic used by the existing index ping check ). SendToPdV1 - This function is triggered by a message being posted to the sent-to-pd AWS SNS topic. This function handles the actual sending of an alert to PD and is also shared with the default legacy index ping check.","title":"Custom Index Ping Check"},{"location":"incident_response/pupgov/#index-alert-handling","text":"Given that this is a dedicated farm and as such, very rarely has indexes added or removed, it is not common for it to trigger an alert. Additionally, this document is specifically for a time of scheduled elevated traffic and the customer is under a code freeze, so it is highly unlikely to be adding or removing indexes. So with that it mind, more then likely the only reason you would see any index ping alerts is if one of the servers in the colony is rebooted or relaunched.","title":"Index Alert Handling"},{"location":"incident_response/pupgov/#master-404-and-slave-404","text":"Log into the Acquia Search Governor . In the textbox titled Title contains , enter the core ID (ex. AJLM-28483). From the resulting search results, click on the link pertaining to the alerting core ( NOTE : since multiple cores can be associated with an individual subscription, the search may return multiple results ). Click the \"Edit\" tab, scroll down to the bottom of the form, leave a message like \"Resaving node with no update\" and save it. Depending upon the number of cores on the farm and what EC2 region it is located in, will determine how long it will take to deploy the core, but is usually within a couple of minutes. To verify that the core was deployed, execute the following: CORE= ah-search ping $CORE","title":"Master 404 and Slave 404"},{"location":"incident_response/pupgov/#master-200-and-slave-404","text":"Log into the slave server. fssh javaephem-702 Become the search user. sudo su - useast1as Attempt to load the core. CORE= rake client_force_reload client=${CORE} If the above results in a 500 error with a message saying that the client already exists, run a full rebuild rake rebuild If this results in a 400 error, you will need to remove the files that are already on the server and retry the reload . rm -r /var/www/html/useast1ass696m/docroot/files/indexes/${CORE} Once you have succesfully loaded the core, run the cron task. rake cron Verify it is no longer throwing a 404, from the bastion server, execute the following. CORE= ah-search ping $CORE If the ping is successful, repeat as necessary. If no more alerting cores exist, you can resolve the alert in Pager Duty.","title":"Master 200 and Slave 404"},{"location":"incident_response/pupgov/#master-404-and-slave-200","text":"Log onto the master server. fssh javasrv-701 Become the search user. sudo su - useast1as Attempt to load the core. CORE= rake client_force_reload client=${CORE} If the above results in a 500 error with a message saying that the client already exists, run a full rebuild rake rebuild If this results in a 400 error, you will need to remove the files that are already on the server and retry the reload command. rm -r /var/www/html/useast1ass696m/docroot/files/indexes/${CORE} Once you have successfully loaded the core, run the cron task. rake cron Verify it is no longer throwing a 404 , from the bastion server, execute the following. CORE= ah-search ping $CORE If the ping is successful, repeat as necessary. If no more alerting cores exist, you can resolve the alert in Pager Duty.","title":"Master 404 and Slave 200"},{"location":"incident_response/pupgov/#master-200-and-slave-5xx","text":"Log onto master server. fssh javasrv-701 Become the search user. sudo su - useast1as Run rake rebuild. rake rebuild If you see 400 error for any of the cores, you will need to remove the existing files for each of the cores, repeating the below instructions for each core. Then re-run the rake rebuild . CORE= rm -r /var/www/html/useast1ass696m/docroot/files/indexes/${CORE} Once you get a clean rebuild run, run the cron task. rake cron Verify it is no longer throwing a 404. CORE= ah-search ping $CORE","title":"Master 200 and Slave 5xx"},{"location":"incident_response/pupgov/#master-5xx-and-slave-200","text":"Log onto slave server. fssh javaephem-702 Become the search user. sudo su - useast1as Run rake rebuild. rake rebuild If you see 400 error for any of the cores, you will need to remove the existing files for each of the cores, repeating the below instructions for each core. Then re-run the rake rebuild . CORE= rm -r /var/www/html/useast1ass696m/docroot/files/indexes/${CORE} Once you get a clean rebuild run, run the cron task. rake cron Verify it is no longer throwing a 404. CORE= ah-search ping $CORE","title":"Master 5xx and Slave 200"},{"location":"incident_response/pupgov/#499-error","text":"If you see a 499 status code, that indicates that the Solr index ping didn't respond in 5 seconds. This is probably a sign of an over-taxed server or a networking issue and should be investigated as such. If you see a large number of 499's for a farm, there is a good chance that the instance is impaired and will need to be relaunched; checked the status of the server. SERVER= ah-server status $SERVER","title":"499 Error"},{"location":"incident_response/pupgov/#tomcat-out-of-memory","text":"This alert can be triggered by two scenarios. In the first scenario, the catalina.out log has grown to such a size that the NRPE check can't process it before Nagios times out waiting for a response. This will be indicated by the Last State of the alert being UNKNOWN . The second scenario is when the check finds an OutOfMemoryError in the logs.","title":"Tomcat Out of Memory"},{"location":"incident_response/pupgov/#response","text":"If the Last State is UNKNOWN , manually run the Tomcat OOM check to make sure that we are not experiencing Tomcat OOM's in addition to the log file getting too big. /usr/lib/nagios/plugins/check_tomcat_oom If no OutOfMemoryError 's are detected, proceed to the manually rotating the log section. If OutOfMemoryError 's are detected, we will first need to determine what kind of memory issue the server is experiencing. cd /var/log/sites/$SITENAME/logs/$SERVER grep 'SEVERE.\\*java.lang.OutOfMemoryError' catalina.out If the error is java.lang.OutOfMemoryError: PermGen space or you want to check the PermGen usage, please perform the following steps Determine the Tomcat process, you will see two lines output. The line we want is the line that has Bootstrap start . jps -ml Next, display the status of the JVM, substituting PROCESSID= jstat -gcutil -h20 $PROCESSID 1000 If the P (Permgen) column number is high, for example, greater then 90, then the server is running out of Permgen space. By default, we do not configure Permgen space but instead use the default value. However, we can increase the Permgen space as follows. Get the site for the server in question. SERVER= SITE=$(ah-site list on:${SERVER}) Check to see if the Permgen space has already been configured. ah-site list $SITE -c tomcat6_java_opts:JAVA_OPTS If the Permgen space hasn't been configure, then configure it as follows: ah-site edit $SITE -c tomcat6_java_opts:JAVA_OPTS=\"-XX:PermSize=64M -XX:MaxPermSize=128M\" If the site has already been configured, increase the maximum size as the memory usage on the server allows. If the error is java.lang.OutOfMemoryError: Java heap space , the JVM is in need of more memory. It may be possible ton increase the JVM heap space, but we do not want it to exceed a certain level. Log onto the alerting server. SERVER= fssh $SERVER Determine how much memory is available. We want to take only the memory that is currently free, not including what is used for buffers or cache. free -m Take 80 percent of the value retrieved in the previous step, if the value is greater then 3072, then we can upsize the heap space. If not and the server hasn't already been upsized, the server can be upsized per the below instructions. If the server has already been upsized, escalate to the search team for further guidance. Stop Puppet sudo puppet agent --disable \"Manually upsizing heap space - DO NOT renable Puppet\" Open the Tomcat launch script for editing. sudo vi /mnt/gfs/useast1as.s696master/tomcat6/bin/control.sh Locate the memory configuration line as shown below: JAVA_OPTS=\"-server -Djava.awt.headless=true -Xms40642m -Xmx40642m\" Add an additional 2048 MB to both Xms and Xmx (Example. 40642 + 2048 = 42690) and save the file. Restart Tomcat sudo /etc/init.d/tomcat_useast1as.s696master restart Finally, to clear the alert, manually rotating the log section.","title":"Response"},{"location":"incident_response/pupgov/#manually-rotating-the-log-file","text":"Backup catalina.out SITENAME= SERVER= cd /var/log/sites/$SITENAME/logs/$SERVER cp catalina.out /mnt/tmp/ gzip /mnt/tmp/catalina.out Truncate the log file truncate -s 0 catalina.out Verify the alert is gone /usr/lib/nagios/plugins/check_tomcat_oom","title":"Manually rotating the log file"},{"location":"incident_response/pupgov/#elb-metrics","text":"An AWS Lambda function has been created, pupgov-prod-pupcloudwatch which retrieves AWS CLoudWatch metrics for the pupgov ELB and sends them to SignalFX . The script is scheduled to run every 5 minutes. The metric data is being fed into a special dashboard in the Acquia Internal Services account and can be accessed via the following URL . This is the same account that houses the dashboards for the Atlassian products, so you should be able to access it. If you cannot access, please send an email to shane.vanhart@acquia.com requesting an invite to the account.","title":"ELB Metrics"},{"location":"incident_response/pupgov/#additional-troubleshooting","text":"After a instance is relaunched, when a search farm has a lot of indexes with custom configuration, it will often fail the first time fields-config-web.php is executed. Try running fields-config-web.php again. sudo fields-config-web.php If you run fields-config-web.php and you see 400 errors for one or more of the indexes, do the following. Become the site user. UNIX_USERNAME= sudo su - $UNIX_USERNAME Remove the indexes that are reporting issues. rm -r /var/www/html/<SITENAME>/docroot/files/indexes/<SITENAME> Run rebuild. rake rebuild It is not uncommon that new 400 errors to appear, so it might be necessary to repeat the delete and rake step again. Once you have a clean rebuild, run the cron job. rake cron Verify that all indexes are okay, from bastion run the following: FARM_ID= ah-search ping_farm $FARM_ID If you have republished the indexes in the Governor and the rake tasks complete without issue on the effected server, take a look at the nxephem's. Log onto one of the farm's nxephems Run an nginx configuration test. sudo /etc/init.d/nginx configtest If the configtest fails, please raise a critical AS ticket and email search.admins . If the configuration test is clean, restart Nginx. sudo /etc/init.d/nginx restart","title":"Additional troubleshooting"},{"location":"incident_response/pupgov/#upsizing","text":"Currently, the farm is the largest tier, which is m2.4xlarge for the javasrv and javaephem . There has been some conversation about pro-actively upsizing them to i2.4xlarges . The largest supported instance type is an i2.8xlarge, if all other remedies have been exhausted and an upsize to the next instance type is believed to resolve the issue, then said upsize is approved without requiring consultation with the search team. However, if the farm has been upsized to the largest possible instance type and problems still exist, escalate to the search team using the procedures escalation procedure below.","title":"Upsizing"},{"location":"incident_response/pupgov/#escalations","text":"Per SOP, support should be notified of any alerts that requires action upon ops part. Escalating to the search team should be handled like any normal escalation to search. (see the Confluence How-to-get-help page )","title":"Escalations"},{"location":"incident_response/puppet_agent_disabled/","text":"Puppet Agent Disabled alert This alert means that Puppet has been disabled. Then someone downtimed the alert generated when Puppet is disabled and that period of time for the downtime has expired. sudo /usr/lib/nagios/plugins/check_puppet_agent_disabled_lockfile Response The pager duty alert and the ops-incident generated JIRA ticket will contain the JIRA ticket number added to a comment when a person originally disabled puppet, say for example a VCL test. If you ran puppet agent -t you would also see the comment, though it is preferred just to read it from the ticket. Example: CRITICAL: Puppet agent is disabled, reason: OP-89028 VCL Test, and was disabled 1055913 seconds ago! Review the original ticket and see if additional days, 3 to 5 days, are needed. Downtime the Puppet check additional time. JIRA is the original ticket number. SERVER= JIRA= MINUTES= sv-downtimeservice $SERVER \"Puppet Agent Disabled\" $MINUTES \"$JIRA\" If it appears that puppet should be re-enabled after review of the original ticket, then puppet can be re-enabled. It may be worthwhile to contact the assignee of the ticket first. puppet agent --enable puppet agent -t Enabling/Disabling Masterless Puppet To disable Puppet working in Masterless Puppet mode , use the following command: sudo ah-puppet-disable ${OP} Then to enable it again, use the following: sudo ah-puppet-enable sudo run-puppet","title":"Puppet Agent Disabled alert"},{"location":"incident_response/puppet_agent_disabled/#puppet-agent-disabled-alert","text":"This alert means that Puppet has been disabled. Then someone downtimed the alert generated when Puppet is disabled and that period of time for the downtime has expired. sudo /usr/lib/nagios/plugins/check_puppet_agent_disabled_lockfile","title":"Puppet Agent Disabled alert"},{"location":"incident_response/puppet_agent_disabled/#response","text":"The pager duty alert and the ops-incident generated JIRA ticket will contain the JIRA ticket number added to a comment when a person originally disabled puppet, say for example a VCL test. If you ran puppet agent -t you would also see the comment, though it is preferred just to read it from the ticket. Example: CRITICAL: Puppet agent is disabled, reason: OP-89028 VCL Test, and was disabled 1055913 seconds ago! Review the original ticket and see if additional days, 3 to 5 days, are needed. Downtime the Puppet check additional time. JIRA is the original ticket number. SERVER= JIRA= MINUTES= sv-downtimeservice $SERVER \"Puppet Agent Disabled\" $MINUTES \"$JIRA\" If it appears that puppet should be re-enabled after review of the original ticket, then puppet can be re-enabled. It may be worthwhile to contact the assignee of the ticket first. puppet agent --enable puppet agent -t","title":"Response"},{"location":"incident_response/puppet_agent_disabled/#enablingdisabling-masterless-puppet","text":"To disable Puppet working in Masterless Puppet mode , use the following command: sudo ah-puppet-disable ${OP} Then to enable it again, use the following: sudo ah-puppet-enable sudo run-puppet","title":"Enabling/Disabling Masterless Puppet"},{"location":"incident_response/puppet_agent_run_status/","text":"Puppet Agent Run Status This alert means that the puppet agent lock file has been in place for longer than 3600 seconds. Puppet will not run again if the lock file is in place. This is normally caused if the server was rebooted during a puppet run or if the server was low on memory. sudo /usr/lib/nagios/plugins/check_puppet_agent_catalog_run_lockfile CRITICAL: Puppet agent has been running for 38074! Check to see if puppet is still running. ps auxwwwf | grep [p]uppet Response If puppet is not running, but the lock file is in place, then run puppet on the server that is alerting. sudo puppet agent -t OR in Masterless Puppet mode sudo run-puppet After running puppet, run an sv-service recheck from the bastion sv-servicerecheck $SERVER \"Puppet Agent Run Status\"","title":"Puppet Agent Run Status"},{"location":"incident_response/puppet_agent_run_status/#puppet-agent-run-status","text":"This alert means that the puppet agent lock file has been in place for longer than 3600 seconds. Puppet will not run again if the lock file is in place. This is normally caused if the server was rebooted during a puppet run or if the server was low on memory. sudo /usr/lib/nagios/plugins/check_puppet_agent_catalog_run_lockfile CRITICAL: Puppet agent has been running for 38074! Check to see if puppet is still running. ps auxwwwf | grep [p]uppet","title":"Puppet Agent Run Status"},{"location":"incident_response/puppet_agent_run_status/#response","text":"If puppet is not running, but the lock file is in place, then run puppet on the server that is alerting. sudo puppet agent -t OR in Masterless Puppet mode sudo run-puppet After running puppet, run an sv-service recheck from the bastion sv-servicerecheck $SERVER \"Puppet Agent Run Status\"","title":"Response"},{"location":"incident_response/search_index_mon/","text":"Search Core Index Alerts Note: To login Search jumpboxes, follow these instructions Search core index checks are high-level checks which probe each index advertised by the Governor. The checks are run in AWS Lambda in the search-service account and consist of three Lambda functions: InitiateIndexCheck : this function queries the Governor retrieving a list of indexes and then groups them by farm. It then publishes messages to AWS SNS containing each farm's list of indexes. It is triggered via a CloudWatch event every five minutes. checkLegacyFarm : this function takes the list of indexes for a farm and ping's them on both the javasrv and the javaephem . If any of the pings fail, an alert message is created and is published to AWS SNS where the SendToPd function picks it up. SendToPd : this function takes the alert message body and attempts to send an alert to Pager Duty. It will try three times before throwing an error. The code for the above functions is located in the ops-lambda Git repo. NOTE : when a server is relaunched/rebooted using ah-server in the search account, a squelch is set. The index check code looks for said squelch and if it exists, does not check any indexes for the affected server. The squelch automatically times out after one hour as a precaution so that a server doesn't remain squelched indefinitely . Disabling the Core Index Checks To disable the index core check, you will need to disable the CloudWatch event that triggers the InitiateIndexCheck function. You can disable the event either via the AWS Console or the following commands: asearch aws events disable-rule --name InitiateIndexCheck To re-enable it, you can again use the AWS console or the following commands: asearch aws events enable-rule --name InitiateIndexCheck NOTE : You will also need to disable the meta-monitoring that ensures the check is running as explained below. Meta-monitoring As mentioned above, the index ping check is a collection of AWS Lambda functions. To ensure we know that we are aware if the check is having issues and to make sure it is being running, a series of AWS CLoudwatch alarms have been configured. Below you will see the list of CloudWatch alarms, of them ops will only receive alerts for CheckNotInitated , all the rest will go to the search team. The Cloudwatch alarms exist in the legacy search account just like the servers and Lambda functions. CheckNotInitated : generates an alert if the InitiateIndexCheck hasn't executed within the last 15 minutes. CheckFarmNotRunning : generates an alert if the checkLegacyFarm hasn't executed within the last 15 minutes. InitiateIndexCheckError : generates an alert if the InitiateIndexCheck execution results in an error 2 times or more within 15 minutes. PingIndexFailure : generates an alert if the checkLegacyFarm execution results in an error 2 times or more within 15 minutes. SendToPdFunctionError : generates an alert if the SendToPd function execution results in an error at least once within 5 minutes. NOTE : If it is necessary to disable the meta-monitoring, for example, the index check is temporarily disabled, you will need to do the following : Log into the AWS console ( https://209496442179.signin.aws.amazon.com/console ). Select the Cloudwatch service from the available options. Click on alarms from the left-navigation. Check the checkbox for CheckNotInitiated , then click Modify from the Actions dropdown menu. Then in the alerts section, modify Send notification to: setting it to dev_null . Then check the checkbox for CheckFarmNotRunning , then click Modify from the Actions dropdown menu. Then in the alerts section, modify Send notification to: setting it to dev_null . To re-enable, you would need to set the Send Notification to: back to legacy-search-index-check-ops for CheckNotIntiated and to legacy-search-index-check-errors for CheckFarmNotRunning . Information Gathering The alert includes the server and farmm information, but depending upon the alert, additional information may be required to resolve the alert. A tool has been deployed to 1.81 fields to provide the necessary information. It is called ah-search ( NOTE : Ignore the options, they are inherited from fields and are not used ). [cloudservicesdev|search-service:search-service] ~/fields/1.81$ ~/ah-search Commands: ah-search colonies # Get a list of all colonies ah-search colony COLONY_ID # Retrieve information about the provided colony ah-search core INDEX # Retrieve server information pertaining to the provided index. ah-search farm FARM_ID # Retrieve information pertaining to the provided farm ah-search help [COMMAND] # Describe available commands or one specific command ah-search list SERVER # Get a list of indexes associated with the provided server ah-search ping INDEX # Ping the provided Solr index. ah-search ping_farm FARM_ID # Ping all of the indexes on a farm Alert Handling We should create an internal zendesk ticket if index(es) are not deployed for either Master or Slave server or for both. We can find the list of Site names or the number of cores with the help of 'search-site' tool and add this detail to either OP or zendesk ticket. For example: [cloudservicesdev|search-service:search-service] ~/fields/1.81$ search-site -s <search-server-name-like-javaephem-456> Usage: search-site -c <Core ID - ABCD-123456.01live.default> search-site -s <Search server name - javasrv-123 or javaephem-456> To create an internal zendesk ticket, we should select 'Multiple Sites' option while executing 'ticket crit' tool and add the subject as well as the description accordingly: [cloudservicesdev|search-service:search-service] ~/fields/1.81$ ticket crit Single Customer or Multiple Customers? 1. Single Site 2. Multiple Sites Problem Type: 2 Ticket Subject: Please fill below template and add this information in the description while submitting the zendesk ticket. Hi Support, Acquia Search services have been impacted. The information directly below is provided by the OPS team about this incident. OP ticket: [link] Who is impacted - one or multiple customers? List known customers, core ID, or indexes, etc. depending on the situation: [link] What action has OPS taken yet, if any?: [info] Actions Support can do to help, if needed: [info] Is this escalated to the AS (Acquia Search) team? If so, please link to the AS ticket in Jira: [link] Here is a link to the Support runbook for Acquia Search shared services: https://confluence.acquia.com/display/support/Search For reference, here is a link to the OPS runbook: https://runbook.ops.acquia.com/master/incident_response/search_index_mon [OPS ticket creator] Index not deployed (slave_code=404 & master_code=404) Log into the Acquia Search Governor . In the textbox titled Title contains , enter the core ID (ex. AJLM-28483). From the resulting search results, click on the link pertaining to the alerting core ( NOTE : since multiple cores can be associated with an individual subscription, the search may return multiple results ). Click the \"Edit\" tab, scroll down to the bottom of the form, leave a message like \" Resaving node with no update \" and save it. Depending upon the number of cores on the farm and what EC2 region it is located in, will determine how long it will take to deploy the core, but is usually within a couple of minutes. To verify that the core was deployed, execute the following: CORE= ah-search ping $CORE Index missing on slave (slave_code=404 & master_code=200) Log into the slave server. Load the core. UNIX_USERNAME= su - $UNIX_USERNAME CORE= rake client_force_reload client=${CORE} rake cron Verify it is no longer throwing a 404. CORE= ah-search ping $CORE If the ping is successful, repeat as necessary. If no more alerting cores exist, you can resolve the alert in Pager Duty. If this doesn't resolve the error, see below for additional troubleshooting & resolution steps. Index missing on master (slave_code=200 & master_code=404) Log onto the master server. Load the core. UNIX_USERNAME= su - $UNIX_USERNAME CORE= rake client_force_reload client=${CORE} rake cron Verify it is no longer throwing a 404. CORE= ah-search ping $CORE If the ping is successful, repeat as necessary. If no more alerting cores exist, you can resolve the alert in Pager Duty. If this doesn't resolve the error, see below for additional troubleshooting & resolution steps. Slave is erroring (slave_code=5xx & master_code=200) Log onto slave server. Do the rake dance UNIX_USERNAME= sudo su - $USERNAME rake rebuild rake cron Verify it is no longer throwing a 5xx. CORE= ah-search ping $CORE If the ping is successful, repeat as necessary. If no more alerting cores exist, you can resolve the alert in Pager Duty. If this doesn't resolve the error, see below for additional troubleshooting & resolution . Master is erroring (slave_code=200 & master_code=5xx) Log onto master server. Do the rake dance UNIX_USERNAME= sudo su - $USERNAME rake rebuild rake cron Verify it is no longer throwing a 5xx. CORE= ah-search ping $CORE If the ping is successful, repeat as necessary. If no more alerting cores exist, you can resolve the alert in Pager Duty. If this doesn't resolve the error, see below for additional troubleshooting & resolution steps. Index failing on rake rebuild with boot- core already exists This is what the error will look like after running a 'rake rebuild'. Call to CoreAdmin API failed with code 500, URL: http://localhost:8081/solr/admin/cores?action=CREATE&name=boot-ADEW-83285.dev.default&instanceDir=cores/ADEW-83285.dev.default&wt=json, Full response: {\"responseHeader\":{\"status\":500,\"QTime\":1},\"error\":{\"msg\":\"Core with name 'boot-ADEW-83285.dev.default' already exists.\",\"trace\":\"org.apache.solr.common.SolrException: Core with name 'boot-ADEW-83285.dev.default' already exists.\\n\\tat Log onto the server that is failing to reload the index. Set the index name environment variable. export INDEX_NAME=<index-name> Unload the boot- index manually. curl -sS \"http://localhost:8081/solr/admin/cores?action=UNLOAD&core=boot-$INDEX_NAME\" Attempt to reload the index again. rake client_force_reload client=$INDEX_NAME If you get the same issue again then the subscription data for the index is most likely corrupt. Repeat the steps above but after unloading the boot- index, unpublish and publish the index in the governor before trying to do a client_force reload again. 499 status code If you see a 499 status code, that indicates that the Solr index ping didn't respond in 5 seconds. This is probably a sign of an over-taxed server or a networking issue and should be investigated as such. If you see a large number of 499's for a farm, there is a good chance that the instance is impaired and will need to be relaunched; checked the status of the server. SERVER= ah-server status $SERVER Impaired Search Instances We should create an internal zendesk ticket if either Master or Slave server get impaired. We can find the list of Site names or the number of cores with the help of 'search-site' tool and add this detail to either OP or zendesk ticket. For example: [cloudservicesdev|search-service:search-service] ~/fields/1.81$ search-site -s <search-server-name-like-javaephem-456> Usage: search-site -c <Core ID - ABCD-123456.01live.default> search-site -s <Search server name - javasrv-123 or javaephem-456> To create an internal zendesk ticket, we should select 'Multiple Sites' option while executing 'ticket crit' tool and add the subject as well as the description accordingly: [cloudservicesdev|search-service:search-service] ~/fields/1.81$ ticket crit Single Customer or Multiple Customers? 1. Single Site 2. Multiple Sites Problem Type: 2 Ticket Subject: Please fill below template and add this information in the description while submitting the zendesk ticket. Hi Support, Acquia Search services have been impacted. The information directly below is provided by the OPS team about this incident. OP ticket: [link] Who is impacted - one or multiple customers? List known customers, core ID, or indexes, etc. depending on the situation: [link] What action has OPS taken yet, if any?: [info] Actions Support can do to help, if needed: [info] Is this escalated to the AS (Acquia Search) team? If so, please link to the AS ticket in Jira: [link] Here is a link to the Support runbook for Acquia Search shared services: https://confluence.acquia.com/display/support/Search For reference, here is a link to the OPS runbook: https://runbook.ops.acquia.com/master/incident_response/search_index_mon [OPS ticket creator] Before relaunching the impaired instance, please review the Search section in the known server relaunch issues doc Relaunch the impaired instance SERVER= ah-server abandon $SERVER ah-server launch $SERVER Once the new server is up, the launcher will automatically make sure the fields-config-web.php is run along with the rake dance. If these should fail, the launcher will let you know, please see below for troubleshooting & resolution steps. ( NOTE : The launcher will automatically squelch any index checks for the affected server while it is being relaunched. However, if a task should fail, after the the issue has been resolved, you will need to manually unsquelch the server ). Other Troubleshooting and Resolution Procedures After a instance is relaunched, when a search farm has a lot of indexes with custom configuration, it will often fail the first time fields-config-web.php is executed. Try running fields-config-web.php again. sudo fields-config-web.php If you run fields-config-web.php and you see 400 errors for one or more of the indexes, do the following. Become the site user. UNIX_USERNAME= sudo su - $UNIX_USERNAME Remove the indexes that are reporting issues. rm -r /var/www/html/<SITENAME>/docroot/files/indexes/<SITENAME> Run rebuild. rake rebuild It is not uncommon that new 400 errors to appear, so it might be necessary to repeat the delete and rake step again. Once you have a clean rebuild, run the cron job. rake cron Verify that all indexes are okay, from bastion run the following: FARM_ID= ah-search ping_farm $FARM_ID If you have republished the indexes in the Governor and the rake tasks complete without issue on the effected server, take a look at the nxephem's. Log onto one of the farm's nxephems Run an nginx configuration test. sudo /etc/init.d/nginx configtest If the configtest fails, please raise a critical AS ticket and email search.admins . If the configuration test is clean, restart Nginx. sudo /etc/init.d/nginx restart","title":"Search Core Index Alerts"},{"location":"incident_response/search_index_mon/#search-core-index-alerts","text":"Note: To login Search jumpboxes, follow these instructions Search core index checks are high-level checks which probe each index advertised by the Governor. The checks are run in AWS Lambda in the search-service account and consist of three Lambda functions: InitiateIndexCheck : this function queries the Governor retrieving a list of indexes and then groups them by farm. It then publishes messages to AWS SNS containing each farm's list of indexes. It is triggered via a CloudWatch event every five minutes. checkLegacyFarm : this function takes the list of indexes for a farm and ping's them on both the javasrv and the javaephem . If any of the pings fail, an alert message is created and is published to AWS SNS where the SendToPd function picks it up. SendToPd : this function takes the alert message body and attempts to send an alert to Pager Duty. It will try three times before throwing an error. The code for the above functions is located in the ops-lambda Git repo. NOTE : when a server is relaunched/rebooted using ah-server in the search account, a squelch is set. The index check code looks for said squelch and if it exists, does not check any indexes for the affected server. The squelch automatically times out after one hour as a precaution so that a server doesn't remain squelched indefinitely .","title":"Search Core Index Alerts"},{"location":"incident_response/search_index_mon/#disabling-the-core-index-checks","text":"To disable the index core check, you will need to disable the CloudWatch event that triggers the InitiateIndexCheck function. You can disable the event either via the AWS Console or the following commands: asearch aws events disable-rule --name InitiateIndexCheck To re-enable it, you can again use the AWS console or the following commands: asearch aws events enable-rule --name InitiateIndexCheck NOTE : You will also need to disable the meta-monitoring that ensures the check is running as explained below.","title":"Disabling the Core Index Checks"},{"location":"incident_response/search_index_mon/#meta-monitoring","text":"As mentioned above, the index ping check is a collection of AWS Lambda functions. To ensure we know that we are aware if the check is having issues and to make sure it is being running, a series of AWS CLoudwatch alarms have been configured. Below you will see the list of CloudWatch alarms, of them ops will only receive alerts for CheckNotInitated , all the rest will go to the search team. The Cloudwatch alarms exist in the legacy search account just like the servers and Lambda functions. CheckNotInitated : generates an alert if the InitiateIndexCheck hasn't executed within the last 15 minutes. CheckFarmNotRunning : generates an alert if the checkLegacyFarm hasn't executed within the last 15 minutes. InitiateIndexCheckError : generates an alert if the InitiateIndexCheck execution results in an error 2 times or more within 15 minutes. PingIndexFailure : generates an alert if the checkLegacyFarm execution results in an error 2 times or more within 15 minutes. SendToPdFunctionError : generates an alert if the SendToPd function execution results in an error at least once within 5 minutes. NOTE : If it is necessary to disable the meta-monitoring, for example, the index check is temporarily disabled, you will need to do the following : Log into the AWS console ( https://209496442179.signin.aws.amazon.com/console ). Select the Cloudwatch service from the available options. Click on alarms from the left-navigation. Check the checkbox for CheckNotInitiated , then click Modify from the Actions dropdown menu. Then in the alerts section, modify Send notification to: setting it to dev_null . Then check the checkbox for CheckFarmNotRunning , then click Modify from the Actions dropdown menu. Then in the alerts section, modify Send notification to: setting it to dev_null . To re-enable, you would need to set the Send Notification to: back to legacy-search-index-check-ops for CheckNotIntiated and to legacy-search-index-check-errors for CheckFarmNotRunning .","title":"Meta-monitoring"},{"location":"incident_response/search_index_mon/#information-gathering","text":"The alert includes the server and farmm information, but depending upon the alert, additional information may be required to resolve the alert. A tool has been deployed to 1.81 fields to provide the necessary information. It is called ah-search ( NOTE : Ignore the options, they are inherited from fields and are not used ). [cloudservicesdev|search-service:search-service] ~/fields/1.81$ ~/ah-search Commands: ah-search colonies # Get a list of all colonies ah-search colony COLONY_ID # Retrieve information about the provided colony ah-search core INDEX # Retrieve server information pertaining to the provided index. ah-search farm FARM_ID # Retrieve information pertaining to the provided farm ah-search help [COMMAND] # Describe available commands or one specific command ah-search list SERVER # Get a list of indexes associated with the provided server ah-search ping INDEX # Ping the provided Solr index. ah-search ping_farm FARM_ID # Ping all of the indexes on a farm","title":"Information Gathering"},{"location":"incident_response/search_index_mon/#alert-handling","text":"We should create an internal zendesk ticket if index(es) are not deployed for either Master or Slave server or for both. We can find the list of Site names or the number of cores with the help of 'search-site' tool and add this detail to either OP or zendesk ticket. For example: [cloudservicesdev|search-service:search-service] ~/fields/1.81$ search-site -s <search-server-name-like-javaephem-456> Usage: search-site -c <Core ID - ABCD-123456.01live.default> search-site -s <Search server name - javasrv-123 or javaephem-456> To create an internal zendesk ticket, we should select 'Multiple Sites' option while executing 'ticket crit' tool and add the subject as well as the description accordingly: [cloudservicesdev|search-service:search-service] ~/fields/1.81$ ticket crit Single Customer or Multiple Customers? 1. Single Site 2. Multiple Sites Problem Type: 2 Ticket Subject: Please fill below template and add this information in the description while submitting the zendesk ticket. Hi Support, Acquia Search services have been impacted. The information directly below is provided by the OPS team about this incident. OP ticket: [link] Who is impacted - one or multiple customers? List known customers, core ID, or indexes, etc. depending on the situation: [link] What action has OPS taken yet, if any?: [info] Actions Support can do to help, if needed: [info] Is this escalated to the AS (Acquia Search) team? If so, please link to the AS ticket in Jira: [link] Here is a link to the Support runbook for Acquia Search shared services: https://confluence.acquia.com/display/support/Search For reference, here is a link to the OPS runbook: https://runbook.ops.acquia.com/master/incident_response/search_index_mon [OPS ticket creator]","title":"Alert Handling"},{"location":"incident_response/search_index_mon/#index-not-deployed-slave_code404-master_code404","text":"Log into the Acquia Search Governor . In the textbox titled Title contains , enter the core ID (ex. AJLM-28483). From the resulting search results, click on the link pertaining to the alerting core ( NOTE : since multiple cores can be associated with an individual subscription, the search may return multiple results ). Click the \"Edit\" tab, scroll down to the bottom of the form, leave a message like \" Resaving node with no update \" and save it. Depending upon the number of cores on the farm and what EC2 region it is located in, will determine how long it will take to deploy the core, but is usually within a couple of minutes. To verify that the core was deployed, execute the following: CORE= ah-search ping $CORE","title":"Index not deployed (slave_code=404 &amp; master_code=404)"},{"location":"incident_response/search_index_mon/#index-missing-on-slave-slave_code404-master_code200","text":"Log into the slave server. Load the core. UNIX_USERNAME= su - $UNIX_USERNAME CORE= rake client_force_reload client=${CORE} rake cron Verify it is no longer throwing a 404. CORE= ah-search ping $CORE If the ping is successful, repeat as necessary. If no more alerting cores exist, you can resolve the alert in Pager Duty. If this doesn't resolve the error, see below for additional troubleshooting & resolution steps.","title":"Index missing on slave (slave_code=404 &amp; master_code=200)"},{"location":"incident_response/search_index_mon/#index-missing-on-master-slave_code200-master_code404","text":"Log onto the master server. Load the core. UNIX_USERNAME= su - $UNIX_USERNAME CORE= rake client_force_reload client=${CORE} rake cron Verify it is no longer throwing a 404. CORE= ah-search ping $CORE If the ping is successful, repeat as necessary. If no more alerting cores exist, you can resolve the alert in Pager Duty. If this doesn't resolve the error, see below for additional troubleshooting & resolution steps.","title":"Index missing on master (slave_code=200 &amp; master_code=404)"},{"location":"incident_response/search_index_mon/#slave-is-erroring-slave_code5xx-master_code200","text":"Log onto slave server. Do the rake dance UNIX_USERNAME= sudo su - $USERNAME rake rebuild rake cron Verify it is no longer throwing a 5xx. CORE= ah-search ping $CORE If the ping is successful, repeat as necessary. If no more alerting cores exist, you can resolve the alert in Pager Duty. If this doesn't resolve the error, see below for additional troubleshooting & resolution .","title":"Slave is erroring (slave_code=5xx &amp; master_code=200)"},{"location":"incident_response/search_index_mon/#master-is-erroring-slave_code200-master_code5xx","text":"Log onto master server. Do the rake dance UNIX_USERNAME= sudo su - $USERNAME rake rebuild rake cron Verify it is no longer throwing a 5xx. CORE= ah-search ping $CORE If the ping is successful, repeat as necessary. If no more alerting cores exist, you can resolve the alert in Pager Duty. If this doesn't resolve the error, see below for additional troubleshooting & resolution steps.","title":"Master is erroring (slave_code=200 &amp; master_code=5xx)"},{"location":"incident_response/search_index_mon/#index-failing-on-rake-rebuild-with-boot-core-already-exists","text":"This is what the error will look like after running a 'rake rebuild'. Call to CoreAdmin API failed with code 500, URL: http://localhost:8081/solr/admin/cores?action=CREATE&name=boot-ADEW-83285.dev.default&instanceDir=cores/ADEW-83285.dev.default&wt=json, Full response: {\"responseHeader\":{\"status\":500,\"QTime\":1},\"error\":{\"msg\":\"Core with name 'boot-ADEW-83285.dev.default' already exists.\",\"trace\":\"org.apache.solr.common.SolrException: Core with name 'boot-ADEW-83285.dev.default' already exists.\\n\\tat Log onto the server that is failing to reload the index. Set the index name environment variable. export INDEX_NAME=<index-name> Unload the boot- index manually. curl -sS \"http://localhost:8081/solr/admin/cores?action=UNLOAD&core=boot-$INDEX_NAME\" Attempt to reload the index again. rake client_force_reload client=$INDEX_NAME If you get the same issue again then the subscription data for the index is most likely corrupt. Repeat the steps above but after unloading the boot- index, unpublish and publish the index in the governor before trying to do a client_force reload again.","title":"Index failing on rake rebuild with boot- core already exists"},{"location":"incident_response/search_index_mon/#499-status-code","text":"If you see a 499 status code, that indicates that the Solr index ping didn't respond in 5 seconds. This is probably a sign of an over-taxed server or a networking issue and should be investigated as such. If you see a large number of 499's for a farm, there is a good chance that the instance is impaired and will need to be relaunched; checked the status of the server. SERVER= ah-server status $SERVER","title":"499 status code"},{"location":"incident_response/search_index_mon/#impaired-search-instances","text":"We should create an internal zendesk ticket if either Master or Slave server get impaired. We can find the list of Site names or the number of cores with the help of 'search-site' tool and add this detail to either OP or zendesk ticket. For example: [cloudservicesdev|search-service:search-service] ~/fields/1.81$ search-site -s <search-server-name-like-javaephem-456> Usage: search-site -c <Core ID - ABCD-123456.01live.default> search-site -s <Search server name - javasrv-123 or javaephem-456> To create an internal zendesk ticket, we should select 'Multiple Sites' option while executing 'ticket crit' tool and add the subject as well as the description accordingly: [cloudservicesdev|search-service:search-service] ~/fields/1.81$ ticket crit Single Customer or Multiple Customers? 1. Single Site 2. Multiple Sites Problem Type: 2 Ticket Subject: Please fill below template and add this information in the description while submitting the zendesk ticket. Hi Support, Acquia Search services have been impacted. The information directly below is provided by the OPS team about this incident. OP ticket: [link] Who is impacted - one or multiple customers? List known customers, core ID, or indexes, etc. depending on the situation: [link] What action has OPS taken yet, if any?: [info] Actions Support can do to help, if needed: [info] Is this escalated to the AS (Acquia Search) team? If so, please link to the AS ticket in Jira: [link] Here is a link to the Support runbook for Acquia Search shared services: https://confluence.acquia.com/display/support/Search For reference, here is a link to the OPS runbook: https://runbook.ops.acquia.com/master/incident_response/search_index_mon [OPS ticket creator] Before relaunching the impaired instance, please review the Search section in the known server relaunch issues doc Relaunch the impaired instance SERVER= ah-server abandon $SERVER ah-server launch $SERVER Once the new server is up, the launcher will automatically make sure the fields-config-web.php is run along with the rake dance. If these should fail, the launcher will let you know, please see below for troubleshooting & resolution steps. ( NOTE : The launcher will automatically squelch any index checks for the affected server while it is being relaunched. However, if a task should fail, after the the issue has been resolved, you will need to manually unsquelch the server ).","title":"Impaired Search Instances"},{"location":"incident_response/search_index_mon/#other-troubleshooting-and-resolution-procedures","text":"After a instance is relaunched, when a search farm has a lot of indexes with custom configuration, it will often fail the first time fields-config-web.php is executed. Try running fields-config-web.php again. sudo fields-config-web.php If you run fields-config-web.php and you see 400 errors for one or more of the indexes, do the following. Become the site user. UNIX_USERNAME= sudo su - $UNIX_USERNAME Remove the indexes that are reporting issues. rm -r /var/www/html/<SITENAME>/docroot/files/indexes/<SITENAME> Run rebuild. rake rebuild It is not uncommon that new 400 errors to appear, so it might be necessary to repeat the delete and rake step again. Once you have a clean rebuild, run the cron job. rake cron Verify that all indexes are okay, from bastion run the following: FARM_ID= ah-search ping_farm $FARM_ID If you have republished the indexes in the Governor and the rake tasks complete without issue on the effected server, take a look at the nxephem's. Log onto one of the farm's nxephems Run an nginx configuration test. sudo /etc/init.d/nginx configtest If the configtest fails, please raise a critical AS ticket and email search.admins . If the configuration test is clean, restart Nginx. sudo /etc/init.d/nginx restart","title":"Other Troubleshooting and Resolution Procedures"},{"location":"incident_response/services_check/","text":"Services Check This alert checks that the proper number of processes are running for each applicable service on a server. The list of services varies by server type. You can check running services with: SERVER= sv-checkservices ${SERVER} Or, if you're logged into the server: sudo /usr/lib/nagios/plugins/check_services | head -n2 For Node.js service check alerts - please see the section given for node alerts Resolution Triage the Service If the alert reports ' execution expired ' or is timing out, check if the server is responsive: sv-up ${SERVER} ah-server status ${SERVER} If the server is system_status impaired , relaunch it . Otherwise, reboot it: ah-server reboot -i ${SERVER} After the server reboots, investigate the cause of death. Common reasons include OOMing, AWS network blips, resource oversaturation, etc. Check if the service was deliberately stopped. Check for workflows in progress: sv-workflow ${SERVER} Check if Puppet is disabled: fssh ${SERVER} 'sudo cat /var/lib/puppet/state/agent_disabled.lock' If it is, find out why and follow the Puppet agent disabled runbook . Check the Ops Handover Board Search Jira for recent tickets mentioning the server Ask about it in the team-ops and ops-private-team chat rooms. Check for OOMs: sv-oomanalysis ${SERVER} If services on a server are failing often (often due to OOMing), then assess whether the server meets our emergency upsize guidelines . As with any emergency upsize, don't forget to file an AM ticket via Ops Portal Check logs for errors on why the service is down. Restart the Service First, try to restore services the easy way: In most cases, running Puppet will restore services: sv-puppetkick ${SERVER} For PHP-FPM, you may also need to run fields-config-web.php : sv-fcwkick ${SERVER} Some services may not be able to run if the Gluster mount is not accessible. If you suspect something is wrong with Gluster, try remounting it for the server (or the whole site), and then try to restore services again: sv-fsremount ${SERVER} Note: Sometimes (particularly for Gluster 3.4), remounting gluster does not properly restore the gluster mount. If sv-fsremount reports success but there are still problems, following the Gluster troubleshooting runbook . If the easy way doesn't work, log into the server and attempt to restart services manually. Ensure the service is completely stopped: SERVICE= service ${SERVICE} stop This should end all processes associated with the service, but this is not always the case. Double check: ps -Fp $(pgrep -f service) If there are rogue processes hanging around, kill them. Do not use kill -9 except as a last resort. Run Puppet to start the service: puppet agent -t OR in Masterless Puppet mode sudo run-puppet If Puppet doesn't start the service, try starting it manually: service ${SERVICE} start Verify Services and Follow-up Verify the server passes the service check: sv-checkservices ${SERVER} Node service checks failure This alert is triggered when a node service is down and cannot be checked through Nagios check_services plugin as it is specific to particular node.js service. To check the exact cause of the error - execute the following script from ops-misc - which will give you error message: node-checkservices ${SERVER} If you see \"Error: listen EACCES: permission denied 0.0.0.0:80\" - it means the node script is trying to run on port 80 which is not permitted. Port number is defined in $PORT environment variable by customer. Thus customer need to change the port to higher numbered port. Even port number 8080 is not allowed. Service failed for wsnodejssandbox-dev-12218.service at emitErrorNT (net.js:1307:8) Emitted 'error' event at: Error: listen EACCES: permission denied 0.0.0.0:80 throw er; // Unhandled 'error' event Create a customer facing zendesk ticket for this purpose using ticket crit tool using the Service interuption template. If the environment name seen in top line has dev - then use non-production template and for prod - use the production template. Add the following comment so that Support can take a follow up with customer: Customer is trying to run node.js process on port 80 which is not allowed. This is causing service failure. Customer need to change the port number and redeploy code Downtime the service check alert for some duration to avoid alerts on pagerduty: sv-downtimeservice ${SERVER} \"Check Services\" DURATION OP","title":"Services Check"},{"location":"incident_response/services_check/#services-check","text":"This alert checks that the proper number of processes are running for each applicable service on a server. The list of services varies by server type. You can check running services with: SERVER= sv-checkservices ${SERVER} Or, if you're logged into the server: sudo /usr/lib/nagios/plugins/check_services | head -n2 For Node.js service check alerts - please see the section given for node alerts","title":"Services Check"},{"location":"incident_response/services_check/#resolution","text":"","title":"Resolution"},{"location":"incident_response/services_check/#triage-the-service","text":"If the alert reports ' execution expired ' or is timing out, check if the server is responsive: sv-up ${SERVER} ah-server status ${SERVER} If the server is system_status impaired , relaunch it . Otherwise, reboot it: ah-server reboot -i ${SERVER} After the server reboots, investigate the cause of death. Common reasons include OOMing, AWS network blips, resource oversaturation, etc. Check if the service was deliberately stopped. Check for workflows in progress: sv-workflow ${SERVER} Check if Puppet is disabled: fssh ${SERVER} 'sudo cat /var/lib/puppet/state/agent_disabled.lock' If it is, find out why and follow the Puppet agent disabled runbook . Check the Ops Handover Board Search Jira for recent tickets mentioning the server Ask about it in the team-ops and ops-private-team chat rooms. Check for OOMs: sv-oomanalysis ${SERVER} If services on a server are failing often (often due to OOMing), then assess whether the server meets our emergency upsize guidelines . As with any emergency upsize, don't forget to file an AM ticket via Ops Portal Check logs for errors on why the service is down.","title":"Triage the Service"},{"location":"incident_response/services_check/#restart-the-service","text":"First, try to restore services the easy way: In most cases, running Puppet will restore services: sv-puppetkick ${SERVER} For PHP-FPM, you may also need to run fields-config-web.php : sv-fcwkick ${SERVER} Some services may not be able to run if the Gluster mount is not accessible. If you suspect something is wrong with Gluster, try remounting it for the server (or the whole site), and then try to restore services again: sv-fsremount ${SERVER} Note: Sometimes (particularly for Gluster 3.4), remounting gluster does not properly restore the gluster mount. If sv-fsremount reports success but there are still problems, following the Gluster troubleshooting runbook . If the easy way doesn't work, log into the server and attempt to restart services manually. Ensure the service is completely stopped: SERVICE= service ${SERVICE} stop This should end all processes associated with the service, but this is not always the case. Double check: ps -Fp $(pgrep -f service) If there are rogue processes hanging around, kill them. Do not use kill -9 except as a last resort. Run Puppet to start the service: puppet agent -t OR in Masterless Puppet mode sudo run-puppet If Puppet doesn't start the service, try starting it manually: service ${SERVICE} start","title":"Restart the Service"},{"location":"incident_response/services_check/#verify-services-and-follow-up","text":"Verify the server passes the service check: sv-checkservices ${SERVER}","title":"Verify Services and Follow-up"},{"location":"incident_response/services_check/#node-service-checks-failure","text":"This alert is triggered when a node service is down and cannot be checked through Nagios check_services plugin as it is specific to particular node.js service. To check the exact cause of the error - execute the following script from ops-misc - which will give you error message: node-checkservices ${SERVER} If you see \"Error: listen EACCES: permission denied 0.0.0.0:80\" - it means the node script is trying to run on port 80 which is not permitted. Port number is defined in $PORT environment variable by customer. Thus customer need to change the port to higher numbered port. Even port number 8080 is not allowed. Service failed for wsnodejssandbox-dev-12218.service at emitErrorNT (net.js:1307:8) Emitted 'error' event at: Error: listen EACCES: permission denied 0.0.0.0:80 throw er; // Unhandled 'error' event Create a customer facing zendesk ticket for this purpose using ticket crit tool using the Service interuption template. If the environment name seen in top line has dev - then use non-production template and for prod - use the production template. Add the following comment so that Support can take a follow up with customer: Customer is trying to run node.js process on port 80 which is not allowed. This is causing service failure. Customer need to change the port number and redeploy code Downtime the service check alert for some duration to avoid alerts on pagerduty: sv-downtimeservice ${SERVER} \"Check Services\" DURATION OP","title":"Node service checks failure"},{"location":"incident_response/site_capacity/","text":"Site Capacity alert Cause This alert means that we have either created enough sites to reach our threshold on a shared bal/svn server or a new shared server was just provisioned and no site is using it as yet. The check ignores deleted sites. Sample alerts: CRITICAL: Server is full. Please provision a new server - 950` WARNING: Server nearing full - 948` UNKNOWN: Could not find number of sites on server at /var/acquia/NUMBER_OF_SITES_ON_SERVER-VCS` Thresholds Balancers: 1500 (ACP), 250 (ACE) SVN Servers: 950 CRITICAL: Server is full SVN Servers As customers come and go the number of sites on an svn server fluctuate. Note that in ACE several customers have dedicated svn servers. Get the numbers of sites on a server for every svn server in the region of the realm: fpdsh -t % -n svn -r $REGION -c \"sudo cat /var/acquia/NUMBER_OF_SITES_ON_SERVER-VCS\" If there are no reasonably free hosts available, provision a new server and move the tags as appropriate for the stage and region in question. ACE SVN server ACP SVN Server Staging Servers Important Note Do not abort workflows! If you are unable to resolve a problem with a workflow, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership Shared Non-RA Staging Servers (Automated) Shared Non-RA Staging Servers are handled via workflow automation. ah-stage create-new-shared-servers Inspect the output and pay close attention to workflow_args.body.ec2_region , workflow_args.body.shared_server_tag , and workflow_args.body.shared_server_type . If they are valid (meaning that the region and host type are correct for what is alerting as full), then invoke the workflow with --no-dry-run : ah-stage create-new-shared-servers --no-dry-run Monitor the output of the workflow and provide the full output in the OP ticket. Shared Non-RA Staging Servers (Manual) ACE/Provision Infra/Shared Staging Shared RA Staging Servers (Automated) Shared RA staging servers are handled via workflow automation. ah-stage create-new-shared-servers Inspect the output and pay close attention to workflow_args.body.ec2_region , workflow_args.body.shared_server_tag , and workflow_args.body.shared_server_type . If they are valid (meaning that the region and host type are correct for what is alerting as full), then invoke the workflow with --no-dry-run : ah-stage create-new-shared-servers --no-dry-run Monitor the output of the workflow and provide the full output in the OP ticket. Shared RA Staging Servers (Manual) ACE/Provision Infra/Shared RA Staging BAL Servers If tags can be moved back to a less-full balancer (< 75% capacity), we should try that first. Set the below variable to the name of one of the bals that's alerting. SERVER= Execute the below block. SERVER_INFO=($(ah-server list ${SERVER} \\ -c ec2_region ec2_availability_zone vpc_id bal_cluster_id tags --no-name | \\ sed 's/,/ /g')) REGION=${SERVER_INFO[0]} AZ=${SERVER_INFO[1]} VPC_ID=${SERVER_INFO[2]} VPC_NAME=$(ah-vpc list % -w id=${VPC_ID}) BAL_CLUSTER_ID=$(echo ${SERVER_INFO[3]}) TAGS=($(echo ${SERVER_INFO[4]} | sed 's/+/\\n/g' | \\ egrep -v '^shared|ssl_|workflow' | sed 's/\\n/ /g')) SSL_TAG=$(echo ${SERVER_INFO[4]} | sed 's/+/\\n/g' | grep ssl_) AVAILABLE_SERVERS=$(ah-server list tag:${SSL_TAG} \\ -w type=bal vpc_id=${VPC_ID} ec2_region=${REGION} \\ -c tags | grep shared | cut -d, -f1 | paste -sd,) if [[ -z \"${AVAILABLE_SERVERS}\" ]]; then echo \"ERROR: No other shared bals in ${VPC_NAME}. Please allocate a new balancer pair.\"; fi case \"${FIELDS_STAGE}\" in prod ) THRESHOLD=250 ;; devcloud ) THRESHOLD=1500 ;; esac LIMIT=$(expr ${THRESHOLD} / 4 \\* 3) NEW_SERVERS=($(ah-server list ${AVAILABLE_SERVERS} -c site-count \\ | sed 's/,/ /g' | sort -k2 -n \\ | awk -v var=${LIMIT} '{ if ($2 <= var) print $1 }' | head -n2)) NEW_SERVERS_CSV=$(array-csv ${NEW_SERVERS[@]}) BAL_CLUSTER_IDS=($(ah-server list ${NEW_SERVERS_CSV} -c bal_cluster_id --no-name)) if [[ ${BAL_CLUSTER_IDS[0]} -ne ${BAL_CLUSTER_IDS[1]} ]]; then echo \"ERROR: Bal cluster ids do not match\"; echo \"Servers selected: ${NEW_SERVERS_CSV}\"; fi If an error stating no other shared bals are present, skip to the next section If no errors are reported, proceed with moving the requisite tags. ah-server tag add ${NEW_SERVERS[@]} -t ${TAGS[@]} ah-server tag remove $(ah-server list % \\ -w bal_cluster_id=${BAL_CLUSTER_ID} | paste -sd' ') -t ${TAGS[@]} Refresh the mons for the region. fpdsh -t mon -r $REGION -c 'sudo fields-config-mon.php' Refresh the checks for the impacted hosts. for SERVER in $(ah-server list % -w bal_cluster_id=${BAL_CLUSTER_ID}); do sv-servicerecheck ${SERVER} \"Site capacity\"; done Verify that this region has 2 bals, 1 svn, and 1 mon server with the devcloud-shared tag. This will cause a Sev0 if the region does not have these tagged servers! ah-server list tag:devcloud-shared -w ec2_region=${REGION} You should also avoid having more than this quantity of each server type in a region. However, a region can have more than 2 bals depending on which VPC they are serving. Provision Shared Balancers Shared bals can be handled via workflow automation. The workflow will automatically transfer the tags and SSL certificates where appropriate. Run the below command to invoke the workflow in \"dry-run\" mode. ah-stage create-new-shared-servers Inspect the output and pay close attention to workflow_args.body.ec2_region , workflow_args.body.shared_server_tag , and workflow_args.body.shared_server_type . If they are valid (meaning that the region and host type are correct for what is alerting as full), then invoke the workflow with --no-dry-run : ah-stage create-new-shared-servers --no-dry-run Monitor the output of the workflow and provide the full output in the OP ticket. UNKNOWN: Could not find number of sites For a new server you can just wait and the alert will clear once a site is provisioned that uses the new server. Or you can execute a command to force the creation of the file used by the check. Call either sudo fields-config-bal.php on the balancer or sudo fields-config-svn.php on the svn server and the alert will clear on the next run.","title":"Site Capacity alert"},{"location":"incident_response/site_capacity/#site-capacity-alert","text":"","title":"Site Capacity alert"},{"location":"incident_response/site_capacity/#cause","text":"This alert means that we have either created enough sites to reach our threshold on a shared bal/svn server or a new shared server was just provisioned and no site is using it as yet. The check ignores deleted sites. Sample alerts: CRITICAL: Server is full. Please provision a new server - 950` WARNING: Server nearing full - 948` UNKNOWN: Could not find number of sites on server at /var/acquia/NUMBER_OF_SITES_ON_SERVER-VCS`","title":"Cause"},{"location":"incident_response/site_capacity/#thresholds","text":"Balancers: 1500 (ACP), 250 (ACE) SVN Servers: 950","title":"Thresholds"},{"location":"incident_response/site_capacity/#critical-server-is-full","text":"","title":"CRITICAL: Server is full"},{"location":"incident_response/site_capacity/#svn-servers","text":"As customers come and go the number of sites on an svn server fluctuate. Note that in ACE several customers have dedicated svn servers. Get the numbers of sites on a server for every svn server in the region of the realm: fpdsh -t % -n svn -r $REGION -c \"sudo cat /var/acquia/NUMBER_OF_SITES_ON_SERVER-VCS\" If there are no reasonably free hosts available, provision a new server and move the tags as appropriate for the stage and region in question. ACE SVN server ACP SVN Server","title":"SVN Servers"},{"location":"incident_response/site_capacity/#staging-servers","text":"","title":"Staging Servers"},{"location":"incident_response/site_capacity/#important-note","text":"Do not abort workflows! If you are unable to resolve a problem with a workflow, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership","title":"Important Note"},{"location":"incident_response/site_capacity/#shared-non-ra-staging-servers-automated","text":"Shared Non-RA Staging Servers are handled via workflow automation. ah-stage create-new-shared-servers Inspect the output and pay close attention to workflow_args.body.ec2_region , workflow_args.body.shared_server_tag , and workflow_args.body.shared_server_type . If they are valid (meaning that the region and host type are correct for what is alerting as full), then invoke the workflow with --no-dry-run : ah-stage create-new-shared-servers --no-dry-run Monitor the output of the workflow and provide the full output in the OP ticket.","title":"Shared Non-RA Staging Servers (Automated)"},{"location":"incident_response/site_capacity/#shared-non-ra-staging-servers-manual","text":"ACE/Provision Infra/Shared Staging","title":"Shared Non-RA Staging Servers (Manual)"},{"location":"incident_response/site_capacity/#shared-ra-staging-servers-automated","text":"Shared RA staging servers are handled via workflow automation. ah-stage create-new-shared-servers Inspect the output and pay close attention to workflow_args.body.ec2_region , workflow_args.body.shared_server_tag , and workflow_args.body.shared_server_type . If they are valid (meaning that the region and host type are correct for what is alerting as full), then invoke the workflow with --no-dry-run : ah-stage create-new-shared-servers --no-dry-run Monitor the output of the workflow and provide the full output in the OP ticket.","title":"Shared RA Staging Servers (Automated)"},{"location":"incident_response/site_capacity/#shared-ra-staging-servers-manual","text":"ACE/Provision Infra/Shared RA Staging","title":"Shared RA Staging Servers (Manual)"},{"location":"incident_response/site_capacity/#bal-servers","text":"If tags can be moved back to a less-full balancer (< 75% capacity), we should try that first. Set the below variable to the name of one of the bals that's alerting. SERVER= Execute the below block. SERVER_INFO=($(ah-server list ${SERVER} \\ -c ec2_region ec2_availability_zone vpc_id bal_cluster_id tags --no-name | \\ sed 's/,/ /g')) REGION=${SERVER_INFO[0]} AZ=${SERVER_INFO[1]} VPC_ID=${SERVER_INFO[2]} VPC_NAME=$(ah-vpc list % -w id=${VPC_ID}) BAL_CLUSTER_ID=$(echo ${SERVER_INFO[3]}) TAGS=($(echo ${SERVER_INFO[4]} | sed 's/+/\\n/g' | \\ egrep -v '^shared|ssl_|workflow' | sed 's/\\n/ /g')) SSL_TAG=$(echo ${SERVER_INFO[4]} | sed 's/+/\\n/g' | grep ssl_) AVAILABLE_SERVERS=$(ah-server list tag:${SSL_TAG} \\ -w type=bal vpc_id=${VPC_ID} ec2_region=${REGION} \\ -c tags | grep shared | cut -d, -f1 | paste -sd,) if [[ -z \"${AVAILABLE_SERVERS}\" ]]; then echo \"ERROR: No other shared bals in ${VPC_NAME}. Please allocate a new balancer pair.\"; fi case \"${FIELDS_STAGE}\" in prod ) THRESHOLD=250 ;; devcloud ) THRESHOLD=1500 ;; esac LIMIT=$(expr ${THRESHOLD} / 4 \\* 3) NEW_SERVERS=($(ah-server list ${AVAILABLE_SERVERS} -c site-count \\ | sed 's/,/ /g' | sort -k2 -n \\ | awk -v var=${LIMIT} '{ if ($2 <= var) print $1 }' | head -n2)) NEW_SERVERS_CSV=$(array-csv ${NEW_SERVERS[@]}) BAL_CLUSTER_IDS=($(ah-server list ${NEW_SERVERS_CSV} -c bal_cluster_id --no-name)) if [[ ${BAL_CLUSTER_IDS[0]} -ne ${BAL_CLUSTER_IDS[1]} ]]; then echo \"ERROR: Bal cluster ids do not match\"; echo \"Servers selected: ${NEW_SERVERS_CSV}\"; fi If an error stating no other shared bals are present, skip to the next section If no errors are reported, proceed with moving the requisite tags. ah-server tag add ${NEW_SERVERS[@]} -t ${TAGS[@]} ah-server tag remove $(ah-server list % \\ -w bal_cluster_id=${BAL_CLUSTER_ID} | paste -sd' ') -t ${TAGS[@]} Refresh the mons for the region. fpdsh -t mon -r $REGION -c 'sudo fields-config-mon.php' Refresh the checks for the impacted hosts. for SERVER in $(ah-server list % -w bal_cluster_id=${BAL_CLUSTER_ID}); do sv-servicerecheck ${SERVER} \"Site capacity\"; done Verify that this region has 2 bals, 1 svn, and 1 mon server with the devcloud-shared tag. This will cause a Sev0 if the region does not have these tagged servers! ah-server list tag:devcloud-shared -w ec2_region=${REGION} You should also avoid having more than this quantity of each server type in a region. However, a region can have more than 2 bals depending on which VPC they are serving.","title":"BAL Servers"},{"location":"incident_response/site_capacity/#provision-shared-balancers","text":"Shared bals can be handled via workflow automation. The workflow will automatically transfer the tags and SSL certificates where appropriate. Run the below command to invoke the workflow in \"dry-run\" mode. ah-stage create-new-shared-servers Inspect the output and pay close attention to workflow_args.body.ec2_region , workflow_args.body.shared_server_tag , and workflow_args.body.shared_server_type . If they are valid (meaning that the region and host type are correct for what is alerting as full), then invoke the workflow with --no-dry-run : ah-stage create-new-shared-servers --no-dry-run Monitor the output of the workflow and provide the full output in the OP ticket.","title":"Provision Shared Balancers"},{"location":"incident_response/site_capacity/#unknown-could-not-find-number-of-sites","text":"For a new server you can just wait and the alert will clear once a site is provisioned that uses the new server. Or you can execute a command to force the creation of the file used by the check. Call either sudo fields-config-bal.php on the balancer or sudo fields-config-svn.php on the svn server and the alert will clear on the next run.","title":"UNKNOWN: Could not find number of sites"},{"location":"incident_response/tomcat_memory_check/","text":"Tomcat Memory Check alert Note: To login Search jumpboxes, follow these instructions This alert can be triggered by two scenarios. In the first scenario, the catalina.out log has grown to such a size that the NRPE check can't process it before Nagios times out waiting for a response. This will be indicated by the Last State of the alert being UNKNOWN . The second scenario is when the check finds an OutOfMemoryError in the logs. Response If the Last State is UNKNOWN , manually run the Tomcat OOM check to make sure that we are not experiencing Tomcat OOM's in addition to the log file getting too big. /usr/lib/nagios/plugins/check_tomcat_oom If no OutOfMemoryError 's are detected, proceed to the manually rotating the log section. If OutOfMemoryError 's are detected, we will first need to determine what kind of memory issue the server is experiencing. cd /var/log/sites/$SITENAME/logs/$SERVER grep 'SEVERE.*java.lang.OutOfMemoryError' catalina.out If the error is java.lang.OutOfMemoryError: Java heap space , the server is in need of more memory. Please upsize the server to the next server size (ex. m1.large -> m1.xlarge) and create an AS ticket for the search team to investigate to determine the next steps. In the ticket please provide what the current server memory usage (i.e. free -m) and attach a copy of the current catalina.out log as a tarball to the ticket. Since the logs are on ephemeral storage, a relaunch will delete the logs preventing any further investigation. If the error is java.lang.OutOfMemoryError: PermGen space or you want to check the PermGen usage, please perform the following steps Determine the Tomcat process, you will see two lines output. The line we want is the line that has Bootstrap start . jps -ml Next, display the status of the JVM, substituting PROCESSID= jstat -gcutil -h20 $PROCESSID 1000 If the P (Permgen) column number is high, for example, greater then 90, then the server is running out of Permgen space. By default, we do not configure Permgen space but instead use the default value. However, we can increase the Permgen space as follows. Get the site for the server in question. SERVER= SITE=$(ah-site list on:${SERVER}) Check to see if the Permgen space has already been configured. ah-site list $SITE -c tomcat6_java_opts:JAVA_OPTS If the Permgen space hasn't been configure, then configure it as follows: ah-site edit $SITE -c tomcat6_java_opts:JAVA_OPTS=\"-XX:PermSize=64M -XX:MaxPermSize=128M\" If the site has already been configured, increase the maximum size as the memory usage on the server allows. Finally, to clear the alert, manually rotating the log section. Manually rotating the log file Backup catalina.out SITENAME= SERVER= cd /var/log/sites/$SITENAME/logs/$SERVER cp catalina.out /mnt/tmp/ gzip /mnt/tmp/catalina.out Truncate the log file truncate -s 0 catalina.out Verify the alert is gone /usr/lib/nagios/plugins/check_tomcat_oom","title":"Tomcat Memory Check alert"},{"location":"incident_response/tomcat_memory_check/#tomcat-memory-check-alert","text":"Note: To login Search jumpboxes, follow these instructions This alert can be triggered by two scenarios. In the first scenario, the catalina.out log has grown to such a size that the NRPE check can't process it before Nagios times out waiting for a response. This will be indicated by the Last State of the alert being UNKNOWN . The second scenario is when the check finds an OutOfMemoryError in the logs.","title":"Tomcat Memory Check alert"},{"location":"incident_response/tomcat_memory_check/#response","text":"If the Last State is UNKNOWN , manually run the Tomcat OOM check to make sure that we are not experiencing Tomcat OOM's in addition to the log file getting too big. /usr/lib/nagios/plugins/check_tomcat_oom If no OutOfMemoryError 's are detected, proceed to the manually rotating the log section. If OutOfMemoryError 's are detected, we will first need to determine what kind of memory issue the server is experiencing. cd /var/log/sites/$SITENAME/logs/$SERVER grep 'SEVERE.*java.lang.OutOfMemoryError' catalina.out If the error is java.lang.OutOfMemoryError: Java heap space , the server is in need of more memory. Please upsize the server to the next server size (ex. m1.large -> m1.xlarge) and create an AS ticket for the search team to investigate to determine the next steps. In the ticket please provide what the current server memory usage (i.e. free -m) and attach a copy of the current catalina.out log as a tarball to the ticket. Since the logs are on ephemeral storage, a relaunch will delete the logs preventing any further investigation. If the error is java.lang.OutOfMemoryError: PermGen space or you want to check the PermGen usage, please perform the following steps Determine the Tomcat process, you will see two lines output. The line we want is the line that has Bootstrap start . jps -ml Next, display the status of the JVM, substituting PROCESSID= jstat -gcutil -h20 $PROCESSID 1000 If the P (Permgen) column number is high, for example, greater then 90, then the server is running out of Permgen space. By default, we do not configure Permgen space but instead use the default value. However, we can increase the Permgen space as follows. Get the site for the server in question. SERVER= SITE=$(ah-site list on:${SERVER}) Check to see if the Permgen space has already been configured. ah-site list $SITE -c tomcat6_java_opts:JAVA_OPTS If the Permgen space hasn't been configure, then configure it as follows: ah-site edit $SITE -c tomcat6_java_opts:JAVA_OPTS=\"-XX:PermSize=64M -XX:MaxPermSize=128M\" If the site has already been configured, increase the maximum size as the memory usage on the server allows. Finally, to clear the alert, manually rotating the log section.","title":"Response"},{"location":"incident_response/tomcat_memory_check/#manually-rotating-the-log-file","text":"Backup catalina.out SITENAME= SERVER= cd /var/log/sites/$SITENAME/logs/$SERVER cp catalina.out /mnt/tmp/ gzip /mnt/tmp/catalina.out Truncate the log file truncate -s 0 catalina.out Verify the alert is gone /usr/lib/nagios/plugins/check_tomcat_oom","title":"Manually rotating the log file"},{"location":"incident_response/tomcat_running/","text":"Tomcat Running alert Note: To login Search jumpboxes, follow these instructions This alert means the tomcat service is not running. This can happen for a number of reasons, first, if there are no indexes assigned to this server, Tomcat can't get configured properly. Second, occasionally the server's OOM-killer will kill Tomcat. Finally, Tomcat could have experience and issue and crashed. Response You will first need to determine why Tomcat isn't running. Verify that one or more indexes have been assigned to this server, this can be done on bastion by executing: SERVER= ah-search list $SERVER If the server has no indexes assigned, this usually occurs for one of three reasons, it is a new dedicated farm or two, an existing shared farm has reached its capacity necessitating a new farm be created, or it is a new farm in a new region. Check the Jira ticket that provisioned the farm, if it is a new shared farm due to capacity issues, you should be able to migrate at least one index. If it is a new dedicated farm or a farm in a new region, the only real choice is to wait to the first index is provisioned to the farm, so downtiming the alert for a period of time is probably your best course of action. If the server has indexes assigned to, check the syslog for OOM messages. If Tomcat was OOM-killed, check the current memory usage of the server. If it appears to be okay, you can simply restart Tomcat. However, if this is the third time that Tomcat was OOM-killed within 72 hours, emergency upsize the server to the next larger size (i.e. m1.large -> m1.xlarge). /etc/init.d/tomcat_XXXXXXas.sXXslave restart If Tomcat isn't running because of any other reason, verify that fields-config-web has been run. SERVER= fssh $SERVER \"sudo fields-config-web.php\" If that doesn't resolve the Tomcat not running alert, escalate to search via the documented process in Confluence","title":"Tomcat Running alert"},{"location":"incident_response/tomcat_running/#tomcat-running-alert","text":"Note: To login Search jumpboxes, follow these instructions This alert means the tomcat service is not running. This can happen for a number of reasons, first, if there are no indexes assigned to this server, Tomcat can't get configured properly. Second, occasionally the server's OOM-killer will kill Tomcat. Finally, Tomcat could have experience and issue and crashed.","title":"Tomcat Running alert"},{"location":"incident_response/tomcat_running/#response","text":"You will first need to determine why Tomcat isn't running. Verify that one or more indexes have been assigned to this server, this can be done on bastion by executing: SERVER= ah-search list $SERVER If the server has no indexes assigned, this usually occurs for one of three reasons, it is a new dedicated farm or two, an existing shared farm has reached its capacity necessitating a new farm be created, or it is a new farm in a new region. Check the Jira ticket that provisioned the farm, if it is a new shared farm due to capacity issues, you should be able to migrate at least one index. If it is a new dedicated farm or a farm in a new region, the only real choice is to wait to the first index is provisioned to the farm, so downtiming the alert for a period of time is probably your best course of action. If the server has indexes assigned to, check the syslog for OOM messages. If Tomcat was OOM-killed, check the current memory usage of the server. If it appears to be okay, you can simply restart Tomcat. However, if this is the third time that Tomcat was OOM-killed within 72 hours, emergency upsize the server to the next larger size (i.e. m1.large -> m1.xlarge). /etc/init.d/tomcat_XXXXXXas.sXXslave restart If Tomcat isn't running because of any other reason, verify that fields-config-web has been run. SERVER= fssh $SERVER \"sudo fields-config-web.php\" If that doesn't resolve the Tomcat not running alert, escalate to search via the documented process in Confluence","title":"Response"},{"location":"incident_response/triage_unresponsive_servers/","text":"Triage unresponsive ACE, ACP, ACSF, Network, trex and [WMG/UMG]Gardens servers While on alerts, you may encounter a server that is unresponsive. This may come in the form of a PagerDuty alert which specifies that $SERVER is DOWN or you may have received a Sev 1 JIRA ticket from Support. For example: Description: ** PROBLEM Host Alert: bal-17333.prod is DOWN ** This document outlines the process to triage and resolve an impaired server or instance. NOTE: for auditing purposes it is absolutely crucial to document all resolution steps carried out in a JIRA ticket Initial steps Determine if the server is accessible sv-up $SERVER If you do not receive the uptime of $SERVER , then there is a chance the instance may be impaired or the OS has crashed. On the other hand, should you receive an error message to the equivalent of out of memory , then the server may be running out of available resources. Refer to the Services Check runbook for further information and troubleshooting once the server is available. Determine the instance status from AWS ah-server status $SERVER After running the preceding, you will see one of the following: [cloudservicesdev|hosting-prod:prod] ~/fields/1.95$ ah-server status staging-4404 staging-4404 (i-360c9ae4): running in us-east-1b system_status ok [{:name=>\"reachability\", :status=>\"passed\"}] instance_status ok [{:name=>\"reachability\", :status=>\"passed\"}] In this case, the server can be rebooted . [cloudservicesdev|enterprise-g1:enterprise-g1] ~/fields/1.95$ ah-server status dbmaster-1158 dbmaster-1158 (i-00e65ec45f1207e78): running in us-west-2a system_status impaired [{:name=>\"reachability\", :status=>\"failed\", :impaired_since=>2016-12-09 20:30:00 UTC}] instance_status impaired [{:name=>\"reachability\", :status=>\"failed\", :impaired_since=>2016-12-09 20:30:00 UTC}] [hosting-prod:prod] ~/fields/1.93$ ah-server status backup-9979 backup-9979 (i-9efc2a0d): running in us-east-1c system_status ok [{:name=>\"reachability\", :status=>\"passed\"}] instance_status impaired [{:name=>\"reachability\", :status=>\"failed\", :impaired_since=>2016-09-16 17:22:00 UTC}] [hosting-prod:prod] ~/fields/1.90$ ah-server status dbmaster-18257 dbmaster-18257 (i-6cafe4e4): running in eu-west-1a system_status insufficient-data [{:name=>\"reachability\", :status=>\"insufficient-data\"}] instance_status insufficient-data [{:name=>\"reachability\", :status=>\"insufficient-data\"}] The preceding are all examples of where an instance will need to be relaunched . Rebooting Normally a server can be rebooted with ah-server reboot -i $SERVER and you can monitor the status of the reboot by running sv-up $SERVER . The server is online once you see the output of uptime . Should you observe the reboot taking longer than 5 minutes, then the reboot has most likely failed. This can be resolved by sending the reboot command 5 times as follows: for i in {1..5} ; do ah-server reboot $SERVER -i;done Monitor the progress of the reboot by issuing sv-up $SERVER and waiting for the output of uptime . Clean up Once the $SERVER has come back online, we will need to ensure that the server has come back up cleanly. If $SERVER is a database (ded, dbmaster or fsdb) server: Run ah-db-cluster status $SERVER and resolve replication lag + failover status. Remount gluster with site-fsremount $(ah-site list on:$SERVER|head -1) . Run puppet agent -t OR in Masterless Puppet mode sudo run-puppet to refresh system and application level services. If $SERVER is a Single-tier ded, web, managed or staging : Remount gluster with site-fsremount $(ah-site list on:$SERVER|head -1) . Refresh the site code with fields-config-web.php . Run puppet agent -t OR in Masterless Puppet mode sudo run-puppet to refresh system and application level services. Restart PHP-FPM with site-restartfpm $(ah-site list on:$SERVER|head -1) . Check the rotation status of the affected webs with site-checkwebs $(ah-site list on:$SERVER|head -1) . Verify that all sites hosted on $SERVER are online for site in $(ah-site list on:$SERVER);do echo -ne \"${site}:\\t\" ; site-check ${site} 2>/dev/null | tail -n1;done For all other $SERVER types: Remount gluster with site-fsremount $(ah-site list on:$SERVER|head -1) . Run puppet agent -t OR in Masterless Puppet mode sudo run-puppet to refresh system and application level services.","title":"Triage unresponsive ACE, ACP, ACSF, Network, trex and [WMG/UMG]Gardens servers"},{"location":"incident_response/triage_unresponsive_servers/#triage-unresponsive-ace-acp-acsf-network-trex-and-wmgumggardens-servers","text":"While on alerts, you may encounter a server that is unresponsive. This may come in the form of a PagerDuty alert which specifies that $SERVER is DOWN or you may have received a Sev 1 JIRA ticket from Support. For example: Description: ** PROBLEM Host Alert: bal-17333.prod is DOWN ** This document outlines the process to triage and resolve an impaired server or instance.","title":"Triage unresponsive ACE, ACP, ACSF, Network, trex and [WMG/UMG]Gardens servers"},{"location":"incident_response/triage_unresponsive_servers/#note-for-auditing-purposes-it-is-absolutely-crucial-to-document-all-resolution-steps-carried-out-in-a-jira-ticket","text":"","title":"NOTE: for auditing purposes it is absolutely crucial to document all resolution steps carried out in a JIRA ticket"},{"location":"incident_response/triage_unresponsive_servers/#initial-steps","text":"","title":"Initial steps"},{"location":"incident_response/triage_unresponsive_servers/#determine-if-the-server-is-accessible","text":"sv-up $SERVER If you do not receive the uptime of $SERVER , then there is a chance the instance may be impaired or the OS has crashed. On the other hand, should you receive an error message to the equivalent of out of memory , then the server may be running out of available resources. Refer to the Services Check runbook for further information and troubleshooting once the server is available.","title":"Determine if the server is accessible"},{"location":"incident_response/triage_unresponsive_servers/#determine-the-instance-status-from-aws","text":"ah-server status $SERVER After running the preceding, you will see one of the following: [cloudservicesdev|hosting-prod:prod] ~/fields/1.95$ ah-server status staging-4404 staging-4404 (i-360c9ae4): running in us-east-1b system_status ok [{:name=>\"reachability\", :status=>\"passed\"}] instance_status ok [{:name=>\"reachability\", :status=>\"passed\"}] In this case, the server can be rebooted . [cloudservicesdev|enterprise-g1:enterprise-g1] ~/fields/1.95$ ah-server status dbmaster-1158 dbmaster-1158 (i-00e65ec45f1207e78): running in us-west-2a system_status impaired [{:name=>\"reachability\", :status=>\"failed\", :impaired_since=>2016-12-09 20:30:00 UTC}] instance_status impaired [{:name=>\"reachability\", :status=>\"failed\", :impaired_since=>2016-12-09 20:30:00 UTC}] [hosting-prod:prod] ~/fields/1.93$ ah-server status backup-9979 backup-9979 (i-9efc2a0d): running in us-east-1c system_status ok [{:name=>\"reachability\", :status=>\"passed\"}] instance_status impaired [{:name=>\"reachability\", :status=>\"failed\", :impaired_since=>2016-09-16 17:22:00 UTC}] [hosting-prod:prod] ~/fields/1.90$ ah-server status dbmaster-18257 dbmaster-18257 (i-6cafe4e4): running in eu-west-1a system_status insufficient-data [{:name=>\"reachability\", :status=>\"insufficient-data\"}] instance_status insufficient-data [{:name=>\"reachability\", :status=>\"insufficient-data\"}] The preceding are all examples of where an instance will need to be relaunched .","title":"Determine the instance status from AWS"},{"location":"incident_response/triage_unresponsive_servers/#rebooting","text":"Normally a server can be rebooted with ah-server reboot -i $SERVER and you can monitor the status of the reboot by running sv-up $SERVER . The server is online once you see the output of uptime . Should you observe the reboot taking longer than 5 minutes, then the reboot has most likely failed. This can be resolved by sending the reboot command 5 times as follows: for i in {1..5} ; do ah-server reboot $SERVER -i;done Monitor the progress of the reboot by issuing sv-up $SERVER and waiting for the output of uptime .","title":"Rebooting"},{"location":"incident_response/triage_unresponsive_servers/#clean-up","text":"Once the $SERVER has come back online, we will need to ensure that the server has come back up cleanly. If $SERVER is a database (ded, dbmaster or fsdb) server: Run ah-db-cluster status $SERVER and resolve replication lag + failover status. Remount gluster with site-fsremount $(ah-site list on:$SERVER|head -1) . Run puppet agent -t OR in Masterless Puppet mode sudo run-puppet to refresh system and application level services. If $SERVER is a Single-tier ded, web, managed or staging : Remount gluster with site-fsremount $(ah-site list on:$SERVER|head -1) . Refresh the site code with fields-config-web.php . Run puppet agent -t OR in Masterless Puppet mode sudo run-puppet to refresh system and application level services. Restart PHP-FPM with site-restartfpm $(ah-site list on:$SERVER|head -1) . Check the rotation status of the affected webs with site-checkwebs $(ah-site list on:$SERVER|head -1) . Verify that all sites hosted on $SERVER are online for site in $(ah-site list on:$SERVER);do echo -ne \"${site}:\\t\" ; site-check ${site} 2>/dev/null | tail -n1;done For all other $SERVER types: Remount gluster with site-fsremount $(ah-site list on:$SERVER|head -1) . Run puppet agent -t OR in Masterless Puppet mode sudo run-puppet to refresh system and application level services.","title":"Clean up"},{"location":"incident_response/tungsten_latency/","text":"Tungsten Latency This alert means that tungsten replication is lagging. Resolution Run site-tungstatus $SITE Work through troubleshooting common problems","title":"Tungsten Latency"},{"location":"incident_response/tungsten_latency/#tungsten-latency","text":"This alert means that tungsten replication is lagging.","title":"Tungsten Latency"},{"location":"incident_response/tungsten_latency/#resolution","text":"Run site-tungstatus $SITE Work through troubleshooting common problems","title":"Resolution"},{"location":"incident_response/tungsten_online/","text":"Tungsten Online CRITICAL - tungsten servers not ONLINE - critical: 1 servers not ONLINE Check the status site-tungstatus $(ah-site list on:${SERVER}) Try to resync the database site-tungstenslaveresync $(ah-site list on:${SERVER}) If one of the tungsten servers was recently relaunched, follow this: missing peers Work through troubleshooting common problems","title":"Tungsten Online"},{"location":"incident_response/tungsten_online/#tungsten-online","text":"CRITICAL - tungsten servers not ONLINE - critical: 1 servers not ONLINE Check the status site-tungstatus $(ah-site list on:${SERVER}) Try to resync the database site-tungstenslaveresync $(ah-site list on:${SERVER}) If one of the tungsten servers was recently relaunched, follow this: missing peers Work through troubleshooting common problems","title":"Tungsten Online"},{"location":"incident_response/tungsten_troubleshooting/","text":"Troubleshooting Tungsten Common Problems Offline Symptom - 1/2 remote fsdbmesh's alert to a node/s in the other region as being offline. Diagnosis - trepctl services on the complaining machines will show GOING-ONLINE:SYNCHRONIZING . Resolution - Check out top on the server they are complaining about, you will most likely see stunnel using a lot of cpu. service stunnel4 restart . Tunnel configuration files missing Symptom - Service for a node showing \"GOING-ONLINE:SYNCHRONIZING\" status on all other nodes. Diagnosis - Check for missing peers . Resolution - See missing peers . Error: unexpected seqno Symptom - Diagnosis - Resolution - Split brain Symptom - Error: Statement succeeded on master but failed on slave Diagnosis - Resolution - Run tungsten-slave-resync Seqno -1 & State Is ONLINE Symptom - No error and node online but sequence number is reported as -1 Diagnosis - The replicator service for that node is pointing to a binlog that has been removed or there is an issue with the relay logs. If there is no error in the trepsvc.log restart treplicator - service treplicator restart (this will not affect MySQL) and check the trepsvc.log again for errors. The current binlog entry can be found in the tungsten_${SERVICE} database in mysql in the trep_commit_seqno table. If the binlog file doesn't exit anymore tungsten doesn't know what to do. Resolution - Reset the replicator service for that node. So if node-1 is the local service start there and run: trepctl -service ${SERVICE} unload trepctl -service ${SERVICE} reset trepctl -service ${SERVICE} load Seqno -1 & State Is OFFLINE:ERROR If appliedLastSeqno is -1 and state is OFFLINE:ERROR this is probably a Tungsten bug, but when a server in a cluster is relaunched all the other servers can get confused about the epoch numbers for the relaunched server. As background, the replication position between a master and a slave is communicated using both a sequence number and an epoch number. The epoch number is generated by the master and is the first sequence number that is generated since the last start of Tungsten. So if the service is new and only has one event both the epoch and sequence number will be 1. After the relaunch it seems the other nodes think the epoch number for the relaunched server is 0 which is wrong. trepctl -service fsdbmeshBBBB status will show the following line: pendingExceptionMessage: Client handshake failure: Client response validation failed: Log epoch numbers do not \\ match: client source ID=fsdbmesh-6457 seqno=2959985 server epoch number=2959958 client epoch number=0 Determine the correct epoch number for the master service on the relaunched server. For this example the relaunched server is fsdbmesh-BBBB , the seqno in the error message is nnnnn and the epoch number is eeeee : root@fsdbmesh-BBBB.prod:~# thl -service fsdbmeshBBBB list -seqno nnnnn SEQ# = nnnnn / FRAG# = 0 (last frag) - TIME = 2014-09-09 15:32:36.0 - EPOCH# = eeeee Perform the following actions on each of the nodes that are showing this error (fsdbmesh-AAAA, fsdbmesh-CCCC and fsdbmesh-DDDD): trepctl -service fsdbmeshBBBB unload -y thl -service fsdbmeshBBBB purge -y mysql -e \"update tungsten_fsdbmeshBBBB.trep_commit_seqno set epoch_number=eeeee\" trepctl -service fsdbmeshBBBB load","title":"Troubleshooting Tungsten"},{"location":"incident_response/tungsten_troubleshooting/#troubleshooting-tungsten","text":"","title":"Troubleshooting Tungsten"},{"location":"incident_response/tungsten_troubleshooting/#common-problems","text":"","title":"Common Problems"},{"location":"incident_response/tungsten_troubleshooting/#offline","text":"Symptom - 1/2 remote fsdbmesh's alert to a node/s in the other region as being offline. Diagnosis - trepctl services on the complaining machines will show GOING-ONLINE:SYNCHRONIZING . Resolution - Check out top on the server they are complaining about, you will most likely see stunnel using a lot of cpu. service stunnel4 restart .","title":"Offline"},{"location":"incident_response/tungsten_troubleshooting/#tunnel-configuration-files-missing","text":"Symptom - Service for a node showing \"GOING-ONLINE:SYNCHRONIZING\" status on all other nodes. Diagnosis - Check for missing peers . Resolution - See missing peers .","title":"Tunnel configuration files missing"},{"location":"incident_response/tungsten_troubleshooting/#error-unexpected-seqno","text":"Symptom - Diagnosis - Resolution -","title":"Error: unexpected seqno"},{"location":"incident_response/tungsten_troubleshooting/#split-brain","text":"Symptom - Error: Statement succeeded on master but failed on slave Diagnosis - Resolution - Run tungsten-slave-resync","title":"Split brain"},{"location":"incident_response/tungsten_troubleshooting/#seqno-1-state-is-online","text":"Symptom - No error and node online but sequence number is reported as -1 Diagnosis - The replicator service for that node is pointing to a binlog that has been removed or there is an issue with the relay logs. If there is no error in the trepsvc.log restart treplicator - service treplicator restart (this will not affect MySQL) and check the trepsvc.log again for errors. The current binlog entry can be found in the tungsten_${SERVICE} database in mysql in the trep_commit_seqno table. If the binlog file doesn't exit anymore tungsten doesn't know what to do. Resolution - Reset the replicator service for that node. So if node-1 is the local service start there and run: trepctl -service ${SERVICE} unload trepctl -service ${SERVICE} reset trepctl -service ${SERVICE} load","title":"Seqno -1 &amp; State Is ONLINE"},{"location":"incident_response/tungsten_troubleshooting/#seqno-1-state-is-offlineerror","text":"If appliedLastSeqno is -1 and state is OFFLINE:ERROR this is probably a Tungsten bug, but when a server in a cluster is relaunched all the other servers can get confused about the epoch numbers for the relaunched server. As background, the replication position between a master and a slave is communicated using both a sequence number and an epoch number. The epoch number is generated by the master and is the first sequence number that is generated since the last start of Tungsten. So if the service is new and only has one event both the epoch and sequence number will be 1. After the relaunch it seems the other nodes think the epoch number for the relaunched server is 0 which is wrong. trepctl -service fsdbmeshBBBB status will show the following line: pendingExceptionMessage: Client handshake failure: Client response validation failed: Log epoch numbers do not \\ match: client source ID=fsdbmesh-6457 seqno=2959985 server epoch number=2959958 client epoch number=0 Determine the correct epoch number for the master service on the relaunched server. For this example the relaunched server is fsdbmesh-BBBB , the seqno in the error message is nnnnn and the epoch number is eeeee : root@fsdbmesh-BBBB.prod:~# thl -service fsdbmeshBBBB list -seqno nnnnn SEQ# = nnnnn / FRAG# = 0 (last frag) - TIME = 2014-09-09 15:32:36.0 - EPOCH# = eeeee Perform the following actions on each of the nodes that are showing this error (fsdbmesh-AAAA, fsdbmesh-CCCC and fsdbmesh-DDDD): trepctl -service fsdbmeshBBBB unload -y thl -service fsdbmeshBBBB purge -y mysql -e \"update tungsten_fsdbmeshBBBB.trep_commit_seqno set epoch_number=eeeee\" trepctl -service fsdbmeshBBBB load","title":"Seqno -1 &amp; State Is OFFLINE:ERROR"},{"location":"incident_response/unmonitored_sites_check/","text":"Unmonitored Site Check alert This alert only applies in ACP and Site Factory The alert indicates that the site was removed from monitoring Resolution Search for an existing Jira ticket where it was removed from monitoring Add the site back to monitoring site-monenable $SITES","title":"Unmonitored Site Check alert"},{"location":"incident_response/unmonitored_sites_check/#unmonitored-site-check-alert","text":"This alert only applies in ACP and Site Factory The alert indicates that the site was removed from monitoring","title":"Unmonitored Site Check alert"},{"location":"incident_response/unmonitored_sites_check/#resolution","text":"Search for an existing Jira ticket where it was removed from monitoring Add the site back to monitoring site-monenable $SITES","title":"Resolution"},{"location":"incident_response/varnish_http/","text":"Check Varnish HTTP This alert means varnish is not responding Resolution If this is the primary bal then fail the EIP to the other bal Check syslog for varnish errors or out of memory errors Restart varnish service varnish restart Verify varnish is responding /usr/lib/nagios/plugins/check_http -I 127.0.0.1 -u /elb-health-check -c 3","title":"Check Varnish HTTP"},{"location":"incident_response/varnish_http/#check-varnish-http","text":"This alert means varnish is not responding","title":"Check Varnish HTTP"},{"location":"incident_response/varnish_http/#resolution","text":"If this is the primary bal then fail the EIP to the other bal Check syslog for varnish errors or out of memory errors Restart varnish service varnish restart Verify varnish is responding /usr/lib/nagios/plugins/check_http -I 127.0.0.1 -u /elb-health-check -c 3","title":"Resolution"},{"location":"incident_response/vpn_connection/","text":"VPN Connection The server is not connected to its VPN. This alert is only affects servers using the old VNS vpn servers. Resolution If the server was relaunched recently and the client pack was not installed then you need to follow these instructions to setup the vpn.","title":"VPN Connection"},{"location":"incident_response/vpn_connection/#vpn-connection","text":"The server is not connected to its VPN. This alert is only affects servers using the old VNS vpn servers.","title":"VPN Connection"},{"location":"incident_response/vpn_connection/#resolution","text":"If the server was relaunched recently and the client pack was not installed then you need to follow these instructions to setup the vpn.","title":"Resolution"},{"location":"incident_response/vpn_mon/","text":"Name of Alert This alert checks that both tunnels for a given VPC VPN are up. They can go down for a number of reasons that are all unactionable for Operations. This check needs to come out of the platform. Until CL-14336 is actioned downtime the service. Resolution To downtime the service you'll need to get the VPC name and VPN name from the alert's service description. The description is in the format VPC_NAME . VPN_NAME . So if the service description is bstoutenburghvpc1.vpn2 the VPC name is bstotuenburghvpc1 and the VPN name is vpn2 . VPC_NAME= VPN_NAME= vpn-mondowntime ${VPC_NAME} ${VPN_NAME} 525600 \"Unactionable, CL-14336\"","title":"Name of Alert"},{"location":"incident_response/vpn_mon/#name-of-alert","text":"This alert checks that both tunnels for a given VPC VPN are up. They can go down for a number of reasons that are all unactionable for Operations. This check needs to come out of the platform. Until CL-14336 is actioned downtime the service.","title":"Name of Alert"},{"location":"incident_response/vpn_mon/#resolution","text":"To downtime the service you'll need to get the VPC name and VPN name from the alert's service description. The description is in the format VPC_NAME . VPN_NAME . So if the service description is bstoutenburghvpc1.vpn2 the VPC name is bstotuenburghvpc1 and the VPN name is vpn2 . VPC_NAME= VPN_NAME= vpn-mondowntime ${VPC_NAME} ${VPN_NAME} 525600 \"Unactionable, CL-14336\"","title":"Resolution"},{"location":"incident_response/web_audit/","text":"Web Audit This alert is an audit to find webs that are: Assigned to a site Not in rotation (inactive) on that site Monitoring is enabled Resolution Review status Ensure monitoring_status is 2 (monitored) and web_service_status is 1 (not in rotation). Example: $ WEBS=\"web-xxx web-yyy web-zzz\" $ ah-server list ${WEBS[@]} -c monitoring_status web_service_status web-xxx, 2, 1 web-yyy, 2, 1 web-zzz, 2, 1 It is okay for a web to be launched ( status=0 ) and inactive ( web_service_status=1 ) on a site. Check to see what sites are impacted: $ SITES=$(for i in ${WEBS}; do ah-site list on:$i;done | sort -u | \\ paste -sd\" \"); echo $SITES The most common reason for this alert is work in a recent planned or unplanned JIRA ticket. Search recent JIRA and Chat activity Search recent JIRA tickets for activity relating to the webs and/or sites that are alerting. Review recent chat in the Operations, Ops-Team, and Outage rooms. If you are unable to determine the intended state of the web through either method, use your best judgment or escalate to another Ops team member for help. Enabling/Disabling the host Announce your intended changes in the Operations chat room. @OpsBot alerts who - web-xxx placing back into rotation on $SITE @OpsBot alerts who - setting web-xxx inactive on $SITE To place a host into rotation: sv-webenable $WEB To set a web to inactive: ah-site list on:$WEB ./fields-provision.php --site-set-web $SITE:inactive -webs $WEB | head -n 1","title":"Web Audit"},{"location":"incident_response/web_audit/#web-audit","text":"This alert is an audit to find webs that are: Assigned to a site Not in rotation (inactive) on that site Monitoring is enabled","title":"Web Audit"},{"location":"incident_response/web_audit/#resolution","text":"","title":"Resolution"},{"location":"incident_response/web_audit/#review-status","text":"Ensure monitoring_status is 2 (monitored) and web_service_status is 1 (not in rotation). Example: $ WEBS=\"web-xxx web-yyy web-zzz\" $ ah-server list ${WEBS[@]} -c monitoring_status web_service_status web-xxx, 2, 1 web-yyy, 2, 1 web-zzz, 2, 1 It is okay for a web to be launched ( status=0 ) and inactive ( web_service_status=1 ) on a site. Check to see what sites are impacted: $ SITES=$(for i in ${WEBS}; do ah-site list on:$i;done | sort -u | \\ paste -sd\" \"); echo $SITES The most common reason for this alert is work in a recent planned or unplanned JIRA ticket.","title":"Review status"},{"location":"incident_response/web_audit/#search-recent-jira-and-chat-activity","text":"Search recent JIRA tickets for activity relating to the webs and/or sites that are alerting. Review recent chat in the Operations, Ops-Team, and Outage rooms. If you are unable to determine the intended state of the web through either method, use your best judgment or escalate to another Ops team member for help.","title":"Search recent JIRA and Chat activity"},{"location":"incident_response/web_audit/#enablingdisabling-the-host","text":"Announce your intended changes in the Operations chat room. @OpsBot alerts who - web-xxx placing back into rotation on $SITE @OpsBot alerts who - setting web-xxx inactive on $SITE To place a host into rotation: sv-webenable $WEB To set a web to inactive: ah-site list on:$WEB ./fields-provision.php --site-set-web $SITE:inactive -webs $WEB | head -n 1","title":"Enabling/Disabling the host"},{"location":"incident_response/host_alert/fsdbmesh/","text":"fsdbmesh These are a trap! Server Region DB Cluster fsdbmesh-8806 active primary fsdbmesh-8807 active secondary fsdbmesh-8808 passive primary fsdbmesh-8809 passive secondary Is there a site down alert? Which region is the server in (active or passive)? Is the server the primary or secondary DB? Ticket creation priority: If there is a site down alert create a ticket for the site. If the server is in the active region: 11. [Investigating] High availability impaired for your production site If the server is in the passive region: 12. [No Action Required] Acquia has detected an interruption in serv... Action If the server is a primary, ensure that the db failover has occurred: ah-db-cluster status $SERVER Manually failover if it hasn't (using information from the previous command): dns-update cluster-$CLUSTER_ID $SECONDARY Handle getting the server back online. Relaunching and diagnosing host impairment is beyond the scope of this document. Please escalate for assistance if you need assistance handling this part. Clean up Tungsten is a fragile technology that works via magic involving stunnels between all hosts, some fields fairy dust and a steaming load of Java. SITE= Reconfigure all mesh servers for the site: fpdsh -t site:$SITE -n fsdbmesh \\ -c \"sudo su -c 'ah-config-hosts \\ && ah-config-iptables \\ && fields-config-tungsten-peers.php \\ && service stunnel4 restart'\" Verify treplication status: site-tungstatus $SITE Work through the troubleshooting common problems .","title":"fsdbmesh"},{"location":"incident_response/host_alert/fsdbmesh/#fsdbmesh","text":"These are a trap! Server Region DB Cluster fsdbmesh-8806 active primary fsdbmesh-8807 active secondary fsdbmesh-8808 passive primary fsdbmesh-8809 passive secondary Is there a site down alert? Which region is the server in (active or passive)? Is the server the primary or secondary DB? Ticket creation priority: If there is a site down alert create a ticket for the site. If the server is in the active region: 11. [Investigating] High availability impaired for your production site If the server is in the passive region: 12. [No Action Required] Acquia has detected an interruption in serv...","title":"fsdbmesh"},{"location":"incident_response/host_alert/fsdbmesh/#action","text":"If the server is a primary, ensure that the db failover has occurred: ah-db-cluster status $SERVER Manually failover if it hasn't (using information from the previous command): dns-update cluster-$CLUSTER_ID $SECONDARY Handle getting the server back online. Relaunching and diagnosing host impairment is beyond the scope of this document. Please escalate for assistance if you need assistance handling this part.","title":"Action"},{"location":"incident_response/host_alert/fsdbmesh/#clean-up","text":"Tungsten is a fragile technology that works via magic involving stunnels between all hosts, some fields fairy dust and a steaming load of Java. SITE= Reconfigure all mesh servers for the site: fpdsh -t site:$SITE -n fsdbmesh \\ -c \"sudo su -c 'ah-config-hosts \\ && ah-config-iptables \\ && fields-config-tungsten-peers.php \\ && service stunnel4 restart'\" Verify treplication status: site-tungstatus $SITE Work through the troubleshooting common problems .","title":"Clean up"},{"location":"incident_response/host_alert/master/","text":"Master Down A downed or in any way impaired master is a Sev0. The follow steps must be actioned in order. Escalate to a Tier 2 Operations member immediately. Create a critical ticket: $ ticket crit Single Customer or Multiple Customers? 1. Single Site 2. Multiple Sites Problem Type: 2 Ticket Subject: master.prod is down Leave a brief comment and send it. In the Support chat room, do what ever is needed to raise a person to get the Sev0 train rolling. Alert the on-call Ops Manager: Navigate to pagerduty Click the Manually open a new incident button in the top right-hand corner Select notify-ops-management and compose a brief, but appropriate message. A master outage impacts: All task based things Automated code deploys (customer facing) Disaster Recovery volume backups Server re/launching Tooling: ops-misc environment setup functions (aprod, adevcloud, etc.). Those functions have a failure mode, but they will retry connecting to the master several times before continuing. ah-tools ./fields-provision.php AHT (support) A master outage does not: Impair currently running sites Triage We need to minimise the impact of the master being unavailable. Task and backup servers must have some key services stopped to avoid greater customer impact. Clean up will be required, but that will be handled later. These are the currently running backup servers for each Realm. Multiple servers are listed for redundancy. Realm Servers network backup-2 prod backup-30, backup-1264, backup-5786, backup-7917 devcloud backup-2, backup-944, backup-4113, backup-4115 search backup-4 gardens backup-43, backup-251 enterpriseg1 backup-123, backup-124 wmgegardens backup-9 umgegardens backup-2, backup-35 Set a variable. You only need to choose a single backup server from the table above: BACKUP_SERVER= Disable puppet and stop the task service on task and backup servers: Find all task and backup servers: TASK_SERVERS=$(fssh ${BACKUP_SERVER} grep task /etc/hosts \\ | awk '{print $3}' \\ | paste -sd,) BACKUP_SERVERS=$(fssh ${BACKUP_SERVER} grep backup /etc/hosts \\ | awk '{print $3}' \\ | paste -sd,) Iterate through the lists and disable services. fpdsh -l ${TASK_SERVERS} \\ -c \"sudo puppet agent --disable 'master is down' \\ && sudo crontab -r \\ && sudo service ah-task-server stop\" fpdsh -l ${BACKUP_SERVERS} \\ -c \"sudo puppet agent --disable 'master is down' \\ && sudo crontab -r\" Find the master The Master doesn't have a presence in the fields_master DB. Get the ip address MASTER_IP=$(host master.e.${FIELDS_STAGE}.f.e2a.us \\ | grep -Po '\\d+\\.\\d+\\.\\d+\\.\\d+$') Find the instance id: MASTER_INSTANCE_ID=$(aws ec2 describe-instances \\ --region=us-east-1 \\ --filters \"Name=ip-address,Values=${MASTER_IP}\" \\ --query 'Reservations[*].Instances[*].{InstanceId:InstanceId}' \\ --output text) Reboot / Relaunch The decision to reboot or relaunch depends on the state of the master. A relaunch should only ever be performed if the steps to reboot successively fail, or the instance itself is impaired: aws ec2 describe-instance-status \\ --region=us-east-1 \\ --instance-id=${MASTER_INSTANCE_ID} Reboot a master Relaunch a master Nagstamon If the master is currently down, you will be seeing a lot of alerts. Add this filter to Nagstamon to remove unwanted noise: Nagstamon: Settings -> Filters -> Regular expression for status informations .ah-admin-users.|.puppet-agent.|.ah-post-commit.","title":"Master Down"},{"location":"incident_response/host_alert/master/#master-down","text":"A downed or in any way impaired master is a Sev0. The follow steps must be actioned in order. Escalate to a Tier 2 Operations member immediately. Create a critical ticket: $ ticket crit Single Customer or Multiple Customers? 1. Single Site 2. Multiple Sites Problem Type: 2 Ticket Subject: master.prod is down Leave a brief comment and send it. In the Support chat room, do what ever is needed to raise a person to get the Sev0 train rolling. Alert the on-call Ops Manager: Navigate to pagerduty Click the Manually open a new incident button in the top right-hand corner Select notify-ops-management and compose a brief, but appropriate message. A master outage impacts: All task based things Automated code deploys (customer facing) Disaster Recovery volume backups Server re/launching Tooling: ops-misc environment setup functions (aprod, adevcloud, etc.). Those functions have a failure mode, but they will retry connecting to the master several times before continuing. ah-tools ./fields-provision.php AHT (support) A master outage does not: Impair currently running sites","title":"Master Down"},{"location":"incident_response/host_alert/master/#triage","text":"We need to minimise the impact of the master being unavailable. Task and backup servers must have some key services stopped to avoid greater customer impact. Clean up will be required, but that will be handled later. These are the currently running backup servers for each Realm. Multiple servers are listed for redundancy. Realm Servers network backup-2 prod backup-30, backup-1264, backup-5786, backup-7917 devcloud backup-2, backup-944, backup-4113, backup-4115 search backup-4 gardens backup-43, backup-251 enterpriseg1 backup-123, backup-124 wmgegardens backup-9 umgegardens backup-2, backup-35 Set a variable. You only need to choose a single backup server from the table above: BACKUP_SERVER= Disable puppet and stop the task service on task and backup servers: Find all task and backup servers: TASK_SERVERS=$(fssh ${BACKUP_SERVER} grep task /etc/hosts \\ | awk '{print $3}' \\ | paste -sd,) BACKUP_SERVERS=$(fssh ${BACKUP_SERVER} grep backup /etc/hosts \\ | awk '{print $3}' \\ | paste -sd,) Iterate through the lists and disable services. fpdsh -l ${TASK_SERVERS} \\ -c \"sudo puppet agent --disable 'master is down' \\ && sudo crontab -r \\ && sudo service ah-task-server stop\" fpdsh -l ${BACKUP_SERVERS} \\ -c \"sudo puppet agent --disable 'master is down' \\ && sudo crontab -r\"","title":"Triage"},{"location":"incident_response/host_alert/master/#find-the-master","text":"The Master doesn't have a presence in the fields_master DB. Get the ip address MASTER_IP=$(host master.e.${FIELDS_STAGE}.f.e2a.us \\ | grep -Po '\\d+\\.\\d+\\.\\d+\\.\\d+$') Find the instance id: MASTER_INSTANCE_ID=$(aws ec2 describe-instances \\ --region=us-east-1 \\ --filters \"Name=ip-address,Values=${MASTER_IP}\" \\ --query 'Reservations[*].Instances[*].{InstanceId:InstanceId}' \\ --output text)","title":"Find the master"},{"location":"incident_response/host_alert/master/#reboot-relaunch","text":"The decision to reboot or relaunch depends on the state of the master. A relaunch should only ever be performed if the steps to reboot successively fail, or the instance itself is impaired: aws ec2 describe-instance-status \\ --region=us-east-1 \\ --instance-id=${MASTER_INSTANCE_ID} Reboot a master Relaunch a master","title":"Reboot / Relaunch"},{"location":"incident_response/host_alert/master/#nagstamon","text":"If the master is currently down, you will be seeing a lot of alerts. Add this filter to Nagstamon to remove unwanted noise: Nagstamon: Settings -> Filters -> Regular expression for status informations .ah-admin-users.|.puppet-agent.|.ah-post-commit.","title":"Nagstamon"},{"location":"kanban_tickets/","text":"Kanban Tickets Bastion servers are privileged jump hosts from which people can connect to fields infrastructure. Access is restricted with two-factor authentication and the EIPs of all three bastions are white listed in all regions for all accounts. Production Bastions: bastion-21.network.hosting.acquia.com (us-east-1) bastion-22.network.hosting.acquia.com (eu-west-1) bastion-133.network.hosting.acquia.com (ap-southeast-2) Topic Summary Kanban Tickets Topics Bastion Database Gluster Dedicated Balancers Instance Deprovision Instance Management Instance Provision Ops Procedures Search Site Deprovision Site Management Site Provision SSL Tier Conversion VPC Index 1.81 Hosting Release 1.81 Hosting Release Procedure Optional steps Disabling the puppet agent Re-enabling the puppet agent Verification Acquiamail Acquiamail.acquia.com Dump Restore Overview Procedure ACSF Deprovision Site Factory Sitegroup Deprovisioning Preparation Usage Examples and Useful Some-Liners Usage of acsf-sitegroupterminate List sitegroups List sites List servers List sites on servers Deprovisioning Suspension Termination Add Custom Proxy Config Add a custom Mod-Proxy file to a Site Enabling mod_proxy Step Ticket Requirements Testing on a dedicated staging Review Deploy once the change has been hotfixed Done Add Remove Site Monitoring Add/Remove Sites to/from Monitoring Monitoring Sites - ACE Add ACE site to monitoring Remove ACE site from monitoring Monitoring URLs - Site Factory Add ACSF site to monitoring Remove ACSF site from monitoring Monitoring Sites - ACP & Network Add site to monitoring Remove site from monitoring Add/Remove Webs From Rotation Add/Remove Webs From Rotation Overview Web Rotation Status Web Service Status Pre-Flight Checks Procedures Disabling/Removing Disabling Web Service for single OR multiple hosts Disabling Web Rotation on a single host, single site Disabling Web Rotation on multiple hosts, single site Enabling/Adding Enabling Web Service for single OR multiple hosts Enabling Web Rotation on a single host, single site Enabling Web Rotation on multiple hosts, single site Add User Bastion Provisioning Gather Required Information Approval Choosing a Username Granting Access to Bastion Provisioning a user EXAMPLE: Bastion ONLY EXAMPLE: ACE,ACP production access Confirm that User Can Log In Test Log-in AH Rabot Modify the list of bastion users that can sudo ahrabot Arbitrary php.ini Settings Arbitrary php.ini settings Changing php.ini settings Adding or changing arbitrary directives Removing arbitrary directives Bastion Access Bastion Access User Changes Updating a user's SSH key Changing a user's group Adding a user to an additional stage Bastion Troubleshooting Troubleshooting When a User Just Can't Log In When a User Gets Locked Out after successful previous logins Bulk Site Move Bulk Site Move Preparation Procedure Variables Home directory copy commands Important Note Site Move Verification Post Steps Bulk Site PHP Edits Bulk Site PHP Edits Preparation Procedure Verification Capacity Limit Edge Cluster Capacity limit Capacity Limit Reached for Non-RA Environments Capacity Limit Reached for RA Environments change_balancers_on_existing_environment Change balancers on existing environment Information ELB Configuration VPC Placement SSL Requirements Tag Validation and Migration Custom VCL Requirements Procedures Change DB Password Site Database Password Change Changing Credentials ClamAV ClamAV Daemon Enabling Tunables Disabling Code Checkout Failures Code Checkout Failures Incorrect VCS path Clean checkout Configuring HSD for Sites HSD (Higher Site Density) To check if hsd is enabled for particular site To enable hsd To disable hsd Core Dumps Enable Coredumps for Capturing PHP Segfaults Managing Coredumps Enabling Disabling Coredump Analysis Preparing Analysing Interpreting A Sample Backtrace Create a Test Balancer Create a test balancer Preparation Procedure Operation Extend the duration of a test balancer before its deprovision Verify if a site has test balancers Monitoring Known bugs Custom Tungsten Settings Custom Tungsten Settings Configure-service Static Configuration Files Replication Filter Dedicated To Dedicated Bals Dedicated To Dedicated Hardware Allocation Pre-Assignment Assigning Balancers Post-Assignment Dedicated to Shared Bals Dedicated to Shared Pre-work Assign Balancers Post-Assignment Shared to Dedicated Bals Shared to Dedicated Hardware Allocation Pre-Assignment Assigning Balancers Post-Assignment Shared to Shared Bals Shared to Shared Pre-work Assigning Balancers Post-Assignment Dedicated Hypervisor Set servers to be dedicated instances Preparation Procedure Verification Dedicated Memcache Dedicated Memcache About Dedicated Memcache What site-setmemcache does Procedure Memcache Service Status Deploy Certificate Deploying an SSL / TLS certificate to a balancer cluster Table of Contents Determine balancers and tag Prepare Certificate chain Private key Certificates management Adding a new certificate (Both Edge Cluster and Legacy) Deploy a certificate override (Edge cluster) Deploy a certificate override (Legacy balancer) Remove a certificate override and set to default Acquia certificates (Edge cluster) Remove a certificate override and set to default Acquia certificates (Legacy balancer) Setting a default certificate (This is for entire realm) Verify Deploy Test VCL Deploy custom VCL for customer testing Deprovision Search Colony Deprovision a Search Colony Prerequisites Procedure Deprovision Search Farm Deprovision a Search Farm Prerequisites Procedures Deprovisioning ACE and ACP Deprovisioning ACE & ACP Preparation Caveats Deprovisioning a specific site stage Deprovisioning a sitegroup Deprovisioning A Note About ACP Suspension Termination Bulk site/environment Termination Seprovisioning Mail Server Deprovisoning a mail server Remove from monitoring and puppet manifest Removing DNS entries for the mail server Terminating server from Rackspace Diagnostics * [Certificate Files](./diagnostics.md#certificate-files) * [Compare Cert and Key](./diagnostics.md#compare-cert-and-key) * [Compare CSR and Key](./diagnostics.md#compare-csr-and-key) * [View Certificate Information](./diagnostics.md#view-certificate-information) * [Get notBefore/notAfter (Expiration) date](./diagnostics.md#get-notbeforenotafter-expiration-date) * [Services over SSL](./diagnostics.md#services-over-ssl) * [Verify Certificate Chain](./diagnostics.md#verify-certificate-chain) * [Asynchronous Keys](./diagnostics.md#asynchronous-keys) * [Get public key from private key](./diagnostics.md#get-public-key-from-private-key) Disable TLS Version Disable TLS versions Check for Shared balancers Disable TLSv1.0 only Disable TLSv1.1 Disable TLSv1.1 in Edge Clusters Duplicate Certificates Duplicate Certificates Important Note How to Duplicate a Certificate Edge Cluster Edge Cluster Available commands Describe available commands or one specific command Create a new Edge Cluster Delete an Edge Cluster Relaunching bals in an Edge Cluster Note View details of an existing Edge Cluster View a list of Edge Clusters on the current realm Add an environment to an existing Edge Cluster Remove an environment from an existing Edge Cluster Increase an Edge Cluster capacity by doubling its number of servers. Cannot scale more than once Important Apply a tag to an Edge Cluster Remove a tag from an Edge Cluster Migrations Manual migration of a customer from a legacy bal pair to an Edge Cluster Manual migration of a customer from an Edge Cluster to a Legacy Balancers Handling Legacy to Edge migrations for customers with ELB ELB Creation ELB Creation Initialize Variables For Customers For Whom We Have The Cert and Key For Customers For Whom We Do Not Have The Cert and Key Email Blacklist Acquia Email Server Blacklist Removal An example of a host being \"listed\" List of mail servers according to realm Investigation A word of caution Resolution Enabling mod_proxy Enabling Mod-Proxy on a Site Required Information Procedure Documentation Custom proxy.conf file Enabling Xdebug Enabling xdebug for a Site Required Information Procedure Enabling Xdebug Enabling Xdebug Remote Documentation Extended Validation Certificates Extended Validation Certificates Fix Livedev Fixing/Enabling livedev Identify the error Remediation Generating CSRs Generating a Certificate Signing Request (CSR) Subject SSL Plus/EV CSR Generation Procedure Wildcard Plus CSR Generation UCC/EV Multi-Domain CSR Generation Using an existing key for UCC CSR Generation UCC CSR Generation Example Gluster Downgrade Downgrade Gluster Version from 3.4 to 3.0 THIS PROCESS SHOULD BE USED ONLY ON GLUSTER 3.4 SERVERS Initial Variables Info Gathering Provision new FS servers and fix volumes Allocate new FS servers Add brick volumes Configure FS servers for gluster 3.0 Allocate FS cluster Fix backup vol on secondary server to 1gb Fix ebs1 volumes on both servers to 1gb Launch FS Servers Filesystem Data Transfer Create Temporary SSH key rsync from source server to destination server Web servers cutover Take webs out of rotation Re-run rysnc Disable Puppet and cron on webs Stop gluster and Unmount gluster Add webs to New FS cluster Relaunch suspended webs Remount gluster on webs check gluster for site Put webs back into rotation Restart PHP, Run FCW on webs Verification Cleanup Gluster Upgrade Upgrade Gluster Version from 3.0 to 3.4 THIS PROCESS SHOULD BE USED ONLY ON GLUSTER 3.0 SERVERS Initial Variables Info Gathering Provision new FS servers and fix volumes Allocate new FS servers Add brick volumes Configure FS servers for gluster 3.4 Allocate FS cluster Fix backup vol on secondary server to 1gb Fix ebs1 volumes on both servers to 1gb Launch FS Servers Filesystem Data Transfer Create Temporary SSH key rsync from source server to destination server Web servers cutover Take webs out of rotation Re-run rysnc Disable Puppet and cron on webs Stop gluster and Unmount gluster Add webs to New FS cluster Relaunch suspended webs Remount gluster on webs check gluster for site Put webs back into rotation Restart PHP, Run FCW on webs Verification Cleanup Loadtest Balancer Load Test Balancer Adding a Load Test Balancer Find a Valid Load Test Balancer Add the balancer Check the ELB Removing a Load Test Balancer Logforward Log Forwarding Log Forwarding through Ops Portal Manually Enabling Log Forwarding Requirements Enable ACE ACSF Verify ACE ACSF Disable ACE ACSF Restarting Log forwarding for Sumo Logic Follow these steps when logs forwarding breaks down for customer Diagnose log forwarding for Sumo Logic Follow these steps when logs are not being forwarded to Sumo Logic Troubleshooting td-agent and New Log Forwarding issues Manage End-to-end Encryption Manage End To End Encryption Preparation Preparation: Get sitegroup, site names and servers Enable E2E Encryption Checking the E2E Installation Disable E2E Encryption Rotate E2E Encryption Keys Verifying the e2e configuration Masterless Puppet Masterless Puppet How to tell if a Server is Masterless Move Customer Repo Move Provisioning Pointer Moving the Index Provisioning Pointer Information Multi-region Failover Testing Performing a Multi-Region Failover Test Pre-Flight Set up some Variables Validate and Document that the Site is Healthy Prior to Initiating the Failover Simulate a Region Outage, at this time the TAM should instruct the customer to fail over DNS to their Secondary Region Initiate the Multi-Region Failover to the Secondary Region Begin the Multi-Region Fail-back to the Primary Region Perform Health Checks and Document the Output in the ticket Multi-tier to Full-tier Multi-tier to Full-tier Upsize Prep Maintenance Window Site Move Procedure Cleanup Multi-tier to Single-tier Multi-tier to Single-tier Downsize Traps Important Note Set Variables Gather information Verify Server Settings Add DED SERVERS back to Site/s Check Replication Manage EIPs Move EIP Clean Up End Mysql Daily Replication Fix * [Daily Automated replication fix](./mysql-daily-replication-fix.md#daily-automated-replication-fix) * [Manually finding list of servers](./mysql-daily-replication-fix.md#manually-finding-list-of-servers) * [Attempting to fix the clusters](./mysql-daily-replication-fix.md#attempting-to-fix-the-clusters) Mysql Audit Enabling or Disabling MySQL Auditing Enabling MySQL Auditing Disabling MySQL Auditing Orphans Instances * [Preparation](./orphans.md#preparation) * [Procedure](./orphans.md#procedure) * [Determine the orphan instance status](./orphans.md#determine-the-orphan-instance-status) * [Determine when the server was launched](./orphans.md#determine-when-the-server-was-launched) * [Devcloud](./orphans.md#devcloud) * [All Other Environments](./orphans.md#all-other-environments) * [If the orphan instance report is not showing a server name](./orphans.md#if-the-orphan-instance-report-is-not-showing-a-server-name) * [Removing orphans nodes](./orphans.md#removing-orphans-nodes) SSL Overview SSL Overview Important Note Customer-facing Documentation on docs.ccquia.com Technical details of how SSL/TLS cert chains work Ordering SSL Certificates Pre-flight Check WHOIS Types of Actions Trial Certs General Information/Process Trial Certificate FAQ Point in Time Recovery MySQL Point in Time Recovery Warning Procedure Restoring With Binlogs From Secondary Instance Restoring With Binlogs From Primary Preallocating EIPs for Webs Preallocating EIPs for webs Procedure Provision ACE Gather Information Provisioning With Juno Manual Provisioning of Customer Hardware Manual Provisioning of Infrastructure Hardware Provision ACE Customer Provision customer hardware and sites Allocating Hardware Determine if the VPC exists or needs to be created Setting variables Region and AZs Volume Size VPC FS Cluster variables Single-Tier Multi-Tier Full-Tier Get or allocate the Bals If dedicated If customer plans to use [edge cluster bals](/kanban_tickets/edge_cluster) Get or allocate the Staging server(s) Change mntfs volume size on Gen3 instances Set HIPAA settings if applicable Get the SVN (VCS) server Set opportunity ID to the dedicated hardware Creating sites prod test dev ra Set the smtp return path for prod test and dev Provisioning prod and ra sites with different stage names tagged prod tagged ra Tagging consequences Setup FIPS - FIPS compliant stacks only FIPS server config setting Mysql version server config setting Launching Servers If Launching A DB Server Initially Should Fail NOTE Verification Add production sites to Monitoring Provision ACE Dedicated Cron Dedicated Cron For Single Tier Sites Provision ACE Employee Free Sites Provisioning employee free sites Find the hardware available in the requested region Bals available in the requested region Bals in us-east-1 Bals in ap-southeast-1 region SVN SERVER Create SITES Prod site test dev Enable HSD on the SITES Provision ACE Infrastructe Hardware Provision shared and infra hardware Shared SVN Shared Edge Clustered Balancers Shared Staging Shared RA servers RA within VPC Ossec servers Mon servers Backup servers Provision ACP Manually Provision a DevCloud Site & Server Provision and creation Provision a dedicated SRV server Manual steps for sites creation prod dev staging ra Provisioning prod and ra sites with different stage names tagged prod tagged ra Tagging consequences Add production sites to monitoring Provision ACSF Site Factory provisioning Preparation Procedure Creating additional environments Creating an ELB for the site factory Adding a \"Stack\" Adding a \"Load test environment\" Use cases Arguments needed Commands creating a load test environment for a customer Provision Bastion Provisioning Provision Log Server Log Servers Introduction Pre-requisites Provision Log Servers Manage A New Cluster Manage An Existing Cluster Manage Clients Provision Multi-region Multi-Region Provisioning Preparation Provision the Balancers Provision a Multi-Tier-MR Cluster Provision a Full-Tier-MR Cluster Create the site Customize and tune the Cluster Launch the cluster Install Tungsten Setup File Replication Add the site to monitoring Verification Provision Search Colony Provisioning a Search Colony Allocate and launch load balancers Create the site Configure the site Create the ELB Create the CNAME in AWS Route53 Add the colony to the Governor Provision Search Farm Provision a Search Farm First time preparation Sizing Deploying an extractor Solr version Allocate and launch servers Determine names Example Create and configure sites Extra: If you are deploying Solr 4 Provision Site Site Provision By Realm Tiers Provisioning a Fedramp Site (With Acquia Shield) Provision FedRAMP Customer Site with Acquia Cloud Shield Allocating Hardware Create the VPC Setting variables Region and AZs Volume Size VPC FS Cluster variables Single-Tier Multi-Tier Full-Tier Allocate the Bals Allocate the Staging server(s) Change mntfs volume size on Gen3 instances Set HIPAA settings if applicable Get the SVN (VCS) server Set opportunity ID to the dedicated hardware Creating sites prod test dev ra Set the smtp return path for prod test and dev Setup FIPS FIPS server config setting Mysql version server config setting Launching Servers If Launching A DB Server Initially Should Fail NOTE Verification SAML Support Enable the Network Boundary for the VPC Create an ELB Add production sites to Monitoring Provisioning a Fedramp Site (Without Acquia Shield) Provision FedRAMP Customer Site without Acquia Cloud Shield Allocating Hardware Create the VPC Setting variables Region and AZs Volume Size VPC FS Cluster variables Single-Tier Multi-Tier Full-Tier Allocate the Bals Allocate the Staging server(s) Change mntfs volume size on Gen3 instances Set HIPAA settings if applicable Get the SVN (VCS) server Set opportunity ID to the dedicated hardware Creating sites prod test dev ra Set the smtp return path for prod test and dev Setup FIPS FIPS server config setting MySQL version server config setting Launching Servers If Launching A DB Server Initially Should Fail NOTE Verification SAML Support Create an ELB Add production sites to Monitoring Provisioning Mail Server Provisioning a mail server for Acquia Hosting Platform Cloning an existing mail server DNS Management Configuring the new mail server Testing the new mail server Replacing mail server with new server Adding the mail server to monitoring Adding the mail server in mxtoolbox for blacklist monitoring Puppet Master Generating and updating the root CA cert for puppet master Change directory to ssl path Setup steps Remove old newcert.pem from last time Check config Create/Set file \"index.txt\" Create/Set file \"serial\" Create/Set file \"openssl.cnf\" Create directory \"newcerts\" if it does not exist Generate csr and cert Get CA password Generate csr Generate pem Check newcert.pem looks normal relative to ca.pem Verify the new cert Choose a server to verify At this point, make a backup of the current cert Reload Apache Test that puppet runs on the master and the new CA is cached Test that puppet runs on an arbitrary server Choose a server to test Now we need to move the current ca on all clients in the stage Regenerate netrcs Regenerating netrc Credentials Summary WARNINGS Procedure Ahops Ahsupport Releasing Domains Site Domains Management Usage Checking domains for old site Removing domain from old site Adding domain to new site Real-life Example Remove User Deprovision User Access Bastion access Ops-Puppet Fields AWS Renewing Certificates Renewing SSL Certificates Preface Important Note Procedure renewing_puppet_master_cert Renewing SSL cert for puppet master Steps to renew puppet master SSL cert Resize Bastion Volumes Modify volumes on bastions manually Preparatory steps Gather volume information and create a backup snapshot Creating and attaching the volume Formatting the file system Copy data: rsync method Maintenance window steps Swap the volumes once the data transfer is complete Restore Snapshot on New Hardware Restore Snapshots on New Hardware (ACE) Restore DB from backup Restore files from backup Unmount the snapshot volumes after restoring everything Restore Volumes Restore Volume Backups Procedure Set the Variables Find the backup to be used for restore Mounting (Not ACSF DB) Mounting ACSF DB Communication Cleanup (Not ACSF DB) Cleanup (ACSF DB) Restore Repo Revert SSL/TLS Certificate Restoring an Acquia-Managed SSL Cert How to revert certificates for LEGACY BALANCERS How to revert certificates for EDGE CLUSTERS Root Cause Analysis Root Cause Analysis Process Copy the Template Perform the RCA Request Feedback/Approval Search Index Migration Search Index Migration Gathering information Risks and Customer Notification Procedures Same Colony Different Colony, Same Region Different Colony, Different Region Moving the index WITHOUT the data Moving the index WITH the data Secondary DB Cluster Provisioning of single-region secondary database cluster Preparation Procedure Verification Self Service SSL/TLS Certificate Self-service SSL (on ELBs) Important Note Enabling Self-Service SSL Location of the CSR, cert, and key Support-Specified Certificate Path Pre-Existing Certificates on Bals Pre-Existing Certificate on ELBs Debugging SSL on ELBs Adding Certs to ELBs Manually or Updating an Existing ELB Cert Single-tier to Multi-tier Single-tier to Multi-tier Upsize Traps Set Variables Existing Webs Gather information AMI Types and Constrained AZs Start the Workflow Adding New EIPs Important Note After Workflow: Memcache Account Management Dealsheet Single-tier to Multi-tier (manual) Single-tier to Multi-tier Upsize Traps Set Variables Existing Webs Gather information Create Provision New Webs Cluster New Webs Add Webs to Site/s Verify Server Settings Launch New Webs Post Launch Manage EIPs Check Replication Move EIP Clean Up End Account Management Dealsheet Site Audit Performing a Site Audit Converting to Gen2 Downsizing / Upsizing clusters Bal Layer Cache Layer Web Layer DB Layer FS Layer Customer Renewals Additional Docroots Summary/Recommendations of Audit Site Move Site Move VPC ODE/CDE instructions Site Factory Preparation Procedure Important Note Syncing Data Prior to Downtime Same Region Variables Home directory copy commands Site Move - Same region Different Regions Variables - Different regions Home directory copy commands multi-region Site Move - Different region Verification Recovery Cleanup SNI Certificates SNI Certificates (deployed to bals) Some SNI concepts (for information purposes - can be skipped) SNI features in fields Uploading new certificate/key pair and activating it for use with SNI Changing active cert/key pair for a site which has multiple cert/key pairs availabile for SNI Making an SNI key/pair 'inactive' for disabling SNI Deleting an SNI key/pair 'inactive' for a site AWS Certificate Manager AWS Certificate Manager Requesting A Certificate Deploying an ACM Certificate Staging Single Tier to Multi-tier Upsize (manual) Staging Single Tier to Multi-tier Upsize Traps Set Variables Existing Webs Gather information Create Provision New Webs Cluster New Webs Add Webs to Site/s Verify Server Settings Launch New Webs Post Launch Manage EIPs Move EIP Clean Up End Account Management Dealsheet SVN Server Certificates SVN Server Certificates Test VCL Deployment (Automated) Test VCL Deployment - Automated Review the VCL PR CREATE a VCL test bal from an initial request UPDATE a test VCL on an existing VCL test balancer DESTROY a test VCL balancer Test VCL Deployment (Manual) Test VCL Deployment - MANUAL Review the VCL PR Set Up Some Variables Provision a Test Balancer Set up the Test Balancer Deploy the Test VCL to the Test Balancer Troubleshooting Bastion Troubleshooting When a User Just Can't Log In When a User Gets Locked Out after successful previous logins Troubleshooting Yubikey Troubleshooting Yubikey When a User Just Can't Log In with Yubikey Resources on Confluence Installation steps for Yubikey Download yk_bastion_init tool Command to run after installation When a User Gets Locked Out after Three Attempts When a User Gets Permission denied (publickey) while connecting bastion Unblocking Email Service Unblock Email Sending for a Customer Investigation Resolution Update Search Colony Certificate Update Search Colony Certificate Get ELB for Colony Get Certificate Info Deploy cert to ELB Verify Search Extractor Search Extractor Determining Whether a javaephem is an Extractor Test Procedure Remediation VPC Deprovision Deprovision a VPC Preparation Procedure Verification VPC Network Boundaries VPC Network Boundaries Notes on Shield behavior Provisioning a VPC Network Boundary Preparing to create Registering the Network Boundary Deregistering a VPC Network Boundary Preparing to deregister Deregistering the Network Boundary Inspecting existing Network Boundaries Listing all the Network Boundaries in a realm Viewing the details of a Network Boundary VPC Provision Provision a VPC Preparation Procedure FedRAMP Verification VPC VPN Deprovision Deprovision a Shield VPN Preparation Procedure Verification VPC VPN Management Updating Shield VPNs Add a route Preparation for route addition Procedure for route addition Verification of route addition Remove a route Preparation for route removal Procedure for route removal Verification of route removal VPC VPN Provision Provisioning a Shield VPN Preparation Procedure Verification Wildcard SSL/TLS Certificates Wildcard Certificates Important Note Wildcard Management for Customers Combining Wildcard Certificates and UCCs Wildcard Management for Acquia How to handle Duplicates on a Wildcard Certificate Creating a duplicate under an existing Wildcard Certificate A Note On Transmitting \"Secured\" Information","title":"Kanban Tickets"},{"location":"kanban_tickets/#kanban-tickets","text":"Bastion servers are privileged jump hosts from which people can connect to fields infrastructure. Access is restricted with two-factor authentication and the EIPs of all three bastions are white listed in all regions for all accounts. Production Bastions: bastion-21.network.hosting.acquia.com (us-east-1) bastion-22.network.hosting.acquia.com (eu-west-1) bastion-133.network.hosting.acquia.com (ap-southeast-2)","title":"Kanban Tickets"},{"location":"kanban_tickets/#topic-summary","text":"Kanban Tickets Topics Bastion Database Gluster Dedicated Balancers Instance Deprovision Instance Management Instance Provision Ops Procedures Search Site Deprovision Site Management Site Provision SSL Tier Conversion VPC","title":"Topic Summary"},{"location":"kanban_tickets/#index","text":"","title":"Index"},{"location":"kanban_tickets/#181-hosting-release","text":"1.81 Hosting Release Procedure Optional steps Disabling the puppet agent Re-enabling the puppet agent Verification","title":"1.81 Hosting Release"},{"location":"kanban_tickets/#acquiamail","text":"Acquiamail.acquia.com Dump Restore Overview Procedure","title":"Acquiamail"},{"location":"kanban_tickets/#acsf-deprovision","text":"Site Factory Sitegroup Deprovisioning Preparation Usage Examples and Useful Some-Liners Usage of acsf-sitegroupterminate List sitegroups List sites List servers List sites on servers Deprovisioning Suspension Termination","title":"ACSF Deprovision"},{"location":"kanban_tickets/#add-custom-proxy-config","text":"Add a custom Mod-Proxy file to a Site Enabling mod_proxy Step Ticket Requirements Testing on a dedicated staging Review Deploy once the change has been hotfixed Done","title":"Add Custom Proxy Config"},{"location":"kanban_tickets/#add-remove-site-monitoring","text":"Add/Remove Sites to/from Monitoring Monitoring Sites - ACE Add ACE site to monitoring Remove ACE site from monitoring Monitoring URLs - Site Factory Add ACSF site to monitoring Remove ACSF site from monitoring Monitoring Sites - ACP & Network Add site to monitoring Remove site from monitoring","title":"Add Remove Site Monitoring"},{"location":"kanban_tickets/#addremove-webs-from-rotation","text":"Add/Remove Webs From Rotation Overview Web Rotation Status Web Service Status Pre-Flight Checks Procedures Disabling/Removing Disabling Web Service for single OR multiple hosts Disabling Web Rotation on a single host, single site Disabling Web Rotation on multiple hosts, single site Enabling/Adding Enabling Web Service for single OR multiple hosts Enabling Web Rotation on a single host, single site Enabling Web Rotation on multiple hosts, single site","title":"Add/Remove Webs From Rotation"},{"location":"kanban_tickets/#add-user","text":"Bastion Provisioning Gather Required Information Approval Choosing a Username Granting Access to Bastion Provisioning a user EXAMPLE: Bastion ONLY EXAMPLE: ACE,ACP production access Confirm that User Can Log In Test Log-in","title":"Add User"},{"location":"kanban_tickets/#ah-rabot","text":"Modify the list of bastion users that can sudo ahrabot","title":"AH Rabot"},{"location":"kanban_tickets/#arbitrary-phpini-settings","text":"Arbitrary php.ini settings Changing php.ini settings Adding or changing arbitrary directives Removing arbitrary directives","title":"Arbitrary php.ini Settings"},{"location":"kanban_tickets/#bastion-access","text":"Bastion Access User Changes Updating a user's SSH key Changing a user's group Adding a user to an additional stage","title":"Bastion Access"},{"location":"kanban_tickets/#bastion-troubleshooting","text":"Troubleshooting When a User Just Can't Log In When a User Gets Locked Out after successful previous logins","title":"Bastion Troubleshooting"},{"location":"kanban_tickets/#bulk-site-move","text":"Bulk Site Move Preparation Procedure Variables Home directory copy commands Important Note Site Move Verification Post Steps","title":"Bulk Site Move"},{"location":"kanban_tickets/#bulk-site-php-edits","text":"Bulk Site PHP Edits Preparation Procedure Verification","title":"Bulk Site PHP Edits"},{"location":"kanban_tickets/#capacity-limit","text":"Edge Cluster Capacity limit Capacity Limit Reached for Non-RA Environments Capacity Limit Reached for RA Environments","title":"Capacity Limit"},{"location":"kanban_tickets/#change_balancers_on_existing_environment","text":"Change balancers on existing environment Information ELB Configuration VPC Placement SSL Requirements Tag Validation and Migration Custom VCL Requirements Procedures","title":"change_balancers_on_existing_environment"},{"location":"kanban_tickets/#change-db-password","text":"Site Database Password Change Changing Credentials","title":"Change DB Password"},{"location":"kanban_tickets/#clamav","text":"ClamAV Daemon Enabling Tunables Disabling","title":"ClamAV"},{"location":"kanban_tickets/#code-checkout-failures","text":"Code Checkout Failures Incorrect VCS path Clean checkout","title":"Code Checkout Failures"},{"location":"kanban_tickets/#configuring-hsd-for-sites","text":"HSD (Higher Site Density) To check if hsd is enabled for particular site To enable hsd To disable hsd","title":"Configuring HSD for Sites"},{"location":"kanban_tickets/#core-dumps","text":"Enable Coredumps for Capturing PHP Segfaults Managing Coredumps Enabling Disabling Coredump Analysis Preparing Analysing Interpreting A Sample Backtrace","title":"Core Dumps"},{"location":"kanban_tickets/#create-a-test-balancer","text":"Create a test balancer Preparation Procedure Operation Extend the duration of a test balancer before its deprovision Verify if a site has test balancers Monitoring Known bugs","title":"Create a Test Balancer"},{"location":"kanban_tickets/#custom-tungsten-settings","text":"Custom Tungsten Settings Configure-service Static Configuration Files Replication Filter","title":"Custom Tungsten Settings"},{"location":"kanban_tickets/#dedicated-to-dedicated-bals","text":"Dedicated To Dedicated Hardware Allocation Pre-Assignment Assigning Balancers Post-Assignment","title":"Dedicated To Dedicated Bals"},{"location":"kanban_tickets/#dedicated-to-shared-bals","text":"Dedicated to Shared Pre-work Assign Balancers Post-Assignment","title":"Dedicated to Shared Bals"},{"location":"kanban_tickets/#shared-to-dedicated-bals","text":"Shared to Dedicated Hardware Allocation Pre-Assignment Assigning Balancers Post-Assignment","title":"Shared to Dedicated Bals"},{"location":"kanban_tickets/#shared-to-shared-bals","text":"Shared to Shared Pre-work Assigning Balancers Post-Assignment","title":"Shared to Shared Bals"},{"location":"kanban_tickets/#dedicated-hypervisor","text":"Set servers to be dedicated instances Preparation Procedure Verification","title":"Dedicated Hypervisor"},{"location":"kanban_tickets/#dedicated-memcache","text":"Dedicated Memcache About Dedicated Memcache What site-setmemcache does Procedure Memcache Service Status","title":"Dedicated Memcache"},{"location":"kanban_tickets/#deploy-certificate","text":"Deploying an SSL / TLS certificate to a balancer cluster Table of Contents Determine balancers and tag Prepare Certificate chain Private key Certificates management Adding a new certificate (Both Edge Cluster and Legacy) Deploy a certificate override (Edge cluster) Deploy a certificate override (Legacy balancer) Remove a certificate override and set to default Acquia certificates (Edge cluster) Remove a certificate override and set to default Acquia certificates (Legacy balancer) Setting a default certificate (This is for entire realm) Verify","title":"Deploy Certificate"},{"location":"kanban_tickets/#deploy-test-vcl","text":"Deploy custom VCL for customer testing","title":"Deploy Test VCL"},{"location":"kanban_tickets/#deprovision-search-colony","text":"Deprovision a Search Colony Prerequisites Procedure","title":"Deprovision Search Colony"},{"location":"kanban_tickets/#deprovision-search-farm","text":"Deprovision a Search Farm Prerequisites Procedures","title":"Deprovision Search Farm"},{"location":"kanban_tickets/#deprovisioning-ace-and-acp","text":"Deprovisioning ACE & ACP Preparation Caveats Deprovisioning a specific site stage Deprovisioning a sitegroup Deprovisioning A Note About ACP Suspension Termination Bulk site/environment Termination","title":"Deprovisioning ACE and ACP"},{"location":"kanban_tickets/#seprovisioning-mail-server","text":"Deprovisoning a mail server Remove from monitoring and puppet manifest Removing DNS entries for the mail server Terminating server from Rackspace","title":"Seprovisioning Mail Server"},{"location":"kanban_tickets/#diagnostics","text":"* [Certificate Files](./diagnostics.md#certificate-files) * [Compare Cert and Key](./diagnostics.md#compare-cert-and-key) * [Compare CSR and Key](./diagnostics.md#compare-csr-and-key) * [View Certificate Information](./diagnostics.md#view-certificate-information) * [Get notBefore/notAfter (Expiration) date](./diagnostics.md#get-notbeforenotafter-expiration-date) * [Services over SSL](./diagnostics.md#services-over-ssl) * [Verify Certificate Chain](./diagnostics.md#verify-certificate-chain) * [Asynchronous Keys](./diagnostics.md#asynchronous-keys) * [Get public key from private key](./diagnostics.md#get-public-key-from-private-key)","title":"Diagnostics"},{"location":"kanban_tickets/#disable-tls-version","text":"Disable TLS versions Check for Shared balancers Disable TLSv1.0 only Disable TLSv1.1 Disable TLSv1.1 in Edge Clusters","title":"Disable TLS Version"},{"location":"kanban_tickets/#duplicate-certificates","text":"Duplicate Certificates Important Note How to Duplicate a Certificate","title":"Duplicate Certificates"},{"location":"kanban_tickets/#edge-cluster","text":"Edge Cluster Available commands Describe available commands or one specific command Create a new Edge Cluster Delete an Edge Cluster Relaunching bals in an Edge Cluster Note View details of an existing Edge Cluster View a list of Edge Clusters on the current realm Add an environment to an existing Edge Cluster Remove an environment from an existing Edge Cluster Increase an Edge Cluster capacity by doubling its number of servers. Cannot scale more than once Important Apply a tag to an Edge Cluster Remove a tag from an Edge Cluster Migrations Manual migration of a customer from a legacy bal pair to an Edge Cluster Manual migration of a customer from an Edge Cluster to a Legacy Balancers Handling Legacy to Edge migrations for customers with ELB","title":"Edge Cluster"},{"location":"kanban_tickets/#elb-creation","text":"ELB Creation Initialize Variables For Customers For Whom We Have The Cert and Key For Customers For Whom We Do Not Have The Cert and Key","title":"ELB Creation"},{"location":"kanban_tickets/#email-blacklist","text":"Acquia Email Server Blacklist Removal An example of a host being \"listed\" List of mail servers according to realm Investigation A word of caution Resolution","title":"Email Blacklist"},{"location":"kanban_tickets/#enabling-mod_proxy","text":"Enabling Mod-Proxy on a Site Required Information Procedure Documentation Custom proxy.conf file","title":"Enabling mod_proxy"},{"location":"kanban_tickets/#enabling-xdebug","text":"Enabling xdebug for a Site Required Information Procedure Enabling Xdebug Enabling Xdebug Remote Documentation","title":"Enabling Xdebug"},{"location":"kanban_tickets/#extended-validation-certificates","text":"Extended Validation Certificates","title":"Extended Validation Certificates"},{"location":"kanban_tickets/#fix-livedev","text":"Fixing/Enabling livedev Identify the error Remediation","title":"Fix Livedev"},{"location":"kanban_tickets/#generating-csrs","text":"Generating a Certificate Signing Request (CSR) Subject SSL Plus/EV CSR Generation Procedure Wildcard Plus CSR Generation UCC/EV Multi-Domain CSR Generation Using an existing key for UCC CSR Generation UCC CSR Generation Example","title":"Generating CSRs"},{"location":"kanban_tickets/#gluster-downgrade","text":"Downgrade Gluster Version from 3.4 to 3.0 THIS PROCESS SHOULD BE USED ONLY ON GLUSTER 3.4 SERVERS Initial Variables Info Gathering Provision new FS servers and fix volumes Allocate new FS servers Add brick volumes Configure FS servers for gluster 3.0 Allocate FS cluster Fix backup vol on secondary server to 1gb Fix ebs1 volumes on both servers to 1gb Launch FS Servers Filesystem Data Transfer Create Temporary SSH key rsync from source server to destination server Web servers cutover Take webs out of rotation Re-run rysnc Disable Puppet and cron on webs Stop gluster and Unmount gluster Add webs to New FS cluster Relaunch suspended webs Remount gluster on webs check gluster for site Put webs back into rotation Restart PHP, Run FCW on webs Verification Cleanup","title":"Gluster Downgrade"},{"location":"kanban_tickets/#gluster-upgrade","text":"Upgrade Gluster Version from 3.0 to 3.4 THIS PROCESS SHOULD BE USED ONLY ON GLUSTER 3.0 SERVERS Initial Variables Info Gathering Provision new FS servers and fix volumes Allocate new FS servers Add brick volumes Configure FS servers for gluster 3.4 Allocate FS cluster Fix backup vol on secondary server to 1gb Fix ebs1 volumes on both servers to 1gb Launch FS Servers Filesystem Data Transfer Create Temporary SSH key rsync from source server to destination server Web servers cutover Take webs out of rotation Re-run rysnc Disable Puppet and cron on webs Stop gluster and Unmount gluster Add webs to New FS cluster Relaunch suspended webs Remount gluster on webs check gluster for site Put webs back into rotation Restart PHP, Run FCW on webs Verification Cleanup","title":"Gluster Upgrade"},{"location":"kanban_tickets/#loadtest-balancer","text":"Load Test Balancer Adding a Load Test Balancer Find a Valid Load Test Balancer Add the balancer Check the ELB Removing a Load Test Balancer","title":"Loadtest Balancer"},{"location":"kanban_tickets/#logforward","text":"Log Forwarding Log Forwarding through Ops Portal Manually Enabling Log Forwarding Requirements Enable ACE ACSF Verify ACE ACSF Disable ACE ACSF Restarting Log forwarding for Sumo Logic Follow these steps when logs forwarding breaks down for customer Diagnose log forwarding for Sumo Logic Follow these steps when logs are not being forwarded to Sumo Logic Troubleshooting td-agent and New Log Forwarding issues","title":"Logforward"},{"location":"kanban_tickets/#manage-end-to-end-encryption","text":"Manage End To End Encryption Preparation Preparation: Get sitegroup, site names and servers Enable E2E Encryption Checking the E2E Installation Disable E2E Encryption Rotate E2E Encryption Keys Verifying the e2e configuration","title":"Manage End-to-end Encryption"},{"location":"kanban_tickets/#masterless-puppet","text":"Masterless Puppet How to tell if a Server is Masterless","title":"Masterless Puppet"},{"location":"kanban_tickets/#move-customer-repo","text":"","title":"Move Customer Repo"},{"location":"kanban_tickets/#move-provisioning-pointer","text":"Moving the Index Provisioning Pointer Information","title":"Move Provisioning Pointer"},{"location":"kanban_tickets/#multi-region-failover-testing","text":"Performing a Multi-Region Failover Test Pre-Flight Set up some Variables Validate and Document that the Site is Healthy Prior to Initiating the Failover Simulate a Region Outage, at this time the TAM should instruct the customer to fail over DNS to their Secondary Region Initiate the Multi-Region Failover to the Secondary Region Begin the Multi-Region Fail-back to the Primary Region Perform Health Checks and Document the Output in the ticket","title":"Multi-region Failover Testing"},{"location":"kanban_tickets/#multi-tier-to-full-tier","text":"Multi-tier to Full-tier Upsize Prep Maintenance Window Site Move Procedure Cleanup","title":"Multi-tier to Full-tier"},{"location":"kanban_tickets/#multi-tier-to-single-tier","text":"Multi-tier to Single-tier Downsize Traps Important Note Set Variables Gather information Verify Server Settings Add DED SERVERS back to Site/s Check Replication Manage EIPs Move EIP Clean Up End","title":"Multi-tier to Single-tier"},{"location":"kanban_tickets/#mysql-daily-replication-fix","text":"* [Daily Automated replication fix](./mysql-daily-replication-fix.md#daily-automated-replication-fix) * [Manually finding list of servers](./mysql-daily-replication-fix.md#manually-finding-list-of-servers) * [Attempting to fix the clusters](./mysql-daily-replication-fix.md#attempting-to-fix-the-clusters)","title":"Mysql Daily Replication Fix"},{"location":"kanban_tickets/#mysql-audit","text":"Enabling or Disabling MySQL Auditing Enabling MySQL Auditing Disabling MySQL Auditing","title":"Mysql Audit"},{"location":"kanban_tickets/#orphans-instances","text":"* [Preparation](./orphans.md#preparation) * [Procedure](./orphans.md#procedure) * [Determine the orphan instance status](./orphans.md#determine-the-orphan-instance-status) * [Determine when the server was launched](./orphans.md#determine-when-the-server-was-launched) * [Devcloud](./orphans.md#devcloud) * [All Other Environments](./orphans.md#all-other-environments) * [If the orphan instance report is not showing a server name](./orphans.md#if-the-orphan-instance-report-is-not-showing-a-server-name) * [Removing orphans nodes](./orphans.md#removing-orphans-nodes)","title":"Orphans Instances"},{"location":"kanban_tickets/#ssl-overview","text":"SSL Overview Important Note Customer-facing Documentation on docs.ccquia.com Technical details of how SSL/TLS cert chains work Ordering SSL Certificates Pre-flight Check WHOIS Types of Actions Trial Certs General Information/Process Trial Certificate FAQ","title":"SSL Overview"},{"location":"kanban_tickets/#point-in-time-recovery","text":"MySQL Point in Time Recovery Warning Procedure Restoring With Binlogs From Secondary Instance Restoring With Binlogs From Primary","title":"Point in Time Recovery"},{"location":"kanban_tickets/#preallocating-eips-for-webs","text":"Preallocating EIPs for webs Procedure","title":"Preallocating EIPs for Webs"},{"location":"kanban_tickets/#provision-ace","text":"Gather Information Provisioning With Juno Manual Provisioning of Customer Hardware Manual Provisioning of Infrastructure Hardware","title":"Provision ACE"},{"location":"kanban_tickets/#provision-ace-customer","text":"Provision customer hardware and sites Allocating Hardware Determine if the VPC exists or needs to be created Setting variables Region and AZs Volume Size VPC FS Cluster variables Single-Tier Multi-Tier Full-Tier Get or allocate the Bals If dedicated If customer plans to use [edge cluster bals](/kanban_tickets/edge_cluster) Get or allocate the Staging server(s) Change mntfs volume size on Gen3 instances Set HIPAA settings if applicable Get the SVN (VCS) server Set opportunity ID to the dedicated hardware Creating sites prod test dev ra Set the smtp return path for prod test and dev Provisioning prod and ra sites with different stage names tagged prod tagged ra Tagging consequences Setup FIPS - FIPS compliant stacks only FIPS server config setting Mysql version server config setting Launching Servers If Launching A DB Server Initially Should Fail NOTE Verification Add production sites to Monitoring","title":"Provision ACE Customer"},{"location":"kanban_tickets/#provision-ace-dedicated-cron","text":"Dedicated Cron For Single Tier Sites","title":"Provision ACE Dedicated Cron"},{"location":"kanban_tickets/#provision-ace-employee-free-sites","text":"Provisioning employee free sites Find the hardware available in the requested region Bals available in the requested region Bals in us-east-1 Bals in ap-southeast-1 region SVN SERVER Create SITES Prod site test dev Enable HSD on the SITES","title":"Provision ACE Employee Free Sites"},{"location":"kanban_tickets/#provision-ace-infrastructe-hardware","text":"Provision shared and infra hardware Shared SVN Shared Edge Clustered Balancers Shared Staging Shared RA servers RA within VPC Ossec servers Mon servers Backup servers","title":"Provision ACE Infrastructe Hardware"},{"location":"kanban_tickets/#provision-acp","text":"Manually Provision a DevCloud Site & Server Provision and creation Provision a dedicated SRV server Manual steps for sites creation prod dev staging ra Provisioning prod and ra sites with different stage names tagged prod tagged ra Tagging consequences Add production sites to monitoring","title":"Provision ACP"},{"location":"kanban_tickets/#provision-acsf","text":"Site Factory provisioning Preparation Procedure Creating additional environments Creating an ELB for the site factory Adding a \"Stack\" Adding a \"Load test environment\" Use cases Arguments needed Commands creating a load test environment for a customer","title":"Provision ACSF"},{"location":"kanban_tickets/#provision-bastion","text":"Provisioning","title":"Provision Bastion"},{"location":"kanban_tickets/#provision-log-server","text":"Log Servers Introduction Pre-requisites Provision Log Servers Manage A New Cluster Manage An Existing Cluster Manage Clients","title":"Provision Log Server"},{"location":"kanban_tickets/#provision-multi-region","text":"Multi-Region Provisioning Preparation Provision the Balancers Provision a Multi-Tier-MR Cluster Provision a Full-Tier-MR Cluster Create the site Customize and tune the Cluster Launch the cluster Install Tungsten Setup File Replication Add the site to monitoring Verification","title":"Provision Multi-region"},{"location":"kanban_tickets/#provision-search-colony","text":"Provisioning a Search Colony Allocate and launch load balancers Create the site Configure the site Create the ELB Create the CNAME in AWS Route53 Add the colony to the Governor","title":"Provision Search Colony"},{"location":"kanban_tickets/#provision-search-farm","text":"Provision a Search Farm First time preparation Sizing Deploying an extractor Solr version Allocate and launch servers Determine names Example Create and configure sites Extra: If you are deploying Solr 4","title":"Provision Search Farm"},{"location":"kanban_tickets/#provision-site","text":"Site Provision By Realm Tiers","title":"Provision Site"},{"location":"kanban_tickets/#provisioning-a-fedramp-site-with-acquia-shield","text":"Provision FedRAMP Customer Site with Acquia Cloud Shield Allocating Hardware Create the VPC Setting variables Region and AZs Volume Size VPC FS Cluster variables Single-Tier Multi-Tier Full-Tier Allocate the Bals Allocate the Staging server(s) Change mntfs volume size on Gen3 instances Set HIPAA settings if applicable Get the SVN (VCS) server Set opportunity ID to the dedicated hardware Creating sites prod test dev ra Set the smtp return path for prod test and dev Setup FIPS FIPS server config setting Mysql version server config setting Launching Servers If Launching A DB Server Initially Should Fail NOTE Verification SAML Support Enable the Network Boundary for the VPC Create an ELB Add production sites to Monitoring","title":"Provisioning a Fedramp Site (With Acquia Shield)"},{"location":"kanban_tickets/#provisioning-a-fedramp-site-without-acquia-shield","text":"Provision FedRAMP Customer Site without Acquia Cloud Shield Allocating Hardware Create the VPC Setting variables Region and AZs Volume Size VPC FS Cluster variables Single-Tier Multi-Tier Full-Tier Allocate the Bals Allocate the Staging server(s) Change mntfs volume size on Gen3 instances Set HIPAA settings if applicable Get the SVN (VCS) server Set opportunity ID to the dedicated hardware Creating sites prod test dev ra Set the smtp return path for prod test and dev Setup FIPS FIPS server config setting MySQL version server config setting Launching Servers If Launching A DB Server Initially Should Fail NOTE Verification SAML Support Create an ELB Add production sites to Monitoring","title":"Provisioning a Fedramp Site (Without Acquia Shield)"},{"location":"kanban_tickets/#provisioning-mail-server","text":"Provisioning a mail server for Acquia Hosting Platform Cloning an existing mail server DNS Management Configuring the new mail server Testing the new mail server Replacing mail server with new server Adding the mail server to monitoring Adding the mail server in mxtoolbox for blacklist monitoring","title":"Provisioning Mail Server"},{"location":"kanban_tickets/#puppet-master","text":"Generating and updating the root CA cert for puppet master Change directory to ssl path Setup steps Remove old newcert.pem from last time Check config Create/Set file \"index.txt\" Create/Set file \"serial\" Create/Set file \"openssl.cnf\" Create directory \"newcerts\" if it does not exist Generate csr and cert Get CA password Generate csr Generate pem Check newcert.pem looks normal relative to ca.pem Verify the new cert Choose a server to verify At this point, make a backup of the current cert Reload Apache Test that puppet runs on the master and the new CA is cached Test that puppet runs on an arbitrary server Choose a server to test Now we need to move the current ca on all clients in the stage","title":"Puppet Master"},{"location":"kanban_tickets/#regenerate-netrcs","text":"Regenerating netrc Credentials Summary WARNINGS Procedure Ahops Ahsupport","title":"Regenerate netrcs"},{"location":"kanban_tickets/#releasing-domains","text":"Site Domains Management Usage Checking domains for old site Removing domain from old site Adding domain to new site Real-life Example","title":"Releasing Domains"},{"location":"kanban_tickets/#remove-user","text":"Deprovision User Access Bastion access Ops-Puppet Fields AWS","title":"Remove User"},{"location":"kanban_tickets/#renewing-certificates","text":"Renewing SSL Certificates Preface Important Note Procedure","title":"Renewing Certificates"},{"location":"kanban_tickets/#renewing_puppet_master_cert","text":"Renewing SSL cert for puppet master Steps to renew puppet master SSL cert","title":"renewing_puppet_master_cert"},{"location":"kanban_tickets/#resize-bastion-volumes","text":"Modify volumes on bastions manually Preparatory steps Gather volume information and create a backup snapshot Creating and attaching the volume Formatting the file system Copy data: rsync method Maintenance window steps Swap the volumes once the data transfer is complete","title":"Resize Bastion Volumes"},{"location":"kanban_tickets/#restore-snapshot-on-new-hardware","text":"Restore Snapshots on New Hardware (ACE) Restore DB from backup Restore files from backup Unmount the snapshot volumes after restoring everything","title":"Restore Snapshot on New Hardware"},{"location":"kanban_tickets/#restore-volumes","text":"Restore Volume Backups Procedure Set the Variables Find the backup to be used for restore Mounting (Not ACSF DB) Mounting ACSF DB Communication Cleanup (Not ACSF DB) Cleanup (ACSF DB) Restore Repo","title":"Restore Volumes"},{"location":"kanban_tickets/#revert-ssltls-certificate","text":"Restoring an Acquia-Managed SSL Cert How to revert certificates for LEGACY BALANCERS How to revert certificates for EDGE CLUSTERS","title":"Revert SSL/TLS Certificate"},{"location":"kanban_tickets/#root-cause-analysis","text":"Root Cause Analysis Process Copy the Template Perform the RCA Request Feedback/Approval","title":"Root Cause Analysis"},{"location":"kanban_tickets/#search-index-migration","text":"Search Index Migration Gathering information Risks and Customer Notification Procedures Same Colony Different Colony, Same Region Different Colony, Different Region Moving the index WITHOUT the data Moving the index WITH the data","title":"Search Index Migration"},{"location":"kanban_tickets/#secondary-db-cluster","text":"Provisioning of single-region secondary database cluster Preparation Procedure Verification","title":"Secondary DB Cluster"},{"location":"kanban_tickets/#self-service-ssltls-certificate","text":"Self-service SSL (on ELBs) Important Note Enabling Self-Service SSL Location of the CSR, cert, and key Support-Specified Certificate Path Pre-Existing Certificates on Bals Pre-Existing Certificate on ELBs Debugging SSL on ELBs Adding Certs to ELBs Manually or Updating an Existing ELB Cert","title":"Self Service SSL/TLS Certificate"},{"location":"kanban_tickets/#single-tier-to-multi-tier","text":"Single-tier to Multi-tier Upsize Traps Set Variables Existing Webs Gather information AMI Types and Constrained AZs Start the Workflow Adding New EIPs Important Note After Workflow: Memcache Account Management Dealsheet","title":"Single-tier to Multi-tier"},{"location":"kanban_tickets/#single-tier-to-multi-tier-manual","text":"Single-tier to Multi-tier Upsize Traps Set Variables Existing Webs Gather information Create Provision New Webs Cluster New Webs Add Webs to Site/s Verify Server Settings Launch New Webs Post Launch Manage EIPs Check Replication Move EIP Clean Up End Account Management Dealsheet","title":"Single-tier to Multi-tier (manual)"},{"location":"kanban_tickets/#site-audit","text":"Performing a Site Audit Converting to Gen2 Downsizing / Upsizing clusters Bal Layer Cache Layer Web Layer DB Layer FS Layer Customer Renewals Additional Docroots Summary/Recommendations of Audit","title":"Site Audit"},{"location":"kanban_tickets/#site-move","text":"Site Move VPC ODE/CDE instructions Site Factory Preparation Procedure Important Note Syncing Data Prior to Downtime Same Region Variables Home directory copy commands Site Move - Same region Different Regions Variables - Different regions Home directory copy commands multi-region Site Move - Different region Verification Recovery Cleanup","title":"Site Move"},{"location":"kanban_tickets/#sni-certificates","text":"SNI Certificates (deployed to bals) Some SNI concepts (for information purposes - can be skipped) SNI features in fields Uploading new certificate/key pair and activating it for use with SNI Changing active cert/key pair for a site which has multiple cert/key pairs availabile for SNI Making an SNI key/pair 'inactive' for disabling SNI Deleting an SNI key/pair 'inactive' for a site","title":"SNI Certificates"},{"location":"kanban_tickets/#aws-certificate-manager","text":"AWS Certificate Manager Requesting A Certificate Deploying an ACM Certificate","title":"AWS Certificate Manager"},{"location":"kanban_tickets/#staging-single-tier-to-multi-tier-upsize-manual","text":"Staging Single Tier to Multi-tier Upsize Traps Set Variables Existing Webs Gather information Create Provision New Webs Cluster New Webs Add Webs to Site/s Verify Server Settings Launch New Webs Post Launch Manage EIPs Move EIP Clean Up End Account Management Dealsheet","title":"Staging Single Tier to Multi-tier Upsize (manual)"},{"location":"kanban_tickets/#svn-server-certificates","text":"SVN Server Certificates","title":"SVN Server Certificates"},{"location":"kanban_tickets/#test-vcl-deployment-automated","text":"Test VCL Deployment - Automated Review the VCL PR CREATE a VCL test bal from an initial request UPDATE a test VCL on an existing VCL test balancer DESTROY a test VCL balancer","title":"Test VCL Deployment (Automated)"},{"location":"kanban_tickets/#test-vcl-deployment-manual","text":"Test VCL Deployment - MANUAL Review the VCL PR Set Up Some Variables Provision a Test Balancer Set up the Test Balancer Deploy the Test VCL to the Test Balancer","title":"Test VCL Deployment (Manual)"},{"location":"kanban_tickets/#troubleshooting-bastion","text":"Troubleshooting When a User Just Can't Log In When a User Gets Locked Out after successful previous logins","title":"Troubleshooting Bastion"},{"location":"kanban_tickets/#troubleshooting-yubikey","text":"Troubleshooting Yubikey When a User Just Can't Log In with Yubikey Resources on Confluence Installation steps for Yubikey Download yk_bastion_init tool Command to run after installation When a User Gets Locked Out after Three Attempts When a User Gets Permission denied (publickey) while connecting bastion","title":"Troubleshooting Yubikey"},{"location":"kanban_tickets/#unblocking-email-service","text":"Unblock Email Sending for a Customer Investigation Resolution","title":"Unblocking Email Service"},{"location":"kanban_tickets/#update-search-colony-certificate","text":"Update Search Colony Certificate Get ELB for Colony Get Certificate Info Deploy cert to ELB","title":"Update Search Colony Certificate"},{"location":"kanban_tickets/#verify-search-extractor","text":"Search Extractor Determining Whether a javaephem is an Extractor Test Procedure Remediation","title":"Verify Search Extractor"},{"location":"kanban_tickets/#vpc-deprovision","text":"Deprovision a VPC Preparation Procedure Verification","title":"VPC Deprovision"},{"location":"kanban_tickets/#vpc-network-boundaries","text":"VPC Network Boundaries Notes on Shield behavior Provisioning a VPC Network Boundary Preparing to create Registering the Network Boundary Deregistering a VPC Network Boundary Preparing to deregister Deregistering the Network Boundary Inspecting existing Network Boundaries Listing all the Network Boundaries in a realm Viewing the details of a Network Boundary","title":"VPC Network Boundaries"},{"location":"kanban_tickets/#vpc-provision","text":"Provision a VPC Preparation Procedure FedRAMP Verification","title":"VPC Provision"},{"location":"kanban_tickets/#vpc-vpn-deprovision","text":"Deprovision a Shield VPN Preparation Procedure Verification","title":"VPC VPN Deprovision"},{"location":"kanban_tickets/#vpc-vpn-management","text":"Updating Shield VPNs Add a route Preparation for route addition Procedure for route addition Verification of route addition Remove a route Preparation for route removal Procedure for route removal Verification of route removal","title":"VPC VPN Management"},{"location":"kanban_tickets/#vpc-vpn-provision","text":"Provisioning a Shield VPN Preparation Procedure Verification","title":"VPC VPN Provision"},{"location":"kanban_tickets/#wildcard-ssltls-certificates","text":"Wildcard Certificates Important Note Wildcard Management for Customers Combining Wildcard Certificates and UCCs Wildcard Management for Acquia How to handle Duplicates on a Wildcard Certificate Creating a duplicate under an existing Wildcard Certificate A Note On Transmitting \"Secured\" Information","title":"Wildcard SSL/TLS Certificates"},{"location":"kanban_tickets/1.81_release/","text":"1.81 Hosting Release This procedure will release a fields 1.81 tag to the search stage. This process is designed to have no loss in read access and, in rare cases, a brief loss of write access depending on what is being changed. This procedure will release to the entire search stage. Procedure These commands should be run on the bastion. Use the 'asearch' command to set the environment to the search stage. Note: To login Search jumpboxes, follow these instructions Gather information about the tag. git fetch git tag # Check if the git tag you want already exists, if it does don't create a new tag Export tag name that will be used throughout the release. # If the tag exists, use its name, otherwise bump the version from the newest tag from the step before. For this example, we assume the tag you want doesn't exist and its name will be 1.81.65 export VERSION=\"1_81_65\" export VERSION_DOTS=\"1.81.65\" If there isn't already a git tag, cut and push a new tag to git. git pull origin 1.81 git log --pretty=oneline 1.81...$tag to verify commits # verify the commits match the 1.81 branch commits in github git tag ${VERSION_DOTS} git push origin ${VERSION_DOTS} Set other environment variables. # Gather lists of running servers by type export MASTERS_RUNNING=$(ah-server list % -w type=javasrv status=0 | sort -R | paste -sd,) export SLAVES_RUNNING=$(ah-server list % -w type=javaephem status=0 | sort -R | paste -sd,) export CANARY_SERVERS_1='nxephem-193,javasrv-67' export CANARY_SERVERS_2='nxephem-194,javaephem-68' # Setup logging and concurrency CONCURRENCY=20 LOG=${OPSLOG}/${USER}.${FIELDS_STAGE}.${VERSION}.$(date +%F).log Update packages on all servers. First all other servers and then the master. fpdsh -t % -p 100 -c \"sudo apt-get update\" fssh master sudo apt-get update Deploy the git tag to the stage. This will checkout the git tag in the master. ah-release deploy -t ${VERSION_DOTS} --debug Switch the hosting version on the master, run puppet and verify that the correct hosting tag was deployed. ./fields-provision.php --switch-version master::${VERSION} fssh master \"sudo -H /bin/bash -c 'puppet agent --test'\" fssh master 'sudo cat /var/acquia/HOSTING_VERSION' # verify its on the right version Switch the hosting version on the backup and run puppet. ah-server edit backup-% -s hosting_version=${VERSION} fpdsh -t backup-% -c \"sudo -H /bin/bash -c 'puppet agent --test'\" Deploy the hosting version to the canary colony. Note: see sections Disabling the puppet agent and Re-enabling the puppet agent if you need to avoid unattended puppet runs during this release in order to maintain high-availability. ./fields-provision.php --switch-version ${CANARY_SERVERS_1}::${VERSION} fpdsh -l ${CANARY_SERVERS_1} -p ${CONCURRENCY} -c \"sudo -H /bin/bash -c 'puppet agent -t'\" 2>&1 | tee -a ${LOG} ./fields-provision.php --switch-version ${CANARY_SERVERS_2}::${VERSION} fpdsh -l ${CANARY_SERVERS_2} -p ${CONCURRENCY} -c \"sudo -H /bin/bash -c 'puppet agent -t'\" 2>&1 | tee -a ${LOG} Ping acquia.com's index to make sure the canary servers step before was succesful governor index:ping GIKU-17871 Set the default hosting version for all servers in the stage. ./fields-provision.php --set-default-version ${VERSION} Switch the hosting version on the rest of the servers in the stage. ./fields-provision.php --switch-version $(ah-server list % | paste -sd,)::${VERSION} Run puppet on all javasrvs. fpdsh -l ${MASTERS_RUNNING} -p ${CONCURRENCY} -c \"sudo -H /bin/bash -c 'puppet agent -t'\" 2>&1 | tee -a ${LOG} Run puppet on all javaephems. fpdsh -l ${SLAVES_RUNNING} -p ${CONCURRENCY} -c \"sudo -H /bin/bash -c 'puppet agent -t'\" 2>&1 | tee -a ${LOG} Run puppet on all nxephems. We can only do one availability zone per region at a time so there will be 3 seperate batches. Note: if you have disabled the puppet agent, you need to re-enable it first before running puppet on each group (see section Re-enabling the puppet agent ). # Run puppet on all nxephems in the first AZ in every region NXEPHEMS_ONE=$(ah-server list % -w type=nxephem ec2_availability_zoneINap-southeast-1a,ap-southeast-2a,eu-west-1a,us-east-1b,us-west-2a | paste -sd,) fpdsh -l ${NXEPHEMS_ONE} -p ${CONCURRENCY} -c \"sudo -H /bin/bash -c 'puppet agent -t'\" 2>&1 | tee -a ${LOG} # Then the second AZ in every region NXEPHEMS_TWO=$(ah-server list % -w type=nxephem ec2_availability_zoneINap-southeast-1b,ap-southeast-2b,eu-west-1b,us-east-1c,us-west-2b | paste -sd,) fpdsh -l ${NXEPHEMS_TWO} -p ${CONCURRENCY} -c \"sudo -H /bin/bash -c 'puppet agent -t'\" 2>&1 | tee -a ${LOG} # Then the third AZ in every region NXEPHEMS_THREE=$(ah-server list % -w type=nxephem ec2_availability_zoneINeu-west-1c,us-east-1d,us-west-2c | paste -sd,) fpdsh -l ${NXEPHEMS_THREE} -p ${CONCURRENCY} -c \"sudo -H /bin/bash -c 'puppet agent -t'\" 2>&1 | tee -a ${LOG} Run puppet on the rest of the server types in the search stage. This includes svn, log, stats, ossec and mon. OTHER_SERVERS=$(ah-server list % -w typeINsvn,log,stats,ossec,mon | paste -sd,) fpdsh -l ${OTHER_SERVERS} -p ${CONCURRENCY} -c \"sudo -H /bin/bash -c 'puppet agent -t'\" 2>&1 | tee -a ${LOG} Get someone with sudo access on the bastion to deploy the hosting version to the bastion. Shane Van Hart is able to do this. Optional steps Disabling the puppet agent There are code releases in which it may be necessary to keep some servers from running puppet, as this may result in an out-of-order interruption of the service. An example of this is changing the pinned version of nginx on nxephem servers, which would result in puppet restarting the service. To avoid this scenario, you should disable the puppet agent first: SERVERS= PUPPET_DISABLE_REASON= ah-server edit ${SERVERS} -s monitoring_status=1 fpdsh -l ${SERVERS} -p ${CONCURRENCY} -c \"sudo puppet agent --disable '${PUPPET_DISABLE_REASON}' && sudo service cron stop\" Re-enabling the puppet agent If the puppet agent has been disabled based on the previous section ( Disabling the puppet agent ), you need to follow these steps to be able to run puppet again as part of other/remaining steps in the runbook. SERVERS= ah-server edit ${SERVERS} -s monitoring_status=2 fpdsh -l ${SERVERS} -p ${CONCURRENCY} -c \"sudo puppet agent --enable && sudo service cron start\" Verification Run the following command to audit the stage. It will let you know if any of the puppet runs didn't successfully deploy the hosting release specified in $VERSION. release-audit ${CONCURRENCY}","title":"1.81 Hosting Release"},{"location":"kanban_tickets/1.81_release/#181-hosting-release","text":"This procedure will release a fields 1.81 tag to the search stage. This process is designed to have no loss in read access and, in rare cases, a brief loss of write access depending on what is being changed. This procedure will release to the entire search stage.","title":"1.81 Hosting Release"},{"location":"kanban_tickets/1.81_release/#procedure","text":"These commands should be run on the bastion. Use the 'asearch' command to set the environment to the search stage. Note: To login Search jumpboxes, follow these instructions Gather information about the tag. git fetch git tag # Check if the git tag you want already exists, if it does don't create a new tag Export tag name that will be used throughout the release. # If the tag exists, use its name, otherwise bump the version from the newest tag from the step before. For this example, we assume the tag you want doesn't exist and its name will be 1.81.65 export VERSION=\"1_81_65\" export VERSION_DOTS=\"1.81.65\" If there isn't already a git tag, cut and push a new tag to git. git pull origin 1.81 git log --pretty=oneline 1.81...$tag to verify commits # verify the commits match the 1.81 branch commits in github git tag ${VERSION_DOTS} git push origin ${VERSION_DOTS} Set other environment variables. # Gather lists of running servers by type export MASTERS_RUNNING=$(ah-server list % -w type=javasrv status=0 | sort -R | paste -sd,) export SLAVES_RUNNING=$(ah-server list % -w type=javaephem status=0 | sort -R | paste -sd,) export CANARY_SERVERS_1='nxephem-193,javasrv-67' export CANARY_SERVERS_2='nxephem-194,javaephem-68' # Setup logging and concurrency CONCURRENCY=20 LOG=${OPSLOG}/${USER}.${FIELDS_STAGE}.${VERSION}.$(date +%F).log Update packages on all servers. First all other servers and then the master. fpdsh -t % -p 100 -c \"sudo apt-get update\" fssh master sudo apt-get update Deploy the git tag to the stage. This will checkout the git tag in the master. ah-release deploy -t ${VERSION_DOTS} --debug Switch the hosting version on the master, run puppet and verify that the correct hosting tag was deployed. ./fields-provision.php --switch-version master::${VERSION} fssh master \"sudo -H /bin/bash -c 'puppet agent --test'\" fssh master 'sudo cat /var/acquia/HOSTING_VERSION' # verify its on the right version Switch the hosting version on the backup and run puppet. ah-server edit backup-% -s hosting_version=${VERSION} fpdsh -t backup-% -c \"sudo -H /bin/bash -c 'puppet agent --test'\" Deploy the hosting version to the canary colony. Note: see sections Disabling the puppet agent and Re-enabling the puppet agent if you need to avoid unattended puppet runs during this release in order to maintain high-availability. ./fields-provision.php --switch-version ${CANARY_SERVERS_1}::${VERSION} fpdsh -l ${CANARY_SERVERS_1} -p ${CONCURRENCY} -c \"sudo -H /bin/bash -c 'puppet agent -t'\" 2>&1 | tee -a ${LOG} ./fields-provision.php --switch-version ${CANARY_SERVERS_2}::${VERSION} fpdsh -l ${CANARY_SERVERS_2} -p ${CONCURRENCY} -c \"sudo -H /bin/bash -c 'puppet agent -t'\" 2>&1 | tee -a ${LOG} Ping acquia.com's index to make sure the canary servers step before was succesful governor index:ping GIKU-17871 Set the default hosting version for all servers in the stage. ./fields-provision.php --set-default-version ${VERSION} Switch the hosting version on the rest of the servers in the stage. ./fields-provision.php --switch-version $(ah-server list % | paste -sd,)::${VERSION} Run puppet on all javasrvs. fpdsh -l ${MASTERS_RUNNING} -p ${CONCURRENCY} -c \"sudo -H /bin/bash -c 'puppet agent -t'\" 2>&1 | tee -a ${LOG} Run puppet on all javaephems. fpdsh -l ${SLAVES_RUNNING} -p ${CONCURRENCY} -c \"sudo -H /bin/bash -c 'puppet agent -t'\" 2>&1 | tee -a ${LOG} Run puppet on all nxephems. We can only do one availability zone per region at a time so there will be 3 seperate batches. Note: if you have disabled the puppet agent, you need to re-enable it first before running puppet on each group (see section Re-enabling the puppet agent ). # Run puppet on all nxephems in the first AZ in every region NXEPHEMS_ONE=$(ah-server list % -w type=nxephem ec2_availability_zoneINap-southeast-1a,ap-southeast-2a,eu-west-1a,us-east-1b,us-west-2a | paste -sd,) fpdsh -l ${NXEPHEMS_ONE} -p ${CONCURRENCY} -c \"sudo -H /bin/bash -c 'puppet agent -t'\" 2>&1 | tee -a ${LOG} # Then the second AZ in every region NXEPHEMS_TWO=$(ah-server list % -w type=nxephem ec2_availability_zoneINap-southeast-1b,ap-southeast-2b,eu-west-1b,us-east-1c,us-west-2b | paste -sd,) fpdsh -l ${NXEPHEMS_TWO} -p ${CONCURRENCY} -c \"sudo -H /bin/bash -c 'puppet agent -t'\" 2>&1 | tee -a ${LOG} # Then the third AZ in every region NXEPHEMS_THREE=$(ah-server list % -w type=nxephem ec2_availability_zoneINeu-west-1c,us-east-1d,us-west-2c | paste -sd,) fpdsh -l ${NXEPHEMS_THREE} -p ${CONCURRENCY} -c \"sudo -H /bin/bash -c 'puppet agent -t'\" 2>&1 | tee -a ${LOG} Run puppet on the rest of the server types in the search stage. This includes svn, log, stats, ossec and mon. OTHER_SERVERS=$(ah-server list % -w typeINsvn,log,stats,ossec,mon | paste -sd,) fpdsh -l ${OTHER_SERVERS} -p ${CONCURRENCY} -c \"sudo -H /bin/bash -c 'puppet agent -t'\" 2>&1 | tee -a ${LOG} Get someone with sudo access on the bastion to deploy the hosting version to the bastion. Shane Van Hart is able to do this.","title":"Procedure"},{"location":"kanban_tickets/1.81_release/#optional-steps","text":"","title":"Optional steps"},{"location":"kanban_tickets/1.81_release/#disabling-the-puppet-agent","text":"There are code releases in which it may be necessary to keep some servers from running puppet, as this may result in an out-of-order interruption of the service. An example of this is changing the pinned version of nginx on nxephem servers, which would result in puppet restarting the service. To avoid this scenario, you should disable the puppet agent first: SERVERS= PUPPET_DISABLE_REASON= ah-server edit ${SERVERS} -s monitoring_status=1 fpdsh -l ${SERVERS} -p ${CONCURRENCY} -c \"sudo puppet agent --disable '${PUPPET_DISABLE_REASON}' && sudo service cron stop\"","title":"Disabling the puppet agent"},{"location":"kanban_tickets/1.81_release/#re-enabling-the-puppet-agent","text":"If the puppet agent has been disabled based on the previous section ( Disabling the puppet agent ), you need to follow these steps to be able to run puppet again as part of other/remaining steps in the runbook. SERVERS= ah-server edit ${SERVERS} -s monitoring_status=2 fpdsh -l ${SERVERS} -p ${CONCURRENCY} -c \"sudo puppet agent --enable && sudo service cron start\"","title":"Re-enabling the puppet agent"},{"location":"kanban_tickets/1.81_release/#verification","text":"Run the following command to audit the stage. It will let you know if any of the puppet runs didn't successfully deploy the hosting release specified in $VERSION. release-audit ${CONCURRENCY}","title":"Verification"},{"location":"kanban_tickets/acquiamail/","text":"Acquiamail.acquia.com Dump Restore Overview acquiamail.acquia.com runs a MySQL server that all other acquiamail*.acquia.com hosts receive binlogs from. Occasionally (as evidenced in OP-72265 ) a host may stop receiving events from the master and mail for newly-launched or relaunched instances will not be relayed due to the instances' information not being populated in the database running on each one of the hosts. In order to resolve this, you can attempt to perform a dump-restore. Procedure Specify the ticket information and the target acquiamail server fully-qualified host name TICKET= TARGET_SERVER= Perform a dump of the master's database TICKET= mysqldump -cK --master-data=1 --single-transaction exim | pv | gzip > /tmp/${TICKET}_dump_restore_$(date +%F).sql.gz Copy the file down to the bastion scp ${USER}@acquiamail.acquia.com:/tmp/${TICKET}_dump_restore_$(date +%F).sql.gz \\ $OPSTMP/${TICKET}_dump_restore_$(date +%F).sql.gz Copy the file to the target server scp $OPSTMP/${TICKET}_dump_restore_$(date +%F).sql.gz ${USER}@${TARGET_SERVER}:/tmp/ Copy the MySQL directory on the target server out of the way cp -a /var/lib/mysql /var/lib/mysql.${TICKET} Stop the slave mysql -e 'stop slave;' Perform the dump restore zcat /tmp/${TICKET}_dump_restore_$(date +%F).sql.gz | mysql exim On the master ( acquiamail.acquia.com ), look up the binlog file and position mysql -e 'show master status\\G' | grep File | awk {'print $2'} mysql -e 'show master status\\G' | grep Position | awk {'print $2'} Attempt to start the slave thread mysql -e 'start slave;' Check the slave status mysql -e 'show slave status\\G' Tail the mysql error log tail /var/log/mysql/error.log If the replication thread cannot connect or the \"Last_Error\" field is populated, document the full output of the command and the relevant lines from /var/log/mysql/error.log in the OP and escalate to another Ops team member or DBA.","title":"Acquiamail.acquia.com Dump Restore"},{"location":"kanban_tickets/acquiamail/#acquiamailacquiacom-dump-restore","text":"","title":"Acquiamail.acquia.com Dump Restore"},{"location":"kanban_tickets/acquiamail/#overview","text":"acquiamail.acquia.com runs a MySQL server that all other acquiamail*.acquia.com hosts receive binlogs from. Occasionally (as evidenced in OP-72265 ) a host may stop receiving events from the master and mail for newly-launched or relaunched instances will not be relayed due to the instances' information not being populated in the database running on each one of the hosts. In order to resolve this, you can attempt to perform a dump-restore.","title":"Overview"},{"location":"kanban_tickets/acquiamail/#procedure","text":"Specify the ticket information and the target acquiamail server fully-qualified host name TICKET= TARGET_SERVER= Perform a dump of the master's database TICKET= mysqldump -cK --master-data=1 --single-transaction exim | pv | gzip > /tmp/${TICKET}_dump_restore_$(date +%F).sql.gz Copy the file down to the bastion scp ${USER}@acquiamail.acquia.com:/tmp/${TICKET}_dump_restore_$(date +%F).sql.gz \\ $OPSTMP/${TICKET}_dump_restore_$(date +%F).sql.gz Copy the file to the target server scp $OPSTMP/${TICKET}_dump_restore_$(date +%F).sql.gz ${USER}@${TARGET_SERVER}:/tmp/ Copy the MySQL directory on the target server out of the way cp -a /var/lib/mysql /var/lib/mysql.${TICKET} Stop the slave mysql -e 'stop slave;' Perform the dump restore zcat /tmp/${TICKET}_dump_restore_$(date +%F).sql.gz | mysql exim On the master ( acquiamail.acquia.com ), look up the binlog file and position mysql -e 'show master status\\G' | grep File | awk {'print $2'} mysql -e 'show master status\\G' | grep Position | awk {'print $2'} Attempt to start the slave thread mysql -e 'start slave;' Check the slave status mysql -e 'show slave status\\G' Tail the mysql error log tail /var/log/mysql/error.log If the replication thread cannot connect or the \"Last_Error\" field is populated, document the full output of the command and the relevant lines from /var/log/mysql/error.log in the OP and escalate to another Ops team member or DBA.","title":"Procedure"},{"location":"kanban_tickets/acsf_deprovision/","text":"Site Factory Sitegroup Deprovisioning Preparation The AM needs to approve in the ticket before proceeding. Verify that the AM that approved is the AM listed in CCI. If you cannot find the subscription in CCI, then it is likely that the AM has already deleted it. Run acsf-sitegroupterminate to get a list of everything associated with the sitegroup to be deprovisioned. Execute the commands given by acsf-sitegroupterminate with caution! Usage Examples and Useful Some-Liners Usage of acsf-sitegroupterminate $ acsf-sitegroupterminate ERROR: Invalid number of arguments. /mnt/apps/ops-misc/master/bin/acsf-sitegroupterminate CUSTOMER_NAME JIRA_TICKET [OP-12345] $ acsf-sitegroupterminate training01 OP-12345 ... List sitegroups ah-sitegroup list ${CUSTOMER}% List sites ah-site list % -w sitegroupIN${SITEGROUPS_CSV} List servers for site in ${SITES}; do ah-server list site:${site} -w \"type NOT IN svn\" done | sort | uniq List sites on servers for srv in ${SERVERS}; do echo ${srv}: $(ah-site list on:${srv} | paste -sd,); done Deprovisioning Site and/or hardware deprovisioning is done in two stages, suspension and termination, in order to allow a 7-day window of opportunity to undo any mistakes or miscommunication before data is lost. Do not terminate anything without this window unless you have explicit customer/AM approval! Additionally, customers in Acquia Site Factory environments have 3 sitegroups associated with them. These sitegroups often ( but not always ) have the following naming convention, ${CUSTOMER} , ${CUSTOMER}sf , ${CUSTOMER}theme . These sitegroups cannot be deprovisioned independently of one another. Suspension Check perf-mon for any production sites in monitoring and remove them: site-mondisable $SITE If there are other sites that will remain on the hardware, add the first site on the primary DB-class instance to monitoring: site-monenable $(ah-site list on:$DBMASTER | head -n1) If there are no other sites on them, suspend the servers: ah-server suspend $SERVERS Update Jira Create a TSR ticket and set the Start After field for 7 days from now and the Finish Before field for any day after that. Paste the commands to execute for full termination into the description. See termination , for examples of what to include. Link the TSR ticket to the original ticket. Select 'Move to Kanban', this will allow it to appear when the Start After date has passed Terminating single stack out of site factory setup Sometimes, you will be asked to terminate single stack (original or the add-ons) stack from the factory setup. While there is no tooling available for it as of now and there is a ticket for it DG-24954 , you must ensure the ticket has neccessary information available before proceeding. Ticket should have exact information which environments and servers need to deprovisioned. Ask the requestor for clear information if not available. Information about the stack i.e. if it is parent stack originally created as part of site factory provision or an add on stack. If it is parent stack, then we need to get the information about the add on stack using the following command: CUSTOMER_NAME= # The parent stack name without sf or 01live rm -rf ~/.gittools/ git clone -q --depth 1 --single-branch git@github.com:acquia/gittools.git ~/.gittools /mnt/apps/ops-misc/master/rubybin/acsf-findcustomerstacks.rb $CUSTOMER_NAME ~/.gittools/build-tools/customers_info_v2.yml #Use rubybin path till [OP-318674](https://backlog.acquia.com/browse/OP-318674) is fixed. This should give an output like the following: [cloudservicesdev|enterprise-g1:enterprise-g1] ~/fields/1.148$ /mnt/apps/ops-misc/master/rubybin/acsf-findcustomerstacks.rb fanniemaesf ~/.gittools/build-tools/customers_info_v2.yml fanniemaesf 01 prod test dev uat prev fnmmultifamily 02 prod test dev uat prev In above output - fanniemaesf is parent stack and fnmmultifamily is add on stack. If you are asked to deprovision the parent stack - you will need to ensure the DNS for acsitefactory.com is updated before the TSR process. For this purpose, get all the environments for the add on stack like below: [cloudservicesdev|enterprise-g1:enterprise-g1] ~/fields/1.148$ ah-site list fnmmultifamily% fnmmultifamily02live fnmmultifamily02update fnmmultifamily02test fnmmultifamily02testup fnmmultifamily02dev fnmmultifamily02devup fnmmultifamily02theme fnmmultifamily02uat fnmmultifamily02uatup fnmmultifamily02prev fnmmultifamily02prevup fnmmultifamilyprod #Ignore these as these are proxy env fnmmultifamilytest #Ignore these as these are proxy env fnmmultifamilydev #Ignore these as these are proxy env fnmmultifamilyuat #Ignore these as these are proxy env fnmmultifamilyprev #Ignore these as these are proxy env For each environment, run this command to get how many acsitefactory.com domains are pointed to parent stack DNS: site-domainshost $ENVIRONMENT_NAME | grep acsitefactory.com Note that the process is going to be manual here: An example if given below - The domain mfguide.fanniemaesf.acsitefactory.com belongs to prod environment of add on stack and the CNAME should go to fnmmultifamily02live.enterprise-g1.acquia-sites.com i.e. Acquia default FQDN for the prod add on stack. Similarly - the test environment domain should be mapped to test environment FQDN of add on stack. [cloudservicesdev|enterprise-g1:enterprise-g1] ~/fields/1.148$ site-domainshost fnmmultifamily02live | grep acsitefactory.com mfguide.fanniemaesf.acsitefactory.com mfguide.fanniemaesf.acsitefactory.com is an alias for fanniemaesf01live.enterprise-g1.acquia-sites.com. ah-dns set -t CNAME -h mfguide.fanniemaesf.acsitefactory.com -v fnmmultifamily02live.enterprise-g1.acquia-sites.com [cloudservicesdev|enterprise-g1:enterprise-g1] ~/fields/1.148$ site-domainshost fnmmultifamily02test | grep acsitefactory.com mfguide.test-fanniemaesf.acsitefactory.com mfguide.test-fanniemaesf.acsitefactory.com is an alias for fanniemaesf01test.enterprise-g1.acquia-sites.com. ah-dns set -t CNAME -h mfguide.test-fanniemaesf.acsitefactory.com -v fnmmultifamily02test.enterprise-g1.acquia-sites.com Once these steps are done, you can use the acsf-sitegroupterminate command but run the commands carefully and remove the environments and servers from the commands mentioned by the ticket requestor or the Site factory team. Do not delete ELB as well since the add on stacks and site factory still needs it to be running. Termination Sanity-check the commands given in the TSR ticket and verify that it has been at least 7 days since the hardware was suspended. WARNING: Deleting a site cannot be undone by OPS. If you accidentally delete a site or are asked to restore a deleted site, you must Escalate to Cloud ! Deprovision site ELBs: ah-site ssl deprovision-elb $SITE For each sitegroup: ah-sitegroup delete $SITEGROUP Terminate unshared hardware: ah-server terminate $SERVERS After terminating the hardware remove the lingering associations between sites and webnodes: execute the commands outputted by sv-unlink $SERVERS If the customer is being terminated and has a dedicated VPC/VPN, deprovision them . If the customer has a custom VCL, submit a pull request to remove their VCL file from the hosting-vcl-files repo","title":"Site Factory Sitegroup Deprovisioning"},{"location":"kanban_tickets/acsf_deprovision/#site-factory-sitegroup-deprovisioning","text":"","title":"Site Factory Sitegroup Deprovisioning"},{"location":"kanban_tickets/acsf_deprovision/#preparation","text":"The AM needs to approve in the ticket before proceeding. Verify that the AM that approved is the AM listed in CCI. If you cannot find the subscription in CCI, then it is likely that the AM has already deleted it. Run acsf-sitegroupterminate to get a list of everything associated with the sitegroup to be deprovisioned. Execute the commands given by acsf-sitegroupterminate with caution!","title":"Preparation"},{"location":"kanban_tickets/acsf_deprovision/#usage-examples-and-useful-some-liners","text":"","title":"Usage Examples and Useful Some-Liners"},{"location":"kanban_tickets/acsf_deprovision/#usage-of-acsf-sitegroupterminate","text":"$ acsf-sitegroupterminate ERROR: Invalid number of arguments. /mnt/apps/ops-misc/master/bin/acsf-sitegroupterminate CUSTOMER_NAME JIRA_TICKET [OP-12345] $ acsf-sitegroupterminate training01 OP-12345 ...","title":"Usage of acsf-sitegroupterminate"},{"location":"kanban_tickets/acsf_deprovision/#list-sitegroups","text":"ah-sitegroup list ${CUSTOMER}%","title":"List sitegroups"},{"location":"kanban_tickets/acsf_deprovision/#list-sites","text":"ah-site list % -w sitegroupIN${SITEGROUPS_CSV}","title":"List sites"},{"location":"kanban_tickets/acsf_deprovision/#list-servers","text":"for site in ${SITES}; do ah-server list site:${site} -w \"type NOT IN svn\" done | sort | uniq","title":"List servers"},{"location":"kanban_tickets/acsf_deprovision/#list-sites-on-servers","text":"for srv in ${SERVERS}; do echo ${srv}: $(ah-site list on:${srv} | paste -sd,); done","title":"List sites on servers"},{"location":"kanban_tickets/acsf_deprovision/#deprovisioning","text":"Site and/or hardware deprovisioning is done in two stages, suspension and termination, in order to allow a 7-day window of opportunity to undo any mistakes or miscommunication before data is lost. Do not terminate anything without this window unless you have explicit customer/AM approval! Additionally, customers in Acquia Site Factory environments have 3 sitegroups associated with them. These sitegroups often ( but not always ) have the following naming convention, ${CUSTOMER} , ${CUSTOMER}sf , ${CUSTOMER}theme . These sitegroups cannot be deprovisioned independently of one another.","title":"Deprovisioning"},{"location":"kanban_tickets/acsf_deprovision/#suspension","text":"Check perf-mon for any production sites in monitoring and remove them: site-mondisable $SITE If there are other sites that will remain on the hardware, add the first site on the primary DB-class instance to monitoring: site-monenable $(ah-site list on:$DBMASTER | head -n1) If there are no other sites on them, suspend the servers: ah-server suspend $SERVERS Update Jira Create a TSR ticket and set the Start After field for 7 days from now and the Finish Before field for any day after that. Paste the commands to execute for full termination into the description. See termination , for examples of what to include. Link the TSR ticket to the original ticket. Select 'Move to Kanban', this will allow it to appear when the Start After date has passed","title":"Suspension"},{"location":"kanban_tickets/acsf_deprovision/#terminating-single-stack-out-of-site-factory-setup","text":"Sometimes, you will be asked to terminate single stack (original or the add-ons) stack from the factory setup. While there is no tooling available for it as of now and there is a ticket for it DG-24954 , you must ensure the ticket has neccessary information available before proceeding. Ticket should have exact information which environments and servers need to deprovisioned. Ask the requestor for clear information if not available. Information about the stack i.e. if it is parent stack originally created as part of site factory provision or an add on stack. If it is parent stack, then we need to get the information about the add on stack using the following command: CUSTOMER_NAME= # The parent stack name without sf or 01live rm -rf ~/.gittools/ git clone -q --depth 1 --single-branch git@github.com:acquia/gittools.git ~/.gittools /mnt/apps/ops-misc/master/rubybin/acsf-findcustomerstacks.rb $CUSTOMER_NAME ~/.gittools/build-tools/customers_info_v2.yml #Use rubybin path till [OP-318674](https://backlog.acquia.com/browse/OP-318674) is fixed. This should give an output like the following: [cloudservicesdev|enterprise-g1:enterprise-g1] ~/fields/1.148$ /mnt/apps/ops-misc/master/rubybin/acsf-findcustomerstacks.rb fanniemaesf ~/.gittools/build-tools/customers_info_v2.yml fanniemaesf 01 prod test dev uat prev fnmmultifamily 02 prod test dev uat prev In above output - fanniemaesf is parent stack and fnmmultifamily is add on stack. If you are asked to deprovision the parent stack - you will need to ensure the DNS for acsitefactory.com is updated before the TSR process. For this purpose, get all the environments for the add on stack like below: [cloudservicesdev|enterprise-g1:enterprise-g1] ~/fields/1.148$ ah-site list fnmmultifamily% fnmmultifamily02live fnmmultifamily02update fnmmultifamily02test fnmmultifamily02testup fnmmultifamily02dev fnmmultifamily02devup fnmmultifamily02theme fnmmultifamily02uat fnmmultifamily02uatup fnmmultifamily02prev fnmmultifamily02prevup fnmmultifamilyprod #Ignore these as these are proxy env fnmmultifamilytest #Ignore these as these are proxy env fnmmultifamilydev #Ignore these as these are proxy env fnmmultifamilyuat #Ignore these as these are proxy env fnmmultifamilyprev #Ignore these as these are proxy env For each environment, run this command to get how many acsitefactory.com domains are pointed to parent stack DNS: site-domainshost $ENVIRONMENT_NAME | grep acsitefactory.com Note that the process is going to be manual here: An example if given below - The domain mfguide.fanniemaesf.acsitefactory.com belongs to prod environment of add on stack and the CNAME should go to fnmmultifamily02live.enterprise-g1.acquia-sites.com i.e. Acquia default FQDN for the prod add on stack. Similarly - the test environment domain should be mapped to test environment FQDN of add on stack. [cloudservicesdev|enterprise-g1:enterprise-g1] ~/fields/1.148$ site-domainshost fnmmultifamily02live | grep acsitefactory.com mfguide.fanniemaesf.acsitefactory.com mfguide.fanniemaesf.acsitefactory.com is an alias for fanniemaesf01live.enterprise-g1.acquia-sites.com. ah-dns set -t CNAME -h mfguide.fanniemaesf.acsitefactory.com -v fnmmultifamily02live.enterprise-g1.acquia-sites.com [cloudservicesdev|enterprise-g1:enterprise-g1] ~/fields/1.148$ site-domainshost fnmmultifamily02test | grep acsitefactory.com mfguide.test-fanniemaesf.acsitefactory.com mfguide.test-fanniemaesf.acsitefactory.com is an alias for fanniemaesf01test.enterprise-g1.acquia-sites.com. ah-dns set -t CNAME -h mfguide.test-fanniemaesf.acsitefactory.com -v fnmmultifamily02test.enterprise-g1.acquia-sites.com Once these steps are done, you can use the acsf-sitegroupterminate command but run the commands carefully and remove the environments and servers from the commands mentioned by the ticket requestor or the Site factory team. Do not delete ELB as well since the add on stacks and site factory still needs it to be running.","title":"Terminating single stack out of site factory setup"},{"location":"kanban_tickets/acsf_deprovision/#termination","text":"Sanity-check the commands given in the TSR ticket and verify that it has been at least 7 days since the hardware was suspended. WARNING: Deleting a site cannot be undone by OPS. If you accidentally delete a site or are asked to restore a deleted site, you must Escalate to Cloud ! Deprovision site ELBs: ah-site ssl deprovision-elb $SITE For each sitegroup: ah-sitegroup delete $SITEGROUP Terminate unshared hardware: ah-server terminate $SERVERS After terminating the hardware remove the lingering associations between sites and webnodes: execute the commands outputted by sv-unlink $SERVERS If the customer is being terminated and has a dedicated VPC/VPN, deprovision them . If the customer has a custom VCL, submit a pull request to remove their VCL file from the hosting-vcl-files repo","title":"Termination"},{"location":"kanban_tickets/acsf_proxy/","text":"Identify ACSF Follower and Proxy Environments ACSF maintains a relationship between environments, such as the pairing of the acsfvpc101live and acsfvpc101update environments. Previously these two environments (and other such relationships) were individually managed and kept in sync manually. To ease this management a new type of environment was created: a special type of environment termed a \"proxy\" to which other environments will \"follow\"'. A proxy is the parent environment that follower environments will inherit some configurations from. Follower environments are child environments that are connected to the proxy. Configurations that can be set at the proxy level cannot be set on the follower. Hosting-API will throw an error if that is attempted. SITE='acsfvpc101live' ah-site edit $SITE -c php.ini:memory_limit=192M /mnt/apps/fields/1.122/aq/lib/aq/hosting/api_client.rb:196:in `rescue in with_retries': Setting php.ini:memory_limit on follower environments directly is not allowed (Aq::Hosting::ApiClient::XMLRPCRemoteException) Identifying Proxy Environments # SITE is the site name of one of the ACSF environments SITE='acsfvpc101live' FOLLOWER_UUID=$(ah-site list $SITE --no-name -c uuid) PROXY_UUID=$(ah-site config_proxy get-proxy $FOLLOWER_UUID | awk '/environment_uuid/ { getline; print $3 }') ah-site list % -w uuid=$PROXY_UUID In case the proxy environment does not exist an error will be raised SITE='acsfvpc1sf' FOLLOWER_UUID=$(ah-site list $SITE --no-name -c uuid) PROXY_UUID=$(ah-site config_proxy get-proxy $FOLLOWER_UUID | awk '/environment_uuid/ { getline; print $3 }') RequestError: site with follower_environment_uuid '243884c2-9dfd-46ff-b84b-cc8dc677e67a' not found. Identifying Follower Environments PROXY_SITE='acsfvpc1prod' PROXY_UUID=$(ah-site list $PROXY_SITE --no-name -c uuid) FOLLOWER_SITE_IDS=$(ah-site config_proxy get-followers $PROXY_UUID | perl -ne 'print \"$1\\n\" if / ([\\d]+) /' | tr '\\n' ',') ah-site list % -w idIN${FOLLOWER_SITE_IDS}","title":"Identify ACSF Follower and Proxy Environments"},{"location":"kanban_tickets/acsf_proxy/#identify-acsf-follower-and-proxy-environments","text":"ACSF maintains a relationship between environments, such as the pairing of the acsfvpc101live and acsfvpc101update environments. Previously these two environments (and other such relationships) were individually managed and kept in sync manually. To ease this management a new type of environment was created: a special type of environment termed a \"proxy\" to which other environments will \"follow\"'. A proxy is the parent environment that follower environments will inherit some configurations from. Follower environments are child environments that are connected to the proxy. Configurations that can be set at the proxy level cannot be set on the follower. Hosting-API will throw an error if that is attempted. SITE='acsfvpc101live' ah-site edit $SITE -c php.ini:memory_limit=192M /mnt/apps/fields/1.122/aq/lib/aq/hosting/api_client.rb:196:in `rescue in with_retries': Setting php.ini:memory_limit on follower environments directly is not allowed (Aq::Hosting::ApiClient::XMLRPCRemoteException)","title":"Identify ACSF Follower and Proxy Environments"},{"location":"kanban_tickets/acsf_proxy/#identifying-proxy-environments","text":"# SITE is the site name of one of the ACSF environments SITE='acsfvpc101live' FOLLOWER_UUID=$(ah-site list $SITE --no-name -c uuid) PROXY_UUID=$(ah-site config_proxy get-proxy $FOLLOWER_UUID | awk '/environment_uuid/ { getline; print $3 }') ah-site list % -w uuid=$PROXY_UUID In case the proxy environment does not exist an error will be raised SITE='acsfvpc1sf' FOLLOWER_UUID=$(ah-site list $SITE --no-name -c uuid) PROXY_UUID=$(ah-site config_proxy get-proxy $FOLLOWER_UUID | awk '/environment_uuid/ { getline; print $3 }') RequestError: site with follower_environment_uuid '243884c2-9dfd-46ff-b84b-cc8dc677e67a' not found.","title":"Identifying Proxy Environments"},{"location":"kanban_tickets/acsf_proxy/#identifying-follower-environments","text":"PROXY_SITE='acsfvpc1prod' PROXY_UUID=$(ah-site list $PROXY_SITE --no-name -c uuid) FOLLOWER_SITE_IDS=$(ah-site config_proxy get-followers $PROXY_UUID | perl -ne 'print \"$1\\n\" if / ([\\d]+) /' | tr '\\n' ',') ah-site list % -w idIN${FOLLOWER_SITE_IDS}","title":"Identifying Follower Environments"},{"location":"kanban_tickets/add_custom_proxy_conf/","text":"Add a custom Mod-Proxy file to a Site This procedure is for adding a custom proxy.conf file to a customer's site. Enabling mod_proxy Step Prior to to the following steps the Apache proxy module needs to be enabled. Please see enabling mod_proxy first. Ticket Requirements The requester should provide the following things: A single mod-proxy configuration file. Here's an example one: proxy-sford.conf A dedicated staging server to test the config on. Customers with shared staging equipment won't be able to test their rules. Testing on a dedicated staging Set these variables: export OPS_TICKET= export SERVER= Stop cron and puppet on the staging server puppet agent --disable \"$OPS_TICKET - $USER - Testing mod_proxy file\" ah-runbook \"$OPS_TICKET - $USER - Testing mod_proxy file\" service cron stop OR in Masterless Puppet mode ah-puppet-disable \"$OPS_TICKET - $USER - Testing mod_proxy file\" ah-runbook \"$OPS_TICKET - $USER - Testing mod_proxy file\" service cron stop Install the proxy module and enable related stuff # @TODO: Remove this when CL-16933 is completed. apt-get install libapache2-mod-proxy-html a2enmod proxy a2enmod proxy_http a2enmod proxy_connect a2enmod ssl Copy the customer's proxy config file to the staging server URL= wget -O /etc/apache2/mods-enabled/proxy.conf \\ --no-check-certificate $URL Test the file with: apache2ctl -t ... and if all is good service apache2 restart Downtime the puppet disable alert and services alert sv-downtimeservice $SERVER 'Puppet Agent Disabled' 10080 $OPS_TICKET sv-downtimeservice $SERVER 'Services Check' 10080 $OPS_TICKET After tests are done re-enable and run puppet on the staging server puppet agent --enable puppet agent -t OR in Masterless Puppet mode sudo ah-puppet-enable sudo run-puppet Review When the customer/support agrees with the changes we can create a pull request of that file against the master branch of the fields codebase. Once merged, backport the same changes to the releases you need it in. Rules for mod_proxy are stored in puppet/versions/devel/modules/httpd/files in the form of proxy-$SITEGROUP.conf Deploy once the change has been hotfixed To enable it for a server, you have to set up the following server config: ah-server edit $SERVER --config=puppet:mod_proxy=add puppet:proxy_config=$SITEGROUP The puppet manifest that achieves this is puppet/versions/devel/modules/http/manifests/mod_proxy.pp . Done","title":"Add a custom Mod-Proxy file to a Site"},{"location":"kanban_tickets/add_custom_proxy_conf/#add-a-custom-mod-proxy-file-to-a-site","text":"This procedure is for adding a custom proxy.conf file to a customer's site.","title":"Add a custom Mod-Proxy file to a Site"},{"location":"kanban_tickets/add_custom_proxy_conf/#enabling-mod_proxy-step","text":"Prior to to the following steps the Apache proxy module needs to be enabled. Please see enabling mod_proxy first.","title":"Enabling mod_proxy Step"},{"location":"kanban_tickets/add_custom_proxy_conf/#ticket-requirements","text":"The requester should provide the following things: A single mod-proxy configuration file. Here's an example one: proxy-sford.conf A dedicated staging server to test the config on. Customers with shared staging equipment won't be able to test their rules.","title":"Ticket Requirements"},{"location":"kanban_tickets/add_custom_proxy_conf/#testing-on-a-dedicated-staging","text":"Set these variables: export OPS_TICKET= export SERVER= Stop cron and puppet on the staging server puppet agent --disable \"$OPS_TICKET - $USER - Testing mod_proxy file\" ah-runbook \"$OPS_TICKET - $USER - Testing mod_proxy file\" service cron stop OR in Masterless Puppet mode ah-puppet-disable \"$OPS_TICKET - $USER - Testing mod_proxy file\" ah-runbook \"$OPS_TICKET - $USER - Testing mod_proxy file\" service cron stop Install the proxy module and enable related stuff # @TODO: Remove this when CL-16933 is completed. apt-get install libapache2-mod-proxy-html a2enmod proxy a2enmod proxy_http a2enmod proxy_connect a2enmod ssl Copy the customer's proxy config file to the staging server URL= wget -O /etc/apache2/mods-enabled/proxy.conf \\ --no-check-certificate $URL Test the file with: apache2ctl -t ... and if all is good service apache2 restart Downtime the puppet disable alert and services alert sv-downtimeservice $SERVER 'Puppet Agent Disabled' 10080 $OPS_TICKET sv-downtimeservice $SERVER 'Services Check' 10080 $OPS_TICKET After tests are done re-enable and run puppet on the staging server puppet agent --enable puppet agent -t OR in Masterless Puppet mode sudo ah-puppet-enable sudo run-puppet","title":"Testing on a dedicated staging"},{"location":"kanban_tickets/add_custom_proxy_conf/#review","text":"When the customer/support agrees with the changes we can create a pull request of that file against the master branch of the fields codebase. Once merged, backport the same changes to the releases you need it in. Rules for mod_proxy are stored in puppet/versions/devel/modules/httpd/files in the form of proxy-$SITEGROUP.conf","title":"Review"},{"location":"kanban_tickets/add_custom_proxy_conf/#deploy-once-the-change-has-been-hotfixed","text":"To enable it for a server, you have to set up the following server config: ah-server edit $SERVER --config=puppet:mod_proxy=add puppet:proxy_config=$SITEGROUP The puppet manifest that achieves this is puppet/versions/devel/modules/http/manifests/mod_proxy.pp .","title":"Deploy once the change has been hotfixed"},{"location":"kanban_tickets/add_custom_proxy_conf/#done","text":"","title":"Done"},{"location":"kanban_tickets/add_remove_site_mon/","text":"Add/Remove Sites to/from Monitoring There are different procedures for adding and removing sites vs URLs from monitoring. Monitoring Sites - ACE Pretty much every cluster should have one production site in monitoring. Add ACE site to monitoring site-mon add $SITENAME Remove ACE site from monitoring site-mon remove $SITENAME Monitoring URLs - Site Factory Add ACSF site to monitoring Determine the fields site that it belongs to. REQUESTED_URL= BASE_URL=$(echo ${REQUESTED_URL} | cut -d'/' -f1) SITENAME=$(ah-site list domain:${BASE_URL}) if [[ -z \"${SITENAME}\" ]]; then echo \"ERROR: ${REQUESTED_URL} is not associated with any known site, aborting.\" else echo \"OK: ${BASE_URL} is assigned to ${SITENAME}.\" fi Add the site to monitoring. acsf-site-mon add ${SITENAME} ${REQUESTED_URL} Remove ACSF site from monitoring Determine the fields site that it belongs to. REQUESTED_URL= BASE_URL=$(echo ${REQUESTED_URL} | cut -d'/' -f1) SITENAME=$(ah-site list domain:${BASE_URL}) if [[ -z \"${SITENAME}\" ]]; then echo \"ERROR: ${REQUESTED_URL} is not associated with any known site, aborting.\" else echo \"OK: ${BASE_URL} is assigned to ${SITENAME}.\" fi Remove the site from monitoring. acsf-site-mon remove ${SITENAME} ${REQUESTED_URL} Site's monitoring status also needs to be changed in order to remove fields site's monitoring. site-mondisable ${SITENAME} Monitoring Sites - ACP & Network Typically few sites are enabled for monitoring in acp and network, ensure that a ticket has requested it specifically. Add site to monitoring site-monenable ${SITENAME} Remove site from monitoring site-mondisable ${SITENAME} Note: 'monitoring_status' shows if the site is being monitored or not. So, always make sure if at least 1 site has 'monitoring_status=2' in the db cluster or fs cluster.","title":"Add/Remove Sites to/from Monitoring"},{"location":"kanban_tickets/add_remove_site_mon/#addremove-sites-tofrom-monitoring","text":"There are different procedures for adding and removing sites vs URLs from monitoring.","title":"Add/Remove Sites to/from Monitoring"},{"location":"kanban_tickets/add_remove_site_mon/#monitoring-sites-ace","text":"Pretty much every cluster should have one production site in monitoring.","title":"Monitoring Sites - ACE"},{"location":"kanban_tickets/add_remove_site_mon/#add-ace-site-to-monitoring","text":"site-mon add $SITENAME","title":"Add ACE site to monitoring"},{"location":"kanban_tickets/add_remove_site_mon/#remove-ace-site-from-monitoring","text":"site-mon remove $SITENAME","title":"Remove ACE site from monitoring"},{"location":"kanban_tickets/add_remove_site_mon/#monitoring-urls-site-factory","text":"","title":"Monitoring URLs - Site Factory"},{"location":"kanban_tickets/add_remove_site_mon/#add-acsf-site-to-monitoring","text":"Determine the fields site that it belongs to. REQUESTED_URL= BASE_URL=$(echo ${REQUESTED_URL} | cut -d'/' -f1) SITENAME=$(ah-site list domain:${BASE_URL}) if [[ -z \"${SITENAME}\" ]]; then echo \"ERROR: ${REQUESTED_URL} is not associated with any known site, aborting.\" else echo \"OK: ${BASE_URL} is assigned to ${SITENAME}.\" fi Add the site to monitoring. acsf-site-mon add ${SITENAME} ${REQUESTED_URL}","title":"Add ACSF site to monitoring"},{"location":"kanban_tickets/add_remove_site_mon/#remove-acsf-site-from-monitoring","text":"Determine the fields site that it belongs to. REQUESTED_URL= BASE_URL=$(echo ${REQUESTED_URL} | cut -d'/' -f1) SITENAME=$(ah-site list domain:${BASE_URL}) if [[ -z \"${SITENAME}\" ]]; then echo \"ERROR: ${REQUESTED_URL} is not associated with any known site, aborting.\" else echo \"OK: ${BASE_URL} is assigned to ${SITENAME}.\" fi Remove the site from monitoring. acsf-site-mon remove ${SITENAME} ${REQUESTED_URL} Site's monitoring status also needs to be changed in order to remove fields site's monitoring. site-mondisable ${SITENAME}","title":"Remove ACSF site from monitoring"},{"location":"kanban_tickets/add_remove_site_mon/#monitoring-sites-acp-network","text":"Typically few sites are enabled for monitoring in acp and network, ensure that a ticket has requested it specifically.","title":"Monitoring Sites - ACP &amp; Network"},{"location":"kanban_tickets/add_remove_site_mon/#add-site-to-monitoring","text":"site-monenable ${SITENAME}","title":"Add site to monitoring"},{"location":"kanban_tickets/add_remove_site_mon/#remove-site-from-monitoring","text":"site-mondisable ${SITENAME} Note: 'monitoring_status' shows if the site is being monitored or not. So, always make sure if at least 1 site has 'monitoring_status=2' in the db cluster or fs cluster.","title":"Remove site from monitoring"},{"location":"kanban_tickets/add_remove_webs_from_rotation/","text":"Add/Remove Webs From Rotation Overview There are currently two types of \"web rotation\" on the Acquia platform: Fields - Web Rotation Status Fields - Web Service Status Web Rotation Status This describes the status of a given Drupal site on a given host. NOTE : Web rotation status is declared on a PER-SITE BASIS , meaning that some sites may be served from some hosts and disabled on others. Status 1000 means that the site is currently marked as \"deployed and active\" on that host. Status 1001 means that the site is currently marked \"inactive\" on that host. No code will deploy to this host and no site updates will occur on this host. It will also not appear in nginx configuration files on a site's balancers. Status 1002 means that the site is currently marked as \"deploy\", meaning that the next fields-config-web.php run should check out the site repository, create the appropriate directories, and then update the hosting API to add itself to the balancer rotation and mark itself as status 1000 upon successful code and repository deployment. Web Service Status This describes the status of a given host. NOTE : Web service status is declared on a PER-HOST BASIS , meaning that if a host is set to inactive ( 1 ), it will not serve TCP 80 traffic for ANY sites assigned to that host (as it will not be in the balancer configuration for the aforementioned site or sites). Status 1 means that the host is marked as \"inactive\". Upon subsequent fields-config-bal.php runs for active sites that are associated with the host and the balancer, it will ensure the host is removed from the given site(s)' nginx configuration file as a backend. This will stop all TCP 80 requests going to this web. Status 2 means that the host is marked as \"active\" and will be included in nginx configuration files as a backend for sites associated with the host. NOTE : Marking a host as status 1 without suspending the host will trigger an alert to the Ops On-Call. Pre-Flight Checks Clarify the request: Is the ticket requesting that only a single site be disabled on a given host? Is the ticket requesting that the entire host be disabled? Which host(s) or site(s) will be disabled or marked inactive? Procedures Disabling/Removing Disabling Web Service for single OR multiple hosts HOSTS= #CSV format sv-webdisable $HOSTS Disabling Web Rotation on a single host, single site Generally, this is used to single-out a given host. Sometimes used for cron webs or memcache or other tasks. HOST= SITE= ./fields-provision.php --site-set-web ${SITE}:inactive --webs ${HOST} site-fcw ${SITE} NOTE : While removing webs hosting memcache service on them in site infrastructure, also run the below command to restart the memcache service on all the webs pertaining to the site infrastrcutre, so as to avoid broken memcache due to web removal. site-fcm ${SITE} Disabling Web Rotation on multiple hosts, single site Not generally-used or recommended. HOSTS= SITE= ./fields-provision.php --site-set-web ${SITE}:inactive --webs ${HOSTS} site-fcw ${SITE} NOTE : While removing webs hosting memcache service on them in site infrastructure, also run the below command to restart the memcache service on all the webs pertaining to the site infrastrcutre, so as to avoid broken memcache due to web removal. site-fcm ${SITE} Enabling/Adding Enabling Web Service for single OR multiple hosts HOSTS= #CSV format sv-webenable $HOSTS Enabling Web Rotation on a single host, single site HOST= SITE= ./fields-provision.php --site-set-web ${SITE}:deploy --webs ${HOST} site-fcw ${SITE} Enabling Web Rotation on multiple hosts, single site HOSTS= SITE= ./fields-provision.php --site-set-web ${SITE}:deploy --webs ${HOSTS} site-fcw ${SITE}","title":"Add/Remove Webs From Rotation"},{"location":"kanban_tickets/add_remove_webs_from_rotation/#addremove-webs-from-rotation","text":"","title":"Add/Remove Webs From Rotation"},{"location":"kanban_tickets/add_remove_webs_from_rotation/#overview","text":"There are currently two types of \"web rotation\" on the Acquia platform: Fields - Web Rotation Status Fields - Web Service Status","title":"Overview"},{"location":"kanban_tickets/add_remove_webs_from_rotation/#web-rotation-status","text":"This describes the status of a given Drupal site on a given host. NOTE : Web rotation status is declared on a PER-SITE BASIS , meaning that some sites may be served from some hosts and disabled on others. Status 1000 means that the site is currently marked as \"deployed and active\" on that host. Status 1001 means that the site is currently marked \"inactive\" on that host. No code will deploy to this host and no site updates will occur on this host. It will also not appear in nginx configuration files on a site's balancers. Status 1002 means that the site is currently marked as \"deploy\", meaning that the next fields-config-web.php run should check out the site repository, create the appropriate directories, and then update the hosting API to add itself to the balancer rotation and mark itself as status 1000 upon successful code and repository deployment.","title":"Web Rotation Status"},{"location":"kanban_tickets/add_remove_webs_from_rotation/#web-service-status","text":"This describes the status of a given host. NOTE : Web service status is declared on a PER-HOST BASIS , meaning that if a host is set to inactive ( 1 ), it will not serve TCP 80 traffic for ANY sites assigned to that host (as it will not be in the balancer configuration for the aforementioned site or sites). Status 1 means that the host is marked as \"inactive\". Upon subsequent fields-config-bal.php runs for active sites that are associated with the host and the balancer, it will ensure the host is removed from the given site(s)' nginx configuration file as a backend. This will stop all TCP 80 requests going to this web. Status 2 means that the host is marked as \"active\" and will be included in nginx configuration files as a backend for sites associated with the host. NOTE : Marking a host as status 1 without suspending the host will trigger an alert to the Ops On-Call.","title":"Web Service Status"},{"location":"kanban_tickets/add_remove_webs_from_rotation/#pre-flight-checks","text":"Clarify the request: Is the ticket requesting that only a single site be disabled on a given host? Is the ticket requesting that the entire host be disabled? Which host(s) or site(s) will be disabled or marked inactive?","title":"Pre-Flight Checks"},{"location":"kanban_tickets/add_remove_webs_from_rotation/#procedures","text":"","title":"Procedures"},{"location":"kanban_tickets/add_remove_webs_from_rotation/#disablingremoving","text":"","title":"Disabling/Removing"},{"location":"kanban_tickets/add_remove_webs_from_rotation/#disabling-web-service-for-single-or-multiple-hosts","text":"HOSTS= #CSV format sv-webdisable $HOSTS","title":"Disabling Web Service for single OR multiple hosts"},{"location":"kanban_tickets/add_remove_webs_from_rotation/#disabling-web-rotation-on-a-single-host-single-site","text":"Generally, this is used to single-out a given host. Sometimes used for cron webs or memcache or other tasks. HOST= SITE= ./fields-provision.php --site-set-web ${SITE}:inactive --webs ${HOST} site-fcw ${SITE} NOTE : While removing webs hosting memcache service on them in site infrastructure, also run the below command to restart the memcache service on all the webs pertaining to the site infrastrcutre, so as to avoid broken memcache due to web removal. site-fcm ${SITE}","title":"Disabling Web Rotation on a single host, single site"},{"location":"kanban_tickets/add_remove_webs_from_rotation/#disabling-web-rotation-on-multiple-hosts-single-site","text":"Not generally-used or recommended. HOSTS= SITE= ./fields-provision.php --site-set-web ${SITE}:inactive --webs ${HOSTS} site-fcw ${SITE} NOTE : While removing webs hosting memcache service on them in site infrastructure, also run the below command to restart the memcache service on all the webs pertaining to the site infrastrcutre, so as to avoid broken memcache due to web removal. site-fcm ${SITE}","title":"Disabling Web Rotation on multiple hosts, single site"},{"location":"kanban_tickets/add_remove_webs_from_rotation/#enablingadding","text":"","title":"Enabling/Adding"},{"location":"kanban_tickets/add_remove_webs_from_rotation/#enabling-web-service-for-single-or-multiple-hosts","text":"HOSTS= #CSV format sv-webenable $HOSTS","title":"Enabling Web Service for single OR multiple hosts"},{"location":"kanban_tickets/add_remove_webs_from_rotation/#enabling-web-rotation-on-a-single-host-single-site","text":"HOST= SITE= ./fields-provision.php --site-set-web ${SITE}:deploy --webs ${HOST} site-fcw ${SITE}","title":"Enabling Web Rotation on a single host, single site"},{"location":"kanban_tickets/add_remove_webs_from_rotation/#enabling-web-rotation-on-multiple-hosts-single-site","text":"HOSTS= SITE= ./fields-provision.php --site-set-web ${SITE}:deploy --webs ${HOSTS} site-fcw ${SITE}","title":"Enabling Web Rotation on multiple hosts, single site"},{"location":"kanban_tickets/add_user/","text":"Bastion Provisioning The canonical source of documentation that new bastion users need to consult is: Ops/Engineering: https://confluence.acquia.com/display/OP/Bastion+Host+Guide The docs for Castle are here Gather Required Information A user provision request should be made via an Ops Ticket, with the following information: List of production environments to grant access to (eg, ACE, ACE, SMB Gardens, etc) A 4096 byte size SSH public key The attestation certificate from their YubiKey The business unit they are in The list of stages they need access to Do not continue unless the request has all of these items: https://confluence.acquia.com/display/OP/Bastion+Host+Guide#BastionHostGuide-FilinganAccessRequest Verify that you have the access to Yubikey tracking sheet . You will need the access to verify the Yubikey serial number of the user, while provisioning access. If you don\u2019t have the access, request the access and find out the yubikey serial number allotted to the User, with help of some Ops engineer, who has the access to the sheet. Note the yubikey serial number, allotted to the User, from the sheet. Approval Verify the ticket has been approved by the Product Owner and the User's manager before continuing. Approval Requirements Choosing a Username WARNING: Ensure that you actually verify that the desired username meets this criteria. If not, you run a risk of having to redo steps! The username: Must be unique Should be first name last name (aminastaneh) or first initial + last name (eg: aastaneh) Must be alpha lowercase characters Must have four or more characters Must not be the same as a fields site name in any production stage. Must not be the same as a fields site user name in any production stage. You must check the following in each account (especially on devcloud, as new users get provisioned devcloud sites sometimes) In the following we include status output for an extra level of sanity checking. 2001 = active, 2002 = deletable and 2003 = terminated. Regardless of status names can never be reused: You can check to see if the selected username has the same name as a site with the site-search tool from ops-misc. site-search blkperl The site's unix_name is the same as the sitegroup name itself. The only exception to this is warnermusic in hosting-prod. You can find the exceptions to this rule by running this on a master: mysql -e \"\\ SELECT a.name, b.unix_name \\ FROM acquia_fields_sitegroup_user a \\ INNER JOIN acquia_fields_sitegroup b ON a.name = b.name \\ WHERE NOT a.name = b.unix_name;\" fields_master Granting Access to Bastion Users are added to the bastion with the bastion-provision tool. It requires three arguments. USERNAME: Use the username you used for WIKID that meets the requirements above ROLE: If the user is in Ops or Hosting Engineering, use ahops . For any other team, use ahsupport STAGES: Stages are determined as defined below. Stages by department as determined by department. Ops prod,devcloud,gardens,wmg-egardens,enterprise-g1,search-service,trex-prod,network Support, TAM, and Ready prod,devcloud,gardens,wmg-egardens,enterprise-g1,search-service,trex-prod Others: As determined by the ticket The following command will provision their user account, their SSH key for password login, SVN credentials, and access to each stage specified. $OPSROOT/scripts/bastion-tools/bastion-provision \\ USERNAME ROLE <CSV LIST OF STAGES>/<NO STAGE> Provisioning a user Ensure you know what group the new user needs to belong to. Valid selections are ahops and ahsupport . Others must be approved by Ops Management. Set some variables. NEW_USER= NEW_USER_GROUP= case $NEW_USER_GROUP in ahops ) STAGES_CSV=prod,devcloud,gardens,wmg-egardens,enterprise-g1,search-service,trex-prod,network ;; ahsupport ) STAGES_CSV=prod,devcloud,gardens,wmg-egardens,enterprise-g1,search-service,trex-prod ;; * ) echo \"WARNING: Non-standard group. Double-check the group the user is to be assigned to.\" echo \"If the group is correct, enter a CSV of stages the user should be granted access to:\" read STAGES_CSV ;; esac Validate that you don't have an empty stage list. if [ -z \"$STAGES_CSV\" ]; then echo \"ERROR: Stage list is empty. Proceed ONLY if you are provisioning BASTION-ONLY ACCESS.\" fi Provision the user. /usr/local/ops/scripts/bastion-tools/bastion-provision $NEW_USER $NEW_USER_GROUP $STAGES_CSV Verify the yubikey serial number, shown while running bastion-provision tool, matches the yubikey number allotted to the user as per the Yubikey tracking sheet. If the numbers do not match then press 'N' at the step : Does the serial number match? [y/N] EXAMPLE: Bastion ONLY $ /usr/local/ops/scripts/bastion-tools/bastion-provision kenkeys ahsupport Please paste the user's attestation certificate (including the BEGIN and END markers) followed by ^D: -----BEGIN CERTIFICATE----- MIIDEDCCAfigAwIBAgIRAJdViJb/N9G1PSqSmQv1FuYwDQYJKoZIhvcNAQELBQAw [ several lines deleted ] WdrG8RDXoY8IxPePUHa9JojGepjnU5hsaNTn8t1I7xuBexsvmWq86YnKU/ljvyG4 rm8o7x+fMRj6ufKSN8ygk3Ut/EE= -----END CERTIFICATE----- Please check the serial number below against the IT inventory for kenkeys YubiKey serial number: 1234567 Does the serial number match? [y/N] y Verifying attestation data: Certificate chain - OK PIN policy - OK Touch policy - OK Installing YubiKey public key in: /vol/ebs1/keys/authorized_keys/kenkeys Saving attestation certificate in: /vol/ebs1/home/kenkeys/.ssh/yubikey-attestation.pem YubiKey serial number: 1234567 Identity added: ..acquia-internal/ssh/default (..acquia-internal/ssh/default) Admin user kenkeys, uid 9991 saved. Waiting for user creation.. Waiting for user creation.. ah-admin-users[22569]: creating kenkeys (9991) ah-admin-users[22569]: created kenkeys (9991) ah-admin-users[22569]: updating /vol/ebs1/home/kenkeys/.ssh/authorized_keys ah-admin-users[22569]: updated /vol/ebs1/home/kenkeys/.ssh/authorized_keys ah-admin-users[22569]: creating /vol/ebs1/home/kenkeys/.bash_history ah-admin-users[22569]: created /vol/ebs1/home/kenkeys/.bash_history ah-admin-users[22569]: updated /var/acquia/ah-admin-users.etag Done! SVN Password: redacted Writing out SVN creds file.. Sending Instructions. Provide an email address, or press ^C to skip. ken.keys@acquia.com EXAMPLE: ACE,ACP production access $ /usr/local/ops/scripts/bastion-tools/bastion-provision \\ krisolafson ahops prod,devcloud Please paste the user's attestation certificate (including the BEGIN and END markers) followed by ^D: -----BEGIN CERTIFICATE----- MIIDEDCCAfigAwIBAgIRAJdViJb/N9G1PSqSmQv1FuYwDQYJKoZIhvcNAQELBQAw [ several lines deleted ] WdrG8RDXoY8IxPePUHa9JojGepjnU5hsaNTn8t1I7xuBexsvmWq86YnKU/ljvyG4 rm8o7x+fMRj6ufKSN8ygk3Ut/EE= -----END CERTIFICATE----- Please check the serial number below against the IT inventory for krisolafson YubiKey serial number: 1234567 Does the serial number match? [y/N] y Verifying attestation data: Certificate chain - OK PIN policy - OK Touch policy - OK Installing YubiKey public key in: /vol/ebs1/keys/authorized_keys/krisolafson Saving attestation certificate in: /vol/ebs1/home/krisolafson/.ssh/yubikey-attestation.pem YubiKey serial number: 1234567 Identity added: ..acquia-internal/ssh/default (..acquia-internal/ssh/default) Admin user krisolafson, uid 3301 saved. Waiting for user creation.. Waiting for user creation.. ah-admin-users[22569]: creating krisolafson (3301) ah-admin-users[22569]: created krisolafson (3301) ah-admin-users[22569]: updating /vol/ebs1/home/krisolafson/.ssh/authorized_keys ah-admin-users[22569]: updated /vol/ebs1/home/krisolafson/.ssh/authorized_keys ah-admin-users[22569]: creating /vol/ebs1/home/krisolafson/.bash_history ah-admin-users[22569]: created /vol/ebs1/home/krisolafson/.bash_history ah-admin-users[22569]: updated /var/acquia/ah-admin-users.etag Done! SVN Password: redacted Writing out SVN creds file.. Please paste the provided publickey: ssh-rsa AAAAB3Nz......dne3cvdcpQawQ== kris.olafson@MacBookPro-krisolafson.local Identity added: ..acquia-internal/ssh/default (..acquia-internal/ssh/default) WARNING: Your ssh-agent is tracking more than 5 keys. Admin user krisolafson, uid 3301 saved. Admin user krisolafson, uid 8883 saved. Sending Instructions. Provide an email address, or press ^C to skip. kris.olafson@acquia.com Confirm that User Can Log In The user will be provided their username information via email. They will use their YubiKey to authenticate. Test Log-in Have them attempt to log into the bastion: https://confluence.acquia.com/display/OP/Bastion+Host+Guide#BastionHostGuide-LoggingIntotheBastionHostFortheFirstTime Proceed to Bastion Troubleshooting if they can't login.","title":"Bastion Provisioning"},{"location":"kanban_tickets/add_user/#bastion-provisioning","text":"The canonical source of documentation that new bastion users need to consult is: Ops/Engineering: https://confluence.acquia.com/display/OP/Bastion+Host+Guide The docs for Castle are here","title":"Bastion Provisioning"},{"location":"kanban_tickets/add_user/#gather-required-information","text":"A user provision request should be made via an Ops Ticket, with the following information: List of production environments to grant access to (eg, ACE, ACE, SMB Gardens, etc) A 4096 byte size SSH public key The attestation certificate from their YubiKey The business unit they are in The list of stages they need access to Do not continue unless the request has all of these items: https://confluence.acquia.com/display/OP/Bastion+Host+Guide#BastionHostGuide-FilinganAccessRequest Verify that you have the access to Yubikey tracking sheet . You will need the access to verify the Yubikey serial number of the user, while provisioning access. If you don\u2019t have the access, request the access and find out the yubikey serial number allotted to the User, with help of some Ops engineer, who has the access to the sheet. Note the yubikey serial number, allotted to the User, from the sheet.","title":"Gather Required Information"},{"location":"kanban_tickets/add_user/#approval","text":"Verify the ticket has been approved by the Product Owner and the User's manager before continuing. Approval Requirements","title":"Approval"},{"location":"kanban_tickets/add_user/#choosing-a-username","text":"WARNING: Ensure that you actually verify that the desired username meets this criteria. If not, you run a risk of having to redo steps! The username: Must be unique Should be first name last name (aminastaneh) or first initial + last name (eg: aastaneh) Must be alpha lowercase characters Must have four or more characters Must not be the same as a fields site name in any production stage. Must not be the same as a fields site user name in any production stage. You must check the following in each account (especially on devcloud, as new users get provisioned devcloud sites sometimes) In the following we include status output for an extra level of sanity checking. 2001 = active, 2002 = deletable and 2003 = terminated. Regardless of status names can never be reused: You can check to see if the selected username has the same name as a site with the site-search tool from ops-misc. site-search blkperl The site's unix_name is the same as the sitegroup name itself. The only exception to this is warnermusic in hosting-prod. You can find the exceptions to this rule by running this on a master: mysql -e \"\\ SELECT a.name, b.unix_name \\ FROM acquia_fields_sitegroup_user a \\ INNER JOIN acquia_fields_sitegroup b ON a.name = b.name \\ WHERE NOT a.name = b.unix_name;\" fields_master","title":"Choosing a Username"},{"location":"kanban_tickets/add_user/#granting-access-to-bastion","text":"Users are added to the bastion with the bastion-provision tool. It requires three arguments. USERNAME: Use the username you used for WIKID that meets the requirements above ROLE: If the user is in Ops or Hosting Engineering, use ahops . For any other team, use ahsupport STAGES: Stages are determined as defined below. Stages by department as determined by department. Ops prod,devcloud,gardens,wmg-egardens,enterprise-g1,search-service,trex-prod,network Support, TAM, and Ready prod,devcloud,gardens,wmg-egardens,enterprise-g1,search-service,trex-prod Others: As determined by the ticket The following command will provision their user account, their SSH key for password login, SVN credentials, and access to each stage specified. $OPSROOT/scripts/bastion-tools/bastion-provision \\ USERNAME ROLE <CSV LIST OF STAGES>/<NO STAGE>","title":"Granting Access to Bastion"},{"location":"kanban_tickets/add_user/#provisioning-a-user","text":"Ensure you know what group the new user needs to belong to. Valid selections are ahops and ahsupport . Others must be approved by Ops Management. Set some variables. NEW_USER= NEW_USER_GROUP= case $NEW_USER_GROUP in ahops ) STAGES_CSV=prod,devcloud,gardens,wmg-egardens,enterprise-g1,search-service,trex-prod,network ;; ahsupport ) STAGES_CSV=prod,devcloud,gardens,wmg-egardens,enterprise-g1,search-service,trex-prod ;; * ) echo \"WARNING: Non-standard group. Double-check the group the user is to be assigned to.\" echo \"If the group is correct, enter a CSV of stages the user should be granted access to:\" read STAGES_CSV ;; esac Validate that you don't have an empty stage list. if [ -z \"$STAGES_CSV\" ]; then echo \"ERROR: Stage list is empty. Proceed ONLY if you are provisioning BASTION-ONLY ACCESS.\" fi Provision the user. /usr/local/ops/scripts/bastion-tools/bastion-provision $NEW_USER $NEW_USER_GROUP $STAGES_CSV Verify the yubikey serial number, shown while running bastion-provision tool, matches the yubikey number allotted to the user as per the Yubikey tracking sheet. If the numbers do not match then press 'N' at the step : Does the serial number match? [y/N]","title":"Provisioning a user"},{"location":"kanban_tickets/add_user/#example-bastion-only","text":"$ /usr/local/ops/scripts/bastion-tools/bastion-provision kenkeys ahsupport Please paste the user's attestation certificate (including the BEGIN and END markers) followed by ^D: -----BEGIN CERTIFICATE----- MIIDEDCCAfigAwIBAgIRAJdViJb/N9G1PSqSmQv1FuYwDQYJKoZIhvcNAQELBQAw [ several lines deleted ] WdrG8RDXoY8IxPePUHa9JojGepjnU5hsaNTn8t1I7xuBexsvmWq86YnKU/ljvyG4 rm8o7x+fMRj6ufKSN8ygk3Ut/EE= -----END CERTIFICATE----- Please check the serial number below against the IT inventory for kenkeys YubiKey serial number: 1234567 Does the serial number match? [y/N] y Verifying attestation data: Certificate chain - OK PIN policy - OK Touch policy - OK Installing YubiKey public key in: /vol/ebs1/keys/authorized_keys/kenkeys Saving attestation certificate in: /vol/ebs1/home/kenkeys/.ssh/yubikey-attestation.pem YubiKey serial number: 1234567 Identity added: ..acquia-internal/ssh/default (..acquia-internal/ssh/default) Admin user kenkeys, uid 9991 saved. Waiting for user creation.. Waiting for user creation.. ah-admin-users[22569]: creating kenkeys (9991) ah-admin-users[22569]: created kenkeys (9991) ah-admin-users[22569]: updating /vol/ebs1/home/kenkeys/.ssh/authorized_keys ah-admin-users[22569]: updated /vol/ebs1/home/kenkeys/.ssh/authorized_keys ah-admin-users[22569]: creating /vol/ebs1/home/kenkeys/.bash_history ah-admin-users[22569]: created /vol/ebs1/home/kenkeys/.bash_history ah-admin-users[22569]: updated /var/acquia/ah-admin-users.etag Done! SVN Password: redacted Writing out SVN creds file.. Sending Instructions. Provide an email address, or press ^C to skip. ken.keys@acquia.com","title":"EXAMPLE: Bastion ONLY"},{"location":"kanban_tickets/add_user/#example-aceacp-production-access","text":"$ /usr/local/ops/scripts/bastion-tools/bastion-provision \\ krisolafson ahops prod,devcloud Please paste the user's attestation certificate (including the BEGIN and END markers) followed by ^D: -----BEGIN CERTIFICATE----- MIIDEDCCAfigAwIBAgIRAJdViJb/N9G1PSqSmQv1FuYwDQYJKoZIhvcNAQELBQAw [ several lines deleted ] WdrG8RDXoY8IxPePUHa9JojGepjnU5hsaNTn8t1I7xuBexsvmWq86YnKU/ljvyG4 rm8o7x+fMRj6ufKSN8ygk3Ut/EE= -----END CERTIFICATE----- Please check the serial number below against the IT inventory for krisolafson YubiKey serial number: 1234567 Does the serial number match? [y/N] y Verifying attestation data: Certificate chain - OK PIN policy - OK Touch policy - OK Installing YubiKey public key in: /vol/ebs1/keys/authorized_keys/krisolafson Saving attestation certificate in: /vol/ebs1/home/krisolafson/.ssh/yubikey-attestation.pem YubiKey serial number: 1234567 Identity added: ..acquia-internal/ssh/default (..acquia-internal/ssh/default) Admin user krisolafson, uid 3301 saved. Waiting for user creation.. Waiting for user creation.. ah-admin-users[22569]: creating krisolafson (3301) ah-admin-users[22569]: created krisolafson (3301) ah-admin-users[22569]: updating /vol/ebs1/home/krisolafson/.ssh/authorized_keys ah-admin-users[22569]: updated /vol/ebs1/home/krisolafson/.ssh/authorized_keys ah-admin-users[22569]: creating /vol/ebs1/home/krisolafson/.bash_history ah-admin-users[22569]: created /vol/ebs1/home/krisolafson/.bash_history ah-admin-users[22569]: updated /var/acquia/ah-admin-users.etag Done! SVN Password: redacted Writing out SVN creds file.. Please paste the provided publickey: ssh-rsa AAAAB3Nz......dne3cvdcpQawQ== kris.olafson@MacBookPro-krisolafson.local Identity added: ..acquia-internal/ssh/default (..acquia-internal/ssh/default) WARNING: Your ssh-agent is tracking more than 5 keys. Admin user krisolafson, uid 3301 saved. Admin user krisolafson, uid 8883 saved. Sending Instructions. Provide an email address, or press ^C to skip. kris.olafson@acquia.com","title":"EXAMPLE: ACE,ACP production access"},{"location":"kanban_tickets/add_user/#confirm-that-user-can-log-in","text":"The user will be provided their username information via email. They will use their YubiKey to authenticate.","title":"Confirm that User Can Log In"},{"location":"kanban_tickets/add_user/#test-log-in","text":"Have them attempt to log into the bastion: https://confluence.acquia.com/display/OP/Bastion+Host+Guide#BastionHostGuide-LoggingIntotheBastionHostFortheFirstTime Proceed to Bastion Troubleshooting if they can't login.","title":"Test Log-in"},{"location":"kanban_tickets/ahrabot/","text":"Modify the list of bastion users that can sudo ahrabot When you are requested to add a user to ahrabot execute the following steps: On your personal workstation (not in the bastion!) clone the fields repository. (This may take a while because fields is big.) Skip this step if you already have fields cloned to your workstation. git clone git@github.com:acquia/fields.git Ensure you have a current checkout and create a branch in which to make your changes. NOTE : JIRA_TICKET must be a CL ticket. If one does not yet exist, create one in Jira and link it to the OP. git checkout master git pull JIRA_TICKET=CL-nnnnnn DESCRIPTION=\"something_meaningful_and very_short\" git checkout -b \"${JIRA_TICKET}_${DESCRIPTION}\" Modify puppet/versions/devel/modules/bastion/files/sudoers as indicated in the request ticket (i.e. Add or delete users belonging the group ahrabot that can run sudo su - ahrabot ), then commit your changes. Make sure to provide a detailed but concise commit description. git add puppet/versions/devel/modules/bastion/files/sudoers git commit -m \"${JIRA_TICKET} | SHORT COMMIT DESCRIPTION\" git push -u origin \"${JIRA_TICKET}_${DESCRIPTION}\" Log in to GitHub and create a pull request in the fields repository. The PR name must be in the form CL-nnnnn | short description in order to comply with CL commit standards. Read the fields README for additional information on submitting a Pull Request. You can find further information on committing to fields by reviewing the git commit policy . Tag your PR as \"Needs Review\" and address any feedback or merge conflicts that arise.","title":"Modify the list of bastion users that can sudo ahrabot"},{"location":"kanban_tickets/ahrabot/#modify-the-list-of-bastion-users-that-can-sudo-ahrabot","text":"When you are requested to add a user to ahrabot execute the following steps: On your personal workstation (not in the bastion!) clone the fields repository. (This may take a while because fields is big.) Skip this step if you already have fields cloned to your workstation. git clone git@github.com:acquia/fields.git Ensure you have a current checkout and create a branch in which to make your changes. NOTE : JIRA_TICKET must be a CL ticket. If one does not yet exist, create one in Jira and link it to the OP. git checkout master git pull JIRA_TICKET=CL-nnnnnn DESCRIPTION=\"something_meaningful_and very_short\" git checkout -b \"${JIRA_TICKET}_${DESCRIPTION}\" Modify puppet/versions/devel/modules/bastion/files/sudoers as indicated in the request ticket (i.e. Add or delete users belonging the group ahrabot that can run sudo su - ahrabot ), then commit your changes. Make sure to provide a detailed but concise commit description. git add puppet/versions/devel/modules/bastion/files/sudoers git commit -m \"${JIRA_TICKET} | SHORT COMMIT DESCRIPTION\" git push -u origin \"${JIRA_TICKET}_${DESCRIPTION}\" Log in to GitHub and create a pull request in the fields repository. The PR name must be in the form CL-nnnnn | short description in order to comply with CL commit standards. Read the fields README for additional information on submitting a Pull Request. You can find further information on committing to fields by reviewing the git commit policy . Tag your PR as \"Needs Review\" and address any feedback or merge conflicts that arise.","title":"Modify the list of bastion users that can sudo ahrabot"},{"location":"kanban_tickets/arbitrary_php.ini_settings/","text":"Arbitrary php.ini settings The primary file used to configure PHP is php.ini . This file is unique on Acquia hosting because it allows any arbitrary directive to be added, valid or otherwise. It exists per site, and lives on each web-class server at: /var/www/site-php/${SITENAME}/php.ini Directives are often given a unique name with dot-separated naming, like \"foo.bar.setting\". A list of common directives are documented with PHP . Changing php.ini settings You must specify a unit size when changing php.ini settings. This is because PHP defaults to kilobytes if a value is not specified. If block size parameter is given. SIZE should be in megabytes (M) unless specified otherwise. Examples: SITENAME= SIZE= ah-site edit $SITENAME -c php.ini:memory_limit=${SIZE}M SITENAME= SIZE= ah-site edit $SITENAME -c php:user_cache_size=${SIZE}M Adding or changing arbitrary directives ah-site edit $SITENAME -c php.ini:$DIRECTIVE_1=$VALUE_1 \\ php.ini:$DIRECTIVE_2=$VALUE_2 ... Removing arbitrary directives ah-site edit $SITENAME -c php.ini:$DIRECTIVE_1= php.ini:$DIRECTIVE_2= ... Add multiple extensions in php.ini for the single site-group also add full path to comma-delimited list of extension filename TARGET=sitename EXT1=extension_name_1 EXT2=extension_name_2 LIBRARY_PATH=\"/var/www/html/$TARGET/library/\" ah-site edit $TARGET -c php.ini:extension=\"$LIBRARY_PATH/\"$EXT1,\"$LIBRARY_PATH/\"$EXT2 NOTE: You can add multiple extensions the same way shown above and make sure the list should be comma-delimated example ref ticket OP-291601","title":"Arbitrary php.ini settings"},{"location":"kanban_tickets/arbitrary_php.ini_settings/#arbitrary-phpini-settings","text":"The primary file used to configure PHP is php.ini . This file is unique on Acquia hosting because it allows any arbitrary directive to be added, valid or otherwise. It exists per site, and lives on each web-class server at: /var/www/site-php/${SITENAME}/php.ini Directives are often given a unique name with dot-separated naming, like \"foo.bar.setting\". A list of common directives are documented with PHP .","title":"Arbitrary php.ini settings"},{"location":"kanban_tickets/arbitrary_php.ini_settings/#changing-phpini-settings","text":"You must specify a unit size when changing php.ini settings. This is because PHP defaults to kilobytes if a value is not specified. If block size parameter is given. SIZE should be in megabytes (M) unless specified otherwise. Examples: SITENAME= SIZE= ah-site edit $SITENAME -c php.ini:memory_limit=${SIZE}M SITENAME= SIZE= ah-site edit $SITENAME -c php:user_cache_size=${SIZE}M","title":"Changing php.ini settings"},{"location":"kanban_tickets/arbitrary_php.ini_settings/#adding-or-changing-arbitrary-directives","text":"ah-site edit $SITENAME -c php.ini:$DIRECTIVE_1=$VALUE_1 \\ php.ini:$DIRECTIVE_2=$VALUE_2 ...","title":"Adding or changing arbitrary directives"},{"location":"kanban_tickets/arbitrary_php.ini_settings/#removing-arbitrary-directives","text":"ah-site edit $SITENAME -c php.ini:$DIRECTIVE_1= php.ini:$DIRECTIVE_2= ...","title":"Removing arbitrary directives"},{"location":"kanban_tickets/arbitrary_php.ini_settings/#add-multiple-extensions-in-phpini-for-the-single-site-group-also-add-full-path-to-comma-delimited-list-of-extension-filename","text":"TARGET=sitename EXT1=extension_name_1 EXT2=extension_name_2 LIBRARY_PATH=\"/var/www/html/$TARGET/library/\" ah-site edit $TARGET -c php.ini:extension=\"$LIBRARY_PATH/\"$EXT1,\"$LIBRARY_PATH/\"$EXT2 NOTE: You can add multiple extensions the same way shown above and make sure the list should be comma-delimated example ref ticket OP-291601","title":"Add multiple extensions in php.ini for the single site-group also add full path to comma-delimited list of extension filename"},{"location":"kanban_tickets/bastion_access/","text":"Bastion Access User Changes Acquia users sometimes lose access to the bastions for any number of reasons. This can interrupt their ability to work. NOTE: This is not relevant for provisioning access to a new user. Read this for new user provisioning. Updating a user's SSH key An SSH key replacement request should be made via an Ops Ticket with the new SSH public key. If you don't know the user's username and fields group (i.e. Supportians are generally 'ahsupport', Opsians: 'ahops'), search fields for their last name: ./fields-provision.php --admin-list %lastname% Set variables for their username and fields group USERNAME= GROUP= Verify which stages the user has ssh-keys in already for stage in ${_ACQUIA_ENVIRONMENTS[@]}; do a${stage} ; echo $stage ./fields-provision.php --admin-list ${USERNAME} | grep ssh_pub_key done Do not update the user in stages which fields indicates their SSH key contains nulluser@acquia.com and make a list of appropriate stages to update. ENVS=( ) Save the user's public key to a file vim ${OPSTMP}/${USERNAME}.pub Update all the appropriate stages with the user's new key for stage in ${ENVS[@]}; do a${stage} ; echo $stage ./fields-provision.php --admin-save ${USERNAME}:${GROUP}:${OPSTMP}/${USERNAME}.pub; done Changing a user's group Set variables for the username and fields group USERNAME= GROUP= Find the user's public ssh key if the user has not requested changing the ssh key. ./fields-provision.php --admin-list ${USERNAME} Save the ssh key from the above command's output into ${OPSTMP}/${USERNAME}.pub . If the user has requested to also update ssh key, save new key provided into ${OPSTMP}/${USERNAME}.pub Check which stages the user has ssh-keys in already for stage in ${_ACQUIA_ENVIRONMENTS[@]}; do a${stage} ; echo ${stage} ./fields-provision.php --admin-list ${USERNAME} | grep ssh_pub_key done Make a list of appropriate stages to update. This list should only include stages for which fields indicates the SSH key does not contain nulluser@acquia.com in the above step. ENVS=( ) Update all the appropriate stages with the user's new key for stage in ${ENVS[@]}; do a${stage} ; echo ${stage} ./fields-provision.php --admin-save ${USERNAME}:${GROUP}:${OPSTMP}/${USERNAME}.pub; done If the user is being added to the ahops group, then tmp directories will need to be re-created. USERS=$(/mnt/apps/ops-misc/master/bin/ops-getahopsusers) sudo ${OPSROOT}/bin/ops-mkdir $USERS This command currently requires bastion sudo access, so you may need to escalate this to a Senior Ops Engineer. Delete the user from the bastion and run ah-admin-users sudo userdel ${USERNAME} sudo ah-admin-users Above commands currently requires bastion sudo access, so you may need to escalate this to a Senior Ops Engineer. Verify that user is now in the required bastion group groups ${USERNAME} Delete the user from all the servers and run ah-admin-users in all realms the user has access to. This is required in all stages that are stored the variable ${ENVS[@]} for stage in ${ENVS[@]}; do a${stage}; echo ${stage} fpdsh -p 200 -t % -c \"sudo userdel ${USERNAME}; sudo ah-admin-users\" done note : run of ah-admin-users can be skipped after the running userdel on all servers. There is a cron job on all servers which will run ah-admin-users every hour. Ahsupport and ahops have different netrc creds, so follow the page for Regenerating Netrc Credentails . Adding a user to an additional stage If you don't know the user's username and fields group (i.e. Supportians are generally 'ahsupport', Opsians: 'ahops'), search fields for their last name: ./fields-provision.php --admin-list %lastname% Set variables for their username and fields group USERNAME= GROUP= Save the user's public key to a file vim ${OPSTMP}/${USERNAME}.pub Add the user's ssh key to the new stage. Run this in the stage you're adding. a${stage} ./fields-provision.php --admin-save ${USERNAME}:${GROUP}:${OPSTMP}/${USERNAME}.pub If the user is in the ahsupport group, generate their RPC creds. AWS_ACCOUNT_NAME will be something of the form ${STAGE_NAME}-prod (i.e. trex-prod, hosting-prod, etc), depending on what the new stage is named. ahsupport-rpc-creds-reset ${USERNAME} ${AWS_ACCOUNT_NAME} This command currently requires bastion sudo, so you may need to escalate this to a Senior Ops Engineer If the user needs netrc creds, use the page for Regenerating Netrc Credentails .","title":"Bastion Access User Changes"},{"location":"kanban_tickets/bastion_access/#bastion-access-user-changes","text":"Acquia users sometimes lose access to the bastions for any number of reasons. This can interrupt their ability to work. NOTE: This is not relevant for provisioning access to a new user. Read this for new user provisioning.","title":"Bastion Access User Changes"},{"location":"kanban_tickets/bastion_access/#updating-a-users-ssh-key","text":"An SSH key replacement request should be made via an Ops Ticket with the new SSH public key. If you don't know the user's username and fields group (i.e. Supportians are generally 'ahsupport', Opsians: 'ahops'), search fields for their last name: ./fields-provision.php --admin-list %lastname% Set variables for their username and fields group USERNAME= GROUP= Verify which stages the user has ssh-keys in already for stage in ${_ACQUIA_ENVIRONMENTS[@]}; do a${stage} ; echo $stage ./fields-provision.php --admin-list ${USERNAME} | grep ssh_pub_key done Do not update the user in stages which fields indicates their SSH key contains nulluser@acquia.com and make a list of appropriate stages to update. ENVS=( ) Save the user's public key to a file vim ${OPSTMP}/${USERNAME}.pub Update all the appropriate stages with the user's new key for stage in ${ENVS[@]}; do a${stage} ; echo $stage ./fields-provision.php --admin-save ${USERNAME}:${GROUP}:${OPSTMP}/${USERNAME}.pub; done","title":"Updating a user's SSH key"},{"location":"kanban_tickets/bastion_access/#changing-a-users-group","text":"Set variables for the username and fields group USERNAME= GROUP= Find the user's public ssh key if the user has not requested changing the ssh key. ./fields-provision.php --admin-list ${USERNAME} Save the ssh key from the above command's output into ${OPSTMP}/${USERNAME}.pub . If the user has requested to also update ssh key, save new key provided into ${OPSTMP}/${USERNAME}.pub Check which stages the user has ssh-keys in already for stage in ${_ACQUIA_ENVIRONMENTS[@]}; do a${stage} ; echo ${stage} ./fields-provision.php --admin-list ${USERNAME} | grep ssh_pub_key done Make a list of appropriate stages to update. This list should only include stages for which fields indicates the SSH key does not contain nulluser@acquia.com in the above step. ENVS=( ) Update all the appropriate stages with the user's new key for stage in ${ENVS[@]}; do a${stage} ; echo ${stage} ./fields-provision.php --admin-save ${USERNAME}:${GROUP}:${OPSTMP}/${USERNAME}.pub; done If the user is being added to the ahops group, then tmp directories will need to be re-created. USERS=$(/mnt/apps/ops-misc/master/bin/ops-getahopsusers) sudo ${OPSROOT}/bin/ops-mkdir $USERS This command currently requires bastion sudo access, so you may need to escalate this to a Senior Ops Engineer. Delete the user from the bastion and run ah-admin-users sudo userdel ${USERNAME} sudo ah-admin-users Above commands currently requires bastion sudo access, so you may need to escalate this to a Senior Ops Engineer. Verify that user is now in the required bastion group groups ${USERNAME} Delete the user from all the servers and run ah-admin-users in all realms the user has access to. This is required in all stages that are stored the variable ${ENVS[@]} for stage in ${ENVS[@]}; do a${stage}; echo ${stage} fpdsh -p 200 -t % -c \"sudo userdel ${USERNAME}; sudo ah-admin-users\" done note : run of ah-admin-users can be skipped after the running userdel on all servers. There is a cron job on all servers which will run ah-admin-users every hour. Ahsupport and ahops have different netrc creds, so follow the page for Regenerating Netrc Credentails .","title":"Changing a user's group"},{"location":"kanban_tickets/bastion_access/#adding-a-user-to-an-additional-stage","text":"If you don't know the user's username and fields group (i.e. Supportians are generally 'ahsupport', Opsians: 'ahops'), search fields for their last name: ./fields-provision.php --admin-list %lastname% Set variables for their username and fields group USERNAME= GROUP= Save the user's public key to a file vim ${OPSTMP}/${USERNAME}.pub Add the user's ssh key to the new stage. Run this in the stage you're adding. a${stage} ./fields-provision.php --admin-save ${USERNAME}:${GROUP}:${OPSTMP}/${USERNAME}.pub If the user is in the ahsupport group, generate their RPC creds. AWS_ACCOUNT_NAME will be something of the form ${STAGE_NAME}-prod (i.e. trex-prod, hosting-prod, etc), depending on what the new stage is named. ahsupport-rpc-creds-reset ${USERNAME} ${AWS_ACCOUNT_NAME} This command currently requires bastion sudo, so you may need to escalate this to a Senior Ops Engineer If the user needs netrc creds, use the page for Regenerating Netrc Credentails .","title":"Adding a user to an additional stage"},{"location":"kanban_tickets/bastion_troubleshooting/","text":"Troubleshooting When a User Just Can't Log In Check /var/log/auth.log (look for incorrect name, bad password, \"id_rsa decrypted\" messages, too many connections) Errors in /var/log/auth.log that say \"too many connections\" means that the number of connections for the user are more than the allowed limit. Sometimes it happens if user loses internet connection or terminal. Check the processes for that users: USERNAME= ps -Fp $(pgrep -u ${USERNAME}) And kill the process: kill $PID or if you want to kill all process for the user pkill -u ${USERNAME} When a User Gets Locked Out after successful previous logins A user can lock themselves out of the bastion host if they do the following: Type the incorrect yubikey pin three times. Fail to authenticate to the bastion host using the yubikeys due to yubikey reset. If this happens, a new attestation certificate would be required. See this","title":"Troubleshooting"},{"location":"kanban_tickets/bastion_troubleshooting/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"kanban_tickets/bastion_troubleshooting/#when-a-user-just-cant-log-in","text":"Check /var/log/auth.log (look for incorrect name, bad password, \"id_rsa decrypted\" messages, too many connections) Errors in /var/log/auth.log that say \"too many connections\" means that the number of connections for the user are more than the allowed limit. Sometimes it happens if user loses internet connection or terminal. Check the processes for that users: USERNAME= ps -Fp $(pgrep -u ${USERNAME}) And kill the process: kill $PID or if you want to kill all process for the user pkill -u ${USERNAME}","title":"When a User Just Can't Log In"},{"location":"kanban_tickets/bastion_troubleshooting/#when-a-user-gets-locked-out-after-successful-previous-logins","text":"A user can lock themselves out of the bastion host if they do the following: Type the incorrect yubikey pin three times. Fail to authenticate to the bastion host using the yubikeys due to yubikey reset. If this happens, a new attestation certificate would be required. See this","title":"When a User Gets Locked Out after successful previous logins"},{"location":"kanban_tickets/bulk_site_move/","text":"Bulk Site Move Preparation Carefully read the ticket and verify the information is accurate. Verify the source and destination servers are in the same region. Procedure Variables Set the destination DB server, WEBS (in space-separated format/array) and OP ticket. SITE_FILE is the path to a file containing a new-line delimited list of sites to move. The code below is accepts a plain sitename or sitegroup.env entry. You must provide an array for WEBS . DB= WEBS=() OP= SITE_FILE= WEBS_CSV=$(array-csv ${WEBS[@]}) LOG_FILE=${OPSTMP}/${OP}_site-move.log SITES_COMPLETED_FILE=${OPSTMP}/${OP}_site-move-completed.log Home directory copy commands These commands are generated now but executed later after site-move for moving customer's home directory contents. Copy these to the OP ticket. for SITE in $(cat ${SITE_FILE}); do SRC=$(ah-server list site:${SITE} -w typeINded,fs,fsdb,fsdbmesh,staging | head -1) DST_FS_CLUSTER_ID=$(ah-server list ${WEBS_CSV} --no-name -c fs_cluster_id | head -1) DST=$(ah-server list % -w typeINded,fs,fsdb,fsdbmesh,staging fs_cluster_id=${DST_FS_CLUSTER_ID} | head -1) SITEGROUP=$(ah-site list ${SITE} --no-name -c sitegroup) SITEGROUP_UID=$(ah-sitegroup list ${SITEGROUP} --no-name -c unix_uid) echo \"{code:title= Move $site home directory content from $SRC to $DST}\" echo \"fssh ${DST} 'sudo mkdir -m755 /mnt/gfs/home'\" echo \"sv-rsyncfile -o avPu ${SRC}:/mnt/gfs/home/${SITEGROUP}/ ${WEBS[0]}:/mnt/gfs/home/${SITEGROUP}/\" echo \"fssh ${DST} 'sudo chown -Rh ${SITEGROUP_UID}:${SITEGROUP_UID} /mnt/gfs/home/${SITEGROUP}'\" echo \"{code}\" echo done echo 'COPY THE ABOVE OUTPUT TO JIRA TICKET AND EXECUTE THEM LATER AFTER THE SITE MOVE AS LAST STEP' Important Note Do not abort workflows! If you are unable to resolve a problem with a workflow, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership Site Move Migrate sites in batches of twenty. We must remove the shared fpm parent settings and re-set them after if needed. for site in $(sed -n '1,20p' ${SITE_FILE}); do ah-site edit ${site} -c fpm:parent-pm= fpm.conf:pm= fpm.conf:pm.min_spare_servers= ah-site move ${site} \\ --db=${DB} \\ --webs=${WEBS[@]} \\ --force if [ \"$?\" -eq 0 ]; then echo ${site} >> ${SITES_COMPLETED_FILE} fi done If there has been a workflow failure DO NOT RESTART THE WORKFLOW . Investigate the failure and escalate as-needed. If you are receiving a handover of a bulk site move and the site moves have been completed, check to see if there are any workflows in flight before proceeding. ah-workflow list move_site_workflow \\ -w created\\>\"$(date +%s --date=\"-1day\")\" \\ -c type step_name status \\ | egrep -v 'completed|aborted' Once you are ready to resume the site moves, filter them out of your list and get started (again). SITES_MOVED=$(sed ':a;N;$!ba;s/\\n/|/g' < $SITES_COMPLETED_FILE) for site in $(egrep -v \"$SITES_MOVED\" ${SITE_FILE} | sed -n '1,20p'); do ah-site edit ${site} -c fpm:parent-pm= fpm.conf:pm= fpm.conf:pm.min_spare_servers= ah-site move ${site} \\ --db=${DB} \\ --webs=${WEBS[@]} \\ --force if [ \"$?\" -eq 0 ]; then echo ${site} >> ${SITES_COMPLETED_FILE} fi done As a last step, move the contents of the customer's home directory using the commands we generated above before the site move and copied to JIRA ticket. Verification Verify there are no alerts for any of the hardware or sites affected by the site move. All workflows from the site moves should be in completed state. Post Steps If no more sites remain on the source server(s) then verify if they can be deprovisioned and file a TSR ticket in the OP JIRA project to deprovision the instance(s) in seven days.","title":"Bulk Site Move"},{"location":"kanban_tickets/bulk_site_move/#bulk-site-move","text":"","title":"Bulk Site Move"},{"location":"kanban_tickets/bulk_site_move/#preparation","text":"Carefully read the ticket and verify the information is accurate. Verify the source and destination servers are in the same region.","title":"Preparation"},{"location":"kanban_tickets/bulk_site_move/#procedure","text":"","title":"Procedure"},{"location":"kanban_tickets/bulk_site_move/#variables","text":"Set the destination DB server, WEBS (in space-separated format/array) and OP ticket. SITE_FILE is the path to a file containing a new-line delimited list of sites to move. The code below is accepts a plain sitename or sitegroup.env entry. You must provide an array for WEBS . DB= WEBS=() OP= SITE_FILE= WEBS_CSV=$(array-csv ${WEBS[@]}) LOG_FILE=${OPSTMP}/${OP}_site-move.log SITES_COMPLETED_FILE=${OPSTMP}/${OP}_site-move-completed.log","title":"Variables"},{"location":"kanban_tickets/bulk_site_move/#home-directory-copy-commands","text":"These commands are generated now but executed later after site-move for moving customer's home directory contents. Copy these to the OP ticket. for SITE in $(cat ${SITE_FILE}); do SRC=$(ah-server list site:${SITE} -w typeINded,fs,fsdb,fsdbmesh,staging | head -1) DST_FS_CLUSTER_ID=$(ah-server list ${WEBS_CSV} --no-name -c fs_cluster_id | head -1) DST=$(ah-server list % -w typeINded,fs,fsdb,fsdbmesh,staging fs_cluster_id=${DST_FS_CLUSTER_ID} | head -1) SITEGROUP=$(ah-site list ${SITE} --no-name -c sitegroup) SITEGROUP_UID=$(ah-sitegroup list ${SITEGROUP} --no-name -c unix_uid) echo \"{code:title= Move $site home directory content from $SRC to $DST}\" echo \"fssh ${DST} 'sudo mkdir -m755 /mnt/gfs/home'\" echo \"sv-rsyncfile -o avPu ${SRC}:/mnt/gfs/home/${SITEGROUP}/ ${WEBS[0]}:/mnt/gfs/home/${SITEGROUP}/\" echo \"fssh ${DST} 'sudo chown -Rh ${SITEGROUP_UID}:${SITEGROUP_UID} /mnt/gfs/home/${SITEGROUP}'\" echo \"{code}\" echo done echo 'COPY THE ABOVE OUTPUT TO JIRA TICKET AND EXECUTE THEM LATER AFTER THE SITE MOVE AS LAST STEP'","title":"Home directory copy commands"},{"location":"kanban_tickets/bulk_site_move/#important-note","text":"Do not abort workflows! If you are unable to resolve a problem with a workflow, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership","title":"Important Note"},{"location":"kanban_tickets/bulk_site_move/#site-move","text":"Migrate sites in batches of twenty. We must remove the shared fpm parent settings and re-set them after if needed. for site in $(sed -n '1,20p' ${SITE_FILE}); do ah-site edit ${site} -c fpm:parent-pm= fpm.conf:pm= fpm.conf:pm.min_spare_servers= ah-site move ${site} \\ --db=${DB} \\ --webs=${WEBS[@]} \\ --force if [ \"$?\" -eq 0 ]; then echo ${site} >> ${SITES_COMPLETED_FILE} fi done If there has been a workflow failure DO NOT RESTART THE WORKFLOW . Investigate the failure and escalate as-needed. If you are receiving a handover of a bulk site move and the site moves have been completed, check to see if there are any workflows in flight before proceeding. ah-workflow list move_site_workflow \\ -w created\\>\"$(date +%s --date=\"-1day\")\" \\ -c type step_name status \\ | egrep -v 'completed|aborted' Once you are ready to resume the site moves, filter them out of your list and get started (again). SITES_MOVED=$(sed ':a;N;$!ba;s/\\n/|/g' < $SITES_COMPLETED_FILE) for site in $(egrep -v \"$SITES_MOVED\" ${SITE_FILE} | sed -n '1,20p'); do ah-site edit ${site} -c fpm:parent-pm= fpm.conf:pm= fpm.conf:pm.min_spare_servers= ah-site move ${site} \\ --db=${DB} \\ --webs=${WEBS[@]} \\ --force if [ \"$?\" -eq 0 ]; then echo ${site} >> ${SITES_COMPLETED_FILE} fi done As a last step, move the contents of the customer's home directory using the commands we generated above before the site move and copied to JIRA ticket.","title":"Site Move"},{"location":"kanban_tickets/bulk_site_move/#verification","text":"Verify there are no alerts for any of the hardware or sites affected by the site move. All workflows from the site moves should be in completed state.","title":"Verification"},{"location":"kanban_tickets/bulk_site_move/#post-steps","text":"If no more sites remain on the source server(s) then verify if they can be deprovisioned and file a TSR ticket in the OP JIRA project to deprovision the instance(s) in seven days.","title":"Post Steps"},{"location":"kanban_tickets/bulk_site_php_edits/","text":"Bulk Site PHP Edits We are sometimes required to update settings for multiple sites. In general, we can make changes to all the sites that require the change without issuing call back tasks and then run FCW against all the servers that needed the change. Preparation Create a list of sites provided in the ticket. OP_NUM=OP-1234 mkdir $OPSTMP/$OP_NUM SITE_LIST=$OPSTMP/$OP_NUM/php-sites vim $SITE_LIST (place your list in here). Set PHP_VERSION variable with the version of the php which needs to be updated (e.g. 7.3) PHP_VERSION= Determine if there are any sites that do not need to be changed. Adjust your list accordingly. ah-site list $(cat $SITE_LIST | paste -sd',') -c php:php-path | grep \\ '$php{PHP_VERSION}' Create a list of servers to run fields-config-web.php against. SERVERS=\"$(for SITE in $(cat $SITE_LIST | tr ',' ' '); do ah-server \\ list site:$SITE -w typeINweb,ded,staging,srv; done | sort | uniq | \\ paste -sd, )\"; echo $SERVERS; Procedure Set PHP version without generating call back tasks. for i in $(cat $SITE_LIST); do ah-site edit $i -c \\ php:php-path=/usr/local/php${PHP_VERSION}/sbin/php-fpm --no-config-tasks; done Run fields-config-web.php against your list of servers. fpdsh -p 20 -l $SERVERS -c \"sudo fields-config-web.php\" Verification Steps to take to verify that the procedure has been executed successfully. ah-site list $(cat $SITE_LIST | paste -sd',') \\ -c php:php-path | grep -vi 'php$PHP_VERSION'","title":"Bulk Site PHP Edits"},{"location":"kanban_tickets/bulk_site_php_edits/#bulk-site-php-edits","text":"We are sometimes required to update settings for multiple sites. In general, we can make changes to all the sites that require the change without issuing call back tasks and then run FCW against all the servers that needed the change.","title":"Bulk Site PHP Edits"},{"location":"kanban_tickets/bulk_site_php_edits/#preparation","text":"Create a list of sites provided in the ticket. OP_NUM=OP-1234 mkdir $OPSTMP/$OP_NUM SITE_LIST=$OPSTMP/$OP_NUM/php-sites vim $SITE_LIST (place your list in here). Set PHP_VERSION variable with the version of the php which needs to be updated (e.g. 7.3) PHP_VERSION= Determine if there are any sites that do not need to be changed. Adjust your list accordingly. ah-site list $(cat $SITE_LIST | paste -sd',') -c php:php-path | grep \\ '$php{PHP_VERSION}' Create a list of servers to run fields-config-web.php against. SERVERS=\"$(for SITE in $(cat $SITE_LIST | tr ',' ' '); do ah-server \\ list site:$SITE -w typeINweb,ded,staging,srv; done | sort | uniq | \\ paste -sd, )\"; echo $SERVERS;","title":"Preparation"},{"location":"kanban_tickets/bulk_site_php_edits/#procedure","text":"Set PHP version without generating call back tasks. for i in $(cat $SITE_LIST); do ah-site edit $i -c \\ php:php-path=/usr/local/php${PHP_VERSION}/sbin/php-fpm --no-config-tasks; done Run fields-config-web.php against your list of servers. fpdsh -p 20 -l $SERVERS -c \"sudo fields-config-web.php\"","title":"Procedure"},{"location":"kanban_tickets/bulk_site_php_edits/#verification","text":"Steps to take to verify that the procedure has been executed successfully. ah-site list $(cat $SITE_LIST | paste -sd',') \\ -c php:php-path | grep -vi 'php$PHP_VERSION'","title":"Verification"},{"location":"kanban_tickets/capacity-limit/","text":"Edge Cluster Capacity limit Each Edge Cluster in a region has a hard capacity limit of 200 RA + 80 Non-RA environments. Previously it was 500 RA + 80 Non-RA environments. Once we reach this limit and try to provision or add more environments in that particular Edge Cluster we get an error like below: Cluster is already at capacity limit and no new environments can be added. Please file an Ops ticket to have a new Edge Cluster provisioned. (Aq::Hosting::ApiClient::XMLRPCRemoteException) If the limit is reached for Non-RA environments and we try to provision or add more Non-RA environments to that particular Edge Cluster, we get an error like below: Cluster is already at production capacity limit and no new production environments can be added. Note that production environments are the ones with stage values: prod, dev and stg. Please file an Ops ticket to have a new Edge Cluster provisioned. (Aq::Hosting::ApiClient::XMLRPCRemoteException) If the limit is reached for RA environments and we try to provision or add more RA environments to that particulat Edge Cluster, we get an error like below: Cluster is already at RA capacity limit and no new RA environments can be added. Please file an Ops ticket to have a new Edge Cluster provisioned. (Aq::Hosting::ApiClient::XMLRPCRemoteException) Because of recent events, we have seen that the 500 RA sites limit is not enough when RA is performing activities that update sites frequently. So we are moving to a strategy where Ops will work together with edge team to figure out what is the optimum limit. We will now adopt a 200 RA sites limit which will be controlled by using the tag ra_full . So, if a cluster has the ra_full tag and you try to add an environment to it, you will receive the error: RequestError: This edge cluster is tagged ra_full and cannot have environments added to it NOTE : We use separate edge cluster for RA and NON-RA sites for shared-vpc in regions eu-west-1,us-west-2 and us-east-1. For all other regions and VPCs we use same edge cluster for RA and NON-RA sites(including shared-vpc-hipaa vpc for eu-west-1,us-west-2 and us-east-1) Capacity Limit Reached for Non-RA Environments In most of the cases, capacity limit of Edge Cluster is reached for production environements (i.e. Non-RA environments). In such a case we need to create a new Edge Cluster irrespective of number of RA environments used. Follow below steps: Create a new Edge Cluster in the same Region and same VPC. Use the same size as that of the Edge Cluster which reached its capacity limit. ah-edge create-edge-cluster --availability-zones=AZ1 AZ2 --size=SIZE --vpc=VPC Supported sizes: 'edge1.medium'. Uses t3.medium instances. 'edge1.large'. Uses t3.large instances. 'edge1.xlarge'. Uses t3.xlarge instances. 'edge1.2xlarge'. Uses t3.2xlarge instances. In above command VPC is the VPC name in which the cluster is going to be created. Use the same VPC name of the cluster which reached its capacity limit. An EdgeCluster exists in two Availability Zones. Wait for the status of Edge Cluster to change to CREATED . You can check the status using the uuid from the output of previous step and using below command. UUID= ah-edge describe-edge-cluster --uuid=${UUID} Add tags activebal,activebaldev,activebalstg,activebalprod,shared,shared_vpc to the newly created Edge Cluster using below command. for tag in activebal activebaldev activebalstg activebalprod shared shared_vpc; do ah-edge tag-edge-cluster --tag=${tag} --uuid=${UUID} done NOTE : In case of HIPAA or PCI VPC shared_vpc_hipaa and shared_vpc_pci tags should be added respectively in place of shared_vpc tag. Remove all tags except shared tags from the previous Edge Cluster using below command. for tag in activebal activebaldev activebalstg activebalprod; do ah-edge untag-edge-cluster --tag=${tag} --uuid=${UUID} done Capacity Limit Reached for RA Environments It rarely happens that capacity limit is reached for an Edge Cluster for RA environments as we have a limit of nearly 500 RA environments per Edge Cluster. However, mind that now we are working with 200 RA sites managed by ops using the tag ra_full . You might encounter both scenarios where these limits are reached, if that is the case, follow steps below: Find an Edge Cluster with a low environment count in the same VPC and Region using below command. ah-edge list-edge-clusters UUID= If no suitable cluster exists, create a new Edge Cluster. Remove activebalra tag from the current Edge Cluster for the VPC and Region. ah-edge untag-edge-cluster --tag=activebalra --uuid=${UUID} Add ra_full tag to the current Edge Cluster for the VPC and Region. ah-edge tag-edge-cluster --tag=ra_full --uuid=${UUID} Add activebalra tag to the different Edge Cluster with same VPC and Region. ah-edge tag-edge-cluster --tag=activebalra --uuid=${UUID} Capacity Limit Configuration To have more flexibility managing the sites on clusters we can now define edge cluster capacities. This will avoid engineering intervention in case of any performance problems, Ops will be able to accommodate sites on clusters according to any requirements. However, keep in mind that the current limits are strongly recommended: 200 RA sites and 80 production sites. To configure limits per cluster: ah-edge set-cluster-config --key=ra-max-capacity --value=150 --uuid=UUID ah-edge set-cluster-config --key=prod-max-capacity --value=60 --uuid=UUID To inspect limits per cluster: ah-edge describe-edge-cluster --uuid=UUID","title":"Edge Cluster Capacity limit"},{"location":"kanban_tickets/capacity-limit/#edge-cluster-capacity-limit","text":"Each Edge Cluster in a region has a hard capacity limit of 200 RA + 80 Non-RA environments. Previously it was 500 RA + 80 Non-RA environments. Once we reach this limit and try to provision or add more environments in that particular Edge Cluster we get an error like below: Cluster is already at capacity limit and no new environments can be added. Please file an Ops ticket to have a new Edge Cluster provisioned. (Aq::Hosting::ApiClient::XMLRPCRemoteException) If the limit is reached for Non-RA environments and we try to provision or add more Non-RA environments to that particular Edge Cluster, we get an error like below: Cluster is already at production capacity limit and no new production environments can be added. Note that production environments are the ones with stage values: prod, dev and stg. Please file an Ops ticket to have a new Edge Cluster provisioned. (Aq::Hosting::ApiClient::XMLRPCRemoteException) If the limit is reached for RA environments and we try to provision or add more RA environments to that particulat Edge Cluster, we get an error like below: Cluster is already at RA capacity limit and no new RA environments can be added. Please file an Ops ticket to have a new Edge Cluster provisioned. (Aq::Hosting::ApiClient::XMLRPCRemoteException) Because of recent events, we have seen that the 500 RA sites limit is not enough when RA is performing activities that update sites frequently. So we are moving to a strategy where Ops will work together with edge team to figure out what is the optimum limit. We will now adopt a 200 RA sites limit which will be controlled by using the tag ra_full . So, if a cluster has the ra_full tag and you try to add an environment to it, you will receive the error: RequestError: This edge cluster is tagged ra_full and cannot have environments added to it NOTE : We use separate edge cluster for RA and NON-RA sites for shared-vpc in regions eu-west-1,us-west-2 and us-east-1. For all other regions and VPCs we use same edge cluster for RA and NON-RA sites(including shared-vpc-hipaa vpc for eu-west-1,us-west-2 and us-east-1)","title":"Edge Cluster Capacity limit"},{"location":"kanban_tickets/capacity-limit/#capacity-limit-reached-for-non-ra-environments","text":"In most of the cases, capacity limit of Edge Cluster is reached for production environements (i.e. Non-RA environments). In such a case we need to create a new Edge Cluster irrespective of number of RA environments used. Follow below steps: Create a new Edge Cluster in the same Region and same VPC. Use the same size as that of the Edge Cluster which reached its capacity limit. ah-edge create-edge-cluster --availability-zones=AZ1 AZ2 --size=SIZE --vpc=VPC Supported sizes: 'edge1.medium'. Uses t3.medium instances. 'edge1.large'. Uses t3.large instances. 'edge1.xlarge'. Uses t3.xlarge instances. 'edge1.2xlarge'. Uses t3.2xlarge instances. In above command VPC is the VPC name in which the cluster is going to be created. Use the same VPC name of the cluster which reached its capacity limit. An EdgeCluster exists in two Availability Zones. Wait for the status of Edge Cluster to change to CREATED . You can check the status using the uuid from the output of previous step and using below command. UUID= ah-edge describe-edge-cluster --uuid=${UUID} Add tags activebal,activebaldev,activebalstg,activebalprod,shared,shared_vpc to the newly created Edge Cluster using below command. for tag in activebal activebaldev activebalstg activebalprod shared shared_vpc; do ah-edge tag-edge-cluster --tag=${tag} --uuid=${UUID} done NOTE : In case of HIPAA or PCI VPC shared_vpc_hipaa and shared_vpc_pci tags should be added respectively in place of shared_vpc tag. Remove all tags except shared tags from the previous Edge Cluster using below command. for tag in activebal activebaldev activebalstg activebalprod; do ah-edge untag-edge-cluster --tag=${tag} --uuid=${UUID} done","title":"Capacity Limit Reached for Non-RA Environments"},{"location":"kanban_tickets/capacity-limit/#capacity-limit-reached-for-ra-environments","text":"It rarely happens that capacity limit is reached for an Edge Cluster for RA environments as we have a limit of nearly 500 RA environments per Edge Cluster. However, mind that now we are working with 200 RA sites managed by ops using the tag ra_full . You might encounter both scenarios where these limits are reached, if that is the case, follow steps below: Find an Edge Cluster with a low environment count in the same VPC and Region using below command. ah-edge list-edge-clusters UUID= If no suitable cluster exists, create a new Edge Cluster. Remove activebalra tag from the current Edge Cluster for the VPC and Region. ah-edge untag-edge-cluster --tag=activebalra --uuid=${UUID} Add ra_full tag to the current Edge Cluster for the VPC and Region. ah-edge tag-edge-cluster --tag=ra_full --uuid=${UUID} Add activebalra tag to the different Edge Cluster with same VPC and Region. ah-edge tag-edge-cluster --tag=activebalra --uuid=${UUID}","title":"Capacity Limit Reached for RA Environments"},{"location":"kanban_tickets/capacity-limit/#capacity-limit-configuration","text":"To have more flexibility managing the sites on clusters we can now define edge cluster capacities. This will avoid engineering intervention in case of any performance problems, Ops will be able to accommodate sites on clusters according to any requirements. However, keep in mind that the current limits are strongly recommended: 200 RA sites and 80 production sites. To configure limits per cluster: ah-edge set-cluster-config --key=ra-max-capacity --value=150 --uuid=UUID ah-edge set-cluster-config --key=prod-max-capacity --value=60 --uuid=UUID To inspect limits per cluster: ah-edge describe-edge-cluster --uuid=UUID","title":"Capacity Limit Configuration"},{"location":"kanban_tickets/change_balancers_on_existing_environment/","text":"Change balancers on existing environment Information There are four distinct activities that are possible when Ops is tasked with changing balancers for a customer site: Shared to Dedicated Dedicated to Dedicated Shared to Shared Dedicated to Shared You will also need to validate the following prior to making any changes. ELB Configuration VPC Placement (if applicable) SSL Requirements Custom VCL Requirements ELB Configuration If any of the customer's sites are currently behind an ELB, you must ensure that the balancers' respective AZs are enabled for the ELB. VPC Placement To view the current site config, check the following: SITENAME= ah-server list site:${SITENAME} -w type=bal -c vpc_id Determine the name and type of VPC: ah-vpc list % -w id=${VPC_ID} ah-vpc get ${VPC_NAME} You can then proceed with Allocating Hardware once you have found the above information. Be sure to only provision balancers for this process . If in doubt, ask in the JIRA ticket about VPC placement and mark the ticket \"Waiting For Feedback\". SSL Requirements Many customer sites require SSL termination for HTTPS traffic, for which an SSL certificate and key is required. If the customer's domain is covered by an Ops-managed certificate (rather than a customer-managed SNI cert), then we will need to update the customer's new balancers with a valid certificate/key pair. First check if any of the affected sites have balancers with an Ops-managed certificate. We identify these balancers by giving them an ssl_ tag. SITES= for site in ${SITES[@]}; do ah-server list site:${site} -w type=bal status=0 -c tags done If any single site has balancers with several or mismatched SSL tags, you should investigate why and resolve it if appropriate. (As a general rule, a site should only have one SSL tag.) If the balancers have an SSL tag you need to ensure that the customer's new balancers are set up with a valid SSL cert/key pair that covers the same domains that their current balancers do: for site in ${SITES[@]}; do ahops-ssltool san-audit ${site} done This audit will display: ...all domains served by a site ...all domains covered by the Ops-managed cert on that site's balancers ...all domains covered by the customer-managed SNI cert (if applicable) If the customer-managed SNI cert is valid and covers all of the relevant domains that are currently covered by the Ops-managed cert, or if the customer site does not have any domains covered by the Ops-managed cert (i.e. if they are on shared balancers with a UCC cert which does not cover any customer domains), then you do not need to migrate anything to the new balancers (unless specifically requested). Otherwise, you need to ensure a valid SSL cert/key pair is deployed to the customer's new balancers, which is handled differently depending on which procedure you are doing. . Tag Validation and Migration If the customer requires an SSL certificate that Acquia controls to be deployed at the load balancer layer for their new balancers, determine what their current SSL tag is. ah-server tag list ${OLD_BALS} Apply the same tag to the new balancers. ah-server tag add ${NEW_BALS} -t ${SSL_TAG} Use the Deploy certificate process to deploy the SSL certificate from DigiCert. If the certificate is customer-supplied (i.e. not ordered or managed by Acquia via DigiCert), copy the certificate from the old balancer pair and deploy it using the same method. Custom VCL Requirements Customers may have custom VCL deployed to their balancers. You can verify this by checking the puppet configs. ah-server list ${OLD_BALS} -c puppet:varnish_config If the customer's VCL needs to be deployed on new balancers, configure the new balancers with the same value. ah-server edit ${NEW_BALS} -c puppet:varnish_config=${CONFIG_NAME} Note that if the the target configuration is an Edge Cluster, the following command should be used: ah-edge set-cluster-config --uuid $CLUSTER_UUID --key custom-vcl-name --value $CONFIG_NAME Puppet will run on a callback task after the command runs and may take upward of 5 minutes to complete. Procedures Shared to Dedicated Dedicated to Dedicated Shared to Shared Dedicated to Shared","title":"Change balancers on existing environment"},{"location":"kanban_tickets/change_balancers_on_existing_environment/#change-balancers-on-existing-environment","text":"","title":"Change balancers on existing environment"},{"location":"kanban_tickets/change_balancers_on_existing_environment/#information","text":"There are four distinct activities that are possible when Ops is tasked with changing balancers for a customer site: Shared to Dedicated Dedicated to Dedicated Shared to Shared Dedicated to Shared You will also need to validate the following prior to making any changes. ELB Configuration VPC Placement (if applicable) SSL Requirements Custom VCL Requirements","title":"Information"},{"location":"kanban_tickets/change_balancers_on_existing_environment/#elb-configuration","text":"If any of the customer's sites are currently behind an ELB, you must ensure that the balancers' respective AZs are enabled for the ELB.","title":"ELB Configuration"},{"location":"kanban_tickets/change_balancers_on_existing_environment/#vpc-placement","text":"To view the current site config, check the following: SITENAME= ah-server list site:${SITENAME} -w type=bal -c vpc_id Determine the name and type of VPC: ah-vpc list % -w id=${VPC_ID} ah-vpc get ${VPC_NAME} You can then proceed with Allocating Hardware once you have found the above information. Be sure to only provision balancers for this process . If in doubt, ask in the JIRA ticket about VPC placement and mark the ticket \"Waiting For Feedback\".","title":"VPC Placement"},{"location":"kanban_tickets/change_balancers_on_existing_environment/#ssl-requirements","text":"Many customer sites require SSL termination for HTTPS traffic, for which an SSL certificate and key is required. If the customer's domain is covered by an Ops-managed certificate (rather than a customer-managed SNI cert), then we will need to update the customer's new balancers with a valid certificate/key pair. First check if any of the affected sites have balancers with an Ops-managed certificate. We identify these balancers by giving them an ssl_ tag. SITES= for site in ${SITES[@]}; do ah-server list site:${site} -w type=bal status=0 -c tags done If any single site has balancers with several or mismatched SSL tags, you should investigate why and resolve it if appropriate. (As a general rule, a site should only have one SSL tag.) If the balancers have an SSL tag you need to ensure that the customer's new balancers are set up with a valid SSL cert/key pair that covers the same domains that their current balancers do: for site in ${SITES[@]}; do ahops-ssltool san-audit ${site} done This audit will display: ...all domains served by a site ...all domains covered by the Ops-managed cert on that site's balancers ...all domains covered by the customer-managed SNI cert (if applicable) If the customer-managed SNI cert is valid and covers all of the relevant domains that are currently covered by the Ops-managed cert, or if the customer site does not have any domains covered by the Ops-managed cert (i.e. if they are on shared balancers with a UCC cert which does not cover any customer domains), then you do not need to migrate anything to the new balancers (unless specifically requested). Otherwise, you need to ensure a valid SSL cert/key pair is deployed to the customer's new balancers, which is handled differently depending on which procedure you are doing. .","title":"SSL Requirements"},{"location":"kanban_tickets/change_balancers_on_existing_environment/#tag-validation-and-migration","text":"If the customer requires an SSL certificate that Acquia controls to be deployed at the load balancer layer for their new balancers, determine what their current SSL tag is. ah-server tag list ${OLD_BALS} Apply the same tag to the new balancers. ah-server tag add ${NEW_BALS} -t ${SSL_TAG} Use the Deploy certificate process to deploy the SSL certificate from DigiCert. If the certificate is customer-supplied (i.e. not ordered or managed by Acquia via DigiCert), copy the certificate from the old balancer pair and deploy it using the same method.","title":"Tag Validation and Migration"},{"location":"kanban_tickets/change_balancers_on_existing_environment/#custom-vcl-requirements","text":"Customers may have custom VCL deployed to their balancers. You can verify this by checking the puppet configs. ah-server list ${OLD_BALS} -c puppet:varnish_config If the customer's VCL needs to be deployed on new balancers, configure the new balancers with the same value. ah-server edit ${NEW_BALS} -c puppet:varnish_config=${CONFIG_NAME} Note that if the the target configuration is an Edge Cluster, the following command should be used: ah-edge set-cluster-config --uuid $CLUSTER_UUID --key custom-vcl-name --value $CONFIG_NAME Puppet will run on a callback task after the command runs and may take upward of 5 minutes to complete.","title":"Custom VCL Requirements"},{"location":"kanban_tickets/change_balancers_on_existing_environment/#procedures","text":"Shared to Dedicated Dedicated to Dedicated Shared to Shared Dedicated to Shared","title":"Procedures"},{"location":"kanban_tickets/change_db_password/","text":"Site Database Password Change WARNING : This only applies to Classic Cloud. Sometimes, due to a security breach or mishandling of information, you may need to reset a site's MySQL credentials. Changing Credentials This is done with the following commands: Change the site user's DB credentials. *** ah-site regenerate db-pass $SITE Run fields-config-db.php across the DB servers and fields-config-web.php across the webs. fpdsh -t site:${SITE} -n 'ded|dbmaster|dbmesh|fsdbmesh' -c 'sudo fields-config-db.php' && \\ site-fcw ${SITE} Change the root user's DB credentials. This command only needs to be run on the primary DB server. ah-db-cluster change-root-pass $SERVER *** NOTE: due to CL-15757, this command will not work on dev/test sites located on staging servers. @TODO: Remove this note once that CL is fixed.","title":"Site Database Password Change"},{"location":"kanban_tickets/change_db_password/#site-database-password-change","text":"WARNING : This only applies to Classic Cloud. Sometimes, due to a security breach or mishandling of information, you may need to reset a site's MySQL credentials.","title":"Site Database Password Change"},{"location":"kanban_tickets/change_db_password/#changing-credentials","text":"This is done with the following commands: Change the site user's DB credentials. *** ah-site regenerate db-pass $SITE Run fields-config-db.php across the DB servers and fields-config-web.php across the webs. fpdsh -t site:${SITE} -n 'ded|dbmaster|dbmesh|fsdbmesh' -c 'sudo fields-config-db.php' && \\ site-fcw ${SITE} Change the root user's DB credentials. This command only needs to be run on the primary DB server. ah-db-cluster change-root-pass $SERVER *** NOTE: due to CL-15757, this command will not work on dev/test sites located on staging servers. @TODO: Remove this note once that CL is fixed.","title":"Changing Credentials"},{"location":"kanban_tickets/clamav/","text":"ClamAV Daemon Enabling To enable the ClamAV daemon for all customer-facing servers for a given site: SITE= SERVERS=$(ah-server list site:${SITE} -w typeINded,web,staging) SERVERS_CSV=$(array-csv ${SERVERS[@]}) ah-server edit $SERVERS_CSV -c puppet:clamd=add fpdsh -l $SERVERS_CSV -c 'sudo puppet agent -t' ah-server tag add ${SERVERS[@]} -t clamav OR in Masterless Puppet mode SITE= SERVERS=$(ah-server list site:${SITE} -w typeINded,web,staging) SERVERS_CSV=$(array-csv ${SERVERS[@]}) ah-server edit $SERVERS_CSV -c puppet:clamd=add fpdsh -l $SERVERS_CSV -c 'sudo run-puppet' ah-server tag add ${SERVERS[@]} -t clamav Tunables We can set the following variables to tune ClamAV: StreamMaxLength MaxFileSize The puppet template will append M to your configurations, only specify a number for VALUE . To tune them: ah-server edit $SERVERS_CSV -c puppet:clamd.conf:clamd_stream_max_length=${VALUE} OR ah-server edit $SERVERS_CSV -c puppet:clamd.conf:clamd_max_file_size=${VALUE} Disabling To disable ClamAV: ah-server edit $SERVERS_CSV -c puppet:clamd=","title":"ClamAV Daemon"},{"location":"kanban_tickets/clamav/#clamav-daemon","text":"","title":"ClamAV Daemon"},{"location":"kanban_tickets/clamav/#enabling","text":"To enable the ClamAV daemon for all customer-facing servers for a given site: SITE= SERVERS=$(ah-server list site:${SITE} -w typeINded,web,staging) SERVERS_CSV=$(array-csv ${SERVERS[@]}) ah-server edit $SERVERS_CSV -c puppet:clamd=add fpdsh -l $SERVERS_CSV -c 'sudo puppet agent -t' ah-server tag add ${SERVERS[@]} -t clamav OR in Masterless Puppet mode SITE= SERVERS=$(ah-server list site:${SITE} -w typeINded,web,staging) SERVERS_CSV=$(array-csv ${SERVERS[@]}) ah-server edit $SERVERS_CSV -c puppet:clamd=add fpdsh -l $SERVERS_CSV -c 'sudo run-puppet' ah-server tag add ${SERVERS[@]} -t clamav","title":"Enabling"},{"location":"kanban_tickets/clamav/#tunables","text":"We can set the following variables to tune ClamAV: StreamMaxLength MaxFileSize The puppet template will append M to your configurations, only specify a number for VALUE . To tune them: ah-server edit $SERVERS_CSV -c puppet:clamd.conf:clamd_stream_max_length=${VALUE} OR ah-server edit $SERVERS_CSV -c puppet:clamd.conf:clamd_max_file_size=${VALUE}","title":"Tunables"},{"location":"kanban_tickets/clamav/#disabling","text":"To disable ClamAV: ah-server edit $SERVERS_CSV -c puppet:clamd=","title":"Disabling"},{"location":"kanban_tickets/code_checkout_failures/","text":"Code Checkout Failures Running fields-config-web.php may produce errors when checking out a site's code. An error about a nonexistent path must be solved by correcting the path. Most other errors are solved by performing a clean checkout. Incorrect VCS path fields-config-web.php will indicate the VCS path does not exist. Check the site's vcs_path setting in fields. ah-site list $SITE -c vcs_path If this is a newly provisioned site for an existing sitegroup, skip ahead and set the VCS path to 'tags/WELCOME'. Check if the site uses SVN or Git. ah-site get $SITE | grep 'svn\\.vcs_type' For Git : View the list of branches and tags available in the repository. On the bastion: site-repo $SITE On the server: SITEGROUP= URL= sudo su -l $SITEGROUP git ls-remote $URL For SVN : Check that you have not regressed back to the terrible time before Git, then question the customer's sanity. date +%Y Work with Support to determine which tag or branch to deploy. Hopefully, there will be an obvious choice. The fallback case is to use 'master' for Git and 'trunk' for SVN. Set the site to use the chosen path. VCS_PATH= ah-site edit $SITE -s vcs_path=$VCS_PATH Run fields-config-web.php . If the branch or tag was deleted by the customer, link your ticket to CL-10960 . Clean checkout Remove the badly-deployed code and re-deploy a fresh copy. Remove the checkout and docroot directories. SITE= rm -r /var/www/repo/$SITE rm -r /var/www/html/$SITE Run fields-config-web.php .","title":"Code Checkout Failures"},{"location":"kanban_tickets/code_checkout_failures/#code-checkout-failures","text":"Running fields-config-web.php may produce errors when checking out a site's code. An error about a nonexistent path must be solved by correcting the path. Most other errors are solved by performing a clean checkout.","title":"Code Checkout Failures"},{"location":"kanban_tickets/code_checkout_failures/#incorrect-vcs-path","text":"fields-config-web.php will indicate the VCS path does not exist. Check the site's vcs_path setting in fields. ah-site list $SITE -c vcs_path If this is a newly provisioned site for an existing sitegroup, skip ahead and set the VCS path to 'tags/WELCOME'. Check if the site uses SVN or Git. ah-site get $SITE | grep 'svn\\.vcs_type' For Git : View the list of branches and tags available in the repository. On the bastion: site-repo $SITE On the server: SITEGROUP= URL= sudo su -l $SITEGROUP git ls-remote $URL For SVN : Check that you have not regressed back to the terrible time before Git, then question the customer's sanity. date +%Y Work with Support to determine which tag or branch to deploy. Hopefully, there will be an obvious choice. The fallback case is to use 'master' for Git and 'trunk' for SVN. Set the site to use the chosen path. VCS_PATH= ah-site edit $SITE -s vcs_path=$VCS_PATH Run fields-config-web.php . If the branch or tag was deleted by the customer, link your ticket to CL-10960 .","title":"Incorrect VCS path"},{"location":"kanban_tickets/code_checkout_failures/#clean-checkout","text":"Remove the badly-deployed code and re-deploy a fresh copy. Remove the checkout and docroot directories. SITE= rm -r /var/www/repo/$SITE rm -r /var/www/html/$SITE Run fields-config-web.php .","title":"Clean checkout"},{"location":"kanban_tickets/configuring_hsd_for_sites/","text":"HSD (Higher Site Density) Traditionally there are limited number of sites deployed on a web server and each site has a preallocated set of resources (PHP processes). HSD enables many sites to be deployed on the same web servers and lets resources float between whichever site is most active at any given moment. So here Ops may need to perform certain actions for HSD sites. To check if hsd is enabled for particular site SITE= ah-site list $SITE -c site:dynamic_process_limit site:systemd NOTE if the output of above query shows \u2018dynamic_process_limit\u2019 is on and value of \u2018systemd\u2019 is 1, it will confirm that HSD is enabled for that particular site. To enable hsd ah-site edit $SITE -c site:dynamic_process_limit=on site:systemd=1 fpm.conf:pm.max_children= NOTE the fpm.conf:pm.max_children must be unset, or it will override the HSD settings. Keep in mind that once you enable HSD on a site, all sites sharing that same hardware need to have HSD enabled as well in order for it to work properly. To disable hsd ah-site edit $SITE -c site:dynamic_process_limit= site:systemd= NOTE Disabling HSD can cause Ooming/downtime and should not be done for pfizer servers or CDE servers.","title":"HSD (Higher Site Density)"},{"location":"kanban_tickets/configuring_hsd_for_sites/#hsd-higher-site-density","text":"Traditionally there are limited number of sites deployed on a web server and each site has a preallocated set of resources (PHP processes). HSD enables many sites to be deployed on the same web servers and lets resources float between whichever site is most active at any given moment. So here Ops may need to perform certain actions for HSD sites.","title":"HSD (Higher Site Density)"},{"location":"kanban_tickets/configuring_hsd_for_sites/#to-check-if-hsd-is-enabled-for-particular-site","text":"SITE= ah-site list $SITE -c site:dynamic_process_limit site:systemd NOTE if the output of above query shows \u2018dynamic_process_limit\u2019 is on and value of \u2018systemd\u2019 is 1, it will confirm that HSD is enabled for that particular site.","title":"To check if hsd is enabled for particular site"},{"location":"kanban_tickets/configuring_hsd_for_sites/#to-enable-hsd","text":"ah-site edit $SITE -c site:dynamic_process_limit=on site:systemd=1 fpm.conf:pm.max_children= NOTE the fpm.conf:pm.max_children must be unset, or it will override the HSD settings. Keep in mind that once you enable HSD on a site, all sites sharing that same hardware need to have HSD enabled as well in order for it to work properly.","title":"To enable hsd"},{"location":"kanban_tickets/configuring_hsd_for_sites/#to-disable-hsd","text":"ah-site edit $SITE -c site:dynamic_process_limit= site:systemd= NOTE Disabling HSD can cause Ooming/downtime and should not be done for pfizer servers or CDE servers.","title":"To disable hsd"},{"location":"kanban_tickets/core_dumps/","text":"Enable Coredumps for Capturing PHP Segfaults By default we do not capture core dumps when applications segfault. This is fine for most of the time, but occasionally we need to dig further into an issue. Kudos to John Meichle for making this a thing. Managing Coredumps Enabling core dumping is a site wide setting. Before starting ensure that: There is enough free space on the ephemeral /mnt volume. You are OK with FPM restarting on every web server in the cluster. If a site is segfaulting with every page request that you do not fill the ephemeral volume. You do not leave core dumps running any longer than you absolutely have to. Enabling It is possible to set the core dumps to be a maximum size, but we are mostly concerned with getting at least one complete dump, so shouldn't needlessly restrict the size: ah-site edit $SITE -c fpm.conf:rlimit_core=unlimited Or, with specifying 256M ah-site edit $SITE -c fpm.conf:rlimit_core=268435456 Disabling ah-site edit $SITE -c fpm.conf:rlimit_core= Coredump Analysis Once you have a coredump, there are several ways to analyze it. It is not recommend to generate a plain backtrace with GDB, as you will see the function calls for the interpreter instead of the PHP code. By using this .gdbinit file you will have the ability to generate a backtrace of PHP interpreted code that was executed, which is useful for helping a determine which code path lead to the segfault. Ticket Ref 3 Preparing Cores are dumped to /mnt/tmp/cores/ # @TODO: Remove this when CL-16933 is completed. apt-get install gdb -y wget --no-check-certificate \\ -O /root/.gdbinit https://raw.githubusercontent.com/php/php-src/PHP-5.6/.gdbinit # If PHP 7.0 use this one # wget --no-check-certificate \\ # -O /root/.gdbinit https://raw.githubusercontent.com/php/php-src/PHP-7.0/.gdbinit cd /root Analysing Find the php path for the site - this is different between versions: ah-site get $SITE | grep php-path To invoke GDB with a coredump: FPM_PATH= CORE_PATH= and invoke gdb to enter the GDB shell gdb $FPM_PATH $CORE_PATH Interpreting A Sample Backtrace To see a backtrace of function calls that lead to an incident use bt . You can provide bt with a numeric argument, to limit the number of frames to show. Without a backtrace limit, recursive/infinite looping could cause the output to spew forever (however, gdb rate limits it). (gdb) bt 10 #0 0x00007fa237529de7 in ?? () from /lib/libgcc_s.so.1 #1 0x00007fa23752a66e in _Unwind_Backtrace () from /lib/libgcc_s.so.1 #2 0x00007fa237fd8e3e in backtrace () from /lib/libc.so.6 #3 0x00007fa233787f1d in nr_signal_tracer_common () from /usr/local/php5.5/lib/php/extensions/newrelic.so #4 0x00007fa233787f89 in agent_fatal_signal_handler () from /usr/local/php5.5/lib/php/extensions/newrelic.so #5 <signal handler called> #6 0x0000000005c20560 in ?? () #7 0x00000000008c8ba0 in execute_ex (execute_data=0x7fa23e9c9d70) at /usr/local/src/php-5.5.11/Zend/zend_vm_execute.h:363 #8 0x00007fa2337ada32 in nr_php_execute_enabled () from /usr/local/php5.5/lib/php/extensions/newrelic.so #9 0x00007fa2337ae011 in nr_php_execute () from /usr/local/php5.5/lib/php/extensions/newrelic.so (More stack frames follow...) Since gdb loads $HOME/.gdbinit it will decode information in execute_data arguments and generate a backtrace of the PHP calls with zbacktrace , for example: (gdb) zbacktrace [0x7fa23e9c9d70] menu_get_item(\"node/79381\") /mnt/www/html/nbcunbc/docroot/sites/nbcunbc/modules/contrib/subpathauto/subpathauto.module:25 [0x7fa23e9c9b30] subpathauto_url_inbound_alter(\"node/79381\", \\ \"nashville-star\", NULL) /mnt/www/html/nbcunbc/docroot/includes/path.inc:272 [0x7fa23e9c9900] drupal_get_normal_path(\"nashville-star\") /mnt/www/html/nbcunbc/docroot/includes/path.inc:21 [0x7fa23e9c96a8] drupal_path_initialize() /mnt/www/html/nbcunbc/docroot/includes/common.inc:5157 [0x7fa23e9c8ca0] _drupal_bootstrap_full() /mnt/www/html/nbcunbc/docroot/includes/bootstrap.inc:2266 [0x7fa23e9c8750] drupal_bootstrap(7) /mnt/www/html/nbcunbc/docroot/index.php:20 By switching your frame you can examine different parts of the backtrace stack. (gdb) frame 7 #7 0x00000000008c8ba0 in execute_ex (execute_data=0x7fa23e9cfda8) at /usr/local/src/php-5.5.11/Zend/zend_vm_execute.h:363 363 in /usr/local/src/php-5.5.11/Zend/zend_vm_execute.h (gdb) info frame Stack level 7, frame at 0x7fff29fe8ce0: rip = 0x8c8ba0 in execute_ex (/usr/local/src/php-5.5.11/Zend/zend_vm_execute.h:363);\\ saved rip 0x7fa2337ada32 called by frame at 0x7fff29fe8d80, caller of frame at 0x7fff29fe8c60 source language c. Arglist at 0x7fff29fe8c58, args: execute_data=0x7fa23e9cfda8 Locals at 0x7fff29fe8c58, Previous frame's sp is 0x7fff29fe8ce0 Saved registers: rbx at 0x7fff29fe8ca8, rbp at 0x7fff29fe8cb0, r12 at 0x7fff29fe8cb8, r13 \\ at 0x7fff29fe8cc0, r14 at 0x7fff29fe8cc8, r15 at 0x7fff29fe8cd0, rip at 0x7fff29fe8cd8 (gdb) info args execute_data = 0x7fa23e9cfda8 (gdb) info locals ret = <value optimized out> original_in_execution = 1 '\\001' You can also do some examination of the function's arguments using gdb. (gdb) set print pretty on (gdb) ptype execute_data type = struct _zend_execute_data { struct _zend_op *opline; zend_function_state function_state; zend_op_array *op_array; zval *object; HashTable *symbol_table; struct _zend_execute_data *prev_execute_data; zval *old_error_reporting; zend_bool nested; zval **original_return_value; zend_class_entry *current_scope; zend_class_entry *current_called_scope; zval *current_this; struct _zend_op *fast_ret; call_slot *call_slots; call_slot *call; } * Show the variable names and values of the structure using print. Since execute_data is actually a pointer, use print * to dereference: (gdb) print *execute_data $2 = { opline = 0x7fa22b8b3418, function_state = { function = 0x2c87c50, arguments = 0x0 }, op_array = 0x2c87c50, object = 0x0, symbol_table = 0x0, prev_execute_data = 0x7fa23e9cfad0, old_error_reporting = 0x0, nested = 0 '\\000', original_return_value = 0x320b5a0, current_scope = 0x0, current_called_scope = 0x7fa23e9cfad0, current_this = 0x0, fast_ret = 0x32a6700, call_slots = 0x7fa23e9cfe98, call = 0x7fa23e9cfe98 } Arrays can be dereferenced using @N where N is the number of items. Lets say we know that execute_data->op_array->last_var has the length of the array execute_data->op_array->vars we can list all members of that array with: (gdb) print *execute_data->op_array->vars@(execute_data->op_array->last_var)","title":"Enable Coredumps for Capturing PHP Segfaults"},{"location":"kanban_tickets/core_dumps/#enable-coredumps-for-capturing-php-segfaults","text":"By default we do not capture core dumps when applications segfault. This is fine for most of the time, but occasionally we need to dig further into an issue. Kudos to John Meichle for making this a thing.","title":"Enable Coredumps for Capturing PHP Segfaults"},{"location":"kanban_tickets/core_dumps/#managing-coredumps","text":"Enabling core dumping is a site wide setting. Before starting ensure that: There is enough free space on the ephemeral /mnt volume. You are OK with FPM restarting on every web server in the cluster. If a site is segfaulting with every page request that you do not fill the ephemeral volume. You do not leave core dumps running any longer than you absolutely have to.","title":"Managing Coredumps"},{"location":"kanban_tickets/core_dumps/#enabling","text":"It is possible to set the core dumps to be a maximum size, but we are mostly concerned with getting at least one complete dump, so shouldn't needlessly restrict the size: ah-site edit $SITE -c fpm.conf:rlimit_core=unlimited Or, with specifying 256M ah-site edit $SITE -c fpm.conf:rlimit_core=268435456","title":"Enabling"},{"location":"kanban_tickets/core_dumps/#disabling","text":"ah-site edit $SITE -c fpm.conf:rlimit_core=","title":"Disabling"},{"location":"kanban_tickets/core_dumps/#coredump-analysis","text":"Once you have a coredump, there are several ways to analyze it. It is not recommend to generate a plain backtrace with GDB, as you will see the function calls for the interpreter instead of the PHP code. By using this .gdbinit file you will have the ability to generate a backtrace of PHP interpreted code that was executed, which is useful for helping a determine which code path lead to the segfault. Ticket Ref 3","title":"Coredump Analysis"},{"location":"kanban_tickets/core_dumps/#preparing","text":"Cores are dumped to /mnt/tmp/cores/ # @TODO: Remove this when CL-16933 is completed. apt-get install gdb -y wget --no-check-certificate \\ -O /root/.gdbinit https://raw.githubusercontent.com/php/php-src/PHP-5.6/.gdbinit # If PHP 7.0 use this one # wget --no-check-certificate \\ # -O /root/.gdbinit https://raw.githubusercontent.com/php/php-src/PHP-7.0/.gdbinit cd /root","title":"Preparing"},{"location":"kanban_tickets/core_dumps/#analysing","text":"Find the php path for the site - this is different between versions: ah-site get $SITE | grep php-path To invoke GDB with a coredump: FPM_PATH= CORE_PATH= and invoke gdb to enter the GDB shell gdb $FPM_PATH $CORE_PATH","title":"Analysing"},{"location":"kanban_tickets/core_dumps/#interpreting-a-sample-backtrace","text":"To see a backtrace of function calls that lead to an incident use bt . You can provide bt with a numeric argument, to limit the number of frames to show. Without a backtrace limit, recursive/infinite looping could cause the output to spew forever (however, gdb rate limits it). (gdb) bt 10 #0 0x00007fa237529de7 in ?? () from /lib/libgcc_s.so.1 #1 0x00007fa23752a66e in _Unwind_Backtrace () from /lib/libgcc_s.so.1 #2 0x00007fa237fd8e3e in backtrace () from /lib/libc.so.6 #3 0x00007fa233787f1d in nr_signal_tracer_common () from /usr/local/php5.5/lib/php/extensions/newrelic.so #4 0x00007fa233787f89 in agent_fatal_signal_handler () from /usr/local/php5.5/lib/php/extensions/newrelic.so #5 <signal handler called> #6 0x0000000005c20560 in ?? () #7 0x00000000008c8ba0 in execute_ex (execute_data=0x7fa23e9c9d70) at /usr/local/src/php-5.5.11/Zend/zend_vm_execute.h:363 #8 0x00007fa2337ada32 in nr_php_execute_enabled () from /usr/local/php5.5/lib/php/extensions/newrelic.so #9 0x00007fa2337ae011 in nr_php_execute () from /usr/local/php5.5/lib/php/extensions/newrelic.so (More stack frames follow...) Since gdb loads $HOME/.gdbinit it will decode information in execute_data arguments and generate a backtrace of the PHP calls with zbacktrace , for example: (gdb) zbacktrace [0x7fa23e9c9d70] menu_get_item(\"node/79381\") /mnt/www/html/nbcunbc/docroot/sites/nbcunbc/modules/contrib/subpathauto/subpathauto.module:25 [0x7fa23e9c9b30] subpathauto_url_inbound_alter(\"node/79381\", \\ \"nashville-star\", NULL) /mnt/www/html/nbcunbc/docroot/includes/path.inc:272 [0x7fa23e9c9900] drupal_get_normal_path(\"nashville-star\") /mnt/www/html/nbcunbc/docroot/includes/path.inc:21 [0x7fa23e9c96a8] drupal_path_initialize() /mnt/www/html/nbcunbc/docroot/includes/common.inc:5157 [0x7fa23e9c8ca0] _drupal_bootstrap_full() /mnt/www/html/nbcunbc/docroot/includes/bootstrap.inc:2266 [0x7fa23e9c8750] drupal_bootstrap(7) /mnt/www/html/nbcunbc/docroot/index.php:20 By switching your frame you can examine different parts of the backtrace stack. (gdb) frame 7 #7 0x00000000008c8ba0 in execute_ex (execute_data=0x7fa23e9cfda8) at /usr/local/src/php-5.5.11/Zend/zend_vm_execute.h:363 363 in /usr/local/src/php-5.5.11/Zend/zend_vm_execute.h (gdb) info frame Stack level 7, frame at 0x7fff29fe8ce0: rip = 0x8c8ba0 in execute_ex (/usr/local/src/php-5.5.11/Zend/zend_vm_execute.h:363);\\ saved rip 0x7fa2337ada32 called by frame at 0x7fff29fe8d80, caller of frame at 0x7fff29fe8c60 source language c. Arglist at 0x7fff29fe8c58, args: execute_data=0x7fa23e9cfda8 Locals at 0x7fff29fe8c58, Previous frame's sp is 0x7fff29fe8ce0 Saved registers: rbx at 0x7fff29fe8ca8, rbp at 0x7fff29fe8cb0, r12 at 0x7fff29fe8cb8, r13 \\ at 0x7fff29fe8cc0, r14 at 0x7fff29fe8cc8, r15 at 0x7fff29fe8cd0, rip at 0x7fff29fe8cd8 (gdb) info args execute_data = 0x7fa23e9cfda8 (gdb) info locals ret = <value optimized out> original_in_execution = 1 '\\001' You can also do some examination of the function's arguments using gdb. (gdb) set print pretty on (gdb) ptype execute_data type = struct _zend_execute_data { struct _zend_op *opline; zend_function_state function_state; zend_op_array *op_array; zval *object; HashTable *symbol_table; struct _zend_execute_data *prev_execute_data; zval *old_error_reporting; zend_bool nested; zval **original_return_value; zend_class_entry *current_scope; zend_class_entry *current_called_scope; zval *current_this; struct _zend_op *fast_ret; call_slot *call_slots; call_slot *call; } * Show the variable names and values of the structure using print. Since execute_data is actually a pointer, use print * to dereference: (gdb) print *execute_data $2 = { opline = 0x7fa22b8b3418, function_state = { function = 0x2c87c50, arguments = 0x0 }, op_array = 0x2c87c50, object = 0x0, symbol_table = 0x0, prev_execute_data = 0x7fa23e9cfad0, old_error_reporting = 0x0, nested = 0 '\\000', original_return_value = 0x320b5a0, current_scope = 0x0, current_called_scope = 0x7fa23e9cfad0, current_this = 0x0, fast_ret = 0x32a6700, call_slots = 0x7fa23e9cfe98, call = 0x7fa23e9cfe98 } Arrays can be dereferenced using @N where N is the number of items. Lets say we know that execute_data->op_array->last_var has the length of the array execute_data->op_array->vars we can list all members of that array with: (gdb) print *execute_data->op_array->vars@(execute_data->op_array->last_var)","title":"Interpreting A Sample Backtrace"},{"location":"kanban_tickets/create_test_balancer/","text":"Create a test balancer Test balancers are separate balancers that customers can use to load test their applications without impacting their normal balancers. When a Test Balancer is created for a site, a new bal% is provisioned and added to the site with the test role (for the rel_site_balancer relation). The test role configures the balancer to respond to loadtest.$SITENAME.$STAGE.acquia-sites.com as well as any of the customer site domains. The balancer will not have an EIP, and will not register with any site ELBs. The loadtest site subdomain will be assigned to the external ip of the test balancer. Load test balancers are created in a scheduled means. The initial creation can either be scheduled using a unix timestamp or immediately. The termination must be scheduled a minimum of 2 hours from the creation time. Test balancers do not affect customer ELBs. Preparation Gather the following information to execute the command: # Site name SITE= # Time used to create the test balancer in UNIX timestamp format if the # creation needs to happen in the future. # # UNIX_CREATE_DATE can also be set to \"now\" # Example date, please fill in the right thing. HUMAN_READABLE_CREATE_DATE=\"December 20th 2015 16:00 UTC\" UNIX_CREATE_DATE=$(ruby -e \"require 'date'; puts DateTime.parse(ARGV[0]).strftime('%s')\" $HUMAN_READABLE_CREATE_DATE) # Time used to destroy the test balancer in UNIX timestamp format (a minimum # time window of 2 hours from the creation time is required). # # Example date, please fill in the right thing. HUMAN_READABLE_DESTROY_DATE=\"December 20th 2015 20:00 UTC\" UNIX_DESTROY_DATE=$(ruby -e \"require 'date'; puts DateTime.parse(ARGV[0]).strftime('%s')\" $HUMAN_READABLE_DESTROY_DATE) # Availability zone AVAILABILITY_ZONE= # AMI type AMI_TYPE=\"m5.large\" Procedure Run the command: ah-site create-test-balancer $SITE \\ --create $UNIX_CREATE_DATE \\ --destroy $UNIX_DESTROY_DATE \\ --avail_zone $AVAILABILITY_ZONE \\ --ami_type $AMI_TYPE Running this command will output: Create task: task 12345 Destroy task: scheduled_task 12345 You may then interact with these ids, for example, by getting the Scheduled Task information: ah-scheduled-task get 12345 Operation Extend the duration of a test balancer before its deprovision ah-scheduled-task set-start-time task_id1[,task_id2,task_id3] TIME Verify if a site has test balancers You can see if a site has any active test balancers by referring to the test_balancers section of the ah-site get site command's output: ah-site get $SITE | grep 'test_balancers' Monitoring Test balancers go into monitoring just like any other server, when launched. When the test time window is up, the test balancer is terminated and removed from monitoring (same as terminating any other server). Test balancers do not get suspended. Known bugs Using ah-server list site:$SITE will not show test balancers as part of the site's servers list. This bug is being tracked AUTO-528. A possible workaround is to use: ah-site get $SITE | grep 'test_balancers'","title":"Create a test balancer"},{"location":"kanban_tickets/create_test_balancer/#create-a-test-balancer","text":"Test balancers are separate balancers that customers can use to load test their applications without impacting their normal balancers. When a Test Balancer is created for a site, a new bal% is provisioned and added to the site with the test role (for the rel_site_balancer relation). The test role configures the balancer to respond to loadtest.$SITENAME.$STAGE.acquia-sites.com as well as any of the customer site domains. The balancer will not have an EIP, and will not register with any site ELBs. The loadtest site subdomain will be assigned to the external ip of the test balancer. Load test balancers are created in a scheduled means. The initial creation can either be scheduled using a unix timestamp or immediately. The termination must be scheduled a minimum of 2 hours from the creation time. Test balancers do not affect customer ELBs.","title":"Create a test balancer"},{"location":"kanban_tickets/create_test_balancer/#preparation","text":"Gather the following information to execute the command: # Site name SITE= # Time used to create the test balancer in UNIX timestamp format if the # creation needs to happen in the future. # # UNIX_CREATE_DATE can also be set to \"now\" # Example date, please fill in the right thing. HUMAN_READABLE_CREATE_DATE=\"December 20th 2015 16:00 UTC\" UNIX_CREATE_DATE=$(ruby -e \"require 'date'; puts DateTime.parse(ARGV[0]).strftime('%s')\" $HUMAN_READABLE_CREATE_DATE) # Time used to destroy the test balancer in UNIX timestamp format (a minimum # time window of 2 hours from the creation time is required). # # Example date, please fill in the right thing. HUMAN_READABLE_DESTROY_DATE=\"December 20th 2015 20:00 UTC\" UNIX_DESTROY_DATE=$(ruby -e \"require 'date'; puts DateTime.parse(ARGV[0]).strftime('%s')\" $HUMAN_READABLE_DESTROY_DATE) # Availability zone AVAILABILITY_ZONE= # AMI type AMI_TYPE=\"m5.large\"","title":"Preparation"},{"location":"kanban_tickets/create_test_balancer/#procedure","text":"Run the command: ah-site create-test-balancer $SITE \\ --create $UNIX_CREATE_DATE \\ --destroy $UNIX_DESTROY_DATE \\ --avail_zone $AVAILABILITY_ZONE \\ --ami_type $AMI_TYPE Running this command will output: Create task: task 12345 Destroy task: scheduled_task 12345 You may then interact with these ids, for example, by getting the Scheduled Task information: ah-scheduled-task get 12345","title":"Procedure"},{"location":"kanban_tickets/create_test_balancer/#operation","text":"","title":"Operation"},{"location":"kanban_tickets/create_test_balancer/#extend-the-duration-of-a-test-balancer-before-its-deprovision","text":"ah-scheduled-task set-start-time task_id1[,task_id2,task_id3] TIME","title":"Extend the duration of a test balancer before its deprovision"},{"location":"kanban_tickets/create_test_balancer/#verify-if-a-site-has-test-balancers","text":"You can see if a site has any active test balancers by referring to the test_balancers section of the ah-site get site command's output: ah-site get $SITE | grep 'test_balancers'","title":"Verify if a site has test balancers"},{"location":"kanban_tickets/create_test_balancer/#monitoring","text":"Test balancers go into monitoring just like any other server, when launched. When the test time window is up, the test balancer is terminated and removed from monitoring (same as terminating any other server). Test balancers do not get suspended.","title":"Monitoring"},{"location":"kanban_tickets/create_test_balancer/#known-bugs","text":"Using ah-server list site:$SITE will not show test balancers as part of the site's servers list. This bug is being tracked AUTO-528. A possible workaround is to use: ah-site get $SITE | grep 'test_balancers'","title":"Known bugs"},{"location":"kanban_tickets/custom_tungsten_settings/","text":"Custom Tungsten Settings This page discusses the different custom settings for Tungsten that we can implement on our platform. We are currently using Tungsten 2.2.0 and after installation of Tungsten the configuration files are NOT under Puppet control. This means that configuration setting changes can be made directly on the server by manually editing the files or by using the supplied tools. Unless you are really familiar with the supplied tools the suggestion is to manually edit the configuration files. IMPORTANT : Any changes to the Tungsten configuration must be approved by a DBA in the ticket and documented in ah-runbook The best way to make changes to the Tungsten configuration is by using the configure-service tool in the tools directory. This will write the change to both the tungsten.cfg and the static configuration files. Since the tungsten.cfg file is used for generating the static configuration files this makes sure that the changes do not get overwritten when someone else uses this method of configuring Tungsten. Configure-service First go to the Tungsten run time directory and then make the change for the service in question as per the example. $ cd /usr/local/tungsten-replicator/tungsten $ tools/configure-service -a --force \\ -c /usr/local/tungsten-replicator/configs/tungsten.cfg \\ -U --thl-log-retention=2d fsdbmesh7680 In this case the thl-log-retention setting was changed to the value of 2d for the service fsdbmesh7680. The available settings can be listed with the following command. tools/configure-service -a -help After the change has been made the replication service needs to be restarted for the change to take effect. For restarting a single service the following commands should be used. $ trepctl -service fsdbmesh7683 unload -y Service stopped successfully: name=fsdbmesh7683 $ trepctl -service fsdbmesh7683 load Service started successfully: name=fsdbmesh7683 If multiple services have been updated it may be quicker to restart the Tungsten daemon. This will not cause downtime but will cause a longer delay in replication than restarting a single service. service treplicator restart Static Configuration Files NOTE : This method is not recommended because changes won't persist over time Most of the configuration files for Tungsten are typically located in the /usr/local/tungsten-replicator/current/tungsten-replicator/conf # ls -alh total 168K drwxr-xr-x 2 tungsten tungsten 4.0K 2014-03-11 12:45 . drwxr-xr-x 10 tungsten tungsten 109 2014-02-28 15:31 .. -rw-r--r-- 1 tungsten tungsten 1.5K 2014-02-28 15:31 development.log4j.properties -rw-r--r-- 1 tungsten tungsten 3.7K 2014-02-28 15:31 log4j.properties -rw-r--r-- 1 tungsten tungsten 4.3K 2014-02-28 15:31 replication-svc-wrapper.conf -rw-r--r-- 1 tungsten tungsten 420 2014-02-28 15:31 replicator.service.properties -rw-r--r-- 1 tungsten tungsten 1.6K 2014-02-28 15:31 services.properties -rw-r--r-- 1 tungsten tungsten 896 2014-02-28 15:31 shard.list -rw-r--r-- 1 tungsten tungsten 31K 2014-02-28 15:31 static-fsdbmesh3.properties -rw-r--r-- 1 tungsten tungsten 31K 2014-03-11 12:26 static-fsdbmesh4.properties -rw-r--r-- 1 tungsten tungsten 31K 2014-02-28 15:36 static-fsdbmesh5.properties -rw-r--r-- 1 tungsten tungsten 31K 2014-02-28 15:37 static-fsdbmesh6.properties -rw-r--r-- 1 tungsten tungsten 5.6K 2014-02-28 15:31 wrapper.conf The static-$NODE.properties files define the service settings for each server. Typically there is one master configuration file and three slave configuration files. The filename indicates the server that the master service is running on. Replication Filter Replication filters can be added to to skip statements on tables during replication. Typical uses for this are the cache_form table when it generates a lot of traffic that is impacting HA and the customer agrees that losing the data in that table is acceptable. Tungsten has different types of replication filters (unlike MySQL) that can do different things. The two filter types that can be use for filtering out statements on a specific table are replicator.filter.replicate and replicator.filter.tableignore. The replicator.filter.replicate filter can be turned on by adding the table names to the following line in the configuration file on all slave properties files on all servers in the cluster. replicator.filter.replicate.ignore=tmp.table1,tmp.table2,tmp.p* After that the filter needs to be activated by adding it to the stage. replicator.stage.q-to-dbms.filters=mysqlsessions,pkey,bidiSlave,EventMetadataFilter,replicate It is important to note that the EventMetadataFilter filter also needs to be added to force reparsing of the statements. This is related to a Tungsten 2.0.6 bug that is fixed in 2.0.7. After the changes to the configuration file have been saved the replicator needs to be restarted service treplicator restart","title":"Custom Tungsten Settings"},{"location":"kanban_tickets/custom_tungsten_settings/#custom-tungsten-settings","text":"This page discusses the different custom settings for Tungsten that we can implement on our platform. We are currently using Tungsten 2.2.0 and after installation of Tungsten the configuration files are NOT under Puppet control. This means that configuration setting changes can be made directly on the server by manually editing the files or by using the supplied tools. Unless you are really familiar with the supplied tools the suggestion is to manually edit the configuration files. IMPORTANT : Any changes to the Tungsten configuration must be approved by a DBA in the ticket and documented in ah-runbook The best way to make changes to the Tungsten configuration is by using the configure-service tool in the tools directory. This will write the change to both the tungsten.cfg and the static configuration files. Since the tungsten.cfg file is used for generating the static configuration files this makes sure that the changes do not get overwritten when someone else uses this method of configuring Tungsten.","title":"Custom Tungsten Settings"},{"location":"kanban_tickets/custom_tungsten_settings/#configure-service","text":"First go to the Tungsten run time directory and then make the change for the service in question as per the example. $ cd /usr/local/tungsten-replicator/tungsten $ tools/configure-service -a --force \\ -c /usr/local/tungsten-replicator/configs/tungsten.cfg \\ -U --thl-log-retention=2d fsdbmesh7680 In this case the thl-log-retention setting was changed to the value of 2d for the service fsdbmesh7680. The available settings can be listed with the following command. tools/configure-service -a -help After the change has been made the replication service needs to be restarted for the change to take effect. For restarting a single service the following commands should be used. $ trepctl -service fsdbmesh7683 unload -y Service stopped successfully: name=fsdbmesh7683 $ trepctl -service fsdbmesh7683 load Service started successfully: name=fsdbmesh7683 If multiple services have been updated it may be quicker to restart the Tungsten daemon. This will not cause downtime but will cause a longer delay in replication than restarting a single service. service treplicator restart","title":"Configure-service"},{"location":"kanban_tickets/custom_tungsten_settings/#static-configuration-files","text":"NOTE : This method is not recommended because changes won't persist over time Most of the configuration files for Tungsten are typically located in the /usr/local/tungsten-replicator/current/tungsten-replicator/conf # ls -alh total 168K drwxr-xr-x 2 tungsten tungsten 4.0K 2014-03-11 12:45 . drwxr-xr-x 10 tungsten tungsten 109 2014-02-28 15:31 .. -rw-r--r-- 1 tungsten tungsten 1.5K 2014-02-28 15:31 development.log4j.properties -rw-r--r-- 1 tungsten tungsten 3.7K 2014-02-28 15:31 log4j.properties -rw-r--r-- 1 tungsten tungsten 4.3K 2014-02-28 15:31 replication-svc-wrapper.conf -rw-r--r-- 1 tungsten tungsten 420 2014-02-28 15:31 replicator.service.properties -rw-r--r-- 1 tungsten tungsten 1.6K 2014-02-28 15:31 services.properties -rw-r--r-- 1 tungsten tungsten 896 2014-02-28 15:31 shard.list -rw-r--r-- 1 tungsten tungsten 31K 2014-02-28 15:31 static-fsdbmesh3.properties -rw-r--r-- 1 tungsten tungsten 31K 2014-03-11 12:26 static-fsdbmesh4.properties -rw-r--r-- 1 tungsten tungsten 31K 2014-02-28 15:36 static-fsdbmesh5.properties -rw-r--r-- 1 tungsten tungsten 31K 2014-02-28 15:37 static-fsdbmesh6.properties -rw-r--r-- 1 tungsten tungsten 5.6K 2014-02-28 15:31 wrapper.conf The static-$NODE.properties files define the service settings for each server. Typically there is one master configuration file and three slave configuration files. The filename indicates the server that the master service is running on.","title":"Static Configuration Files"},{"location":"kanban_tickets/custom_tungsten_settings/#replication-filter","text":"Replication filters can be added to to skip statements on tables during replication. Typical uses for this are the cache_form table when it generates a lot of traffic that is impacting HA and the customer agrees that losing the data in that table is acceptable. Tungsten has different types of replication filters (unlike MySQL) that can do different things. The two filter types that can be use for filtering out statements on a specific table are replicator.filter.replicate and replicator.filter.tableignore. The replicator.filter.replicate filter can be turned on by adding the table names to the following line in the configuration file on all slave properties files on all servers in the cluster. replicator.filter.replicate.ignore=tmp.table1,tmp.table2,tmp.p* After that the filter needs to be activated by adding it to the stage. replicator.stage.q-to-dbms.filters=mysqlsessions,pkey,bidiSlave,EventMetadataFilter,replicate It is important to note that the EventMetadataFilter filter also needs to be added to force reparsing of the statements. This is related to a Tungsten 2.0.6 bug that is fixed in 2.0.7. After the changes to the configuration file have been saved the replicator needs to be restarted service treplicator restart","title":"Replication Filter"},{"location":"kanban_tickets/dedicated_hypervisor/","text":"Set tenancy for the servers This runbook deals with changing the tenancy of the servers to dedicated or default. Prerequisite for dedicated ec2_tenancy: Do not change tenancy to dedicated without approval from Ops Managers and Finance. Dedicated Hypervisor is an outdated setting previously used for HIPAA provisions that is no longer necessary. Preparation Get list of space-delimited servers into a variable and also create CSV and save it under variable. SERVERS=(server-1 server-2 ...) SERVERS_CSV=$(array-csv ${SERVERS[@]}) NOTE : Only one type of Servers can be used and set the variables(e.g Don't club bals or deds in single variable). Also, set these variables: EXPECTED_EC2_TENANCY= #default or dedicated REGION= Ensure the servers are in a VPC ah-server list $SERVERS_CSV -c vpc_id Confirm the ec2_tenancy before relaunch ah-server list $SERVERS_CSV -c ec2_tenancy Procedure for changing tenancy Perform the required pre-checks for servers like checking no db cluster is in locked state. Relaunch the servers (deds, fsdb, webs, dbmaster, fs) ah-server bulk-relaunch ${SERVERS[@]} -e $EXPECTED_EC2_TENANCY --send-notifications false For balancers use ah-bal-cluster to relaunch: ah-bal-cluster relaunch ${SERVERS[@]} -e $EXPECTED_EC2_TENANCY --send-notifications false NOTE : If you are relaunching servers in bulk, then make sure to use --batch-size option. Verify the tenancy is changed After the servers have launched you can look at the tenancy property of the instance to verify it launched as dedicated instead of default by using any of the below commands. aws ec2 describe-instances --instance-ids $(ah-server list \\ $SERVERS -c ec2_id --no-name | paste -sd' ') --query \\ 'Reservations[].Instances[].Placement.Tenancy' --region $REGION ah-server list $SERVERS_CSV -c ec2_tenancy","title":"Set tenancy for the servers"},{"location":"kanban_tickets/dedicated_hypervisor/#set-tenancy-for-the-servers","text":"This runbook deals with changing the tenancy of the servers to dedicated or default. Prerequisite for dedicated ec2_tenancy: Do not change tenancy to dedicated without approval from Ops Managers and Finance. Dedicated Hypervisor is an outdated setting previously used for HIPAA provisions that is no longer necessary.","title":"Set tenancy for the servers"},{"location":"kanban_tickets/dedicated_hypervisor/#preparation","text":"Get list of space-delimited servers into a variable and also create CSV and save it under variable. SERVERS=(server-1 server-2 ...) SERVERS_CSV=$(array-csv ${SERVERS[@]}) NOTE : Only one type of Servers can be used and set the variables(e.g Don't club bals or deds in single variable). Also, set these variables: EXPECTED_EC2_TENANCY= #default or dedicated REGION= Ensure the servers are in a VPC ah-server list $SERVERS_CSV -c vpc_id Confirm the ec2_tenancy before relaunch ah-server list $SERVERS_CSV -c ec2_tenancy","title":"Preparation"},{"location":"kanban_tickets/dedicated_hypervisor/#procedure-for-changing-tenancy","text":"Perform the required pre-checks for servers like checking no db cluster is in locked state. Relaunch the servers (deds, fsdb, webs, dbmaster, fs) ah-server bulk-relaunch ${SERVERS[@]} -e $EXPECTED_EC2_TENANCY --send-notifications false For balancers use ah-bal-cluster to relaunch: ah-bal-cluster relaunch ${SERVERS[@]} -e $EXPECTED_EC2_TENANCY --send-notifications false NOTE : If you are relaunching servers in bulk, then make sure to use --batch-size option.","title":"Procedure for changing tenancy"},{"location":"kanban_tickets/dedicated_hypervisor/#verify-the-tenancy-is-changed","text":"After the servers have launched you can look at the tenancy property of the instance to verify it launched as dedicated instead of default by using any of the below commands. aws ec2 describe-instances --instance-ids $(ah-server list \\ $SERVERS -c ec2_id --no-name | paste -sd' ') --query \\ 'Reservations[].Instances[].Placement.Tenancy' --region $REGION ah-server list $SERVERS_CSV -c ec2_tenancy","title":"Verify the tenancy is changed"},{"location":"kanban_tickets/dedicated_memcache/","text":"Dedicated Memcache About Dedicated Memcache Memcache is usually distributed and shared amongst all of a customer's webs. However, this can sometimes lead to performance issues for customers with many webs (general 8 or more) because memcache may need to query the other memcache servers in the cluster to serve a request. If you would like to learn more about memcache, check out Support's excellent documentation . The amount of ram to dedicate to memcached can be generally calculated as: (total system memory - (os + remaining memory)) For example, on a c5.large instance (3.75GB of total memory): (3700 - (200 + 500)) If you set the memcached memory value too high then there will not be enough free memory to run other processes. Below is a list of supported Memcached memory values per AMI type: Instance Size Memcached Memory Value c5.large / c4.large 3000 m5.large / m4.large 6000 c5.xlarge / c4.xlarge 6000 m5.xlarge / m4.xlarge 12000 c5.2xlarge / c4.2xlarge 12000 r4.large 12000 m5.2xlarge / m4.2xlarge 24000 c5.4xlarge / c4.4xlarge 24000 r4.xlarge 24000 m5.4xlarge / m4.4xlarge 48000 c5.9xlarge 48000 r4.2xlarge 48000 r4.4xlarge 96000 r4.8xlarge 192000 What site-setmemcache does Ops should preferentially use site-setmemcache to provision dedicated memcache servers for sites. Tool has been changed to Juno style provisioning, taking all available AZ's into consideration in realms. This tool will give instructions to provision 4- or 5-series instances and will take an even number of webs as input. Tool will work in prod, enterprise-g1, wmg, and trex realms. The inputs are taken from provisioning scripts and after auditing the provisioning methods. Tool will output instructions to create new dedicated memcache webs, even if a site already has dedicated memcache webs. Colour scheme has been maintained in the tool to segregate in between comments and the commands to be triggered. This tool can verify the memcache values assigned to the dedicated memcache webs to any site and will output steps to correct errors. Procedure: Using site-setmemcache In this method the command site-setmemcache takes care of all operations like allocation, assignment, relaunch etc. Run the site-setmemcache tool for automated steps to add dedicated memcache webs into the site: SITENAME= AMI_TYPE= NUM_WEBS= site-setmemcache -e create -s ${SITENAME} -a ${AMI_TYPE} -n ${NUM_WEBS} Example of usage: site-setmemcache -e create -s ucascom.loadtest3 -a c5.large -n 4 For reference: OP-261904 Run the commands output by the tool. Verify the assigned memcache value on dedicated memcache instances: site-setmemcache -e verify -s ${SITENAME} Procedure: Manual Follow this method when using site-setmemcache is not feasible. Set up variables for the dedicated memcache webs per the table above: MC_AMI= MC_VALUE= Any time you are altering a site's web configuration you should make sure to update all sites in the cluster to prevent snowflakes and mistakes. Use any existing standard web on the site for this: WEB= FS_ID=$(ah-server list ${WEB} --no-name -c fs_cluster_id) FS_SRV=$(ah-server list % -w status=0 fs_cluster_id=${FS_ID} typeINstaging,ded,fsdb,fs,fsdbmesh | head -n1) SITES=($(ah-site list on:${FS_SRV})) OTHER_WEBS=$(ah-server list % -w fs_cluster_id=${FS_ID} typeINstaging,ded,web | paste -sd,) Clone the web as a template for the new memcache servers: ah-server clone-web ${WEB} 2 MC_WEBS=() MC_WEBS_CSV=$(array-csv ${MC_WEBS[@]}) Edit the new memcache webs so that they are in different AZs and have the appropriate AMI type: AZ= ah-server edit ${MC_WEBS[1]} -s ec2_availability_zone=${AZ} ah-server edit ${MC_WEBS_CSV} -s ami_type=${MC_AMI} ah-server edit ${MC_WEBS_CSV} -c memcached.conf:-m=${MC_VALUE} apache2.conf:PoolSize=2 Tag them as oob so future Ops know they are special and take them out of web rotation for all sites: ah-server tag add ${MC_WEBS[@]} --tags=oob sv-webdisable ${MC_WEBS_CSV} for site in ${SITES[@]}; do ./fields-provision.php --site-set-web ${site}:inactive --webs ${MC_WEBS_CSV} | head -n 2 done We remove the dedicated memcache webs from traffic rotation to prevent them from running PHP and OOMing. Launch the dedicated memcache webs: sv-taskrelaunch server -m1 ${MC_WEBS_CSV} NOTE: When relaunching more than 1 memcache servers, please use workflow as its recommended or relaunch one server at a time to prevent any downtime for the customer. Remove memcache config for all other webs in the stack: ah-server edit ${OTHER_WEBS} -c memcached.conf:-m= Verify the web configuration for each site in the stack. Make sure that the dedicated memcache servers have memcache enabled and are not in rotation and that the standard webs have no memcache memory configured and are in rotation. esl2 ${SITES[0]} for site in ${SITES[@]}; do site-getwebrotationstatus ${site} done Memcache Service Status A server will only serve memcache if memcached.conf:-m is set to a valid value and memcache_service_status is enabled. esl or esl2 will display a 2 or a green checkmark if memcache_service_status is enabled, 1 or a red X if it is disabled. By the same reasoning, it is important to ensure that memcache is enabled for the standard webs when the dedicated memcache servers are deprovisioned.","title":"Dedicated Memcache"},{"location":"kanban_tickets/dedicated_memcache/#dedicated-memcache","text":"","title":"Dedicated Memcache"},{"location":"kanban_tickets/dedicated_memcache/#about-dedicated-memcache","text":"Memcache is usually distributed and shared amongst all of a customer's webs. However, this can sometimes lead to performance issues for customers with many webs (general 8 or more) because memcache may need to query the other memcache servers in the cluster to serve a request. If you would like to learn more about memcache, check out Support's excellent documentation . The amount of ram to dedicate to memcached can be generally calculated as: (total system memory - (os + remaining memory)) For example, on a c5.large instance (3.75GB of total memory): (3700 - (200 + 500)) If you set the memcached memory value too high then there will not be enough free memory to run other processes. Below is a list of supported Memcached memory values per AMI type: Instance Size Memcached Memory Value c5.large / c4.large 3000 m5.large / m4.large 6000 c5.xlarge / c4.xlarge 6000 m5.xlarge / m4.xlarge 12000 c5.2xlarge / c4.2xlarge 12000 r4.large 12000 m5.2xlarge / m4.2xlarge 24000 c5.4xlarge / c4.4xlarge 24000 r4.xlarge 24000 m5.4xlarge / m4.4xlarge 48000 c5.9xlarge 48000 r4.2xlarge 48000 r4.4xlarge 96000 r4.8xlarge 192000","title":"About Dedicated Memcache"},{"location":"kanban_tickets/dedicated_memcache/#what-site-setmemcache-does","text":"Ops should preferentially use site-setmemcache to provision dedicated memcache servers for sites. Tool has been changed to Juno style provisioning, taking all available AZ's into consideration in realms. This tool will give instructions to provision 4- or 5-series instances and will take an even number of webs as input. Tool will work in prod, enterprise-g1, wmg, and trex realms. The inputs are taken from provisioning scripts and after auditing the provisioning methods. Tool will output instructions to create new dedicated memcache webs, even if a site already has dedicated memcache webs. Colour scheme has been maintained in the tool to segregate in between comments and the commands to be triggered. This tool can verify the memcache values assigned to the dedicated memcache webs to any site and will output steps to correct errors.","title":"What site-setmemcache does"},{"location":"kanban_tickets/dedicated_memcache/#procedure-using-site-setmemcache","text":"In this method the command site-setmemcache takes care of all operations like allocation, assignment, relaunch etc. Run the site-setmemcache tool for automated steps to add dedicated memcache webs into the site: SITENAME= AMI_TYPE= NUM_WEBS= site-setmemcache -e create -s ${SITENAME} -a ${AMI_TYPE} -n ${NUM_WEBS} Example of usage: site-setmemcache -e create -s ucascom.loadtest3 -a c5.large -n 4 For reference: OP-261904 Run the commands output by the tool. Verify the assigned memcache value on dedicated memcache instances: site-setmemcache -e verify -s ${SITENAME}","title":"Procedure: Using site-setmemcache"},{"location":"kanban_tickets/dedicated_memcache/#procedure-manual","text":"Follow this method when using site-setmemcache is not feasible. Set up variables for the dedicated memcache webs per the table above: MC_AMI= MC_VALUE= Any time you are altering a site's web configuration you should make sure to update all sites in the cluster to prevent snowflakes and mistakes. Use any existing standard web on the site for this: WEB= FS_ID=$(ah-server list ${WEB} --no-name -c fs_cluster_id) FS_SRV=$(ah-server list % -w status=0 fs_cluster_id=${FS_ID} typeINstaging,ded,fsdb,fs,fsdbmesh | head -n1) SITES=($(ah-site list on:${FS_SRV})) OTHER_WEBS=$(ah-server list % -w fs_cluster_id=${FS_ID} typeINstaging,ded,web | paste -sd,) Clone the web as a template for the new memcache servers: ah-server clone-web ${WEB} 2 MC_WEBS=() MC_WEBS_CSV=$(array-csv ${MC_WEBS[@]}) Edit the new memcache webs so that they are in different AZs and have the appropriate AMI type: AZ= ah-server edit ${MC_WEBS[1]} -s ec2_availability_zone=${AZ} ah-server edit ${MC_WEBS_CSV} -s ami_type=${MC_AMI} ah-server edit ${MC_WEBS_CSV} -c memcached.conf:-m=${MC_VALUE} apache2.conf:PoolSize=2 Tag them as oob so future Ops know they are special and take them out of web rotation for all sites: ah-server tag add ${MC_WEBS[@]} --tags=oob sv-webdisable ${MC_WEBS_CSV} for site in ${SITES[@]}; do ./fields-provision.php --site-set-web ${site}:inactive --webs ${MC_WEBS_CSV} | head -n 2 done We remove the dedicated memcache webs from traffic rotation to prevent them from running PHP and OOMing. Launch the dedicated memcache webs: sv-taskrelaunch server -m1 ${MC_WEBS_CSV} NOTE: When relaunching more than 1 memcache servers, please use workflow as its recommended or relaunch one server at a time to prevent any downtime for the customer. Remove memcache config for all other webs in the stack: ah-server edit ${OTHER_WEBS} -c memcached.conf:-m= Verify the web configuration for each site in the stack. Make sure that the dedicated memcache servers have memcache enabled and are not in rotation and that the standard webs have no memcache memory configured and are in rotation. esl2 ${SITES[0]} for site in ${SITES[@]}; do site-getwebrotationstatus ${site} done","title":"Procedure: Manual"},{"location":"kanban_tickets/dedicated_memcache/#memcache-service-status","text":"A server will only serve memcache if memcached.conf:-m is set to a valid value and memcache_service_status is enabled. esl or esl2 will display a 2 or a green checkmark if memcache_service_status is enabled, 1 or a red X if it is disabled. By the same reasoning, it is important to ensure that memcache is enabled for the standard webs when the dedicated memcache servers are deprovisioned.","title":"Memcache Service Status"},{"location":"kanban_tickets/delete_search_index/","text":"Deleting a Search Index Note: To login Search jumpboxes, follow these instructions These instructions apply to indexes that are on shared or dedicated farms, although if the index being deleted is on a dedicated farm, it is likely that the farm is also being deprovisioned, so these instructions are not needed. Verify index unpublished Log into the Governor and search for the index that's being deleted. If it is still indicated that it is published, verify with support that the index is to be deleted and then follow the below steps to unpublish the index. NOTE : also take note as to what farm this index was associated with, it will be needed later . Click on the Edit tab. At the bottom of the page, click Publishing options . Uncheck Published and save. Remove index from javasrv The search index is replicated from the javasrv to the javaephem and the indexes on the javaephem are on ephemeral storage, so we only need to remove the index from the javasrv First you will need to determine which javasrv the index was assigned to. To do this, you will need to know what the farm is associated with the index which you should have noted above. The Governor displays the farm as the Drupal node name and will need to be translated. For example, euwest1as.s1master would become euwest1ass1 for the next step. Retrieve the farm info. FARM= ah-search farm $FARM Example : [cloudservicesdev|search-service:search-service] ~/fields/1.81$ ah-search farm euwest1ass1 Farm - euwest1ass1 ---------------------------------------- Colony: eu-west-1-c7 (shared) Colony URL: euwest1-c7.acquia-search.com SOLR Version: 3.5 Dedicated: false Balancers: nxephem-35, nxephem-36 Master: javasrv-94 Slave: javaephem-95 Unix username: euwest1as Stats ---------------------------------------- Documents: 3037521 Queries: 99168 Index Size: 29681.212111740115 Log onto the pertinent javasrv . SERVER= fssh $SERVER Become the search user. SEARCHUSER= sudo su - $SEARCHUSER Remove the index from memory. INDEX= rake client_remove client=$INDEX Verify index has been removed from memory. rake client_num_docs client=$INDEX Move the index directory to /mnt/tmp. FARM= mv /vol/ebs1/gfs/$FARM/files/$INDEX/ /mnt/tmp/ Verify that the nginx config for the index has been removed from the repo On a number of occasions, old, unpublished indexes have had their nginx configurations for the nxephem remain in the repo. Normally this isn't an issue as long as the farm that used to house the index is still valid. However, once the farm is decommissioned it is possible that this rogue config can prevent Nginx starting on the nxephem . So we need to verify that the configuration has been deleted. First, you will need to determine what repo and branch you need to be working in. This can be retrieved by getting the site associated with one of the nxephems . For example. if the retrieved site is euwest1balc7 , then the repo is euwest1bal and the branch is c7 . NXEPHEM= ah-site list on:${NXEPHEM} Create directory in your home directory on the bastion server if it doesn't already exist. mkdir $HOME/nxephem_configs Checkout the pertinent repo if you haven't already. REPO= cd $HOME/nxephem_configs git clone ssh://${REPO}@svn-3.search-service.hosting.acquia.com:22/vol/ebs1/home/${REPO}/${REPO}.git cd ${REPO} Next, you will need to switch to the appropriate branch. If you already have the the branch locally, you can just switch to it as follows: BRANCH= git checkout $branch If you do not have the branch locally, you will need to check it out as follows: BRANCH= git checkout -b $BRANCH origin/${BRANCH} --track Next, make sure your branch is up-to-date. git pull Search for the deleted index. INDEX= find nginx/server.conf.d/ -name $INDEX If the search comes back empty, then the config has been deleted and you are done. If the index is found, you will need to remove it from the repo and push the changes to the master. git rm nginx/server.conf.d/${INDEX} git commit -m \"Removed Nginx config for unpublished index ${INDEX}\" git push Delete index node from Governor Log into the Governor . Search for the index being deleted. Click on delete link under the index title. Re-check the index name you are about to delete and click on Delete button to confirm the action. You will get a success message saying Service Instance Search Core <index title> has been deleted. If you get an error message also, saying Error deleting search core config file from the repository. , ignore since you have deleted the core config details from repo already. Note: If there are multiple indexs to be deleted, you can select them using the tickboxes of each index record and do a bulk delete(20 indexes max at a time) by selecting Delete Item under Operations dropdown and clicking on Execute . Be extra careful when doing this. Note: If you omit deleting the index from Governor, it will leave an orphan core node in governor which might lead into issues in future.","title":"Deleting a Search Index"},{"location":"kanban_tickets/delete_search_index/#deleting-a-search-index","text":"Note: To login Search jumpboxes, follow these instructions These instructions apply to indexes that are on shared or dedicated farms, although if the index being deleted is on a dedicated farm, it is likely that the farm is also being deprovisioned, so these instructions are not needed.","title":"Deleting a Search Index"},{"location":"kanban_tickets/delete_search_index/#verify-index-unpublished","text":"Log into the Governor and search for the index that's being deleted. If it is still indicated that it is published, verify with support that the index is to be deleted and then follow the below steps to unpublish the index. NOTE : also take note as to what farm this index was associated with, it will be needed later . Click on the Edit tab. At the bottom of the page, click Publishing options . Uncheck Published and save.","title":"Verify index unpublished"},{"location":"kanban_tickets/delete_search_index/#remove-index-from-javasrv","text":"The search index is replicated from the javasrv to the javaephem and the indexes on the javaephem are on ephemeral storage, so we only need to remove the index from the javasrv First you will need to determine which javasrv the index was assigned to. To do this, you will need to know what the farm is associated with the index which you should have noted above. The Governor displays the farm as the Drupal node name and will need to be translated. For example, euwest1as.s1master would become euwest1ass1 for the next step. Retrieve the farm info. FARM= ah-search farm $FARM Example : [cloudservicesdev|search-service:search-service] ~/fields/1.81$ ah-search farm euwest1ass1 Farm - euwest1ass1 ---------------------------------------- Colony: eu-west-1-c7 (shared) Colony URL: euwest1-c7.acquia-search.com SOLR Version: 3.5 Dedicated: false Balancers: nxephem-35, nxephem-36 Master: javasrv-94 Slave: javaephem-95 Unix username: euwest1as Stats ---------------------------------------- Documents: 3037521 Queries: 99168 Index Size: 29681.212111740115 Log onto the pertinent javasrv . SERVER= fssh $SERVER Become the search user. SEARCHUSER= sudo su - $SEARCHUSER Remove the index from memory. INDEX= rake client_remove client=$INDEX Verify index has been removed from memory. rake client_num_docs client=$INDEX Move the index directory to /mnt/tmp. FARM= mv /vol/ebs1/gfs/$FARM/files/$INDEX/ /mnt/tmp/","title":"Remove index from javasrv"},{"location":"kanban_tickets/delete_search_index/#verify-that-the-nginx-config-for-the-index-has-been-removed-from-the-repo","text":"On a number of occasions, old, unpublished indexes have had their nginx configurations for the nxephem remain in the repo. Normally this isn't an issue as long as the farm that used to house the index is still valid. However, once the farm is decommissioned it is possible that this rogue config can prevent Nginx starting on the nxephem . So we need to verify that the configuration has been deleted. First, you will need to determine what repo and branch you need to be working in. This can be retrieved by getting the site associated with one of the nxephems . For example. if the retrieved site is euwest1balc7 , then the repo is euwest1bal and the branch is c7 . NXEPHEM= ah-site list on:${NXEPHEM} Create directory in your home directory on the bastion server if it doesn't already exist. mkdir $HOME/nxephem_configs Checkout the pertinent repo if you haven't already. REPO= cd $HOME/nxephem_configs git clone ssh://${REPO}@svn-3.search-service.hosting.acquia.com:22/vol/ebs1/home/${REPO}/${REPO}.git cd ${REPO} Next, you will need to switch to the appropriate branch. If you already have the the branch locally, you can just switch to it as follows: BRANCH= git checkout $branch If you do not have the branch locally, you will need to check it out as follows: BRANCH= git checkout -b $BRANCH origin/${BRANCH} --track Next, make sure your branch is up-to-date. git pull Search for the deleted index. INDEX= find nginx/server.conf.d/ -name $INDEX If the search comes back empty, then the config has been deleted and you are done. If the index is found, you will need to remove it from the repo and push the changes to the master. git rm nginx/server.conf.d/${INDEX} git commit -m \"Removed Nginx config for unpublished index ${INDEX}\" git push","title":"Verify that the nginx config for the index has been removed from the repo"},{"location":"kanban_tickets/delete_search_index/#delete-index-node-from-governor","text":"Log into the Governor . Search for the index being deleted. Click on delete link under the index title. Re-check the index name you are about to delete and click on Delete button to confirm the action. You will get a success message saying Service Instance Search Core <index title> has been deleted. If you get an error message also, saying Error deleting search core config file from the repository. , ignore since you have deleted the core config details from repo already. Note: If there are multiple indexs to be deleted, you can select them using the tickboxes of each index record and do a bulk delete(20 indexes max at a time) by selecting Delete Item under Operations dropdown and clicking on Execute . Be extra careful when doing this. Note: If you omit deleting the index from Governor, it will leave an orphan core node in governor which might lead into issues in future.","title":"Delete index node from Governor"},{"location":"kanban_tickets/deploy_certificate/","text":"Deploying an SSL / TLS certificate to a balancer cluster Table of Contents Determine balancers and tag Prepare Certificate Chain Private key Certificates management Adding a new certificate Deploy a certificate override (Edge cluster) Deploy a certificate override (Legacy balancer) Remove a certificate override (Edge cluster) Remove a certificate override (Legacy balancer) Setting a default certificate Verify Testing a production certificate on a test balancer This doc is intended for use if you are already in possession of both a certificate and a key file that is ready for deployment. Determine balancers and tag Certificates are deployed based on tag, so you will need to find or create the tag. For dedicated balancers, these tags have the form ssl_\\* , where * is usually a sitename. Shared balancers always get shared UCCs are are tagged ssl_ucc1 , ssl_ucc2 , etc. to match. If the certificate is being deployed for a site, find the balancers and their tags. Shared balancers will be tagged shared , dedicated balancers will not. ah-server list site:$SITE -w type=bal status=0 -c tags If you already know the balancers, find their tags. ah-server list $BALS -c tags If the balancers are already tagged, make sure the tag is not in use elsewhere. If it is, make sure the certificate should also be deployed there. ah-server list tag:$SSL_TAG View the current certificate and make sure it makes sense to replace it with the new certificate. Specifically, the subject should be the same. sv-getcert $BAL If the balancers are dedicated and not tagged, tag them. Make sure the tag is not in use elsewhere. Sometimes sites have multiple certificates and you will need to be more descriptive with the tag. ah-server tag add $BALS --tags ssl_$SITENAME If the balancers are shared and not tagged, you must be deploying a shared UCC certificate, and one that has plenty of slots free. Check this in DigiCert. Tag the balancers as above. Otherwise, the certificate was provisioned incorrectly. Prepare On the bastion, you will need two files: The certificate chain and the private key. Certificate chain If you are downloading a certificate chain from DigiCert, either choose the option \"A single .pem file containing all the certs\" (including the root), or the copy/paste option and copy the certs in the order displayed into one file. Certificate chains usually come as several certificates that first need to be identified. First, make sure all of the certificates are in PEM format. This format starts with the following line verbatim : -----BEGIN CERTIFICATE----- It will then contain base64-encoded data, which consists entirely of printable characters, and end with the following line verbatim : -----END CERTIFICATE----- If a certificate is not in PEM format, convert it. openssl x509 -inform DER -outform PEM -in $CERT -out $CERT.pem Get the subject and issuer of the certificate file (or files, if you have the intermediate and root certs in separate files) cert-chain $CERT_FILE Determine the order of the certificates. Example of a good order for the chain: [cloudservicesprod|hosting-prod:prod] ~$ cert-chain acquia-sites.pem Chain for acquia-sites.pem: subject=/C=US/ST=Massachusetts/L=Boston/O=Acquia Inc/OU=Acquia Hosting/CN=*.acquia-sites.com issuer=/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert SHA2 High Assurance Server CA subject=/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert SHA2 High Assurance Server CA issuer=/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert High Assurance EV Root CA subject=/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert High Assurance EV Root CA issuer=/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert High Assurance EV Root CA Notes : The chain is usually three certificates long, but can be longer (more than one intermediate certificate) or shorter (first issuer matches root subject). Sometimes, the intermediate or root certificates will not be provided and you will need to go the issuer's website and download them. The first certificate will have a subject with the domain being secured. The issuer of this certificate will be the subject of the next certificate. Further certificates, called intermediate certificates, will each have the same subject as the issuer of the preceding certificate. The issuer of the last intermediate certificate will be the subject of the root certificate. The last certificate, called the root certificate, will have an identical subject and issuer. This is referred to as a self-signed certificate. Concatenate the individual certificates together in order into a single file. This is the certificate chain. Private key The private key must be in PEM format. This format starts with one of the following lines verbatim : -----BEGIN PRIVATE KEY----- -----BEGIN RSA PRIVATE KEY----- It will then contain base64-encoded data, which consists entirely of printable characters, and end in one of the following lines verbatim : -----END PRIVATE KEY----- -----END RSA PRIVATE KEY----- If a key is not in PEM format, convert it: openssl rsa -inform DER -outform PEM -in $KEY -out $KEY.pem Additionally, a key can not be password protected. Certificates management The following tooling can be used for both edge clusters and legacy bals. Adding a new certificate (Both Edge Cluster and Legacy) Both certificate name and the certificate associated with name are immutable, and as such can never be overwritten. Once the certificate has been generated or provided by a customer it needs to uploaded to Hosting API using ah-edge tooling. To upload a certificate the following command is used. (Note: until the certificate is set as an override or as the default certificate for a realm it won't be used). If an Edge Cluster is used by multiple sitegroups or an SSL is to be used by multiple Edge Clusters, then you need to choose one SITENAME as the one to use. Typically it is something like how the ibmcom-v5 SSL is used by Edge Clusters in sitegroups ibmcom , ibmextend and ibmcom5 in a different stack, or it's typically still one customer just different sitegroups. For Legacy Balancers, the SSL tag is defined as ssl_$SITENAME . Again, if multiple sitegroups or multiple balancers, you need to choose one SITENAME to be the root name. SERVER_CERTIFICATE_NAME is ${SSL_TAG}-v${version} , same idea as EDGE CLUSTER though prepended with ssl_ . CERTIFICATE_CHAIN and PRIVATE_KEY should be the full path name to the files containing the certification chain and private key respectively. SERVER_CERTIFICATE_NAME=${SITENAME}-v${version} CERTIFICATE_CHAIN=/Users/xyz/ca.cer PRIVATE_KEY=/Users/xyz/siteName.key ah-edge create-server-certificate --name=$SERVER_CERTIFICATE_NAME --certificate-chain=$CERTIFICATE_CHAIN --private-key=$PRIVATE_KEY Or you can cat its contents as a command input: ah-edge create-server-certificate --name=$SERVER_CERTIFICATE_NAME --certificate-chain=\"$(cat $CERTIFICATE_CHAIN)\" --private-key=\"$(cat $PRIVATE_KEY)\" Deploy a certificate override (Edge cluster) Edge clusters can have their own unique certificate provided by a customer. Once the certificate has been uploaded the cluster config needs to be updated: ah-edge set-cluster-config --uuid=${CLUSTER_UUID} --key=default-certificate --value=${SERVER_CERTIFICATE_NAME} The next time fields-config-bal.php runs, the server certificate on each balancer will be updated to the override value. (Note: fields-config-bal.php runs automatically). Deploy a certificate override (Legacy balancer) Bal servers can have their own unique certificate provided by a customer. Once the certificate has been uploaded, the balancer needs to be associated with the certificate. The same certificate can be associated with multiple bal servers. All bals with the same certificate should ideally have the same ssl_* tag, if not you can manually set BALANCERS to an array of bals to deploy the certificate to: SSL_TAG= BALANCERS=( $(ah-server list tag:${SSL_TAG} -w type=bal) ) for bal in \"${BALANCERS[@]}\"; do ah-edge override-balancer-default-certificate --server-certificate-name=${SERVER_CERTIFICATE_NAME} --server-name=${bal} done The next time fields-config-bal.php runs, the server certificate on each balancer will be updated to the override value. (Note: fields-config-bal.php runs automatically). Remove a certificate override and set to default Acquia certificates (Edge cluster) Edge clusters can be reverted to the default server certificate. This is done by unsetting the custom-certificate: ah-edge unset-cluster-config --uuid=${CLUSTER_UUID} --key=default-certificate The next time fields-config-bal.php runs, the certificate on each balancer will be updated to the default server certificate. (Note: fields-config-bal.php runs automatically). Remove a certificate override and set to default Acquia certificates (Legacy balancer) Bal servers can be reverted to the default server certificate(*.prod.acquia-sites.com). This is done by removing the override: All bals with the same certificate should ideally have the same ssl_* tag, if not you can manually set BALANCERS to an array of bals to deploy the certificate to: SSL_TAG= # If the list of balancers where you want to deploy default Acquia certificate don't have tags, populate 'BALANCERS' array variable with those balancers BALANCERS=( $(ah-server list tag:${SSL_TAG} -w type=bal) ) for bal in \"${BALANCERS[@]}\"; do ah-edge remove-balancer-default-certificate-override --server-name=${bal}; done The next time fields-config-bal.php runs, the certificate on each balancer will be updated to the default server certificate. (Note: fields-config-bal.php runs automatically). To ensure that balancers get the default Acquia certificate immediately, you can run the following command fpdsh -l $(array-csv ${BALANCERS[@]}) -p 20 -c 'sudo fields-config-bal.php' You can then run sv-getcert bal-xyz to verify that required bal has the default Acquia certificate. After deploying default Acquia certificate, please remove any custom ssl tags from the balancers to prevent any future confusion. for bal in \"${BALANCERS[@]}\"; do ah-server tag remove ${bal} -t ${SSL_TAG}; done Setting a default certificate (This is for entire realm) WARNING: This command will change the default balancer certificate for the entire realm! A realm requires a default certificate. Once the certificate that is desired to be used as the default certificate is uploaded it should be set as the default for a given realm: bundle exec ruby bin/ah-stage set-config --key=EdgeService.DefaultServerCertificate --value=${SERVER_CERTIFICATE_NAME} The next time fields-config-bal.php runs, the server certificate on each balancer will be updated unless the server/cluster has an override. (Note: fields-config-bal.php runs automatically). If you want to view the current default certificate, you can run: bundle exec ruby bin/ah-stage describe-config --key=EdgeService.DefaultServerCertificate Verify Use openssl's s_client to connect to the EIP of a bal you pushed to and simulate an SSL / TLS client connection to show the certificate a balancer is serving any errors. An error for a self-signed certificate in the chain is normal. It is the root certificate. sv-getcert $BAL Or, connect to the bal in a browser and check out the cert: https://bal-xxxx.prod.hosting.acquia.com/ Testing a production certificate on a test balancer There are times when a production certificate needs to be tested on a customers test environment. The certificates can either be direct install or sni certificates. Direct install certificate If the certificate is a direct install certificate, determine the cluster or the bals that need the certificate. Then use the instructions from above to set an override for the cluster or bals . Once testing is complete the override can be removed from the cluster or bal . Sni certificate If the certificate is a sni certificate find the id of the certificate that you want to copy: ah-site ssl show ${site_name} Once you have the certificate id run the following command with the list of bals you want to update and the certificate id that you want to copy. (If the bals are part of cluster the cluster will be updated). ah-edge copy-site-certificate-to-server-certificate --site-certificate-id ${certificate_id} --server-names ${server_name_1} ${server_name_2} The command will copy the site certificate, creating a direct install certificate and setting up a certificate override. The response from the API call contain name of the certificate that was created and the servers/clusters that have had an override created. Once testing is complete the override can be removed for each of the listed clusters and/or bals .","title":"Deploying an SSL / TLS certificate to a balancer cluster"},{"location":"kanban_tickets/deploy_certificate/#deploying-an-ssl-tls-certificate-to-a-balancer-cluster","text":"","title":"Deploying an SSL / TLS certificate to a balancer cluster"},{"location":"kanban_tickets/deploy_certificate/#table-of-contents","text":"Determine balancers and tag Prepare Certificate Chain Private key Certificates management Adding a new certificate Deploy a certificate override (Edge cluster) Deploy a certificate override (Legacy balancer) Remove a certificate override (Edge cluster) Remove a certificate override (Legacy balancer) Setting a default certificate Verify Testing a production certificate on a test balancer This doc is intended for use if you are already in possession of both a certificate and a key file that is ready for deployment.","title":"Table of Contents"},{"location":"kanban_tickets/deploy_certificate/#determine-balancers-and-tag","text":"Certificates are deployed based on tag, so you will need to find or create the tag. For dedicated balancers, these tags have the form ssl_\\* , where * is usually a sitename. Shared balancers always get shared UCCs are are tagged ssl_ucc1 , ssl_ucc2 , etc. to match. If the certificate is being deployed for a site, find the balancers and their tags. Shared balancers will be tagged shared , dedicated balancers will not. ah-server list site:$SITE -w type=bal status=0 -c tags If you already know the balancers, find their tags. ah-server list $BALS -c tags If the balancers are already tagged, make sure the tag is not in use elsewhere. If it is, make sure the certificate should also be deployed there. ah-server list tag:$SSL_TAG View the current certificate and make sure it makes sense to replace it with the new certificate. Specifically, the subject should be the same. sv-getcert $BAL If the balancers are dedicated and not tagged, tag them. Make sure the tag is not in use elsewhere. Sometimes sites have multiple certificates and you will need to be more descriptive with the tag. ah-server tag add $BALS --tags ssl_$SITENAME If the balancers are shared and not tagged, you must be deploying a shared UCC certificate, and one that has plenty of slots free. Check this in DigiCert. Tag the balancers as above. Otherwise, the certificate was provisioned incorrectly.","title":"Determine balancers and tag"},{"location":"kanban_tickets/deploy_certificate/#prepare","text":"On the bastion, you will need two files: The certificate chain and the private key.","title":"Prepare"},{"location":"kanban_tickets/deploy_certificate/#certificate-chain","text":"If you are downloading a certificate chain from DigiCert, either choose the option \"A single .pem file containing all the certs\" (including the root), or the copy/paste option and copy the certs in the order displayed into one file. Certificate chains usually come as several certificates that first need to be identified. First, make sure all of the certificates are in PEM format. This format starts with the following line verbatim : -----BEGIN CERTIFICATE----- It will then contain base64-encoded data, which consists entirely of printable characters, and end with the following line verbatim : -----END CERTIFICATE----- If a certificate is not in PEM format, convert it. openssl x509 -inform DER -outform PEM -in $CERT -out $CERT.pem Get the subject and issuer of the certificate file (or files, if you have the intermediate and root certs in separate files) cert-chain $CERT_FILE Determine the order of the certificates. Example of a good order for the chain: [cloudservicesprod|hosting-prod:prod] ~$ cert-chain acquia-sites.pem Chain for acquia-sites.pem: subject=/C=US/ST=Massachusetts/L=Boston/O=Acquia Inc/OU=Acquia Hosting/CN=*.acquia-sites.com issuer=/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert SHA2 High Assurance Server CA subject=/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert SHA2 High Assurance Server CA issuer=/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert High Assurance EV Root CA subject=/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert High Assurance EV Root CA issuer=/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert High Assurance EV Root CA Notes : The chain is usually three certificates long, but can be longer (more than one intermediate certificate) or shorter (first issuer matches root subject). Sometimes, the intermediate or root certificates will not be provided and you will need to go the issuer's website and download them. The first certificate will have a subject with the domain being secured. The issuer of this certificate will be the subject of the next certificate. Further certificates, called intermediate certificates, will each have the same subject as the issuer of the preceding certificate. The issuer of the last intermediate certificate will be the subject of the root certificate. The last certificate, called the root certificate, will have an identical subject and issuer. This is referred to as a self-signed certificate. Concatenate the individual certificates together in order into a single file. This is the certificate chain.","title":"Certificate chain"},{"location":"kanban_tickets/deploy_certificate/#private-key","text":"The private key must be in PEM format. This format starts with one of the following lines verbatim : -----BEGIN PRIVATE KEY----- -----BEGIN RSA PRIVATE KEY----- It will then contain base64-encoded data, which consists entirely of printable characters, and end in one of the following lines verbatim : -----END PRIVATE KEY----- -----END RSA PRIVATE KEY----- If a key is not in PEM format, convert it: openssl rsa -inform DER -outform PEM -in $KEY -out $KEY.pem Additionally, a key can not be password protected.","title":"Private key"},{"location":"kanban_tickets/deploy_certificate/#certificates-management","text":"The following tooling can be used for both edge clusters and legacy bals.","title":"Certificates management"},{"location":"kanban_tickets/deploy_certificate/#adding-a-new-certificate-both-edge-cluster-and-legacy","text":"Both certificate name and the certificate associated with name are immutable, and as such can never be overwritten. Once the certificate has been generated or provided by a customer it needs to uploaded to Hosting API using ah-edge tooling. To upload a certificate the following command is used. (Note: until the certificate is set as an override or as the default certificate for a realm it won't be used). If an Edge Cluster is used by multiple sitegroups or an SSL is to be used by multiple Edge Clusters, then you need to choose one SITENAME as the one to use. Typically it is something like how the ibmcom-v5 SSL is used by Edge Clusters in sitegroups ibmcom , ibmextend and ibmcom5 in a different stack, or it's typically still one customer just different sitegroups. For Legacy Balancers, the SSL tag is defined as ssl_$SITENAME . Again, if multiple sitegroups or multiple balancers, you need to choose one SITENAME to be the root name. SERVER_CERTIFICATE_NAME is ${SSL_TAG}-v${version} , same idea as EDGE CLUSTER though prepended with ssl_ . CERTIFICATE_CHAIN and PRIVATE_KEY should be the full path name to the files containing the certification chain and private key respectively. SERVER_CERTIFICATE_NAME=${SITENAME}-v${version} CERTIFICATE_CHAIN=/Users/xyz/ca.cer PRIVATE_KEY=/Users/xyz/siteName.key ah-edge create-server-certificate --name=$SERVER_CERTIFICATE_NAME --certificate-chain=$CERTIFICATE_CHAIN --private-key=$PRIVATE_KEY Or you can cat its contents as a command input: ah-edge create-server-certificate --name=$SERVER_CERTIFICATE_NAME --certificate-chain=\"$(cat $CERTIFICATE_CHAIN)\" --private-key=\"$(cat $PRIVATE_KEY)\"","title":"Adding a new certificate (Both Edge Cluster and Legacy)"},{"location":"kanban_tickets/deploy_certificate/#deploy-a-certificate-override-edge-cluster","text":"Edge clusters can have their own unique certificate provided by a customer. Once the certificate has been uploaded the cluster config needs to be updated: ah-edge set-cluster-config --uuid=${CLUSTER_UUID} --key=default-certificate --value=${SERVER_CERTIFICATE_NAME} The next time fields-config-bal.php runs, the server certificate on each balancer will be updated to the override value. (Note: fields-config-bal.php runs automatically).","title":"Deploy a certificate override (Edge cluster)"},{"location":"kanban_tickets/deploy_certificate/#deploy-a-certificate-override-legacy-balancer","text":"Bal servers can have their own unique certificate provided by a customer. Once the certificate has been uploaded, the balancer needs to be associated with the certificate. The same certificate can be associated with multiple bal servers. All bals with the same certificate should ideally have the same ssl_* tag, if not you can manually set BALANCERS to an array of bals to deploy the certificate to: SSL_TAG= BALANCERS=( $(ah-server list tag:${SSL_TAG} -w type=bal) ) for bal in \"${BALANCERS[@]}\"; do ah-edge override-balancer-default-certificate --server-certificate-name=${SERVER_CERTIFICATE_NAME} --server-name=${bal} done The next time fields-config-bal.php runs, the server certificate on each balancer will be updated to the override value. (Note: fields-config-bal.php runs automatically).","title":"Deploy a certificate override (Legacy balancer)"},{"location":"kanban_tickets/deploy_certificate/#remove-a-certificate-override-and-set-to-default-acquia-certificates-edge-cluster","text":"Edge clusters can be reverted to the default server certificate. This is done by unsetting the custom-certificate: ah-edge unset-cluster-config --uuid=${CLUSTER_UUID} --key=default-certificate The next time fields-config-bal.php runs, the certificate on each balancer will be updated to the default server certificate. (Note: fields-config-bal.php runs automatically).","title":"Remove a certificate override and set to default Acquia certificates (Edge cluster)"},{"location":"kanban_tickets/deploy_certificate/#remove-a-certificate-override-and-set-to-default-acquia-certificates-legacy-balancer","text":"Bal servers can be reverted to the default server certificate(*.prod.acquia-sites.com). This is done by removing the override: All bals with the same certificate should ideally have the same ssl_* tag, if not you can manually set BALANCERS to an array of bals to deploy the certificate to: SSL_TAG= # If the list of balancers where you want to deploy default Acquia certificate don't have tags, populate 'BALANCERS' array variable with those balancers BALANCERS=( $(ah-server list tag:${SSL_TAG} -w type=bal) ) for bal in \"${BALANCERS[@]}\"; do ah-edge remove-balancer-default-certificate-override --server-name=${bal}; done The next time fields-config-bal.php runs, the certificate on each balancer will be updated to the default server certificate. (Note: fields-config-bal.php runs automatically). To ensure that balancers get the default Acquia certificate immediately, you can run the following command fpdsh -l $(array-csv ${BALANCERS[@]}) -p 20 -c 'sudo fields-config-bal.php' You can then run sv-getcert bal-xyz to verify that required bal has the default Acquia certificate. After deploying default Acquia certificate, please remove any custom ssl tags from the balancers to prevent any future confusion. for bal in \"${BALANCERS[@]}\"; do ah-server tag remove ${bal} -t ${SSL_TAG}; done","title":"Remove a certificate override and set to default Acquia certificates (Legacy balancer)"},{"location":"kanban_tickets/deploy_certificate/#setting-a-default-certificate-this-is-for-entire-realm","text":"WARNING: This command will change the default balancer certificate for the entire realm! A realm requires a default certificate. Once the certificate that is desired to be used as the default certificate is uploaded it should be set as the default for a given realm: bundle exec ruby bin/ah-stage set-config --key=EdgeService.DefaultServerCertificate --value=${SERVER_CERTIFICATE_NAME} The next time fields-config-bal.php runs, the server certificate on each balancer will be updated unless the server/cluster has an override. (Note: fields-config-bal.php runs automatically). If you want to view the current default certificate, you can run: bundle exec ruby bin/ah-stage describe-config --key=EdgeService.DefaultServerCertificate","title":"Setting a default certificate (This is for entire realm)"},{"location":"kanban_tickets/deploy_certificate/#verify","text":"Use openssl's s_client to connect to the EIP of a bal you pushed to and simulate an SSL / TLS client connection to show the certificate a balancer is serving any errors. An error for a self-signed certificate in the chain is normal. It is the root certificate. sv-getcert $BAL Or, connect to the bal in a browser and check out the cert: https://bal-xxxx.prod.hosting.acquia.com/","title":"Verify"},{"location":"kanban_tickets/deploy_certificate/#testing-a-production-certificate-on-a-test-balancer","text":"There are times when a production certificate needs to be tested on a customers test environment. The certificates can either be direct install or sni certificates.","title":"Testing a production certificate on a test balancer"},{"location":"kanban_tickets/deploy_certificate/#direct-install-certificate","text":"If the certificate is a direct install certificate, determine the cluster or the bals that need the certificate. Then use the instructions from above to set an override for the cluster or bals . Once testing is complete the override can be removed from the cluster or bal .","title":"Direct install certificate"},{"location":"kanban_tickets/deploy_certificate/#sni-certificate","text":"If the certificate is a sni certificate find the id of the certificate that you want to copy: ah-site ssl show ${site_name} Once you have the certificate id run the following command with the list of bals you want to update and the certificate id that you want to copy. (If the bals are part of cluster the cluster will be updated). ah-edge copy-site-certificate-to-server-certificate --site-certificate-id ${certificate_id} --server-names ${server_name_1} ${server_name_2} The command will copy the site certificate, creating a direct install certificate and setting up a certificate override. The response from the API call contain name of the certificate that was created and the servers/clusters that have had an override created. Once testing is complete the override can be removed for each of the listed clusters and/or bals .","title":"Sni certificate"},{"location":"kanban_tickets/deploy_test_vcl/","text":"Deploy custom VCL for customer testing Once a VCL file is ready for customer testing, it must be deployed to a test balancer for customer testing. RECOMMENDED: Automated FALLBACK: Manual","title":"Deploy custom VCL for customer testing"},{"location":"kanban_tickets/deploy_test_vcl/#deploy-custom-vcl-for-customer-testing","text":"Once a VCL file is ready for customer testing, it must be deployed to a test balancer for customer testing. RECOMMENDED: Automated FALLBACK: Manual","title":"Deploy custom VCL for customer testing"},{"location":"kanban_tickets/deprovision_search_colony/","text":"Deprovision a Search Colony Note: To login Search jumpboxes, follow these instructions Prerequisites If this is your first time deprovisioning a search colony, you will need to download the id_search keypair from the Ops KeePassX and store it in ${SECURE}/ec2/search-service/ssh/default . If you do not have access to this repository, please contact an Ops Manager. You have a colony ID. If a colony ID is not provided in the Jira ticket, send ticket back to the requestor. Procedure Before you can deprovision a colony, all of the associated farms need to be previously deprovisioned. To verify that no farms remain associated with this colony, execute the following: COLONY= ah-search colony $COLONY --farms If any farms are retrieved, please verify that the remaining farms are supposed to be decommisioned. If not, then this colony cannot be decommisioned. If the farm(s) can be decommissioned, proceed with the deprovision Farm runbook. Assign the nxephems and region retrieved in the above command to variables. REGION= NXEPHEM1= NXEPHEM2= Get the ELB name and ELB_URL , run the below command. The ELB name will be search-service-### . It is important to note that only the first series of numbers matter. For example, a ELB_URL of search-service-642-2018485732.us-west-2.elb.amazonaws.com would give you a ELB name of search-service-642 . bundle exec site-elbdescribe $(ah-site list on:${NXEPHEM1}) ELB_NAME=<eg: search-service-XYZ> ELB_URL=<eg: search-service-XYZ-ABCD.us-west-2.elb.amazonaws.com> Determine the extractor associated with this colony. Unfortunately there is no easy to determine what the extractor is from the command line. The easiest way is to use the Governor . Log in to the Acquia Search Governor Select the Server List tab. Select the appropriate colony from the Colony (field colony) select box and click Apply . Take note of the server as you will need to know it later. Click on the appropriate result Click the Edit tab. Click the Publishing options then uncheck Published and click Save to unpublish the node. Unpublish the colony in the Governor . Log in to the Acquia Search Governor Type the colony name into the Title contains textbox and click Apply . Click on the appropriate result Click the Edit tab. Click the Publishing options then uncheck Published and click Save . Suspend the hardware. EXTRACTOR= ah-server suspend ${EXTRACTOR},${NXEPHEM1},${NXEPHEM2} aws elb delete-load-balancer --region $REGION --load-balancer-name $ELB_NAME Delete CNAME entries for ELB . CNAME entries exist in Route53 . 1. Get credentials and token to elevate temporarily and be able to write DNS records: aws sts assume-role \\ --output json \\ --role-arn 'arn:aws:iam::345874614325:role/Search-R53-Access' \\ --role-session-name \"colony-creation-$(whoami)\" 1. Populate the following variables from the output of the previous command: export AWS_ACCESS_KEY_ID= export AWS_SECRET_ACCESS_KEY= export AWS_SESSION_TOKEN= 1. Find the id of the `acquia-search.com` zone, and populate the proper variable: AS_ZONE=$(aws route53 list-hosted-zones --output json | \\ jq '.HostedZones' | \\ jq '.[] | select(.Name == \"acquia-search.com.\")' | \\ jq '.Id' | \\ sed 's/\"//g') (Note: if `AS_ZONE` isn't being populated, just run the aws command to list zones above and find the id of the `acquia-search.com` zone to populate the variable manually) 1. Set `RECORD_NAME` variable. Use the region identifier (SITEGROUP minus \"bal\"), followed by a dash, then COLONY, which is followed by \".acquia-search.com\" RECORD_NAME=<eg: apseast1-c60.acquia-search.com> 1. Check whether the CNAME exists in Route53. aws route53 list-resource-record-sets --hosted-zone-id ${AS_ZONE}| \\ jq -r '.ResourceRecordSets[].Name'| \\ grep ${RECORD_NAME} > /dev/null && \\ echo \"CNAME exists in Route53\" || \\ echo \"CNAME does NOT exist in Route53\" If it exists, continue with below steps. Else, skip to main `Step 8`. 1. Prepare the record json(Use the Jira ticket number you are working on as the comment for the json): JIRA_TICKET=<eg: OP-185615> ELB_CNAME=\"{ \\\"Comment\\\": \\\"${JIRA_TICKET}\\\", \\\"Changes\\\": [ { \\\"Action\\\": \\\"DELETE\\\", \\\"ResourceRecordSet\\\": { \\\"Name\\\": \\\"${RECORD_NAME}\\\", \\\"Type\\\": \\\"CNAME\\\", \\\"TTL\\\": 30, \\\"ResourceRecords\\\": [ { \\\"Value\\\": \\\"${ELB_URL}\\\" } ] } } ] }\" 1. Print the zone and record and review that everything looks good: echo ${AS_ZONE} echo ${ELB_CNAME} | jq 1. Delete the record. CHANGE_ID=$(aws route53 change-resource-record-sets \\ --output json \\ --hosted-zone-id ${AS_ZONE} \\ --change-batch \"${ELB_CNAME}\" | jq '.ChangeInfo.Id' | \\ sed 's/\"//g') 1. Check whether the change is properly applied (in INSYNC status, may take a couple of minutes) aws route53 get-change --id ${CHANGE_ID} 1. Lastly, confirm the record is deleted. aws route53 list-resource-record-sets --hosted-zone-id ${AS_ZONE}| \\ jq -r '.ResourceRecordSets[].Name'| \\ grep ${RECORD_NAME} > /dev/null && \\ echo \"CNAME still exists in Route53\" || \\ echo \"CNAME does NOT exist anymore in Route53\" Write a TSR to terminate hardware for one week after hardware was suspended. Be sure to include the following commands in the ticket. IMPORTANT , the below commands must not be executed before the one week waiting period. ./fields-provision.php --terminate <EXTRACTOR>,<NXEPHEM1>,<NXEPHEM2> ./fields-provision.php --site-delete <COLONY>","title":"Deprovision a Search Colony"},{"location":"kanban_tickets/deprovision_search_colony/#deprovision-a-search-colony","text":"Note: To login Search jumpboxes, follow these instructions","title":"Deprovision a Search Colony"},{"location":"kanban_tickets/deprovision_search_colony/#prerequisites","text":"If this is your first time deprovisioning a search colony, you will need to download the id_search keypair from the Ops KeePassX and store it in ${SECURE}/ec2/search-service/ssh/default . If you do not have access to this repository, please contact an Ops Manager. You have a colony ID. If a colony ID is not provided in the Jira ticket, send ticket back to the requestor.","title":"Prerequisites"},{"location":"kanban_tickets/deprovision_search_colony/#procedure","text":"Before you can deprovision a colony, all of the associated farms need to be previously deprovisioned. To verify that no farms remain associated with this colony, execute the following: COLONY= ah-search colony $COLONY --farms If any farms are retrieved, please verify that the remaining farms are supposed to be decommisioned. If not, then this colony cannot be decommisioned. If the farm(s) can be decommissioned, proceed with the deprovision Farm runbook. Assign the nxephems and region retrieved in the above command to variables. REGION= NXEPHEM1= NXEPHEM2= Get the ELB name and ELB_URL , run the below command. The ELB name will be search-service-### . It is important to note that only the first series of numbers matter. For example, a ELB_URL of search-service-642-2018485732.us-west-2.elb.amazonaws.com would give you a ELB name of search-service-642 . bundle exec site-elbdescribe $(ah-site list on:${NXEPHEM1}) ELB_NAME=<eg: search-service-XYZ> ELB_URL=<eg: search-service-XYZ-ABCD.us-west-2.elb.amazonaws.com> Determine the extractor associated with this colony. Unfortunately there is no easy to determine what the extractor is from the command line. The easiest way is to use the Governor . Log in to the Acquia Search Governor Select the Server List tab. Select the appropriate colony from the Colony (field colony) select box and click Apply . Take note of the server as you will need to know it later. Click on the appropriate result Click the Edit tab. Click the Publishing options then uncheck Published and click Save to unpublish the node. Unpublish the colony in the Governor . Log in to the Acquia Search Governor Type the colony name into the Title contains textbox and click Apply . Click on the appropriate result Click the Edit tab. Click the Publishing options then uncheck Published and click Save . Suspend the hardware. EXTRACTOR= ah-server suspend ${EXTRACTOR},${NXEPHEM1},${NXEPHEM2} aws elb delete-load-balancer --region $REGION --load-balancer-name $ELB_NAME Delete CNAME entries for ELB . CNAME entries exist in Route53 . 1. Get credentials and token to elevate temporarily and be able to write DNS records: aws sts assume-role \\ --output json \\ --role-arn 'arn:aws:iam::345874614325:role/Search-R53-Access' \\ --role-session-name \"colony-creation-$(whoami)\" 1. Populate the following variables from the output of the previous command: export AWS_ACCESS_KEY_ID= export AWS_SECRET_ACCESS_KEY= export AWS_SESSION_TOKEN= 1. Find the id of the `acquia-search.com` zone, and populate the proper variable: AS_ZONE=$(aws route53 list-hosted-zones --output json | \\ jq '.HostedZones' | \\ jq '.[] | select(.Name == \"acquia-search.com.\")' | \\ jq '.Id' | \\ sed 's/\"//g') (Note: if `AS_ZONE` isn't being populated, just run the aws command to list zones above and find the id of the `acquia-search.com` zone to populate the variable manually) 1. Set `RECORD_NAME` variable. Use the region identifier (SITEGROUP minus \"bal\"), followed by a dash, then COLONY, which is followed by \".acquia-search.com\" RECORD_NAME=<eg: apseast1-c60.acquia-search.com> 1. Check whether the CNAME exists in Route53. aws route53 list-resource-record-sets --hosted-zone-id ${AS_ZONE}| \\ jq -r '.ResourceRecordSets[].Name'| \\ grep ${RECORD_NAME} > /dev/null && \\ echo \"CNAME exists in Route53\" || \\ echo \"CNAME does NOT exist in Route53\" If it exists, continue with below steps. Else, skip to main `Step 8`. 1. Prepare the record json(Use the Jira ticket number you are working on as the comment for the json): JIRA_TICKET=<eg: OP-185615> ELB_CNAME=\"{ \\\"Comment\\\": \\\"${JIRA_TICKET}\\\", \\\"Changes\\\": [ { \\\"Action\\\": \\\"DELETE\\\", \\\"ResourceRecordSet\\\": { \\\"Name\\\": \\\"${RECORD_NAME}\\\", \\\"Type\\\": \\\"CNAME\\\", \\\"TTL\\\": 30, \\\"ResourceRecords\\\": [ { \\\"Value\\\": \\\"${ELB_URL}\\\" } ] } } ] }\" 1. Print the zone and record and review that everything looks good: echo ${AS_ZONE} echo ${ELB_CNAME} | jq 1. Delete the record. CHANGE_ID=$(aws route53 change-resource-record-sets \\ --output json \\ --hosted-zone-id ${AS_ZONE} \\ --change-batch \"${ELB_CNAME}\" | jq '.ChangeInfo.Id' | \\ sed 's/\"//g') 1. Check whether the change is properly applied (in INSYNC status, may take a couple of minutes) aws route53 get-change --id ${CHANGE_ID} 1. Lastly, confirm the record is deleted. aws route53 list-resource-record-sets --hosted-zone-id ${AS_ZONE}| \\ jq -r '.ResourceRecordSets[].Name'| \\ grep ${RECORD_NAME} > /dev/null && \\ echo \"CNAME still exists in Route53\" || \\ echo \"CNAME does NOT exist anymore in Route53\" Write a TSR to terminate hardware for one week after hardware was suspended. Be sure to include the following commands in the ticket. IMPORTANT , the below commands must not be executed before the one week waiting period. ./fields-provision.php --terminate <EXTRACTOR>,<NXEPHEM1>,<NXEPHEM2> ./fields-provision.php --site-delete <COLONY>","title":"Procedure"},{"location":"kanban_tickets/deprovision_search_farm/","text":"Deprovision a Search Farm Note: To login Search jumpboxes, follow these instructions Prerequisites If this is your first time provisioning/deprovisioning a search farm or colony, you will need to download the id_search keypair from the Ops KeePassX and store it in ${SECURE}/ec2/search-service/ssh/default . If you do not have access to this repository, and need to deprovision a search farm, please contact an Operations Manager. Procedures Verify that no cores remain on the farm. FARM= ah-search farm $FARMS --cores If there any indexes returned, you will need to verify that the remaining indexes do not need to be migrated. If the remaining indexes need migrating, migrate them using the search index migration runbook. Otherwise proceed onto the next step. Get the sites associated with the javasrv and javaephem , you will need this info for the TSR ticket that terminates the hardware. MASTER= SLAVE= ah-site list on:${MASTER} ah-site list on:${SLAVE} Unpublish the farm nodes in the Governor . In the Governor , there is a node for the javasrv and one for the javaephem . Their names are based upon the farm name. For example, farm useast1ass1 would become useast1as.s1master for the javasrv and useast1as.s1slave for the javaephem . Log in to the Acquia Search Governor Type the node name for the javasrv per above into the Title contains textbox and click Apply . Click on the appropriate result Click the Edit tab. Click the Publishing options then uncheck Published and click Save . Repeat from step 2 , this time for the javaephem Suspend the hardware. ah-server suspend ${MASTER},${SLAVE} Disable backups for the javasrv sv-backupdisable $MASTER Write a TSR to terminate hardware for one week after hardware was suspended. Be sure to include the following commands in the ticket. IMPORTANT , the below commands must not be executed before the one week waiting period. ./fields-provision.php --terminate <JAVASRV>, <JAVAEPHEM> ./fields-provision.php --site-delete <MASTER_SITE> ./fields-provision.php --site-delete <SLAVE_SITE>","title":"Deprovision a Search Farm"},{"location":"kanban_tickets/deprovision_search_farm/#deprovision-a-search-farm","text":"Note: To login Search jumpboxes, follow these instructions","title":"Deprovision a Search Farm"},{"location":"kanban_tickets/deprovision_search_farm/#prerequisites","text":"If this is your first time provisioning/deprovisioning a search farm or colony, you will need to download the id_search keypair from the Ops KeePassX and store it in ${SECURE}/ec2/search-service/ssh/default . If you do not have access to this repository, and need to deprovision a search farm, please contact an Operations Manager.","title":"Prerequisites"},{"location":"kanban_tickets/deprovision_search_farm/#procedures","text":"Verify that no cores remain on the farm. FARM= ah-search farm $FARMS --cores If there any indexes returned, you will need to verify that the remaining indexes do not need to be migrated. If the remaining indexes need migrating, migrate them using the search index migration runbook. Otherwise proceed onto the next step. Get the sites associated with the javasrv and javaephem , you will need this info for the TSR ticket that terminates the hardware. MASTER= SLAVE= ah-site list on:${MASTER} ah-site list on:${SLAVE} Unpublish the farm nodes in the Governor . In the Governor , there is a node for the javasrv and one for the javaephem . Their names are based upon the farm name. For example, farm useast1ass1 would become useast1as.s1master for the javasrv and useast1as.s1slave for the javaephem . Log in to the Acquia Search Governor Type the node name for the javasrv per above into the Title contains textbox and click Apply . Click on the appropriate result Click the Edit tab. Click the Publishing options then uncheck Published and click Save . Repeat from step 2 , this time for the javaephem Suspend the hardware. ah-server suspend ${MASTER},${SLAVE} Disable backups for the javasrv sv-backupdisable $MASTER Write a TSR to terminate hardware for one week after hardware was suspended. Be sure to include the following commands in the ticket. IMPORTANT , the below commands must not be executed before the one week waiting period. ./fields-provision.php --terminate <JAVASRV>, <JAVAEPHEM> ./fields-provision.php --site-delete <MASTER_SITE> ./fields-provision.php --site-delete <SLAVE_SITE>","title":"Procedures"},{"location":"kanban_tickets/deprovisioning_ace/","text":"Deprovisioning ACE & ACP Preparation The AM needs to approve in the ticket before proceeding. Ops do not need AM involvement/approval for OUT ticket processing where we're deleting \"ee\" (Employee Evaluation) sites. Verify that the AM that approved is the AM listed in CCI. If you cannot find the subscription in CCI, then it is likely that the AM has already deleted it. Run site-terminate-audit to get a list of everything associated with the sitegroup to be deprovisioned. Execute the commands given by site-terminate-audit with caution! Caveats OPE-1611 : site-terminate-audit does not instruct you to delete the dedicated vpc. OPE-1612 : site-terminate-audit does not instruct you to delete volume snapshots. CL-10450 : ACP servers are not automatically terminated. Deprovisioning a specific site stage site-terminate-audit $SITEGROUP.$STAGE Deprovisioning a sitegroup site-terminate-audit $SITEGROUP Deprovisioning Site and/or hardware deprovisioning is usually done in two stages, suspension and termination, in order to allow a 7-day window of opportunity to undo any mistakes or miscommunication before data is lost. Do not terminate anything without this window unless you have explicit customer/AM approval! There is an exception to this for sites that have no dedicated hardware to suspend. In this particular case, it is safe to remove the site from monitoring, deprovision the ELB (if applicable), and delete the site/sitegroup. A Note About ACP Ops should not deprovision ACP servers manually! The AM should do it through CCI. If for some reason the AM can not cancel via CCI, you can do it manually. As always, verify that you are not deprovisioning shared hardware and remove sites from monitoring. ah-site list on:$SERVER site-mondisable $SITE ah-server cancel $SERVER ./fields-provision.php --devcloud-cancel $SERVER Make a TSR ticket in Jira like you would for any other termination . Suspension Verify there are no other sites on the hardware: ah-site list on:$SERVER If there are any production sites in monitoring, remove them. Note: site-mon does not work outside of ACE. site-mon get $SITE site-mon remove $SITE If there are other sites that will remain on the hardware, add the first site on the DB-class instance to monitoring: site-mon add $(ah-site list on:$DBMASTER | head -n1) If there are no other sites on them, suspend the servers: ah-server suspend $SERVERS Update Jira Create a TSR ticket and set the Start After field for 7 days from now and the Finish Before field for any day after that. Paste the commands to execute for full termination into the description. See termination , for examples of what to include. Link the TSR ticket to the original ticket. Select 'Move to Kanban', this will allow it to appear when the Start After date has passed. Termination Sanity-check the commands given in the TSR ticket and verify that it has been at least 7 days since the hardware was suspended. WARNING: Deleting a site cannot be undone by OPS. If you accidentally delete a site or are asked to restore a deleted site, you must Escalate to Cloud ! Deprovision site ELBs: ah-site ssl deprovision-elb $SITE If you are deleting a sitegroup: ah-sitegroup delete $SITEGROUP If you are deleting a single site: ./fields-provision.php --site-delete $SITE Terminate unused hardware (servers that have no sites on them unless the ticket is asking to explicitly keep them for some reason): ah-server terminate $SERVERS After terminating the hardware remove the lingering associations between sites and webnodes: execute the commands outputted by sv-unlink $SERVERS If the customer is being terminated and has a dedicated VPC/VPN, deprovision them . If the customer has a custom VCL, submit a pull request to remove their VCL file from the hosting-vcl-files repo Bulk site/environment Termination If you are deleting/removing more than 10 sites, make sure that you are doing that in batches to avoid a task storm. Recommended batch size for removing/deleting sites is 10. Create a file similar to this and assign file name to variable \"FILENAME\" This one liner can be used to create batch files while working on multiple sites: awk 'NR%10==1{fn && close(fn);fn=\"BATCH-\"++i\".txt\";}{print > fn}' $FILENAME NOTE The above command will create batch files each containing 10 sites. If you are dealing with lot of sites, you may create a directory before executing the above command to avoid making a mess in home directory. Once the batch files are created, delete the sites in a loop with sleep of 1 minute interval in between to avoid burdening task servers. for site in $(cat BATCH-1.txt);do _your_site_deletion_command_here;sleep 120;done","title":"Deprovisioning ACE & ACP"},{"location":"kanban_tickets/deprovisioning_ace/#deprovisioning-ace-acp","text":"","title":"Deprovisioning ACE &amp; ACP"},{"location":"kanban_tickets/deprovisioning_ace/#preparation","text":"The AM needs to approve in the ticket before proceeding. Ops do not need AM involvement/approval for OUT ticket processing where we're deleting \"ee\" (Employee Evaluation) sites. Verify that the AM that approved is the AM listed in CCI. If you cannot find the subscription in CCI, then it is likely that the AM has already deleted it. Run site-terminate-audit to get a list of everything associated with the sitegroup to be deprovisioned. Execute the commands given by site-terminate-audit with caution!","title":"Preparation"},{"location":"kanban_tickets/deprovisioning_ace/#caveats","text":"OPE-1611 : site-terminate-audit does not instruct you to delete the dedicated vpc. OPE-1612 : site-terminate-audit does not instruct you to delete volume snapshots. CL-10450 : ACP servers are not automatically terminated.","title":"Caveats"},{"location":"kanban_tickets/deprovisioning_ace/#deprovisioning-a-specific-site-stage","text":"site-terminate-audit $SITEGROUP.$STAGE","title":"Deprovisioning a specific site stage"},{"location":"kanban_tickets/deprovisioning_ace/#deprovisioning-a-sitegroup","text":"site-terminate-audit $SITEGROUP","title":"Deprovisioning a sitegroup"},{"location":"kanban_tickets/deprovisioning_ace/#deprovisioning","text":"Site and/or hardware deprovisioning is usually done in two stages, suspension and termination, in order to allow a 7-day window of opportunity to undo any mistakes or miscommunication before data is lost. Do not terminate anything without this window unless you have explicit customer/AM approval! There is an exception to this for sites that have no dedicated hardware to suspend. In this particular case, it is safe to remove the site from monitoring, deprovision the ELB (if applicable), and delete the site/sitegroup.","title":"Deprovisioning"},{"location":"kanban_tickets/deprovisioning_ace/#a-note-about-acp","text":"Ops should not deprovision ACP servers manually! The AM should do it through CCI. If for some reason the AM can not cancel via CCI, you can do it manually. As always, verify that you are not deprovisioning shared hardware and remove sites from monitoring. ah-site list on:$SERVER site-mondisable $SITE ah-server cancel $SERVER ./fields-provision.php --devcloud-cancel $SERVER Make a TSR ticket in Jira like you would for any other termination .","title":"A Note About ACP"},{"location":"kanban_tickets/deprovisioning_ace/#suspension","text":"Verify there are no other sites on the hardware: ah-site list on:$SERVER If there are any production sites in monitoring, remove them. Note: site-mon does not work outside of ACE. site-mon get $SITE site-mon remove $SITE If there are other sites that will remain on the hardware, add the first site on the DB-class instance to monitoring: site-mon add $(ah-site list on:$DBMASTER | head -n1) If there are no other sites on them, suspend the servers: ah-server suspend $SERVERS Update Jira Create a TSR ticket and set the Start After field for 7 days from now and the Finish Before field for any day after that. Paste the commands to execute for full termination into the description. See termination , for examples of what to include. Link the TSR ticket to the original ticket. Select 'Move to Kanban', this will allow it to appear when the Start After date has passed.","title":"Suspension"},{"location":"kanban_tickets/deprovisioning_ace/#termination","text":"Sanity-check the commands given in the TSR ticket and verify that it has been at least 7 days since the hardware was suspended. WARNING: Deleting a site cannot be undone by OPS. If you accidentally delete a site or are asked to restore a deleted site, you must Escalate to Cloud ! Deprovision site ELBs: ah-site ssl deprovision-elb $SITE If you are deleting a sitegroup: ah-sitegroup delete $SITEGROUP If you are deleting a single site: ./fields-provision.php --site-delete $SITE Terminate unused hardware (servers that have no sites on them unless the ticket is asking to explicitly keep them for some reason): ah-server terminate $SERVERS After terminating the hardware remove the lingering associations between sites and webnodes: execute the commands outputted by sv-unlink $SERVERS If the customer is being terminated and has a dedicated VPC/VPN, deprovision them . If the customer has a custom VCL, submit a pull request to remove their VCL file from the hosting-vcl-files repo","title":"Termination"},{"location":"kanban_tickets/deprovisioning_ace/#bulk-siteenvironment-termination","text":"If you are deleting/removing more than 10 sites, make sure that you are doing that in batches to avoid a task storm. Recommended batch size for removing/deleting sites is 10. Create a file similar to this and assign file name to variable \"FILENAME\" This one liner can be used to create batch files while working on multiple sites: awk 'NR%10==1{fn && close(fn);fn=\"BATCH-\"++i\".txt\";}{print > fn}' $FILENAME NOTE The above command will create batch files each containing 10 sites. If you are dealing with lot of sites, you may create a directory before executing the above command to avoid making a mess in home directory. Once the batch files are created, delete the sites in a loop with sleep of 1 minute interval in between to avoid burdening task servers. for site in $(cat BATCH-1.txt);do _your_site_deletion_command_here;sleep 120;done","title":"Bulk site/environment Termination"},{"location":"kanban_tickets/deprovisioning_mail_server/","text":"Deprovisoning a mail server Remove from monitoring and puppet manifest Stop notifications by searching for server in ops-mon-2 and then click on the Commands tab. Disable Notifications, Active Checks and Passive checks and say Yes to all the prompts. Edit intranet.cfg in the ops-mon-2 repo by removing the host definitions and the FQDN from members and host_name lines - or as seen here Solicit two approvals from the ops team and merge the PR. Open a CL (Example CL-33291) to remove the mail server's IP from the mail.pp file. Example Ensure to link the PR to the CL for proper review. Removing DNS entries for the mail server Log into dynect , if you need creds, ask a manager. Go to Managed DNS > Click on Manage next to the acquia.com Zone > Select the Mail server from the list on the left > Click on the Down arrow on the right of each record to expand it and then delete each record. Next, scroll down in the list on the right to find the _spf record > Click on the down arrow to expand > remove the IP address for the mail server deprovisioned. Finally, Review Changes and Publish. Terminating server from Rackspace Log into rackspace > Select Rackspace Cloud from the pull down menu at the top > Servers > Cloud Servers > Click on the gear next to the mail server in question and Delete Server. Edit the list of mail servers here and Email Blacklist Response and update the notes with relevant info.","title":"Deprovisoning a mail server"},{"location":"kanban_tickets/deprovisioning_mail_server/#deprovisoning-a-mail-server","text":"","title":"Deprovisoning a mail server"},{"location":"kanban_tickets/deprovisioning_mail_server/#remove-from-monitoring-and-puppet-manifest","text":"Stop notifications by searching for server in ops-mon-2 and then click on the Commands tab. Disable Notifications, Active Checks and Passive checks and say Yes to all the prompts. Edit intranet.cfg in the ops-mon-2 repo by removing the host definitions and the FQDN from members and host_name lines - or as seen here Solicit two approvals from the ops team and merge the PR. Open a CL (Example CL-33291) to remove the mail server's IP from the mail.pp file. Example Ensure to link the PR to the CL for proper review.","title":"Remove from monitoring and puppet manifest"},{"location":"kanban_tickets/deprovisioning_mail_server/#removing-dns-entries-for-the-mail-server","text":"Log into dynect , if you need creds, ask a manager. Go to Managed DNS > Click on Manage next to the acquia.com Zone > Select the Mail server from the list on the left > Click on the Down arrow on the right of each record to expand it and then delete each record. Next, scroll down in the list on the right to find the _spf record > Click on the down arrow to expand > remove the IP address for the mail server deprovisioned. Finally, Review Changes and Publish.","title":"Removing DNS entries for the mail server"},{"location":"kanban_tickets/deprovisioning_mail_server/#terminating-server-from-rackspace","text":"Log into rackspace > Select Rackspace Cloud from the pull down menu at the top > Servers > Cloud Servers > Click on the gear next to the mail server in question and Delete Server. Edit the list of mail servers here and Email Blacklist Response and update the notes with relevant info.","title":"Terminating server from Rackspace"},{"location":"kanban_tickets/diagnostics/","text":"Diagnostics Certificate Files Compare Cert and Key If you have a certificate and corresponding private key file, here's how to verify that the files are in fact intrinsically linked. openssl x509 -noout -modulus -in ssl.crt | openssl md5; \\ openssl rsa -noout -modulus -in ssl.key | openssl md5 Alternatively, use cert-checkkey: cert-checkkey ssl.crt ssl.key Compare CSR and Key openssl req -noout -modulus -in ssl.csr | openssl md5; \\ openssl rsa -noout -modulus -in ssl.key | openssl md5 View Certificate Information To view the domains associated with a cert, the expiry dates, the certificate issuer and some other information: openssl x509 -in sitename.crt -noout -text Get notBefore/notAfter (Expiration) date openssl x509 -in sitename.crt -noout -subject -dates e.g. $ openssl x509 -noout -subject -dates -in Downloads/luminary/NetworkSolutions_CA.crt subject= /C=US/O=Network Solutions L.L.C./CN=Network Solutions Certificate Authority notBefore=Apr 10 00:00:00 2006 GMT notAfter=May 30 10:48:38 2020 GMT OR for checking a series of certs for i in $(ls -1); do echo $i; openssl x509 -noout -subject -dates in $i; done Services over SSL Verify Certificate Chain openssl s_client -showcerts -connect www.domain.com:443 < /dev/null Asynchronous Keys Get public key from private key The public key is embedded in the private key which is why if someone has your private key you are so utterly hosed your face may end up on google and eventually on to a de-motivational meme. ssh-keygen -y -f /path/to/PRIVATE_KEY","title":"Diagnostics"},{"location":"kanban_tickets/diagnostics/#diagnostics","text":"","title":"Diagnostics"},{"location":"kanban_tickets/diagnostics/#certificate-files","text":"","title":"Certificate Files"},{"location":"kanban_tickets/diagnostics/#compare-cert-and-key","text":"If you have a certificate and corresponding private key file, here's how to verify that the files are in fact intrinsically linked. openssl x509 -noout -modulus -in ssl.crt | openssl md5; \\ openssl rsa -noout -modulus -in ssl.key | openssl md5 Alternatively, use cert-checkkey: cert-checkkey ssl.crt ssl.key","title":"Compare Cert and Key"},{"location":"kanban_tickets/diagnostics/#compare-csr-and-key","text":"openssl req -noout -modulus -in ssl.csr | openssl md5; \\ openssl rsa -noout -modulus -in ssl.key | openssl md5","title":"Compare CSR and Key"},{"location":"kanban_tickets/diagnostics/#view-certificate-information","text":"To view the domains associated with a cert, the expiry dates, the certificate issuer and some other information: openssl x509 -in sitename.crt -noout -text","title":"View Certificate Information"},{"location":"kanban_tickets/diagnostics/#get-notbeforenotafter-expiration-date","text":"openssl x509 -in sitename.crt -noout -subject -dates e.g. $ openssl x509 -noout -subject -dates -in Downloads/luminary/NetworkSolutions_CA.crt subject= /C=US/O=Network Solutions L.L.C./CN=Network Solutions Certificate Authority notBefore=Apr 10 00:00:00 2006 GMT notAfter=May 30 10:48:38 2020 GMT OR for checking a series of certs for i in $(ls -1); do echo $i; openssl x509 -noout -subject -dates in $i; done","title":"Get notBefore/notAfter (Expiration) date"},{"location":"kanban_tickets/diagnostics/#services-over-ssl","text":"","title":"Services over SSL"},{"location":"kanban_tickets/diagnostics/#verify-certificate-chain","text":"openssl s_client -showcerts -connect www.domain.com:443 < /dev/null","title":"Verify Certificate Chain"},{"location":"kanban_tickets/diagnostics/#asynchronous-keys","text":"","title":"Asynchronous Keys"},{"location":"kanban_tickets/diagnostics/#get-public-key-from-private-key","text":"The public key is embedded in the private key which is why if someone has your private key you are so utterly hosed your face may end up on google and eventually on to a de-motivational meme. ssh-keygen -y -f /path/to/PRIVATE_KEY","title":"Get public key from private key"},{"location":"kanban_tickets/disable_tls_version/","text":"Disable TLS versions TLSv1.1 and TLSv1.0 are not supported anymore, so balancers and edge clusters configurations that force the use of TLSv1.2 were also deprecated. If you would like a more detailed overview of the edge tier, please see cloud edge docs here . The setting is managed by nginx.conf:ssl_security_policy fields key for the balancers and supports only one value today. The default policy applied is TLS-1-2-Ext-2018-06 , which includes only TLSv1.2.","title":"Disable TLS versions"},{"location":"kanban_tickets/disable_tls_version/#disable-tls-versions","text":"TLSv1.1 and TLSv1.0 are not supported anymore, so balancers and edge clusters configurations that force the use of TLSv1.2 were also deprecated. If you would like a more detailed overview of the edge tier, please see cloud edge docs here . The setting is managed by nginx.conf:ssl_security_policy fields key for the balancers and supports only one value today. The default policy applied is TLS-1-2-Ext-2018-06 , which includes only TLSv1.2.","title":"Disable TLS versions"},{"location":"kanban_tickets/duplicate_certificates/","text":"Duplicate Certificates Occasionally there is a need to use a wildcard or UCC certificate on more than one machine, but for security reasons it's best not to use the original certificate and key. One example of this is using the *.acquia.com certificate on several different internal or external sites. Digicert allows the duplication of wildcard or UCC certificates for domains using a separate CSR and key, that way if the duplicate certificate's key is ever compromised it can be revoked without having to re-issue the original. Important Note Our DigiCert account is upgraded recently where the new platform is called as CertCentral, hence please refer below Digicert Central UI confluence page for updated instructions: https://confluence.acquia.com/display/OE/DigiCert+-+CertCentral+UI How to Duplicate a Certificate Create a new CSR/key pair as described in Generating a Certificate Signing Request (CSR) Log into the DigiCert Management Console . On the My Orders tab, in the list of your current certificates, select the order number for the certificate that you want to duplicate. On the manage page, in the Reissue Actions section, click Get a Duplicate . In the Get A Duplicate Certificate-Step 1 window, in the Add CSR section , paste the CSR text, including the -----BEGIN NEW CERTIFICATE REQUEST----- and -----END NEW CERTIFICATE REQUEST----- tags in to the request form in the area provided. In the Select Your Server Software section, in the drop-down list select nginx . Click Proceed to Step 2. Review the details and click Process now . The duplicate certificate should automatically be issued within a few minutes. To see the duplicate certificate, refresh your browser. Inside your account, the most recent duplicate certificate is located closest to the bottom of the page for this order. Download and install the certificate to the requested server.","title":"Duplicate Certificates"},{"location":"kanban_tickets/duplicate_certificates/#duplicate-certificates","text":"Occasionally there is a need to use a wildcard or UCC certificate on more than one machine, but for security reasons it's best not to use the original certificate and key. One example of this is using the *.acquia.com certificate on several different internal or external sites. Digicert allows the duplication of wildcard or UCC certificates for domains using a separate CSR and key, that way if the duplicate certificate's key is ever compromised it can be revoked without having to re-issue the original.","title":"Duplicate Certificates"},{"location":"kanban_tickets/duplicate_certificates/#important-note","text":"Our DigiCert account is upgraded recently where the new platform is called as CertCentral, hence please refer below Digicert Central UI confluence page for updated instructions: https://confluence.acquia.com/display/OE/DigiCert+-+CertCentral+UI","title":"Important Note"},{"location":"kanban_tickets/duplicate_certificates/#how-to-duplicate-a-certificate","text":"Create a new CSR/key pair as described in Generating a Certificate Signing Request (CSR) Log into the DigiCert Management Console . On the My Orders tab, in the list of your current certificates, select the order number for the certificate that you want to duplicate. On the manage page, in the Reissue Actions section, click Get a Duplicate . In the Get A Duplicate Certificate-Step 1 window, in the Add CSR section , paste the CSR text, including the -----BEGIN NEW CERTIFICATE REQUEST----- and -----END NEW CERTIFICATE REQUEST----- tags in to the request form in the area provided. In the Select Your Server Software section, in the drop-down list select nginx . Click Proceed to Step 2. Review the details and click Process now . The duplicate certificate should automatically be issued within a few minutes. To see the duplicate certificate, refresh your browser. Inside your account, the most recent duplicate certificate is located closest to the bottom of the page for this order. Download and install the certificate to the requested server.","title":"How to Duplicate a Certificate"},{"location":"kanban_tickets/edge_cluster/","text":"Edge Cluster Edge Cluster represents a CloudFormation stack consisting of a Network Load Balancer at the front and balancer servers attached to the NLB Target Groups at the back of the stack (related to the incoming traffic flow). NLB is available in multiple Availability Zones through EIP addresses. Each Edge Cluster has at least two active AZs with enabled Cross-zone load balancing to guarantee availability if an AZ becomes unavailable. NLB determines how to route the traffic based on the selected algorithm. Available commands ah-edge lists all the currently available commands and their descriptions. Please refer to the ah-edge output as the most recent version of the Edge Cluster documentation. Describe available commands or one specific command ah-edge help [COMMAND] Create a new Edge Cluster ah-edge create-edge-cluster --availability-zones=one two --size=SIZE --vpc=VPC [--scheme internal] Supported sizes: 'edge1.medium'. Uses t3.medium instances. 'edge1.large'. Uses t3.large instances. 'edge1.xlarge'. Uses t3.xlarge instances. 'edge1.2xlarge'. Uses t3.2xlarge instances. An EdgeCluster exists in two Availability Zones. Scheme can be provided as an optional parameter, if it is not provided the edge cluster created will be internet facing. The other alternative value is internal . Internal edge clusters are not exposed on the internet and operate in a similar way to internal ELBs. Delete an Edge Cluster NOTE : Edge Cluster must be in Created state before deletion. Also check there should be no environments associated with the cluster. ah-edge delete-edge-cluster --uuid=UUID As of today we have a bug in cloudformation that prevent a graceful stack delete. So, one must be perseverant to delete the stack. Usually after a first try,the cluster may end up with STACK_DELETION_FAILED status. Sometimes with UPDATE_STACK_FAILED. Locate the error out task for deletion of edge cluster and restart it. ah-task list --where='description ~ %UUID%' ah-task restart [TASK_ID] Reset Failed Edge Cluster status ah-edge reset-failed-edge-cluster-state --uuid=UUID Force Edge Cluster stack update This is used when stack in AWS is bad. ah-edge force-edge-cluster-update --uuid=UUID Relaunching bals in an Edge Cluster Bals can be relaunched in an edge cluster one at a time or both using bal cluster workflow. ah-bal-cluster relaunch bal-xxxx bal-yyyy Notes : * Due to the way edge clusters are architected, sv-taskrelaunch or ah-server suspend/launch shouldn't be used in production . Page edge in case the workflow fails. Do not suspend bals in an edge cluster. * The ah-bal-cluster command option -V --vpc_id is ignored for edge clusters since it's elements can't be in different VPCs. View details of an existing Edge Cluster Go to master branch cd ../master bundle exec ./bin/ah-edge describe-edge-cluster --uuid=UUID Shows all the details of the specified Edge Cluster. status field shows the current status/state of an Edge Cluster. Available statuses are: ALLOCATED : initial state. CREATING_SUBNETS . Edge Cluster creation process, should not last more than 10 minutes. CREATING_STACK : Edge Cluster creation process, should not last more than 10 minutes. CREATED : Edge Cluster is up and running. Normal operation state. UPDATING_STACK : Indicates that Edge Cluster is currently updating its CloudFormation stack. Normal operation state. DELETING_STACK : Edge Cluster deletion process, should not last more than 10 minutes. DELETED : Edge Cluster has been deleted. View a list of Edge Clusters on the current realm ah-edge list-edge-clusters Returns a list of all the Edge Clusters (including deleted) on the current realm (stage) and their UUIDs. Add an environment to an existing Edge Cluster ah-edge add-environment-to-edge-cluster --environment-name=ENVIRONMENT_NAME --uuid=UUID After running this command, the environment will be added to a specified Edge Cluster and the environment's DNS records will be updated to point to the Edge Cluster's EIP addresses. Remove an environment from an existing Edge Cluster ah-edge remove-environment-from-edge-cluster --environment-name=ENVIRONMENT_NAME --uuid=UUID Removes the environment from a specified Edge Cluster and updates the environment's DNS records and all the cluster's balancer servers. Upsize bals in Edge Cluster Edge bals can be upsized to supported ami types mentioned above in this runbook.. ah-edge change-edge-cluster-server-size --size=SIZE --uuid=UUID NOTE: Above tool will give success result immediately. Please wait for both the edge bals to be upsized and relaunched to the new size. Please ensure that the state of the Edge Cluster must be CREATED post upsize. Increase an Edge Cluster capacity by doubling its number of servers. Cannot scale more than once ah-edge scale-up-edge-cluster --uuid=UUID This is analog of a Turbo button. Allows to scale an Edge Cluster horizontally by doubling the number of active balancers in each AZ. Edge Cluster automatically handles all the updates. Currently, there is no scale down functionality available. Important Due to a limitation in Juno, scale-up-edge-cluster shouldn't be used in production ** as any cluster without exactly two balancer servers will not be discoverable for new provisions. Please contact Cloud Edge team for any questions. Apply a tag to an Edge Cluster ah-edge tag-edge-cluster --tag=TAG --uuid=UUID Supported tags: shared shared_polaris shared_vpc shared_vpc_hipaa shared_vpc_pci activebal activebaldev activebalstg activebalprod activebalra ra_full Remove a tag from an Edge Cluster ah-edge untag-edge-cluster --tag=TAG --uuid=UUID Differentiate Edge Balancer from Legacy Balancer ah-server list BAL -c edge_cluster_uuid Returns uuid of edge cluster in case of edge balancer. Returns nil for all other servers including legacy balancers. Migrations Manual migration of a customer from a legacy bal pair to an Edge Cluster This section describes how to migrate a customer's environment from a legacy bal pair (not ELB) to an Edge Cluster without downtime. Initialize helper variables. ## CUSTOMER_ENVIRONMENT=site_name CUSTOMER_ENVIRONMENT= # CLUSTER_UUID=aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeeeee CLUSTER_UUID=edge_cluster_uuid # LEGACY_BAL_PAIR=bal-1,bal2 LEGACY_BAL_PAIR= Validate that the site doesn't have the ELB. If they have ELB, make sure to verify the things listed here site-elbdescribe ${CUSTOMER_ENVIRONMENT} Determine the Edge Cluster's public IP addresses. ah-edge describe-edge-cluster --uuid=${CLUSTER_UUID} IP addresses are listed in the eips section of the output. Add the environment to the Edge Cluster. ah-edge add-environment-to-edge-cluster --environment-name=${CUSTOMER_ENVIRONMENT} --uuid=${CLUSTER_UUID} Verify that DNS A records of the acquia-sites.com domain associated with the environment is pointing at the legacy bal pair and the Edge Cluster at the same time. Example (do not run this, use your domain instead): $ nslookup edge2.jackzuban.sites.ahdev.co Server: 8.8.8.8 Address: 8.8.8.8#53 Non-authoritative answer: Name: edge2.jackzuban.sites.ahdev.co Address: 54.164.34.8 Name: edge2.jackzuban.sites.ahdev.co Address: 100.25.108.248 Name: edge2.jackzuban.sites.ahdev.co Address: 3.214.77.49 Where 3.214.77.49 and 100.25.108.248 are IP addresses associated with the Edge Cluster, and 54.164.34.8 is an EIP associated with an active balancer on the legacy bal pair. Update environment's bare and non-bare domain DNS records (when no CNAME is configured). Important: Do this step only for domains that are not using CNAME that points to the environment's acquia-sites.com domain mentioned on the previous step. What to do? You need to communicate with the customer to update domain(s) A records to make sure that they are set to use Edge Cluster's IPs. For bare/apex domains: set A record round-robin to EIPs of NLB (IP addresses returned on the step 2). For Non-bare/apex domains: CNAME to environment's acquia-sites.com domain. Remove the environment from the legacy bal pair. ah-site bal remove ${CUSTOMER_ENVIRONMENT} --bals=${LEGACY_BAL_PAIR} Verify with a DNS tool (nslookup, dig) that the acquia-sites.com domain associated with the environment is pointing to the Edge Cluster's IP addresses only. Example (do not run this, use your domain instead): $ nslookup edge2.jackzuban.sites.ahdev.co Server: 8.8.8.8 Address: 8.8.8.8#53 Non-authoritative answer: Name: edge2.jackzuban.sites.ahdev.co Address: 3.214.77.49 Name: edge2.jackzuban.sites.ahdev.co Address: 100.25.108.248 Manual migration of a customer from an Edge Cluster to a Legacy Balancers This section describes how to migrate a customer's environment from an Edge Cluster to a legacy bal pair (not ELB) without downtime. Initialize helper variables. # CUSTOMER_ENVIRONMENT=site_name CUSTOMER_ENVIRONMENT= # CLUSTER_UUID=aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeeeee CLUSTER_UUID=edge_cluster_uuid # LEGACY_BAL_PAIR=bal-1,bal2 LEGACY_BAL_PAIR= Determine the Edge Cluster's public IP addresses. ah-edge describe-edge-cluster --uuid=${CLUSTER_UUID} IP addresses are listed in the eips section of the output. Add the environment to the legacy bal pair. ah-site bal add ${CUSTOMER_ENVIRONMENT} --bals=${LEGACY_BAL_PAIR} Verify that DNS A records of the acquia-sites.com domain associated with the environment is pointing at the legacy bal pair and the Edge Cluster at the same time. Example (do not run this, use your domain instead): $ nslookup edge2.jackzuban.sites.ahdev.co Server: 8.8.8.8 Address: 8.8.8.8#53 Non-authoritative answer: Name: edge2.jackzuban.sites.ahdev.co Address: 54.164.34.8 Name: edge2.jackzuban.sites.ahdev.co Address: 100.25.108.248 Name: edge2.jackzuban.sites.ahdev.co Address: 3.214.77.49 Where 3.214.77.49 and 100.25.108.248 are IP addresses associated with the Edge Cluster, and 54.164.34.8 is an IP associated with the legacy bal pair. Update environment's DNS records. You need to communicate with the customer to update bare and non-bare domain A records to make sure that they are set to use an active balancer's EIP on legacy bal pair. For bare/apex domains: set A record to point at active balancer's EIP. For Non-bare/apex domains: remove acquia-sites.com domain CNAME . Set A record to point at active balancer's EIP. Remove the environment from the Edge Cluster. ah-edge remove-environment-from-edge-cluster --environment-name=${CUSTOMER_ENVIRONMENT} --uuid=${CLUSTER_UUID} Verify with a DNS tool (nslookup, dig) that the acquia-sites.com domain associated with the environment is pointing to the active balancer's IP address. Example (do not run this, use your domain instead): $ nslookup edge2.jackzuban.sites.ahdev.co Server: 8.8.8.8 Address: 8.8.8.8#53 Non-authoritative answer: Name: edge2.jackzuban.sites.ahdev.co Address: 54.164.34.8 Handling Legacy to Edge migrations for customers with ELB If the site migrating from legacy to edge bals have ELB, then need to ensure the following thing before removing the Legacy bals completely: Customer has been informed that the ELB will be removed and they should not be pointing any domain to ELB URL. Also, verify this using the following commands: site-domainshost ${CUSTOMER_ENVIRONMENT} It may not work if there is CDN in use by customer - so please cross check with the ticket requester about it. In case of ELB, make sure the default $SITE.prod.acquia-sites.com domain is pointing to the EIP of NLB and not to the ELB URL: dig +short $SITE.prod.acquia-sites.com Take approval/confirmation from the ticket requestor to deprovision the ELB after migration.","title":"Edge Cluster"},{"location":"kanban_tickets/edge_cluster/#edge-cluster","text":"Edge Cluster represents a CloudFormation stack consisting of a Network Load Balancer at the front and balancer servers attached to the NLB Target Groups at the back of the stack (related to the incoming traffic flow). NLB is available in multiple Availability Zones through EIP addresses. Each Edge Cluster has at least two active AZs with enabled Cross-zone load balancing to guarantee availability if an AZ becomes unavailable. NLB determines how to route the traffic based on the selected algorithm.","title":"Edge Cluster"},{"location":"kanban_tickets/edge_cluster/#available-commands","text":"ah-edge lists all the currently available commands and their descriptions. Please refer to the ah-edge output as the most recent version of the Edge Cluster documentation.","title":"Available commands"},{"location":"kanban_tickets/edge_cluster/#describe-available-commands-or-one-specific-command","text":"ah-edge help [COMMAND]","title":"Describe available commands or one specific command"},{"location":"kanban_tickets/edge_cluster/#create-a-new-edge-cluster","text":"ah-edge create-edge-cluster --availability-zones=one two --size=SIZE --vpc=VPC [--scheme internal] Supported sizes: 'edge1.medium'. Uses t3.medium instances. 'edge1.large'. Uses t3.large instances. 'edge1.xlarge'. Uses t3.xlarge instances. 'edge1.2xlarge'. Uses t3.2xlarge instances. An EdgeCluster exists in two Availability Zones. Scheme can be provided as an optional parameter, if it is not provided the edge cluster created will be internet facing. The other alternative value is internal . Internal edge clusters are not exposed on the internet and operate in a similar way to internal ELBs.","title":"Create a new Edge Cluster"},{"location":"kanban_tickets/edge_cluster/#delete-an-edge-cluster","text":"NOTE : Edge Cluster must be in Created state before deletion. Also check there should be no environments associated with the cluster. ah-edge delete-edge-cluster --uuid=UUID As of today we have a bug in cloudformation that prevent a graceful stack delete. So, one must be perseverant to delete the stack. Usually after a first try,the cluster may end up with STACK_DELETION_FAILED status. Sometimes with UPDATE_STACK_FAILED. Locate the error out task for deletion of edge cluster and restart it. ah-task list --where='description ~ %UUID%' ah-task restart [TASK_ID]","title":"Delete an Edge Cluster"},{"location":"kanban_tickets/edge_cluster/#reset-failed-edge-cluster-status","text":"ah-edge reset-failed-edge-cluster-state --uuid=UUID","title":"Reset Failed Edge Cluster status"},{"location":"kanban_tickets/edge_cluster/#force-edge-cluster-stack-update","text":"This is used when stack in AWS is bad. ah-edge force-edge-cluster-update --uuid=UUID","title":"Force Edge Cluster stack update"},{"location":"kanban_tickets/edge_cluster/#relaunching-bals-in-an-edge-cluster","text":"Bals can be relaunched in an edge cluster one at a time or both using bal cluster workflow. ah-bal-cluster relaunch bal-xxxx bal-yyyy Notes : * Due to the way edge clusters are architected, sv-taskrelaunch or ah-server suspend/launch shouldn't be used in production . Page edge in case the workflow fails. Do not suspend bals in an edge cluster. * The ah-bal-cluster command option -V --vpc_id is ignored for edge clusters since it's elements can't be in different VPCs.","title":"Relaunching bals in an Edge Cluster"},{"location":"kanban_tickets/edge_cluster/#view-details-of-an-existing-edge-cluster","text":"Go to master branch cd ../master bundle exec ./bin/ah-edge describe-edge-cluster --uuid=UUID Shows all the details of the specified Edge Cluster. status field shows the current status/state of an Edge Cluster. Available statuses are: ALLOCATED : initial state. CREATING_SUBNETS . Edge Cluster creation process, should not last more than 10 minutes. CREATING_STACK : Edge Cluster creation process, should not last more than 10 minutes. CREATED : Edge Cluster is up and running. Normal operation state. UPDATING_STACK : Indicates that Edge Cluster is currently updating its CloudFormation stack. Normal operation state. DELETING_STACK : Edge Cluster deletion process, should not last more than 10 minutes. DELETED : Edge Cluster has been deleted.","title":"View details of an existing Edge Cluster"},{"location":"kanban_tickets/edge_cluster/#view-a-list-of-edge-clusters-on-the-current-realm","text":"ah-edge list-edge-clusters Returns a list of all the Edge Clusters (including deleted) on the current realm (stage) and their UUIDs.","title":"View a list of Edge Clusters on the current realm"},{"location":"kanban_tickets/edge_cluster/#add-an-environment-to-an-existing-edge-cluster","text":"ah-edge add-environment-to-edge-cluster --environment-name=ENVIRONMENT_NAME --uuid=UUID After running this command, the environment will be added to a specified Edge Cluster and the environment's DNS records will be updated to point to the Edge Cluster's EIP addresses.","title":"Add an environment to an existing Edge Cluster"},{"location":"kanban_tickets/edge_cluster/#remove-an-environment-from-an-existing-edge-cluster","text":"ah-edge remove-environment-from-edge-cluster --environment-name=ENVIRONMENT_NAME --uuid=UUID Removes the environment from a specified Edge Cluster and updates the environment's DNS records and all the cluster's balancer servers.","title":"Remove an environment from an existing Edge Cluster"},{"location":"kanban_tickets/edge_cluster/#upsize-bals-in-edge-cluster","text":"Edge bals can be upsized to supported ami types mentioned above in this runbook.. ah-edge change-edge-cluster-server-size --size=SIZE --uuid=UUID NOTE: Above tool will give success result immediately. Please wait for both the edge bals to be upsized and relaunched to the new size. Please ensure that the state of the Edge Cluster must be CREATED post upsize.","title":"Upsize bals in Edge Cluster"},{"location":"kanban_tickets/edge_cluster/#increase-an-edge-cluster-capacity-by-doubling-its-number-of-servers-cannot-scale-more-than-once","text":"ah-edge scale-up-edge-cluster --uuid=UUID This is analog of a Turbo button. Allows to scale an Edge Cluster horizontally by doubling the number of active balancers in each AZ. Edge Cluster automatically handles all the updates. Currently, there is no scale down functionality available.","title":"Increase an Edge Cluster capacity by doubling its number of servers. Cannot scale more than once"},{"location":"kanban_tickets/edge_cluster/#important","text":"Due to a limitation in Juno, scale-up-edge-cluster shouldn't be used in production ** as any cluster without exactly two balancer servers will not be discoverable for new provisions. Please contact Cloud Edge team for any questions.","title":"Important"},{"location":"kanban_tickets/edge_cluster/#apply-a-tag-to-an-edge-cluster","text":"ah-edge tag-edge-cluster --tag=TAG --uuid=UUID Supported tags: shared shared_polaris shared_vpc shared_vpc_hipaa shared_vpc_pci activebal activebaldev activebalstg activebalprod activebalra ra_full","title":"Apply a tag to an Edge Cluster"},{"location":"kanban_tickets/edge_cluster/#remove-a-tag-from-an-edge-cluster","text":"ah-edge untag-edge-cluster --tag=TAG --uuid=UUID","title":"Remove a tag from an Edge Cluster"},{"location":"kanban_tickets/edge_cluster/#differentiate-edge-balancer-from-legacy-balancer","text":"ah-server list BAL -c edge_cluster_uuid Returns uuid of edge cluster in case of edge balancer. Returns nil for all other servers including legacy balancers.","title":"Differentiate Edge Balancer from Legacy Balancer"},{"location":"kanban_tickets/edge_cluster/#migrations","text":"","title":"Migrations"},{"location":"kanban_tickets/edge_cluster/#manual-migration-of-a-customer-from-a-legacy-bal-pair-to-an-edge-cluster","text":"This section describes how to migrate a customer's environment from a legacy bal pair (not ELB) to an Edge Cluster without downtime. Initialize helper variables. ## CUSTOMER_ENVIRONMENT=site_name CUSTOMER_ENVIRONMENT= # CLUSTER_UUID=aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeeeee CLUSTER_UUID=edge_cluster_uuid # LEGACY_BAL_PAIR=bal-1,bal2 LEGACY_BAL_PAIR= Validate that the site doesn't have the ELB. If they have ELB, make sure to verify the things listed here site-elbdescribe ${CUSTOMER_ENVIRONMENT} Determine the Edge Cluster's public IP addresses. ah-edge describe-edge-cluster --uuid=${CLUSTER_UUID} IP addresses are listed in the eips section of the output. Add the environment to the Edge Cluster. ah-edge add-environment-to-edge-cluster --environment-name=${CUSTOMER_ENVIRONMENT} --uuid=${CLUSTER_UUID} Verify that DNS A records of the acquia-sites.com domain associated with the environment is pointing at the legacy bal pair and the Edge Cluster at the same time. Example (do not run this, use your domain instead): $ nslookup edge2.jackzuban.sites.ahdev.co Server: 8.8.8.8 Address: 8.8.8.8#53 Non-authoritative answer: Name: edge2.jackzuban.sites.ahdev.co Address: 54.164.34.8 Name: edge2.jackzuban.sites.ahdev.co Address: 100.25.108.248 Name: edge2.jackzuban.sites.ahdev.co Address: 3.214.77.49 Where 3.214.77.49 and 100.25.108.248 are IP addresses associated with the Edge Cluster, and 54.164.34.8 is an EIP associated with an active balancer on the legacy bal pair. Update environment's bare and non-bare domain DNS records (when no CNAME is configured). Important: Do this step only for domains that are not using CNAME that points to the environment's acquia-sites.com domain mentioned on the previous step. What to do? You need to communicate with the customer to update domain(s) A records to make sure that they are set to use Edge Cluster's IPs. For bare/apex domains: set A record round-robin to EIPs of NLB (IP addresses returned on the step 2). For Non-bare/apex domains: CNAME to environment's acquia-sites.com domain. Remove the environment from the legacy bal pair. ah-site bal remove ${CUSTOMER_ENVIRONMENT} --bals=${LEGACY_BAL_PAIR} Verify with a DNS tool (nslookup, dig) that the acquia-sites.com domain associated with the environment is pointing to the Edge Cluster's IP addresses only. Example (do not run this, use your domain instead): $ nslookup edge2.jackzuban.sites.ahdev.co Server: 8.8.8.8 Address: 8.8.8.8#53 Non-authoritative answer: Name: edge2.jackzuban.sites.ahdev.co Address: 3.214.77.49 Name: edge2.jackzuban.sites.ahdev.co Address: 100.25.108.248","title":"Manual migration of a customer from a legacy bal pair to an Edge Cluster"},{"location":"kanban_tickets/edge_cluster/#manual-migration-of-a-customer-from-an-edge-cluster-to-a-legacy-balancers","text":"This section describes how to migrate a customer's environment from an Edge Cluster to a legacy bal pair (not ELB) without downtime. Initialize helper variables. # CUSTOMER_ENVIRONMENT=site_name CUSTOMER_ENVIRONMENT= # CLUSTER_UUID=aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeeeee CLUSTER_UUID=edge_cluster_uuid # LEGACY_BAL_PAIR=bal-1,bal2 LEGACY_BAL_PAIR= Determine the Edge Cluster's public IP addresses. ah-edge describe-edge-cluster --uuid=${CLUSTER_UUID} IP addresses are listed in the eips section of the output. Add the environment to the legacy bal pair. ah-site bal add ${CUSTOMER_ENVIRONMENT} --bals=${LEGACY_BAL_PAIR} Verify that DNS A records of the acquia-sites.com domain associated with the environment is pointing at the legacy bal pair and the Edge Cluster at the same time. Example (do not run this, use your domain instead): $ nslookup edge2.jackzuban.sites.ahdev.co Server: 8.8.8.8 Address: 8.8.8.8#53 Non-authoritative answer: Name: edge2.jackzuban.sites.ahdev.co Address: 54.164.34.8 Name: edge2.jackzuban.sites.ahdev.co Address: 100.25.108.248 Name: edge2.jackzuban.sites.ahdev.co Address: 3.214.77.49 Where 3.214.77.49 and 100.25.108.248 are IP addresses associated with the Edge Cluster, and 54.164.34.8 is an IP associated with the legacy bal pair. Update environment's DNS records. You need to communicate with the customer to update bare and non-bare domain A records to make sure that they are set to use an active balancer's EIP on legacy bal pair. For bare/apex domains: set A record to point at active balancer's EIP. For Non-bare/apex domains: remove acquia-sites.com domain CNAME . Set A record to point at active balancer's EIP. Remove the environment from the Edge Cluster. ah-edge remove-environment-from-edge-cluster --environment-name=${CUSTOMER_ENVIRONMENT} --uuid=${CLUSTER_UUID} Verify with a DNS tool (nslookup, dig) that the acquia-sites.com domain associated with the environment is pointing to the active balancer's IP address. Example (do not run this, use your domain instead): $ nslookup edge2.jackzuban.sites.ahdev.co Server: 8.8.8.8 Address: 8.8.8.8#53 Non-authoritative answer: Name: edge2.jackzuban.sites.ahdev.co Address: 54.164.34.8","title":"Manual migration of a customer from an Edge Cluster to a Legacy Balancers"},{"location":"kanban_tickets/edge_cluster/#handling-legacy-to-edge-migrations-for-customers-with-elb","text":"If the site migrating from legacy to edge bals have ELB, then need to ensure the following thing before removing the Legacy bals completely: Customer has been informed that the ELB will be removed and they should not be pointing any domain to ELB URL. Also, verify this using the following commands: site-domainshost ${CUSTOMER_ENVIRONMENT} It may not work if there is CDN in use by customer - so please cross check with the ticket requester about it. In case of ELB, make sure the default $SITE.prod.acquia-sites.com domain is pointing to the EIP of NLB and not to the ELB URL: dig +short $SITE.prod.acquia-sites.com Take approval/confirmation from the ticket requestor to deprovision the ELB after migration.","title":"Handling Legacy to Edge migrations for customers with ELB"},{"location":"kanban_tickets/elb_creation/","text":"ELB Creation There are three use cases for adding an ELB to a site Self Service TLS/SSL cert management Better High Availability (using both bals instead of one) Scaling the bal tier horizontally Initialize Variables SITE= For Customers For Whom We Have The Cert and Key Download the cert and key from the bal: for file in {certs/acquia-sites_com.pem,private/acquia-sites_com.key}; do 2>/dev/null fssh $(ah-server list site:$SITE -w type=bal | head -n1) \\ \"sudo cat /etc/ssl/$file\" > ${OPSTMP}/${SITE}.${file##*.} done Split the cert into a cert and intermediate chain cert You will need to manually edit the resulting ${SITE}.pem file to split it into the identity cert and the chain. vim ${OPSTMP}/${SITE}.pem Write the identity cert to ${OPSTMP}/${SITE}.crt and the chain to ${OPSTMP}/${SITE}.ca Proceed with Self-Service SSL For Customers For Whom We Do Not Have The Cert and Key Some of our customers already handle SSL termination themselves, and others unfortunately do not use TLS to encrypt their traffic. In either case we won't have a cert for them. You will need to perform the self-service ssl procedure using a self-signed cert for both the ca and the identity cert. Generate the cert like this: openssl req -subj '/CN=self-signed.localhost/O=Acquia Inc/C=US' -new \\ -sha256 -newkey rsa:2048 -days 365 -nodes -x509 \\ -keyout ${OPSTMP}/${SITE}.key -out ${OPSTMP}/${SITE}.crt Proceed with Self-Service SSL","title":"ELB Creation"},{"location":"kanban_tickets/elb_creation/#elb-creation","text":"There are three use cases for adding an ELB to a site Self Service TLS/SSL cert management Better High Availability (using both bals instead of one) Scaling the bal tier horizontally","title":"ELB Creation"},{"location":"kanban_tickets/elb_creation/#initialize-variables","text":"SITE=","title":"Initialize Variables"},{"location":"kanban_tickets/elb_creation/#for-customers-for-whom-we-have-the-cert-and-key","text":"Download the cert and key from the bal: for file in {certs/acquia-sites_com.pem,private/acquia-sites_com.key}; do 2>/dev/null fssh $(ah-server list site:$SITE -w type=bal | head -n1) \\ \"sudo cat /etc/ssl/$file\" > ${OPSTMP}/${SITE}.${file##*.} done Split the cert into a cert and intermediate chain cert You will need to manually edit the resulting ${SITE}.pem file to split it into the identity cert and the chain. vim ${OPSTMP}/${SITE}.pem Write the identity cert to ${OPSTMP}/${SITE}.crt and the chain to ${OPSTMP}/${SITE}.ca Proceed with Self-Service SSL","title":"For Customers For Whom We Have The Cert and Key"},{"location":"kanban_tickets/elb_creation/#for-customers-for-whom-we-do-not-have-the-cert-and-key","text":"Some of our customers already handle SSL termination themselves, and others unfortunately do not use TLS to encrypt their traffic. In either case we won't have a cert for them. You will need to perform the self-service ssl procedure using a self-signed cert for both the ca and the identity cert. Generate the cert like this: openssl req -subj '/CN=self-signed.localhost/O=Acquia Inc/C=US' -new \\ -sha256 -newkey rsa:2048 -days 365 -nodes -x509 \\ -keyout ${OPSTMP}/${SITE}.key -out ${OPSTMP}/${SITE}.crt Proceed with Self-Service SSL","title":"For Customers For Whom We Do Not Have The Cert and Key"},{"location":"kanban_tickets/email_blacklist/","text":"Acquia Email Server Blacklist Removal Ops is currently subscribed to email notifications from a service called MXToolbox and a nodejs script is executed by Nagios on mon3.ops-mon-2.acquia.com. The script checks the MXToolbox api and checks if mail server is blacklisted or not and send it's status. More information can be found here MXToolbox monitors the \"reputation\" of an email server's FQDN on various spam filtering lists (otherwise known as PBLs or SBLs ). These lists are used by various email providers and email server operators to filter or block email messages attempting to be delivered by hosts listed by FQDN or IP in said lists. Note: Email alerts will go to the Operations team. However, the email team will handle the resolution of these issues. Operations should escalate such issues to the email team via email-service@acquia.pagerduty.com which will generate a PagerDuty alert for the email team. For more information please refer the Acquia Hosting Email Guide or the Email Service Confluence Page An example of a host being \"listed\" Below is an example of a host that has been added to a blacklist. List of mail servers according to realm Acquia Hosting Products (Managed Cloud, Devcloud, Gardens, Enterprise Gardens, and Network) all generate email for the purpose of account management, notifications, etc for hosted sites. In order to ensure delivery, we forward all email through a set of mail relays hosted by Rackspace and maintained by Operations. These relays only allow email from servers hosted by us. The following is a brief description of that mechanism. AH: Exim Smarthost Configuration Exim Puppet template in Fields is used to write out the mail config for all AH servers. Puppet mail manifest describes which mail relay a server will forward emails to depending on what stage it is in. Currently: acquiamail.acquia.com: nagios notification emails, catch-all acquiamail11.acquia.com: Devcloud acquiamail12.acquia.com: Managed Cloud acquiamail13.acquia.com: Drupal Gardens acquiamail14.acquia.com: WMG Enterprise Gardens acquiamail15.acquia.com: Pfizer Enterprise Gardens, Trex acquiamail16.acquia.com: Network Investigation Search JIRA and determine if an OP ticket has been filed for the alert (and if not, file a new one) Find out which product(s) is/are impacted. In the email (usually sent to ops@acquia.com) are links under the column \"Delisting Link\" that can be used to request delisting of the email host. Often information is provided on the PBL/SBL page that can provide clues as to which domain is responsible for the unsolicited email. If you are able to determine the domain, check out which site controls that domain: ah-site list domain:[domain.tld] Once you have found the site that controls it, log that information in the OP ticket SSH to the blacklisted acquiamail host ssh ${USER}@acquiamail[?].acquia.com Check /var/log/exim4/mainlog and any archived versions for messages relating to the domain.tld referenced in the spam listing/complaint egrep -i '[domain.tld]' /var/log/exim4/mainlog # OR zgrep -i '[domain.tld]' /var/log/exim4/mainlog* Record any failure messages on or around the timestamp of the listing in the Ops ticket Query the current exim queue for any messages that might be waiting to be delivered or are being returned to the domain as \"undeliverable\" or otherwise # Query for exim mail IDs outbound FROM the domain.tld exiqgrep -i -f '[domain.tld]' # Query for exim mail IDs inbound TO the domain.tld exiqgrep -i -r '[domain.tld]' If you have any message IDs, you can view the headers and the body of the message MAIL_ID= exim -Mvb ${MAIL_ID}; exim -Mvb ${MAIL_ID} A word of caution Do not, under any circumstances, release any information from any emails you are able to view using the above method. The information contained in many of these emails may be password resets, PII-related (Personally Identifiable Information), or possibly \"privileged\" information (doctor-patient, lawyer-client, etc.). All legal rights to privacy and security apply to Acquia systems, with exceptions into cases of criminal behavior or gross misconduct. Resolution File an SL ticket with details outlining the spam or malicious activity and link it back to the original OP. Also, update the Op ticket with Header and Body of the spam mail Find the servers for the site which are sending the spam or malicious emails and determine if the servers have EIP For each of the server that does not have an EIP, allocate EIP and attach to the respective server # REGION = ec2 region where the server resides # TYPE = 'classic' or 'vpc' without quotes ah-elastic-ip allocate $REGION $TYPE # EIP = ec2-classic/ec2-vpc eip allocated above # SERVER = server whose mail traffic is to be blocked at the impacted mail relay ah-elastic-ip add $EIP $SERVER Block each of allocated eip's on affected mail servers iptables -A INPUT -s x.x.x.x -p tcp --dport 25 -m comment --comment \"Dropping per SL-xxxx\" -j DROP Update the OP with the output of the above command Verify that connection is blocked from the webs by using telnet Request \"delisting\" from the original email notification from MXToolbox using the link(s) included in the email. Sometimes, you need to go to the respective Blacklisting site to request for a Delisting. Attaching an example of such example below. Once delisting occurs, another email will be dispatched from MXToolbox notifying Ops of the change:","title":"Acquia Email Server Blacklist Removal"},{"location":"kanban_tickets/email_blacklist/#acquia-email-server-blacklist-removal","text":"Ops is currently subscribed to email notifications from a service called MXToolbox and a nodejs script is executed by Nagios on mon3.ops-mon-2.acquia.com. The script checks the MXToolbox api and checks if mail server is blacklisted or not and send it's status. More information can be found here MXToolbox monitors the \"reputation\" of an email server's FQDN on various spam filtering lists (otherwise known as PBLs or SBLs ). These lists are used by various email providers and email server operators to filter or block email messages attempting to be delivered by hosts listed by FQDN or IP in said lists. Note: Email alerts will go to the Operations team. However, the email team will handle the resolution of these issues. Operations should escalate such issues to the email team via email-service@acquia.pagerduty.com which will generate a PagerDuty alert for the email team. For more information please refer the Acquia Hosting Email Guide or the Email Service Confluence Page","title":"Acquia Email Server Blacklist Removal"},{"location":"kanban_tickets/email_blacklist/#an-example-of-a-host-being-listed","text":"Below is an example of a host that has been added to a blacklist.","title":"An example of a host being \"listed\""},{"location":"kanban_tickets/email_blacklist/#list-of-mail-servers-according-to-realm","text":"Acquia Hosting Products (Managed Cloud, Devcloud, Gardens, Enterprise Gardens, and Network) all generate email for the purpose of account management, notifications, etc for hosted sites. In order to ensure delivery, we forward all email through a set of mail relays hosted by Rackspace and maintained by Operations. These relays only allow email from servers hosted by us. The following is a brief description of that mechanism. AH: Exim Smarthost Configuration Exim Puppet template in Fields is used to write out the mail config for all AH servers. Puppet mail manifest describes which mail relay a server will forward emails to depending on what stage it is in. Currently: acquiamail.acquia.com: nagios notification emails, catch-all acquiamail11.acquia.com: Devcloud acquiamail12.acquia.com: Managed Cloud acquiamail13.acquia.com: Drupal Gardens acquiamail14.acquia.com: WMG Enterprise Gardens acquiamail15.acquia.com: Pfizer Enterprise Gardens, Trex acquiamail16.acquia.com: Network","title":"List of mail servers according to realm"},{"location":"kanban_tickets/email_blacklist/#investigation","text":"Search JIRA and determine if an OP ticket has been filed for the alert (and if not, file a new one) Find out which product(s) is/are impacted. In the email (usually sent to ops@acquia.com) are links under the column \"Delisting Link\" that can be used to request delisting of the email host. Often information is provided on the PBL/SBL page that can provide clues as to which domain is responsible for the unsolicited email. If you are able to determine the domain, check out which site controls that domain: ah-site list domain:[domain.tld] Once you have found the site that controls it, log that information in the OP ticket SSH to the blacklisted acquiamail host ssh ${USER}@acquiamail[?].acquia.com Check /var/log/exim4/mainlog and any archived versions for messages relating to the domain.tld referenced in the spam listing/complaint egrep -i '[domain.tld]' /var/log/exim4/mainlog # OR zgrep -i '[domain.tld]' /var/log/exim4/mainlog* Record any failure messages on or around the timestamp of the listing in the Ops ticket Query the current exim queue for any messages that might be waiting to be delivered or are being returned to the domain as \"undeliverable\" or otherwise # Query for exim mail IDs outbound FROM the domain.tld exiqgrep -i -f '[domain.tld]' # Query for exim mail IDs inbound TO the domain.tld exiqgrep -i -r '[domain.tld]' If you have any message IDs, you can view the headers and the body of the message MAIL_ID= exim -Mvb ${MAIL_ID}; exim -Mvb ${MAIL_ID}","title":"Investigation"},{"location":"kanban_tickets/email_blacklist/#a-word-of-caution","text":"Do not, under any circumstances, release any information from any emails you are able to view using the above method. The information contained in many of these emails may be password resets, PII-related (Personally Identifiable Information), or possibly \"privileged\" information (doctor-patient, lawyer-client, etc.). All legal rights to privacy and security apply to Acquia systems, with exceptions into cases of criminal behavior or gross misconduct.","title":"A word of caution"},{"location":"kanban_tickets/email_blacklist/#resolution","text":"File an SL ticket with details outlining the spam or malicious activity and link it back to the original OP. Also, update the Op ticket with Header and Body of the spam mail Find the servers for the site which are sending the spam or malicious emails and determine if the servers have EIP For each of the server that does not have an EIP, allocate EIP and attach to the respective server # REGION = ec2 region where the server resides # TYPE = 'classic' or 'vpc' without quotes ah-elastic-ip allocate $REGION $TYPE # EIP = ec2-classic/ec2-vpc eip allocated above # SERVER = server whose mail traffic is to be blocked at the impacted mail relay ah-elastic-ip add $EIP $SERVER Block each of allocated eip's on affected mail servers iptables -A INPUT -s x.x.x.x -p tcp --dport 25 -m comment --comment \"Dropping per SL-xxxx\" -j DROP Update the OP with the output of the above command Verify that connection is blocked from the webs by using telnet Request \"delisting\" from the original email notification from MXToolbox using the link(s) included in the email. Sometimes, you need to go to the respective Blacklisting site to request for a Delisting. Attaching an example of such example below. Once delisting occurs, another email will be dispatched from MXToolbox notifying Ops of the change:","title":"Resolution"},{"location":"kanban_tickets/enabling_mod_proxy/","text":"Enabling Mod-Proxy on a Site This procedure is for enabling Apache mod_proxy on site. Required Information Server Name (mod_proxy must only be on webnodes) proxy config (most likely sslgeneric) Procedure ah-server edit $SERVER -c puppet:mod_proxy=add ah-server edit $SERVER -c puppet:proxy_config=sslgeneric Documentation Apache's Mod_Proxy Doc Mod_Proxy Wikipedia page Custom proxy.conf file If the customer also needs a custom proxy.conf file please jump to add custom proxy.conf and follow up there.","title":"Enabling Mod-Proxy on a Site"},{"location":"kanban_tickets/enabling_mod_proxy/#enabling-mod-proxy-on-a-site","text":"This procedure is for enabling Apache mod_proxy on site.","title":"Enabling Mod-Proxy on a Site"},{"location":"kanban_tickets/enabling_mod_proxy/#required-information","text":"Server Name (mod_proxy must only be on webnodes) proxy config (most likely sslgeneric)","title":"Required Information"},{"location":"kanban_tickets/enabling_mod_proxy/#procedure","text":"ah-server edit $SERVER -c puppet:mod_proxy=add ah-server edit $SERVER -c puppet:proxy_config=sslgeneric","title":"Procedure"},{"location":"kanban_tickets/enabling_mod_proxy/#documentation","text":"Apache's Mod_Proxy Doc Mod_Proxy Wikipedia page","title":"Documentation"},{"location":"kanban_tickets/enabling_mod_proxy/#custom-proxyconf-file","text":"If the customer also needs a custom proxy.conf file please jump to add custom proxy.conf and follow up there.","title":"Custom proxy.conf file"},{"location":"kanban_tickets/enabling_xdebug/","text":"Enabling xdebug for a Site This procedure is for enabling PHP xdebug extension for a site Required Information Sitename Procedure Enabling Xdebug The path to 'xdebug.so' depends on the version of PHP used by the site. PHP Flavour Path to xdebug.so Acquia PHP /usr/local/php${VERSION}/lib/php/extensions/xdebug.so Stock PHP /usr/lib/php5/20090626/xdebug.so SITENAME=<sitename> PHP_PATH=$(ah-site list $SITENAME -c \\ php:php-path --no-name| \\ cut -d'/' -f1-4)/lib/php/extensions/xdebug.so ah-site edit $SITENAME --config \\ php.ini:zend_extension=$PHP_PATH \\ php.ini:xdebug.profiler_output_dir=/mnt/tmp/$SITENAME/ \\ php.ini:xdebug.profiler_enable_trigger=1 \\ php.ini:xdebug.profiler_output_name=xdebug.out.%p.%r Enabling Xdebug Remote Xdebug remote allows users to debug their cloud site remotely. ah-site edit $SITENAME -c \\ php.ini:xdebug.remote_enable=1 \\ php.ini:xdebug.remote_host=localhost \\ php.ini:xdebug.remote_port=9000 The port may differ, although 9000 is selected as the default in most instances. Documentation XDEBUG EXTENSION FOR PHP","title":"Enabling xdebug for a Site"},{"location":"kanban_tickets/enabling_xdebug/#enabling-xdebug-for-a-site","text":"This procedure is for enabling PHP xdebug extension for a site","title":"Enabling xdebug for a Site"},{"location":"kanban_tickets/enabling_xdebug/#required-information","text":"Sitename","title":"Required Information"},{"location":"kanban_tickets/enabling_xdebug/#procedure","text":"","title":"Procedure"},{"location":"kanban_tickets/enabling_xdebug/#enabling-xdebug","text":"The path to 'xdebug.so' depends on the version of PHP used by the site. PHP Flavour Path to xdebug.so Acquia PHP /usr/local/php${VERSION}/lib/php/extensions/xdebug.so Stock PHP /usr/lib/php5/20090626/xdebug.so SITENAME=<sitename> PHP_PATH=$(ah-site list $SITENAME -c \\ php:php-path --no-name| \\ cut -d'/' -f1-4)/lib/php/extensions/xdebug.so ah-site edit $SITENAME --config \\ php.ini:zend_extension=$PHP_PATH \\ php.ini:xdebug.profiler_output_dir=/mnt/tmp/$SITENAME/ \\ php.ini:xdebug.profiler_enable_trigger=1 \\ php.ini:xdebug.profiler_output_name=xdebug.out.%p.%r","title":"Enabling Xdebug"},{"location":"kanban_tickets/enabling_xdebug/#enabling-xdebug-remote","text":"Xdebug remote allows users to debug their cloud site remotely. ah-site edit $SITENAME -c \\ php.ini:xdebug.remote_enable=1 \\ php.ini:xdebug.remote_host=localhost \\ php.ini:xdebug.remote_port=9000 The port may differ, although 9000 is selected as the default in most instances.","title":"Enabling Xdebug Remote"},{"location":"kanban_tickets/enabling_xdebug/#documentation","text":"XDEBUG EXTENSION FOR PHP","title":"Documentation"},{"location":"kanban_tickets/extended_validation_certificates/","text":"Extended Validation Certificates An Extended Validation (EV) certificate is similar to a UCC, but with extra steps and checks. TODO: Document the steps to obtain an EV certificate.","title":"Extended Validation Certificates"},{"location":"kanban_tickets/extended_validation_certificates/#extended-validation-certificates","text":"An Extended Validation (EV) certificate is similar to a UCC, but with extra steps and checks. TODO: Document the steps to obtain an EV certificate.","title":"Extended Validation Certificates"},{"location":"kanban_tickets/fix_livedev/","text":"Fixing/Enabling livedev Sometimes, the customer will be unable to enable LiveDev in their development/ staging envrionment. The customer issues a task via the front end and the magic happens but sometimes the magic fails miserably. In all cases seen so far, support will have been contacted by the customer and a Sev 1 OP will have been opened. The error means that there has been an issue with the permissions of the livedev dir at /mnt/gfs/sitename.env/livedev/ have been incorrectly set or is missing. Identify the error ah-task get $TASK_ID Ensure that you have identified the error which signifies the issue with enabling livedev. You will always see the following in the output: chmod: changing permissions of `/mnt/gfs/sitename.env/livedev/some/path/to/stuff': No such file or directory Remediation The easiest solution is to log into the affected server and recreate the livedev directory then restart the task. The livedir path can be found in the error output of the task. Sometimes, you may notice that there may be an issue with the gluster mount. This can be usually resolved by running sv-fsremount $SERVER . If there is a deeper issue, consult the gluster docs in this runbook to remediate and restore livedev","title":"Fixing/Enabling livedev"},{"location":"kanban_tickets/fix_livedev/#fixingenabling-livedev","text":"Sometimes, the customer will be unable to enable LiveDev in their development/ staging envrionment. The customer issues a task via the front end and the magic happens but sometimes the magic fails miserably. In all cases seen so far, support will have been contacted by the customer and a Sev 1 OP will have been opened. The error means that there has been an issue with the permissions of the livedev dir at /mnt/gfs/sitename.env/livedev/ have been incorrectly set or is missing.","title":"Fixing/Enabling livedev"},{"location":"kanban_tickets/fix_livedev/#identify-the-error","text":"ah-task get $TASK_ID Ensure that you have identified the error which signifies the issue with enabling livedev. You will always see the following in the output: chmod: changing permissions of `/mnt/gfs/sitename.env/livedev/some/path/to/stuff': No such file or directory","title":"Identify the error"},{"location":"kanban_tickets/fix_livedev/#remediation","text":"The easiest solution is to log into the affected server and recreate the livedev directory then restart the task. The livedir path can be found in the error output of the task. Sometimes, you may notice that there may be an issue with the gluster mount. This can be usually resolved by running sv-fsremount $SERVER . If there is a deeper issue, consult the gluster docs in this runbook to remediate and restore livedev","title":"Remediation"},{"location":"kanban_tickets/generating_csrs/","text":"Generating a Certificate Signing Request (CSR) A certificate signing request (CSR) is a file that contains a subject and public key and is used by a certificate vendor to generate a certificate. It is typically generated along with a private key, but can also be generated to match an existing private key. IMPORTANT : Please store any CSR/Key pair you generate in the Ops KeePassX vault! If you are unsure as to how to store your newly-generated pair, please consult another Ops member. Subject The following information is included in CSR or cert subject. For shared UCC certs (and Acquia-owned sites such as www.acquia.com ), the details are Acquia's. For certs dedicated to one customer, the details come from that customer via Support, Account Management, or the ticket submitter. Details not listed should be omitted. Code Name Acquia details C Country (two-letter code) US ST State or province name Massachusetts L Locality name Boston O Organization name Acquia Inc. OU Organizational unit Acquia Hosting CN Common name www.example.com The common name is the domain being secured, for example www.example.com . On UCCs, it will be the first domain being secured. The rest are specified during the certificate ordering process. SSL Plus/EV CSR Generation Procedure Run the following command to generate a new private key and CSR. It will prompt for the information to be put on the CSR. openssl req -nodes -sha256 -newkey rsa:2048 -keyout sitename.key -out sitename.csr To specify all of your details in the command, use the -subj flag and the following example syntax: openssl req -nodes -sha256 -newkey rsa:2048 -keyout sitename.key \\ -out sitename.csr -subj \"/C=US/ST=Massachusetts/L=Boston/O=Acquia Inc.\\ /OU=Acquia Hosting/CN=www.example.com\" You can name the files anything and put them anywhere, but it makes the most sense to name them after the site ( ssl_$CUSTOMER_IDENTIFIER ) and put them within your home directory on a bastion. Always generate RSA keys which are 2048bits or larger . Wildcard Plus CSR Generation The procedure is the same as above. Use an asterisk in the CN, such as *.example.com . UCC/EV Multi-Domain CSR Generation openssl has no options for specifying subject alternative names (SANs) via the command line as needed for CSRs for UCCs, so a configuration file must be used instead. In the directory where you run openssl, create a file with the following contents: [req] default_bits = 2048 default_keyfile = key.key distinguished_name = req_distinguished_name req_extensions = req_ext [req_distinguished_name] countryName = Country Name (2 letter code) countryName_default = US stateOrProvinceName = State or Province Name (full name) stateOrProvinceName_default = Massachusetts localityName = Locality Name (eg, city) localityName_default = Boston organizationName = Organization Name (eg, company) organizationName_default = Acquia Inc. organizationalUnitName = Organizational Unit (eg, department) organizationalUnitName_default = Acquia Hosting commonName = Common Name (eg, YOUR name) commonName_max = 64 [req_ext] subjectAltName = @alt_names [alt_names] DNS.1 = www.example.com DNS.2 = example.com DNS.3 = herpetology.example.com In the [alt_names] section at the bottom of the config, list the domains to be included in the CSR. Do not change any of the other sections. Run openssl with the -config option, specifying the file you created above. It will prompt for details for the CSR as usual and also include the domains listed in the file. The name and size of the private key will also be read from the file. openssl req -nodes -new -out sitename.csr -config sitename.conf Using an existing key for UCC CSR Generation If a new UCC CSR needs to be generated against an existing private key, run the following command where key.key is the existing private key. openssl req -nodes -new -out sitename.csr -config sitename.conf -key key.key UCC CSR Generation Example [hosting-prod:prod] ~/certs/ucctutorial$ ls example.conf [hosting-prod:prod] ~/certs/ucctutorial$ openssl req -nodes -new \\ -out example.csr -config example.conf Generating a 2048 bit RSA private key ...........................................................+++ .............................................................................+++ writing new private key to 'private_key.pem' ----- You are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter '.', the field will be left blank. ----- Country Name (2 letter code) [US]:US State or Province Name (full name) [Massachusetts]:Massachusetts Locality Name (eg, city) [Boston]:Boston Organization Name (eg, company) [Acquia Inc.]:Acquia Inc. Organizational Unit (eg, department) [Operations]:Acquia Hosting Common Name (eg, YOUR name) []:www.example.com [hosting-prod:prod] ~/certs/ucctutorial$ ls example.csr example.pem example.conf [hosting-prod:prod] ~/certs/ucctutorial$ openssl req -noout -text -in example.csr Certificate Request: Data: Version: 0 (0x0) Subject: C=US, ST=Massachusetts, L=Boston, O=Acquia Inc., OU=Acquia \\ Hosting, CN=www.example.com Subject Public Key Info: Public Key Algorithm: rsaEncryption RSA Public Key: (2048 bit) ... Attributes: Requested Extensions: X509v3 Subject Alternative Name: DNS:www.example.com, DNS:example.com, DNS:herpetology.example.com ...","title":"Generating a Certificate Signing Request (CSR)"},{"location":"kanban_tickets/generating_csrs/#generating-a-certificate-signing-request-csr","text":"A certificate signing request (CSR) is a file that contains a subject and public key and is used by a certificate vendor to generate a certificate. It is typically generated along with a private key, but can also be generated to match an existing private key. IMPORTANT : Please store any CSR/Key pair you generate in the Ops KeePassX vault! If you are unsure as to how to store your newly-generated pair, please consult another Ops member.","title":"Generating a Certificate Signing Request (CSR)"},{"location":"kanban_tickets/generating_csrs/#subject","text":"The following information is included in CSR or cert subject. For shared UCC certs (and Acquia-owned sites such as www.acquia.com ), the details are Acquia's. For certs dedicated to one customer, the details come from that customer via Support, Account Management, or the ticket submitter. Details not listed should be omitted. Code Name Acquia details C Country (two-letter code) US ST State or province name Massachusetts L Locality name Boston O Organization name Acquia Inc. OU Organizational unit Acquia Hosting CN Common name www.example.com The common name is the domain being secured, for example www.example.com . On UCCs, it will be the first domain being secured. The rest are specified during the certificate ordering process.","title":"Subject"},{"location":"kanban_tickets/generating_csrs/#ssl-plusev-csr-generation-procedure","text":"Run the following command to generate a new private key and CSR. It will prompt for the information to be put on the CSR. openssl req -nodes -sha256 -newkey rsa:2048 -keyout sitename.key -out sitename.csr To specify all of your details in the command, use the -subj flag and the following example syntax: openssl req -nodes -sha256 -newkey rsa:2048 -keyout sitename.key \\ -out sitename.csr -subj \"/C=US/ST=Massachusetts/L=Boston/O=Acquia Inc.\\ /OU=Acquia Hosting/CN=www.example.com\" You can name the files anything and put them anywhere, but it makes the most sense to name them after the site ( ssl_$CUSTOMER_IDENTIFIER ) and put them within your home directory on a bastion. Always generate RSA keys which are 2048bits or larger .","title":"SSL Plus/EV CSR Generation Procedure"},{"location":"kanban_tickets/generating_csrs/#wildcard-plus-csr-generation","text":"The procedure is the same as above. Use an asterisk in the CN, such as *.example.com .","title":"Wildcard Plus CSR Generation"},{"location":"kanban_tickets/generating_csrs/#uccev-multi-domain-csr-generation","text":"openssl has no options for specifying subject alternative names (SANs) via the command line as needed for CSRs for UCCs, so a configuration file must be used instead. In the directory where you run openssl, create a file with the following contents: [req] default_bits = 2048 default_keyfile = key.key distinguished_name = req_distinguished_name req_extensions = req_ext [req_distinguished_name] countryName = Country Name (2 letter code) countryName_default = US stateOrProvinceName = State or Province Name (full name) stateOrProvinceName_default = Massachusetts localityName = Locality Name (eg, city) localityName_default = Boston organizationName = Organization Name (eg, company) organizationName_default = Acquia Inc. organizationalUnitName = Organizational Unit (eg, department) organizationalUnitName_default = Acquia Hosting commonName = Common Name (eg, YOUR name) commonName_max = 64 [req_ext] subjectAltName = @alt_names [alt_names] DNS.1 = www.example.com DNS.2 = example.com DNS.3 = herpetology.example.com In the [alt_names] section at the bottom of the config, list the domains to be included in the CSR. Do not change any of the other sections. Run openssl with the -config option, specifying the file you created above. It will prompt for details for the CSR as usual and also include the domains listed in the file. The name and size of the private key will also be read from the file. openssl req -nodes -new -out sitename.csr -config sitename.conf","title":"UCC/EV Multi-Domain CSR Generation"},{"location":"kanban_tickets/generating_csrs/#using-an-existing-key-for-ucc-csr-generation","text":"If a new UCC CSR needs to be generated against an existing private key, run the following command where key.key is the existing private key. openssl req -nodes -new -out sitename.csr -config sitename.conf -key key.key","title":"Using an existing key for UCC CSR Generation"},{"location":"kanban_tickets/generating_csrs/#ucc-csr-generation-example","text":"[hosting-prod:prod] ~/certs/ucctutorial$ ls example.conf [hosting-prod:prod] ~/certs/ucctutorial$ openssl req -nodes -new \\ -out example.csr -config example.conf Generating a 2048 bit RSA private key ...........................................................+++ .............................................................................+++ writing new private key to 'private_key.pem' ----- You are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter '.', the field will be left blank. ----- Country Name (2 letter code) [US]:US State or Province Name (full name) [Massachusetts]:Massachusetts Locality Name (eg, city) [Boston]:Boston Organization Name (eg, company) [Acquia Inc.]:Acquia Inc. Organizational Unit (eg, department) [Operations]:Acquia Hosting Common Name (eg, YOUR name) []:www.example.com [hosting-prod:prod] ~/certs/ucctutorial$ ls example.csr example.pem example.conf [hosting-prod:prod] ~/certs/ucctutorial$ openssl req -noout -text -in example.csr Certificate Request: Data: Version: 0 (0x0) Subject: C=US, ST=Massachusetts, L=Boston, O=Acquia Inc., OU=Acquia \\ Hosting, CN=www.example.com Subject Public Key Info: Public Key Algorithm: rsaEncryption RSA Public Key: (2048 bit) ... Attributes: Requested Extensions: X509v3 Subject Alternative Name: DNS:www.example.com, DNS:example.com, DNS:herpetology.example.com ...","title":"UCC CSR Generation Example"},{"location":"kanban_tickets/gluster-downgrade/","text":"Downgrade Gluster Version from 3.4 to 3.0 THIS PROCESS SHOULD BE USED ONLY ON GLUSTER 3.4 SERVERS It may be necessary to downgrade a filesystem stack running 3.4 to 3.0 if recommended by Cloud Data Team. This process will involve an approximate downtime of 30 minutes. Initial Variables JIRA_TICKET= USER= Info Gathering FS Servers mentioned above refers to the filesystem servers in the stack. If you have sitename, you can query for fs servers using below command to find the filesystem servers in the stack SITE= esl2 ${SITE} From the tool output, Pick the filesystem servers in the stack serving the above site and assign the below values: OLD_FS1= OLD_FS2= Gather volume information attached to the filesystem servers using the command sv-vollist ${OLD_FS1} sv-vollist ${OLD_FS2} FS_SIZE= EBS_TYPE= Volume size and ebs volume type should be read from the output of the volume info command unless customer is approved for an upsize. The values should be referred corresponding to /dev/xvdo device. Provision new FS servers and fix volumes It would be ideal to move the filesystem data from like-for-like servers. For example, if the site is currently served by fsdb/ded, it is suggested to move them to fsdb/ded. Similarly site served by fs server type should be moved to fs type. All other variables required for new filesystem server launches should depend on the customer's existing hardware. esl2 ${SITE} From the above command output we need to pick the VPC_ID for the associated webs to bring up filesystem servers also in the same vpc. SERVER_TYPE= INSTANCE_TYPE= AZ1= AZ2= REGION= VPC_ID= Allocate new FS servers FS1=$(ah-server allocate ${SERVER_TYPE} \\ --ami-type ${INSTANCE_TYPE} \\ --region ${REGION} \\ --avail-zone ${AZ1} \\ --vpc-id ${VPC_ID} \\ --secondary-volume-size ${FS_SIZE} --pe --se) FS2=$(ah-server allocate ${SERVER_TYPE} \\ --ami-type ${INSTANCE_TYPE} \\ --region ${REGION} \\ --avail-zone ${AZ2} \\ --vpc-id ${VPC_ID} \\ --secondary-volume-size ${FS_SIZE} --pe --se) Successful execution of the commands should return server names for echo $FS1 $FS2 . Add brick volumes ah-volume add-brick --server ${FS1} --device /dev/xvdo --size ${FS_SIZE} \\ --ebs-volume-type ${EBS_TYPE} --set-encrypted ah-volume add-brick --server ${FS2} --device /dev/xvdo --size ${FS_SIZE} \\ --ebs-volume-type ${EBS_TYPE} --set-encrypted Successful execution of the commands should return Brick IDs. Configure FS servers for gluster 3.0 GLUSTER_VERSION=3.0 ah-server edit ${FS1},${FS2} -c puppet:gluster_version=${GLUSTER_VERSION} Successful execution of the command should set puppet:gluster_version config with the GLUSTER_VERSION value. Allocate FS cluster ./fields-provision.php --fs-cluster-allocate ${SITE}_$(date +%s):${FS1},${FS2} Successful execution of the command should return FS cluster name. Fix backup vol on secondary server to 1gb Of the two servers launched, highest numbered server will be called as secondary server. Backups are run and saved only on primary server on our platform. For that reason, backup volume on secondary server goes unused. We can save AWS cost by editing the backup volume on secondary server to 1gb. sv-vollist ${FS2} Pick the volume ID corresponding to the /vol/backup-ebs/(/dev/xvdn) device to modify. FS2_BACKUP_VOL_ID= ah-volume edit ${FS2_BACKUP_VOL_ID} -s size=1 Successful execution of the command should modify the volume size. Fix ebs1 volumes on both servers to 1gb This step is only applicable if ${FS1} and ${FS2} are fs server type. This change is also to save AWS cost for the unused volume resource. sv-vollist ${FS1} sv-vollist ${FS2} FS1_EBS_VOL_ID= FS2_EBS_VOL_ID= ah-volume edit ${FS1_EBS_VOL_ID} -s size=1 ah-volume edit ${FS2_EBS_VOL_ID} -s size=1 Launch FS Servers sv-taskrelaunch server -m1 ${FS1} ${FS2} Successful execution of the command should trigger a task for each of the servers to be launched and return the tasks state as done with successful server launches. Filesystem Data Transfer Create Temporary SSH key We need to create a ssh keypair on ${OLD_FS1} and copy the public key to authorized keys on ${FS1}. This will enable us to establish a rsync connection for data transfer. fssh ${OLD_FS1} \"sudo ssh-keygen -b 2048 -f /root/.ssh/${JIRA_TICKET}; \\ sudo cat /root/.ssh/${JIRA_TICKET}.pub\" You need to manual specify the value of ${JIRA_TICKET} as we are inside the server. The above command execution will prompt for passphrase which is optional. You can specify a passphrase or press enter key to skip. Surgically insert the public key, CAREFULLY, in to the authorized keys file on the ${FS1} server. fssh ${FS1} sudo su - vim /root/.ssh/authorized_keys2 Paste in the contents of the pub key inclusive of \"ssh-rsa\" and the server hostname including the server hostname makes it obvious to other Ops people that the key was a temporary one. rsync from source server to destination server This step involves rsyncing the data from ${OLD_FS1} to ${FS1}. FS1_FQHN=$(fqual ${FS1}) fssh ${OLD_FS1} sudo su - JIRA_TICKET= screen -mS ${JIRA_TICKET} FS1_FQHN= JIRA_TICKET= rsync -avPe \"ssh -i /root/.ssh/${JIRA_TICKET}\" --exclude=.glusterfs \\ /mnt/brick*/brick/ ${FS1_FQHN}:/mnt/gfs/ Successful execution of the rsync command will start the data transfer and the time for completion will depend on the amount of data we are trying to transfer. In another terminal window, we can watch the progress of data transfer on ${FS1} fssh ${FS1} sudo su - watch 'df -h /mnt/gfs' Once the transfer has completed, run a second rsync to ensure that any new data created on the brick gets transferred to ${FS1} server. fssh ${OLD_FS1} sudo su - JIRA_TICKET= screen -mS ${JIRA_TICKET} FS1_FQHN= JIRA_TICKET= rsync -avPe --delete \"ssh -i /root/.ssh/${JIRA_TICKET}\" --exclude=.glusterfs \\ /mnt/brick*/brick/ ${FS1_FQHN}:/mnt/gfs/ Web servers cutover This process involves pointing the web servers serving the site to point to newly created filesystem servers. This process involves downtime as we will take webs out of rotation. After this point the site will be down. Ping ops hotseat person about the site downtime alert. At any point if ops were to abort the cutover process, ops person should undo all the steps that were done until that point. Take webs out of rotation WEBS=$(ah-server list site:${SITE} -w type=web status=0 | paste -sd,) sv-mondisable ${WEBS} sv-webdisable ${WEBS} Successful execution of the command will set web_service_status to 1 for all the web servers serving the site. Re-run rysnc Once the webs are out of rotation, we should run another run of rsync to ensure there is no mis-match of data between ${OLD_FS1} and ${FS1} servers. fssh ${OLD_FS1} sudo su - JIRA_TICKET= screen -mS ${JIRA_TICKET} JIRA_TICKET= FS1_FQHN= rsync -avPe --delete \"ssh -i /root/.ssh/${JIRA_TICKET}\" --exclude=.glusterfs \\ /mnt/brick*/brick/ ${FS1_FQHN}:/mnt/gfs/ Disable Puppet and cron on webs fpdsh -l ${WEBS} -c \"sudo puppet agent --disable ${JIRA_TICKET} && \\ sudo service cron stop\" Stop gluster and Unmount gluster fpdsh -l ${WEBS} -c 'sudo service glusterfs-server stop' fpdsh -l ${WEBS} -c 'sudo umount /mnt/gfs' Add webs to New FS cluster NEW_FS_CLUSTER_ID=$(ah-server list ${FS1} -c fs_cluster_id --no-name) To add webs to fs cluster, we have to do four steps. First we have to suspend the webs, unset the existing fs_cluster_id , update the gluster_version to ${GLUSTER_VERSION} and finally set ${NEW_FS_CLUSTER_ID} to webs. ah-server suspend $WEBS -P ah-server edit $WEBS --unset fs_cluster_id ah-server edit $WEBS -c puppet:gluster_version=$GLUSTER_VERSION ah-server edit $WEBS -s fs_cluster_id=$NEW_FS_CLUSTER_ID Relaunch suspended webs sv-taskrelaunch server $WEBS -m 1 Successful execution of the command will relaunch webs and turn on the monitoring. Unfortunately, the tool doesn't exit cleanly in the current state. You might have to open a new session, hop onto the stage and verify the state of tasks. The tasks should be successful in ~10 minutes. Once the tasks are successful, you can interrupt the relaunch command execution. You can ensure webs are in good state by running check_services as a root user on the server. Remount gluster on webs site-fsremount ${SITE} check gluster for site site-checkgluster ${SITE} Put webs back into rotation sv-webenable ${WEBS} sv-monenable $WEBS Restart PHP, Run FCW on webs fpdsh -t $WEBS -c \"sudo service safe-httpd restart\" site-restartfpm ${SITE} site-fcw ${SITE} Verification site-check ${SITE} site-checkwebs ${SITE} If ${SITE} is an ACSF site, you can verify if sites.json file is present in the correct path by ssh'ing to a web server and running the below command: [ -f /mnt/files/${SITE}/files-private/sites.json ] && echo \"Found\" || \\ echo \"Not found\" Compare the number of files on the source filesystem server and destination filesystem server. We can check this by doing: fssh ${OLD_FS1} 'sudo find /mnt/gfs/ -type f | wc -l' fssh ${FS1} 'sudo find /mnt/gfs/ -type f | wc -l' You can also do additional checks for an acsf site by doing a curl on one of the domains for the ${SITE}. This check is optional. DOMAINS=$(ah-site get ${SITE} | grep 'domains\\.' | awk -F: '{print $2}') for D in ${DOMAINS}; do curl -IL ${D}; done The curl request will return 200 if everything is OK with the ${SITE}. Cleanup Once the site is operational, we would normally deprovision old servers. You have to be careful doing this step because if the ${SERVER_TYPE} is fsdb/ded then you should not terminate the servers and attached volumes unless the ${SITE} databases are moved to new set of servers. Otherwise, you can deprovision the hardware using the runbook available here . We should also remove the temporary ssh key on ${FS1} server as we no longer need that. This can be done using below steps: fssh ${FS1} sudo su - vim ~/.ssh/authorized_keys2 The temporary key will have a suffix of the ${OLD_FS1} server hostname at the end. The key should be deleted carefully without disturbing any existing entries in the file. Once deleted, save the file and exit.","title":"Downgrade Gluster Version from 3.4 to 3.0"},{"location":"kanban_tickets/gluster-downgrade/#downgrade-gluster-version-from-34-to-30","text":"","title":"Downgrade Gluster Version from 3.4 to 3.0"},{"location":"kanban_tickets/gluster-downgrade/#this-process-should-be-used-only-on-gluster-34-servers","text":"It may be necessary to downgrade a filesystem stack running 3.4 to 3.0 if recommended by Cloud Data Team. This process will involve an approximate downtime of 30 minutes.","title":"THIS PROCESS SHOULD BE USED ONLY ON GLUSTER 3.4 SERVERS"},{"location":"kanban_tickets/gluster-downgrade/#initial-variables","text":"JIRA_TICKET= USER=","title":"Initial Variables"},{"location":"kanban_tickets/gluster-downgrade/#info-gathering","text":"FS Servers mentioned above refers to the filesystem servers in the stack. If you have sitename, you can query for fs servers using below command to find the filesystem servers in the stack SITE= esl2 ${SITE} From the tool output, Pick the filesystem servers in the stack serving the above site and assign the below values: OLD_FS1= OLD_FS2= Gather volume information attached to the filesystem servers using the command sv-vollist ${OLD_FS1} sv-vollist ${OLD_FS2} FS_SIZE= EBS_TYPE= Volume size and ebs volume type should be read from the output of the volume info command unless customer is approved for an upsize. The values should be referred corresponding to /dev/xvdo device.","title":"Info Gathering"},{"location":"kanban_tickets/gluster-downgrade/#provision-new-fs-servers-and-fix-volumes","text":"It would be ideal to move the filesystem data from like-for-like servers. For example, if the site is currently served by fsdb/ded, it is suggested to move them to fsdb/ded. Similarly site served by fs server type should be moved to fs type. All other variables required for new filesystem server launches should depend on the customer's existing hardware. esl2 ${SITE} From the above command output we need to pick the VPC_ID for the associated webs to bring up filesystem servers also in the same vpc. SERVER_TYPE= INSTANCE_TYPE= AZ1= AZ2= REGION= VPC_ID=","title":"Provision new FS servers and fix volumes"},{"location":"kanban_tickets/gluster-downgrade/#allocate-new-fs-servers","text":"FS1=$(ah-server allocate ${SERVER_TYPE} \\ --ami-type ${INSTANCE_TYPE} \\ --region ${REGION} \\ --avail-zone ${AZ1} \\ --vpc-id ${VPC_ID} \\ --secondary-volume-size ${FS_SIZE} --pe --se) FS2=$(ah-server allocate ${SERVER_TYPE} \\ --ami-type ${INSTANCE_TYPE} \\ --region ${REGION} \\ --avail-zone ${AZ2} \\ --vpc-id ${VPC_ID} \\ --secondary-volume-size ${FS_SIZE} --pe --se) Successful execution of the commands should return server names for echo $FS1 $FS2 .","title":"Allocate new FS servers"},{"location":"kanban_tickets/gluster-downgrade/#add-brick-volumes","text":"ah-volume add-brick --server ${FS1} --device /dev/xvdo --size ${FS_SIZE} \\ --ebs-volume-type ${EBS_TYPE} --set-encrypted ah-volume add-brick --server ${FS2} --device /dev/xvdo --size ${FS_SIZE} \\ --ebs-volume-type ${EBS_TYPE} --set-encrypted Successful execution of the commands should return Brick IDs.","title":"Add brick volumes"},{"location":"kanban_tickets/gluster-downgrade/#configure-fs-servers-for-gluster-30","text":"GLUSTER_VERSION=3.0 ah-server edit ${FS1},${FS2} -c puppet:gluster_version=${GLUSTER_VERSION} Successful execution of the command should set puppet:gluster_version config with the GLUSTER_VERSION value.","title":"Configure FS servers for gluster 3.0"},{"location":"kanban_tickets/gluster-downgrade/#allocate-fs-cluster","text":"./fields-provision.php --fs-cluster-allocate ${SITE}_$(date +%s):${FS1},${FS2} Successful execution of the command should return FS cluster name.","title":"Allocate FS cluster"},{"location":"kanban_tickets/gluster-downgrade/#fix-backup-vol-on-secondary-server-to-1gb","text":"Of the two servers launched, highest numbered server will be called as secondary server. Backups are run and saved only on primary server on our platform. For that reason, backup volume on secondary server goes unused. We can save AWS cost by editing the backup volume on secondary server to 1gb. sv-vollist ${FS2} Pick the volume ID corresponding to the /vol/backup-ebs/(/dev/xvdn) device to modify. FS2_BACKUP_VOL_ID= ah-volume edit ${FS2_BACKUP_VOL_ID} -s size=1 Successful execution of the command should modify the volume size.","title":"Fix backup vol on secondary server to 1gb"},{"location":"kanban_tickets/gluster-downgrade/#fix-ebs1-volumes-on-both-servers-to-1gb","text":"This step is only applicable if ${FS1} and ${FS2} are fs server type. This change is also to save AWS cost for the unused volume resource. sv-vollist ${FS1} sv-vollist ${FS2} FS1_EBS_VOL_ID= FS2_EBS_VOL_ID= ah-volume edit ${FS1_EBS_VOL_ID} -s size=1 ah-volume edit ${FS2_EBS_VOL_ID} -s size=1","title":"Fix ebs1 volumes on both servers to 1gb"},{"location":"kanban_tickets/gluster-downgrade/#launch-fs-servers","text":"sv-taskrelaunch server -m1 ${FS1} ${FS2} Successful execution of the command should trigger a task for each of the servers to be launched and return the tasks state as done with successful server launches.","title":"Launch FS Servers"},{"location":"kanban_tickets/gluster-downgrade/#filesystem-data-transfer","text":"","title":"Filesystem Data Transfer"},{"location":"kanban_tickets/gluster-downgrade/#create-temporary-ssh-key","text":"We need to create a ssh keypair on ${OLD_FS1} and copy the public key to authorized keys on ${FS1}. This will enable us to establish a rsync connection for data transfer. fssh ${OLD_FS1} \"sudo ssh-keygen -b 2048 -f /root/.ssh/${JIRA_TICKET}; \\ sudo cat /root/.ssh/${JIRA_TICKET}.pub\" You need to manual specify the value of ${JIRA_TICKET} as we are inside the server. The above command execution will prompt for passphrase which is optional. You can specify a passphrase or press enter key to skip. Surgically insert the public key, CAREFULLY, in to the authorized keys file on the ${FS1} server. fssh ${FS1} sudo su - vim /root/.ssh/authorized_keys2 Paste in the contents of the pub key inclusive of \"ssh-rsa\" and the server hostname including the server hostname makes it obvious to other Ops people that the key was a temporary one.","title":"Create Temporary SSH key"},{"location":"kanban_tickets/gluster-downgrade/#rsync-from-source-server-to-destination-server","text":"This step involves rsyncing the data from ${OLD_FS1} to ${FS1}. FS1_FQHN=$(fqual ${FS1}) fssh ${OLD_FS1} sudo su - JIRA_TICKET= screen -mS ${JIRA_TICKET} FS1_FQHN= JIRA_TICKET= rsync -avPe \"ssh -i /root/.ssh/${JIRA_TICKET}\" --exclude=.glusterfs \\ /mnt/brick*/brick/ ${FS1_FQHN}:/mnt/gfs/ Successful execution of the rsync command will start the data transfer and the time for completion will depend on the amount of data we are trying to transfer. In another terminal window, we can watch the progress of data transfer on ${FS1} fssh ${FS1} sudo su - watch 'df -h /mnt/gfs' Once the transfer has completed, run a second rsync to ensure that any new data created on the brick gets transferred to ${FS1} server. fssh ${OLD_FS1} sudo su - JIRA_TICKET= screen -mS ${JIRA_TICKET} FS1_FQHN= JIRA_TICKET= rsync -avPe --delete \"ssh -i /root/.ssh/${JIRA_TICKET}\" --exclude=.glusterfs \\ /mnt/brick*/brick/ ${FS1_FQHN}:/mnt/gfs/","title":"rsync from source server to destination server"},{"location":"kanban_tickets/gluster-downgrade/#web-servers-cutover","text":"This process involves pointing the web servers serving the site to point to newly created filesystem servers. This process involves downtime as we will take webs out of rotation. After this point the site will be down. Ping ops hotseat person about the site downtime alert. At any point if ops were to abort the cutover process, ops person should undo all the steps that were done until that point.","title":"Web servers cutover"},{"location":"kanban_tickets/gluster-downgrade/#take-webs-out-of-rotation","text":"WEBS=$(ah-server list site:${SITE} -w type=web status=0 | paste -sd,) sv-mondisable ${WEBS} sv-webdisable ${WEBS} Successful execution of the command will set web_service_status to 1 for all the web servers serving the site.","title":"Take webs out of rotation"},{"location":"kanban_tickets/gluster-downgrade/#re-run-rysnc","text":"Once the webs are out of rotation, we should run another run of rsync to ensure there is no mis-match of data between ${OLD_FS1} and ${FS1} servers. fssh ${OLD_FS1} sudo su - JIRA_TICKET= screen -mS ${JIRA_TICKET} JIRA_TICKET= FS1_FQHN= rsync -avPe --delete \"ssh -i /root/.ssh/${JIRA_TICKET}\" --exclude=.glusterfs \\ /mnt/brick*/brick/ ${FS1_FQHN}:/mnt/gfs/","title":"Re-run rysnc"},{"location":"kanban_tickets/gluster-downgrade/#disable-puppet-and-cron-on-webs","text":"fpdsh -l ${WEBS} -c \"sudo puppet agent --disable ${JIRA_TICKET} && \\ sudo service cron stop\"","title":"Disable Puppet and cron on webs"},{"location":"kanban_tickets/gluster-downgrade/#stop-gluster-and-unmount-gluster","text":"fpdsh -l ${WEBS} -c 'sudo service glusterfs-server stop' fpdsh -l ${WEBS} -c 'sudo umount /mnt/gfs'","title":"Stop gluster and Unmount gluster"},{"location":"kanban_tickets/gluster-downgrade/#add-webs-to-new-fs-cluster","text":"NEW_FS_CLUSTER_ID=$(ah-server list ${FS1} -c fs_cluster_id --no-name) To add webs to fs cluster, we have to do four steps. First we have to suspend the webs, unset the existing fs_cluster_id , update the gluster_version to ${GLUSTER_VERSION} and finally set ${NEW_FS_CLUSTER_ID} to webs. ah-server suspend $WEBS -P ah-server edit $WEBS --unset fs_cluster_id ah-server edit $WEBS -c puppet:gluster_version=$GLUSTER_VERSION ah-server edit $WEBS -s fs_cluster_id=$NEW_FS_CLUSTER_ID","title":"Add webs to New FS cluster"},{"location":"kanban_tickets/gluster-downgrade/#relaunch-suspended-webs","text":"sv-taskrelaunch server $WEBS -m 1 Successful execution of the command will relaunch webs and turn on the monitoring. Unfortunately, the tool doesn't exit cleanly in the current state. You might have to open a new session, hop onto the stage and verify the state of tasks. The tasks should be successful in ~10 minutes. Once the tasks are successful, you can interrupt the relaunch command execution. You can ensure webs are in good state by running check_services as a root user on the server.","title":"Relaunch suspended webs"},{"location":"kanban_tickets/gluster-downgrade/#remount-gluster-on-webs","text":"site-fsremount ${SITE}","title":"Remount gluster on webs"},{"location":"kanban_tickets/gluster-downgrade/#check-gluster-for-site","text":"site-checkgluster ${SITE}","title":"check gluster for site"},{"location":"kanban_tickets/gluster-downgrade/#put-webs-back-into-rotation","text":"sv-webenable ${WEBS} sv-monenable $WEBS","title":"Put webs back into rotation"},{"location":"kanban_tickets/gluster-downgrade/#restart-php-run-fcw-on-webs","text":"fpdsh -t $WEBS -c \"sudo service safe-httpd restart\" site-restartfpm ${SITE} site-fcw ${SITE}","title":"Restart PHP, Run FCW on webs"},{"location":"kanban_tickets/gluster-downgrade/#verification","text":"site-check ${SITE} site-checkwebs ${SITE} If ${SITE} is an ACSF site, you can verify if sites.json file is present in the correct path by ssh'ing to a web server and running the below command: [ -f /mnt/files/${SITE}/files-private/sites.json ] && echo \"Found\" || \\ echo \"Not found\" Compare the number of files on the source filesystem server and destination filesystem server. We can check this by doing: fssh ${OLD_FS1} 'sudo find /mnt/gfs/ -type f | wc -l' fssh ${FS1} 'sudo find /mnt/gfs/ -type f | wc -l' You can also do additional checks for an acsf site by doing a curl on one of the domains for the ${SITE}. This check is optional. DOMAINS=$(ah-site get ${SITE} | grep 'domains\\.' | awk -F: '{print $2}') for D in ${DOMAINS}; do curl -IL ${D}; done The curl request will return 200 if everything is OK with the ${SITE}.","title":"Verification"},{"location":"kanban_tickets/gluster-downgrade/#cleanup","text":"Once the site is operational, we would normally deprovision old servers. You have to be careful doing this step because if the ${SERVER_TYPE} is fsdb/ded then you should not terminate the servers and attached volumes unless the ${SITE} databases are moved to new set of servers. Otherwise, you can deprovision the hardware using the runbook available here . We should also remove the temporary ssh key on ${FS1} server as we no longer need that. This can be done using below steps: fssh ${FS1} sudo su - vim ~/.ssh/authorized_keys2 The temporary key will have a suffix of the ${OLD_FS1} server hostname at the end. The key should be deleted carefully without disturbing any existing entries in the file. Once deleted, save the file and exit.","title":"Cleanup"},{"location":"kanban_tickets/gluster-upgrade/","text":"Upgrade Gluster Version from 3.0 to 3.4 THIS PROCESS SHOULD BE USED ONLY ON GLUSTER 3.0 SERVERS It may be necessary to upgrade a filesystem stack running 3.0 to 3.4 if recommended by Cloud Data Team. This process will involve an approximate downtime of 30 minutes. Initial Variables JIRA_TICKET= USER= Info Gathering FS Servers mentioned above refers to the filesystem servers in the stack. If you have sitename, you can query for fs servers using below command to find the filesystem servers in the stack SITE= esl2 ${SITE} From the tool output, Pick the filesystem servers in the stack serving the above site and assign the below values: OLD_FS1= OLD_FS2= Gather volume information attached to the filesystem servers using the command sv-vollist ${OLD_FS1} sv-vollist ${OLD_FS2} FS_SIZE= EBS_TYPE= Volume size and ebs volume type should be read from the output of the volume info command unless customer is approved for an upsize. The values should be referred corresponding to /dev/xvdo device. Provision new FS servers and fix volumes It would be ideal to move the filesystem data from like-for-like servers. For example, if the site is currently served by fsdb/ded, it is suggested to move them to fsdb/ded. Similarly site served by fs server type should be moved to fs type. All other variables required for new filesystem server launches should depend on the customer's existing hardware. esl2 ${SITE} From the above command output we need to pick the VPC_ID for the associated webs to bring up filesystem servers also in the same vpc. SERVER_TYPE= INSTANCE_TYPE= AZ1= AZ2= REGION= VPC_ID= Allocate new FS servers FS1=$(ah-server allocate ${SERVER_TYPE} \\ --ami-type ${INSTANCE_TYPE} \\ --region ${REGION} \\ --avail-zone ${AZ1} \\ --vpc-id ${VPC_ID} \\ --secondary-volume-size ${FS_SIZE} --pe --se) FS2=$(ah-server allocate ${SERVER_TYPE} \\ --ami-type ${INSTANCE_TYPE} \\ --region ${REGION} \\ --avail-zone ${AZ2} \\ --vpc-id ${VPC_ID} \\ --secondary-volume-size ${FS_SIZE} --pe --se) Successful execution of the commands should return server names for echo $FS1 $FS2 . Add brick volumes ah-volume add-brick --server ${FS1} --device /dev/xvdo --size ${FS_SIZE} \\ --ebs-volume-type ${EBS_TYPE} --set-encrypted ah-volume add-brick --server ${FS2} --device /dev/xvdo --size ${FS_SIZE} \\ --ebs-volume-type ${EBS_TYPE} --set-encrypted Successful execution of the commands should return Brick IDs. Configure FS servers for gluster 3.4 GLUSTER_VERSION=3.4 ah-server edit ${FS1},${FS2} -c puppet:gluster_version=${GLUSTER_VERSION} Successful execution of the command should set puppet:gluster_version config with the GLUSTER_VERSION value. Allocate FS cluster ./fields-provision.php --fs-cluster-allocate ${SITE}_$(date +%s):${FS1},${FS2} Successful execution of the command should return FS cluster name. Fix backup vol on secondary server to 1gb Of the two servers launched, highest numbered server will be called as secondary server. Backups are run and saved only on primary server on our platform. For that reason, backup volume on secondary server goes unused. We can save AWS cost by resizing the backup volume on secondary server to 1gb. sv-vollist ${FS2} Pick the volume ID corresponding to the /vol/backup-ebs/(/dev/xvdn) device to proceed with resize. FS2_BACKUP_VOL_ID= ah-volume edit ${FS2_BACKUP_VOL_ID} -s size=1 Successful execution of the command should change the volume size. Fix ebs1 volumes on both servers to 1gb This step is only applicable if ${FS1} and ${FS2} are fs server type. This resize is also to save AWS cost for the unused volume resource. sv-vollist ${FS1} sv-vollist ${FS2} FS1_EBS_VOL_ID= FS2_EBS_VOL_ID= ah-volume edit ${FS1_EBS_VOL_ID} -s size=1 ah-volume edit ${FS2_EBS_VOL_ID} -s size=1 Launch FS Servers sv-taskrelaunch server -m1 ${FS1} ${FS2} Successful execution of the command should trigger a task for each of the servers to be launched and return the tasks state as done with successful server launches. Filesystem Data Transfer Create Temporary SSH key We need to create a ssh keypair on ${OLD_FS1} and copy the public key to authorized keys on ${FS1}. This will enable us to establish a rsync connection for data transfer. fssh ${OLD_FS1} \"sudo ssh-keygen -b 2048 -f /root/.ssh/${JIRA_TICKET}; \\ sudo cat /root/.ssh/${JIRA_TICKET}.pub\" You need to manual specify the value of ${JIRA_TICKET} as we are inside the server. The above command execution will prompt for passphrase which is optional. You can specify a passphrase or press enter key to skip. Surgically insert the public key, CAREFULLY, in to the authorized keys file on the ${FS1} server. fssh ${FS1} sudo su - vim /root/.ssh/authorized_keys2 Paste in the contents of the pub key inclusive of \"ssh-rsa\" and the server hostname including the server hostname makes it obvious to other Ops people that the key was a temporary one. rsync from source server to destination server This step involves rsyncing the data from ${OLD_FS1} to ${FS1}. FS1_FQHN=$(fqual ${FS1}) fssh ${OLD_FS1} sudo su - JIRA_TICKET= screen -mS ${JIRA_TICKET} FS1_FQHN= JIRA_TICKET= rsync -avPe \"ssh -i /root/.ssh/${JIRA_TICKET}\" --exclude=.glusterfs \\ /mnt/brick*/ ${FS1_FQHN}:/mnt/gfs/ Successful execution of the rsync command will start the data transfer and the time for completion will depend on the amount of data we are trying to transfer. In another terminal window, we can watch the progress of data transfer on ${FS1} fssh ${FS1} sudo su - watch 'df -h /mnt/gfs' Once the transfer has completed, run a second rsync to ensure that any new data created on the brick gets transferred to ${FS1} server. fssh ${OLD_FS1} sudo su - JIRA_TICKET= screen -mS ${JIRA_TICKET} FS1_FQHN= JIRA_TICKET= rsync -avPe --delete \"ssh -i /root/.ssh/${JIRA_TICKET}\" --exclude=.glusterfs \\ /mnt/brick*/ ${FS1_FQHN}:/mnt/gfs/ Web servers cutover This process involves pointing the web servers serving the site to point to newly created filesystem servers. This process involves downtime as we will take webs out of rotation. After this point the site will be down. Ping ops hotseat person about the site downtime alert. At any point if ops were to abort the cutover process, ops person should undo all the steps that were done until that point. Take webs out of rotation WEBS=$(ah-server list site:${SITE} -w type=web status=0 | paste -sd,) sv-mondisable ${WEBS} sv-webdisable ${WEBS} Successful execution of the command will set web_service_status to 1 for all the web servers serving the site. Re-run rysnc Once the webs are out of rotation, we should run another run of rsync to ensure there is no mis-match of data between ${OLD_FS1} and ${FS1} servers. fssh ${OLD_FS1} sudo su - JIRA_TICKET= screen -mS ${JIRA_TICKET} JIRA_TICKET= FS1_FQHN= rsync -avPe --delete \"ssh -i /root/.ssh/${JIRA_TICKET}\" --exclude=.glusterfs \\ /mnt/brick*/ ${FS1_FQHN}:/mnt/gfs/ Disable Puppet and cron on webs fpdsh -l ${WEBS} -c \"sudo puppet agent --disable ${JIRA_TICKET} && \\ sudo service cron stop\" Stop gluster and Unmount gluster fpdsh -l ${WEBS} -c 'sudo service glusterfs-server stop' fpdsh -l ${WEBS} -c 'sudo umount /mnt/gfs' Add webs to New FS cluster NEW_FS_CLUSTER_ID=$(ah-server list ${FS1} -c fs_cluster_id --no-name) To add webs to fs cluster, we have to do four steps. First we have to suspend the webs, unset the existing fs_cluster_id , update the gluster_version to ${GLUSTER_VERSION} and finally set ${NEW_FS_CLUSTER_ID} to webs. ah-server suspend $WEBS -P ah-server edit $WEBS --unset fs_cluster_id ah-server edit $WEBS -c puppet:gluster_version=$GLUSTER_VERSION ah-server edit $WEBS -s fs_cluster_id=$NEW_FS_CLUSTER_ID Relaunch suspended webs sv-taskrelaunch server $WEBS -m 1 Successful execution of the command will relaunch webs and turn on the monitoring. Unfortunately, the tool doesn't exit cleanly in the current state. You might have to open a new session, hop onto the stage and verify the state of tasks. The tasks should be successful in ~10 minutes. Once the tasks are successful, you can interrupt the relaunch command execution. You can ensure webs are in good state by running check_services as a root user on the server. Remount gluster on webs site-fsremount ${SITE} check gluster for site site-checkgluster ${SITE} Put webs back into rotation sv-webenable ${WEBS} sv-monenable $WEBS Restart PHP, Run FCW on webs fpdsh -t $WEBS -c \"sudo service safe-httpd restart\" site-restartfpm ${SITE} site-fcw ${SITE} Verification site-check ${SITE} site-checkwebs ${SITE} If ${SITE} is an ACSF site, you can verify if sites.json file is present in the correct path by ssh'ing to a web server and running the below command: [ -f /mnt/files/${SITE}/files-private/sites.json ] && echo \"Found\" || \\ echo \"Not found\" Compare the number of files on the source filesystem server and destination filesystem server. We can check this by doing: fssh ${OLD_FS1} 'sudo find /mnt/gfs/ -type f | wc -l' fssh ${FS1} 'sudo find /mnt/gfs/ -type f | wc -l' You can also do additional checks for an acsf site by doing a curl on one of the domains for the ${SITE}. This check is optional. DOMAINS=$(ah-site get ${SITE} | grep 'domains\\.' | awk -F: '{print $2}') for D in ${DOMAINS}; do curl -IL ${D}; done The curl request will return 200 if everything is OK with the ${SITE}. Cleanup Once the site is operational, we would normally deprovision old servers. You have to be careful doing this step because if the ${SERVER_TYPE} is fsdb/ded then you should not terminate the servers and attached volumes unless the ${SITE} databases are moved to new set of servers. Otherwise, you can deprovision the hardware using the runbook available here . We should also remove the temporary ssh key on ${FS1} server as we no longer need that. This can be done using below steps: fssh ${FS1} sudo su- vim ~/.ssh/authorized_keys2 The temporary key will have a suffix of the ${OLD_FS1} server hostname at the end. The key should be deleted carefully without disturbing any existing entries in the file. Once deleted, save the file and exit.","title":"Upgrade Gluster Version from 3.0 to 3.4"},{"location":"kanban_tickets/gluster-upgrade/#upgrade-gluster-version-from-30-to-34","text":"","title":"Upgrade Gluster Version from 3.0 to 3.4"},{"location":"kanban_tickets/gluster-upgrade/#this-process-should-be-used-only-on-gluster-30-servers","text":"It may be necessary to upgrade a filesystem stack running 3.0 to 3.4 if recommended by Cloud Data Team. This process will involve an approximate downtime of 30 minutes.","title":"THIS PROCESS SHOULD BE USED ONLY ON GLUSTER 3.0 SERVERS"},{"location":"kanban_tickets/gluster-upgrade/#initial-variables","text":"JIRA_TICKET= USER=","title":"Initial Variables"},{"location":"kanban_tickets/gluster-upgrade/#info-gathering","text":"FS Servers mentioned above refers to the filesystem servers in the stack. If you have sitename, you can query for fs servers using below command to find the filesystem servers in the stack SITE= esl2 ${SITE} From the tool output, Pick the filesystem servers in the stack serving the above site and assign the below values: OLD_FS1= OLD_FS2= Gather volume information attached to the filesystem servers using the command sv-vollist ${OLD_FS1} sv-vollist ${OLD_FS2} FS_SIZE= EBS_TYPE= Volume size and ebs volume type should be read from the output of the volume info command unless customer is approved for an upsize. The values should be referred corresponding to /dev/xvdo device.","title":"Info Gathering"},{"location":"kanban_tickets/gluster-upgrade/#provision-new-fs-servers-and-fix-volumes","text":"It would be ideal to move the filesystem data from like-for-like servers. For example, if the site is currently served by fsdb/ded, it is suggested to move them to fsdb/ded. Similarly site served by fs server type should be moved to fs type. All other variables required for new filesystem server launches should depend on the customer's existing hardware. esl2 ${SITE} From the above command output we need to pick the VPC_ID for the associated webs to bring up filesystem servers also in the same vpc. SERVER_TYPE= INSTANCE_TYPE= AZ1= AZ2= REGION= VPC_ID=","title":"Provision new FS servers and fix volumes"},{"location":"kanban_tickets/gluster-upgrade/#allocate-new-fs-servers","text":"FS1=$(ah-server allocate ${SERVER_TYPE} \\ --ami-type ${INSTANCE_TYPE} \\ --region ${REGION} \\ --avail-zone ${AZ1} \\ --vpc-id ${VPC_ID} \\ --secondary-volume-size ${FS_SIZE} --pe --se) FS2=$(ah-server allocate ${SERVER_TYPE} \\ --ami-type ${INSTANCE_TYPE} \\ --region ${REGION} \\ --avail-zone ${AZ2} \\ --vpc-id ${VPC_ID} \\ --secondary-volume-size ${FS_SIZE} --pe --se) Successful execution of the commands should return server names for echo $FS1 $FS2 .","title":"Allocate new FS servers"},{"location":"kanban_tickets/gluster-upgrade/#add-brick-volumes","text":"ah-volume add-brick --server ${FS1} --device /dev/xvdo --size ${FS_SIZE} \\ --ebs-volume-type ${EBS_TYPE} --set-encrypted ah-volume add-brick --server ${FS2} --device /dev/xvdo --size ${FS_SIZE} \\ --ebs-volume-type ${EBS_TYPE} --set-encrypted Successful execution of the commands should return Brick IDs.","title":"Add brick volumes"},{"location":"kanban_tickets/gluster-upgrade/#configure-fs-servers-for-gluster-34","text":"GLUSTER_VERSION=3.4 ah-server edit ${FS1},${FS2} -c puppet:gluster_version=${GLUSTER_VERSION} Successful execution of the command should set puppet:gluster_version config with the GLUSTER_VERSION value.","title":"Configure FS servers for gluster 3.4"},{"location":"kanban_tickets/gluster-upgrade/#allocate-fs-cluster","text":"./fields-provision.php --fs-cluster-allocate ${SITE}_$(date +%s):${FS1},${FS2} Successful execution of the command should return FS cluster name.","title":"Allocate FS cluster"},{"location":"kanban_tickets/gluster-upgrade/#fix-backup-vol-on-secondary-server-to-1gb","text":"Of the two servers launched, highest numbered server will be called as secondary server. Backups are run and saved only on primary server on our platform. For that reason, backup volume on secondary server goes unused. We can save AWS cost by resizing the backup volume on secondary server to 1gb. sv-vollist ${FS2} Pick the volume ID corresponding to the /vol/backup-ebs/(/dev/xvdn) device to proceed with resize. FS2_BACKUP_VOL_ID= ah-volume edit ${FS2_BACKUP_VOL_ID} -s size=1 Successful execution of the command should change the volume size.","title":"Fix backup vol on secondary server to 1gb"},{"location":"kanban_tickets/gluster-upgrade/#fix-ebs1-volumes-on-both-servers-to-1gb","text":"This step is only applicable if ${FS1} and ${FS2} are fs server type. This resize is also to save AWS cost for the unused volume resource. sv-vollist ${FS1} sv-vollist ${FS2} FS1_EBS_VOL_ID= FS2_EBS_VOL_ID= ah-volume edit ${FS1_EBS_VOL_ID} -s size=1 ah-volume edit ${FS2_EBS_VOL_ID} -s size=1","title":"Fix ebs1 volumes on both servers to 1gb"},{"location":"kanban_tickets/gluster-upgrade/#launch-fs-servers","text":"sv-taskrelaunch server -m1 ${FS1} ${FS2} Successful execution of the command should trigger a task for each of the servers to be launched and return the tasks state as done with successful server launches.","title":"Launch FS Servers"},{"location":"kanban_tickets/gluster-upgrade/#filesystem-data-transfer","text":"","title":"Filesystem Data Transfer"},{"location":"kanban_tickets/gluster-upgrade/#create-temporary-ssh-key","text":"We need to create a ssh keypair on ${OLD_FS1} and copy the public key to authorized keys on ${FS1}. This will enable us to establish a rsync connection for data transfer. fssh ${OLD_FS1} \"sudo ssh-keygen -b 2048 -f /root/.ssh/${JIRA_TICKET}; \\ sudo cat /root/.ssh/${JIRA_TICKET}.pub\" You need to manual specify the value of ${JIRA_TICKET} as we are inside the server. The above command execution will prompt for passphrase which is optional. You can specify a passphrase or press enter key to skip. Surgically insert the public key, CAREFULLY, in to the authorized keys file on the ${FS1} server. fssh ${FS1} sudo su - vim /root/.ssh/authorized_keys2 Paste in the contents of the pub key inclusive of \"ssh-rsa\" and the server hostname including the server hostname makes it obvious to other Ops people that the key was a temporary one.","title":"Create Temporary SSH key"},{"location":"kanban_tickets/gluster-upgrade/#rsync-from-source-server-to-destination-server","text":"This step involves rsyncing the data from ${OLD_FS1} to ${FS1}. FS1_FQHN=$(fqual ${FS1}) fssh ${OLD_FS1} sudo su - JIRA_TICKET= screen -mS ${JIRA_TICKET} FS1_FQHN= JIRA_TICKET= rsync -avPe \"ssh -i /root/.ssh/${JIRA_TICKET}\" --exclude=.glusterfs \\ /mnt/brick*/ ${FS1_FQHN}:/mnt/gfs/ Successful execution of the rsync command will start the data transfer and the time for completion will depend on the amount of data we are trying to transfer. In another terminal window, we can watch the progress of data transfer on ${FS1} fssh ${FS1} sudo su - watch 'df -h /mnt/gfs' Once the transfer has completed, run a second rsync to ensure that any new data created on the brick gets transferred to ${FS1} server. fssh ${OLD_FS1} sudo su - JIRA_TICKET= screen -mS ${JIRA_TICKET} FS1_FQHN= JIRA_TICKET= rsync -avPe --delete \"ssh -i /root/.ssh/${JIRA_TICKET}\" --exclude=.glusterfs \\ /mnt/brick*/ ${FS1_FQHN}:/mnt/gfs/","title":"rsync from source server to destination server"},{"location":"kanban_tickets/gluster-upgrade/#web-servers-cutover","text":"This process involves pointing the web servers serving the site to point to newly created filesystem servers. This process involves downtime as we will take webs out of rotation. After this point the site will be down. Ping ops hotseat person about the site downtime alert. At any point if ops were to abort the cutover process, ops person should undo all the steps that were done until that point.","title":"Web servers cutover"},{"location":"kanban_tickets/gluster-upgrade/#take-webs-out-of-rotation","text":"WEBS=$(ah-server list site:${SITE} -w type=web status=0 | paste -sd,) sv-mondisable ${WEBS} sv-webdisable ${WEBS} Successful execution of the command will set web_service_status to 1 for all the web servers serving the site.","title":"Take webs out of rotation"},{"location":"kanban_tickets/gluster-upgrade/#re-run-rysnc","text":"Once the webs are out of rotation, we should run another run of rsync to ensure there is no mis-match of data between ${OLD_FS1} and ${FS1} servers. fssh ${OLD_FS1} sudo su - JIRA_TICKET= screen -mS ${JIRA_TICKET} JIRA_TICKET= FS1_FQHN= rsync -avPe --delete \"ssh -i /root/.ssh/${JIRA_TICKET}\" --exclude=.glusterfs \\ /mnt/brick*/ ${FS1_FQHN}:/mnt/gfs/","title":"Re-run rysnc"},{"location":"kanban_tickets/gluster-upgrade/#disable-puppet-and-cron-on-webs","text":"fpdsh -l ${WEBS} -c \"sudo puppet agent --disable ${JIRA_TICKET} && \\ sudo service cron stop\"","title":"Disable Puppet and cron on webs"},{"location":"kanban_tickets/gluster-upgrade/#stop-gluster-and-unmount-gluster","text":"fpdsh -l ${WEBS} -c 'sudo service glusterfs-server stop' fpdsh -l ${WEBS} -c 'sudo umount /mnt/gfs'","title":"Stop gluster and Unmount gluster"},{"location":"kanban_tickets/gluster-upgrade/#add-webs-to-new-fs-cluster","text":"NEW_FS_CLUSTER_ID=$(ah-server list ${FS1} -c fs_cluster_id --no-name) To add webs to fs cluster, we have to do four steps. First we have to suspend the webs, unset the existing fs_cluster_id , update the gluster_version to ${GLUSTER_VERSION} and finally set ${NEW_FS_CLUSTER_ID} to webs. ah-server suspend $WEBS -P ah-server edit $WEBS --unset fs_cluster_id ah-server edit $WEBS -c puppet:gluster_version=$GLUSTER_VERSION ah-server edit $WEBS -s fs_cluster_id=$NEW_FS_CLUSTER_ID","title":"Add webs to New FS cluster"},{"location":"kanban_tickets/gluster-upgrade/#relaunch-suspended-webs","text":"sv-taskrelaunch server $WEBS -m 1 Successful execution of the command will relaunch webs and turn on the monitoring. Unfortunately, the tool doesn't exit cleanly in the current state. You might have to open a new session, hop onto the stage and verify the state of tasks. The tasks should be successful in ~10 minutes. Once the tasks are successful, you can interrupt the relaunch command execution. You can ensure webs are in good state by running check_services as a root user on the server.","title":"Relaunch suspended webs"},{"location":"kanban_tickets/gluster-upgrade/#remount-gluster-on-webs","text":"site-fsremount ${SITE}","title":"Remount gluster on webs"},{"location":"kanban_tickets/gluster-upgrade/#check-gluster-for-site","text":"site-checkgluster ${SITE}","title":"check gluster for site"},{"location":"kanban_tickets/gluster-upgrade/#put-webs-back-into-rotation","text":"sv-webenable ${WEBS} sv-monenable $WEBS","title":"Put webs back into rotation"},{"location":"kanban_tickets/gluster-upgrade/#restart-php-run-fcw-on-webs","text":"fpdsh -t $WEBS -c \"sudo service safe-httpd restart\" site-restartfpm ${SITE} site-fcw ${SITE}","title":"Restart PHP, Run FCW on webs"},{"location":"kanban_tickets/gluster-upgrade/#verification","text":"site-check ${SITE} site-checkwebs ${SITE} If ${SITE} is an ACSF site, you can verify if sites.json file is present in the correct path by ssh'ing to a web server and running the below command: [ -f /mnt/files/${SITE}/files-private/sites.json ] && echo \"Found\" || \\ echo \"Not found\" Compare the number of files on the source filesystem server and destination filesystem server. We can check this by doing: fssh ${OLD_FS1} 'sudo find /mnt/gfs/ -type f | wc -l' fssh ${FS1} 'sudo find /mnt/gfs/ -type f | wc -l' You can also do additional checks for an acsf site by doing a curl on one of the domains for the ${SITE}. This check is optional. DOMAINS=$(ah-site get ${SITE} | grep 'domains\\.' | awk -F: '{print $2}') for D in ${DOMAINS}; do curl -IL ${D}; done The curl request will return 200 if everything is OK with the ${SITE}.","title":"Verification"},{"location":"kanban_tickets/gluster-upgrade/#cleanup","text":"Once the site is operational, we would normally deprovision old servers. You have to be careful doing this step because if the ${SERVER_TYPE} is fsdb/ded then you should not terminate the servers and attached volumes unless the ${SITE} databases are moved to new set of servers. Otherwise, you can deprovision the hardware using the runbook available here . We should also remove the temporary ssh key on ${FS1} server as we no longer need that. This can be done using below steps: fssh ${FS1} sudo su- vim ~/.ssh/authorized_keys2 The temporary key will have a suffix of the ${OLD_FS1} server hostname at the end. The key should be deleted carefully without disturbing any existing entries in the file. Once deleted, save the file and exit.","title":"Cleanup"},{"location":"kanban_tickets/loadtest_balancer/","text":"Load Test Balancer Acquia will provide customers with a load test balancer upon request. We have some balancers in every region that are reserved for this purpose. \"Load test balancer\" is something of a misnomer because the customer could use it for anything without ever putting the system under high load. Adding a Load Test Balancer Find a Valid Load Test Balancer Set the region and VPC SITE= REGION= VPC_ID=$(ah-server list site:${SITE} -w type=bal --no-name -c vpc_id | uniq) VPC=$(ah-vpc list % -w id=${VPC_ID}) Find an available bal in the same region/VPC: TESTBAL=$(ah-server list tag:loadtestbal -w status=1 ec2_region=${REGION} vpc_id=${VPC_ID} | head -n1) echo ${TESTBAL} If nothing is returned, try finding a balancer in another VPC in the same region: TESTBAL=$(ah-server list tag:loadtestbal -w status=1 ec2_region=${REGION} | head -n1) echo ${TESTBAL} If this found a balancer, make sure to change the VPC for it: ah-server edit ${TESTBAL} -s vpc_id=${VPC_ID} If you still cannot find an available load test bal, then you need to either free up an existing loadtest bal or provision a new one. To free an existing bal: Search Jira for recently updated issues where one of the balancers is mentioned, using the jql expression rendered by this command: echo \"text ~ \\\"$(ah-server list tag:loadtestbal -w ec2_region=${REGION} | paste -sd ' ' | sed 's/ / OR /g')\\\"\" Find one to free up, remove the sites from it , and return to the top of this section. If there is no available bal in the appropriate VPC/region then deploy a new one: AZ= TESTBAL=$(ah-provision stack bal -c 1 -i m5.large -r ${REGION} -z ${AZ} -V ${VPC}) ah-server tag add ${TESTBAL} --tags loadtestbal Remove the EIP (unless an EIP is specifically requested for the bal): EIP_ID=$(ah-server list ${TESTBAL} --no-name -c eip_id) EIP=$(ruby -e \"require 'aq'; puts Aq::Hosting::ElasticIp.from_id(${EIP_ID})['ip']\") ah-elastic-ip remove ${EIP} ${TESTBAL} ah-elastic-ip release ${EIP} Add the balancer sv-taskrelaunch server ${TESTBAL} ah-site bal add ${SITE} --bals=${TESTBAL} Check the ELB If the customer site has an ELB, automation might add the testbal to the ELB rotation and cause an outage for the customer: ELB_NAME=$(ruby -e \"require 'aq'; site = Aq::Hosting::Site.from_query(name: '${SITE}'); \\ puts Aq::Hosting::SiteElb.fromQuery('site_id' => site['id']).record['elb_name']\") echo ${ELB_NAME} If there is an ELB, deregister the new balancer from it: TESTBAL_ID=$(ah-server list ${TESTBAL} --no-name -c ec2_id) aws elb deregister-instances-from-load-balancer --region ${REGION} \\ --load-balancer-name ${ELB_NAME} --instances ${TESTBAL_ID} Removing a Load Test Balancer Set up Variables TESTBAL= SITES=( $(ah-site list on:${TESTBAL}) ) EIP=$(ah-server list ${TEST_BAL} -w eip_id!=nil --no-name -c external_ip) Remove all sites from the bal: for site in ${SITES[@]}; do ah-site bal remove ${site} --bals=${TESTBAL} done If the bal has an EIP, remove it: echo ${EIP} ah-elastic-ip remove ${EIP} ${TESTBAL} ah-elastic-ip release ${EIP} Suspend the bal: ah-server suspend ${TESTBAL}","title":"Load Test Balancer"},{"location":"kanban_tickets/loadtest_balancer/#load-test-balancer","text":"Acquia will provide customers with a load test balancer upon request. We have some balancers in every region that are reserved for this purpose. \"Load test balancer\" is something of a misnomer because the customer could use it for anything without ever putting the system under high load.","title":"Load Test Balancer"},{"location":"kanban_tickets/loadtest_balancer/#adding-a-load-test-balancer","text":"","title":"Adding a Load Test Balancer"},{"location":"kanban_tickets/loadtest_balancer/#find-a-valid-load-test-balancer","text":"Set the region and VPC SITE= REGION= VPC_ID=$(ah-server list site:${SITE} -w type=bal --no-name -c vpc_id | uniq) VPC=$(ah-vpc list % -w id=${VPC_ID}) Find an available bal in the same region/VPC: TESTBAL=$(ah-server list tag:loadtestbal -w status=1 ec2_region=${REGION} vpc_id=${VPC_ID} | head -n1) echo ${TESTBAL} If nothing is returned, try finding a balancer in another VPC in the same region: TESTBAL=$(ah-server list tag:loadtestbal -w status=1 ec2_region=${REGION} | head -n1) echo ${TESTBAL} If this found a balancer, make sure to change the VPC for it: ah-server edit ${TESTBAL} -s vpc_id=${VPC_ID} If you still cannot find an available load test bal, then you need to either free up an existing loadtest bal or provision a new one. To free an existing bal: Search Jira for recently updated issues where one of the balancers is mentioned, using the jql expression rendered by this command: echo \"text ~ \\\"$(ah-server list tag:loadtestbal -w ec2_region=${REGION} | paste -sd ' ' | sed 's/ / OR /g')\\\"\" Find one to free up, remove the sites from it , and return to the top of this section. If there is no available bal in the appropriate VPC/region then deploy a new one: AZ= TESTBAL=$(ah-provision stack bal -c 1 -i m5.large -r ${REGION} -z ${AZ} -V ${VPC}) ah-server tag add ${TESTBAL} --tags loadtestbal Remove the EIP (unless an EIP is specifically requested for the bal): EIP_ID=$(ah-server list ${TESTBAL} --no-name -c eip_id) EIP=$(ruby -e \"require 'aq'; puts Aq::Hosting::ElasticIp.from_id(${EIP_ID})['ip']\") ah-elastic-ip remove ${EIP} ${TESTBAL} ah-elastic-ip release ${EIP}","title":"Find a Valid Load Test Balancer"},{"location":"kanban_tickets/loadtest_balancer/#add-the-balancer","text":"sv-taskrelaunch server ${TESTBAL} ah-site bal add ${SITE} --bals=${TESTBAL}","title":"Add the balancer"},{"location":"kanban_tickets/loadtest_balancer/#check-the-elb","text":"If the customer site has an ELB, automation might add the testbal to the ELB rotation and cause an outage for the customer: ELB_NAME=$(ruby -e \"require 'aq'; site = Aq::Hosting::Site.from_query(name: '${SITE}'); \\ puts Aq::Hosting::SiteElb.fromQuery('site_id' => site['id']).record['elb_name']\") echo ${ELB_NAME} If there is an ELB, deregister the new balancer from it: TESTBAL_ID=$(ah-server list ${TESTBAL} --no-name -c ec2_id) aws elb deregister-instances-from-load-balancer --region ${REGION} \\ --load-balancer-name ${ELB_NAME} --instances ${TESTBAL_ID}","title":"Check the ELB"},{"location":"kanban_tickets/loadtest_balancer/#removing-a-load-test-balancer","text":"Set up Variables TESTBAL= SITES=( $(ah-site list on:${TESTBAL}) ) EIP=$(ah-server list ${TEST_BAL} -w eip_id!=nil --no-name -c external_ip) Remove all sites from the bal: for site in ${SITES[@]}; do ah-site bal remove ${site} --bals=${TESTBAL} done If the bal has an EIP, remove it: echo ${EIP} ah-elastic-ip remove ${EIP} ${TESTBAL} ah-elastic-ip release ${EIP} Suspend the bal: ah-server suspend ${TESTBAL}","title":"Removing a Load Test Balancer"},{"location":"kanban_tickets/logforward/","text":"Log Forwarding Log Forwarding via Ops Portal Manually Enabling Log Forwarding Disabling Log Forwarding Restarting Log Forwarding for Sumo Logic Diagnosing Log Forwarding to Sumo Logic Log Forwarding through Ops Portal Log forwarding should generally be done through the Ops Portal . If you cannot enable log forwarding through the portal, proceed to the following manual procedure. Manually Enabling Log Forwarding Steps for setting up Log Forwarding to client controlled log forward clusters, where splunk is the most common of the logging vendors. This is different and separate from Acquia controlled centralized logging, whose vendor is Sumologic, not discussed here. A Jira ticket will request a site will forward its syslogs or app logs to client controlled log forwarding clusters. Make note some log forward servers will have Splunk in the name and some will not, having a custom name instead. Splunk example: splunk.cloud.name.net:5140 Not-Splunk example: incoming.logs.digitalname.com:5514 Confluence has a list which outlines logs available for forwarding. To request Varnish logs, the balancers must be dedicated. Requirements Requests to enable log forwarding must include: The hostname or IP address of the remote log forward cluster The port A certificate (for authentication) Enable ACE Legacy Log Forwarding is being deprecated for ACE customers. See: Legacy Log Forward EOL on ACE Self-Service Log Forwarding is available for ACE customers now and they can follow below guide to enable/disable this feature on their own. Self-Service Log Forwarding ACSF Take the certificate from Jira and edit into a file in your home directory or /tmp directory on a bastion. vim /tmp/filename_in_ticket.pem CERT_PATH= Configure the site with the provided information. The certificate must be provided separately due to a quirk with -f . Interpret the ticket for name extension $EXTN ; with Splunk tickets it will be EXTN=splunk , note in OP-105262 it is not splunk but pfizerlogs. SITE= HOST= PORT= EXTN=[splunk,pfizerlogs,otherlogs] ah-log site edit ${SITE} -c \\ ${SITE}_${EXTN}:ip=${HOST} \\ ${SITE}_${EXTN}:port=${PORT} \\ ${SITE}_${EXTN}:certificate= \\ -f $CERT_PATH Often all sites in a sitegroup are requested SITEGROUP= for SITE in $(ah-site list % -w sitegroup=$SITEGROUP stage!=ra | paste -sd' ') ; do ah-log site edit ${SITE} -c \\ ${SITE}_${EXTN}:ip=${HOST} \\ ${SITE}_${EXTN}:port=${PORT} \\ ${SITE}_${EXTN}:certificate= \\ -f $CERT_PATH done NOTE The above command will enable log forwarding for all site environments except RA. If log forwarding also needs to be enabled for ra environment, please run the following command: for SITE in $(ah-site list % -w sitegroup=$SITEGROUP | paste -sd' ') ; do ah-log site edit ${SITE} -c \\ ${SITE}_${EXTN}:ip=${HOST} \\ ${SITE}_${EXTN}:port=${PORT} \\ ${SITE}_${EXTN}:certificate= \\ -f $CERT_PATH done Enabling Varnish logs on a dedicated balancer is almost the same as enabling forwarding for a site. You must run these commands for the customer's balancers regardless of whether or not you already enabled remote syslog forwarding for a site. Only proceed if the customer has specifically asked for varnish log forwarding. BALS=[bal1,bal2] ah-log server edit $BALS -c ${SITE}_${EXTN}:ip=$HOST ah-log server edit $BALS -c ${SITE}_${EXTN}:port=$PORT ah-log server edit $BALS -c ${SITE}_${EXTN}:certificate= -f $CERT_PATH ah-log server edit $BALS -c varnish:send_logs=1 fpdsh -l $BALS -c 'sudo ah-config-log' The send_logs option allows you to quickly enable and disable Varnish log forwarding in case the remote destination is overwhelmed by the traffic we send. You can set a custom prefix on a server log if a customer requests one. ah-log server edit $BALS -c ${SITE}_${EXTN}:prefix=$PREFIX Verify ACE Use below command to check if New Log Forwarding is enabled and running ah-log forwarding list --query ${SITE} NOTE: Above command displays output only if the new log forwarding is configured for the customer. ACSF Ensure log_status is on: value=2 . ah-server list site:$SITE -w type=web -c log_status If its value is not 2 , then run the following to edit the server status ah-server edit site:$SITE -w type=web -s log_status=2 Run ah-config-log from the staging|web, or ded if single tier fpdsh -t site:$SITE -n 'web|ded|staging' -c \"sudo ah-config-log\" There should not be Error connecting to remote logging destination. If there is an error in ah-config-log then determine if client has their side certificate is correct/configured. openssl s_client -showcerts -connect $HOST:$PORT -CAfile $CERT_PATH openssl s_client -connect $HOST:$PORT -showcerts Review log location for i in $(ah-site list % -w sitegroup=${SITEGROUP} | paste -sd' '); do echo $i ah-site get $i | grep logs done Check if td-agent is active and running on all the servers related to the site. fpdsh -t site:$SITE -n 'web|ded|staging' -c \"sudo systemctl status td-agent | grep Active\" Check for the pos file, where we store the last position of the forwarded log and see if it is getting updated. cat /var/log/sites/${SITE}/logs/${SERVER}/access.log.pos NOTE: td-agent setup is being monitoring with signalfx, so if logs stop processing cloud team gets alerted. Disable ACE First verify if new logrotate is configured and working fine. ah-log forwarding list --query ${SITE} NOTE: Above command displays only the details of new log forwarding. Unset the relevant variables to disable legacy log forwarding when you are sure that new log forwarding is enabled for the customer. ah-log site edit ${SITE} -c \\ ${SITE}_${EXTN}:certificate= \\ ${SITE}_${EXTN}:ip= \\ ${SITE}_${EXTN}:port= ACSF Unset the relevant variables. ah-log site edit ${SITE} -c \\ ${SITE}_${EXTN}:certificate= \\ ${SITE}_${EXTN}:ip= \\ ${SITE}_${EXTN}:port= Restarting Log forwarding for Sumo Logic Follow these steps when logs forwarding breaks down for customer Update the configuration files for logs by running the following command: fpdsh -t site:$SITE -n web -c \"sudo ah-config-log\" restart td-agent service on all the related servers by running the following command: fpdsh -t site:$SITE -n 'web|ded|staging' -c \"sudo service td-agent restart\" NOTE: We noticed that logs are not forwarded to Sumo Logic if log forwarding breaks down for customer at their end. We need to restart the log forwarding at our end in that case, specifically for trex. Example ticket: OP-218100. Diagnose log forwarding for Sumo Logic Follow these steps when logs are not being forwarded to Sumo Logic Make sure that logging is enabled for the particular site by running following command: SITE= ah-server list site:$SITE -w type=web -c log_status If logging is not enabled or you get the output as 1 for the corresponding servers, then you should enable the logging by running the following command: ah-server edit site:$SITE -w type=web -s log_status=2 Check for the pos file, where we store the last position of the forwarded log and see if it is getting updated cat /var/log/sites/${SITE}/logs/${SERVER}/access.log.pos Update the configuration files for logs by running the following command: fpdsh -t site:$SITE -n web -c \"sudo ah-config-log\" Troubleshooting td-agent and New Log Forwarding issues Follow the steps mentioned in below confluence link to troubleshoot issues on td-agent: Troubleshooting td-agent Follow below steps to troubleshoot issues on New Log Forwarding: Troubleshooting Log Forwarding NOTE: td-agent setup is being monitoring with signalfx, so if logs stop processing cloud team gets alerted.","title":"Log Forwarding"},{"location":"kanban_tickets/logforward/#log-forwarding","text":"Log Forwarding via Ops Portal Manually Enabling Log Forwarding Disabling Log Forwarding Restarting Log Forwarding for Sumo Logic Diagnosing Log Forwarding to Sumo Logic","title":"Log Forwarding"},{"location":"kanban_tickets/logforward/#log-forwarding-through-ops-portal","text":"Log forwarding should generally be done through the Ops Portal . If you cannot enable log forwarding through the portal, proceed to the following manual procedure.","title":"Log Forwarding through Ops Portal"},{"location":"kanban_tickets/logforward/#manually-enabling-log-forwarding","text":"Steps for setting up Log Forwarding to client controlled log forward clusters, where splunk is the most common of the logging vendors. This is different and separate from Acquia controlled centralized logging, whose vendor is Sumologic, not discussed here. A Jira ticket will request a site will forward its syslogs or app logs to client controlled log forwarding clusters. Make note some log forward servers will have Splunk in the name and some will not, having a custom name instead. Splunk example: splunk.cloud.name.net:5140 Not-Splunk example: incoming.logs.digitalname.com:5514 Confluence has a list which outlines logs available for forwarding. To request Varnish logs, the balancers must be dedicated.","title":"Manually Enabling Log Forwarding"},{"location":"kanban_tickets/logforward/#requirements","text":"Requests to enable log forwarding must include: The hostname or IP address of the remote log forward cluster The port A certificate (for authentication)","title":"Requirements"},{"location":"kanban_tickets/logforward/#enable","text":"","title":"Enable"},{"location":"kanban_tickets/logforward/#ace","text":"Legacy Log Forwarding is being deprecated for ACE customers. See: Legacy Log Forward EOL on ACE Self-Service Log Forwarding is available for ACE customers now and they can follow below guide to enable/disable this feature on their own. Self-Service Log Forwarding","title":"ACE"},{"location":"kanban_tickets/logforward/#acsf","text":"Take the certificate from Jira and edit into a file in your home directory or /tmp directory on a bastion. vim /tmp/filename_in_ticket.pem CERT_PATH= Configure the site with the provided information. The certificate must be provided separately due to a quirk with -f . Interpret the ticket for name extension $EXTN ; with Splunk tickets it will be EXTN=splunk , note in OP-105262 it is not splunk but pfizerlogs. SITE= HOST= PORT= EXTN=[splunk,pfizerlogs,otherlogs] ah-log site edit ${SITE} -c \\ ${SITE}_${EXTN}:ip=${HOST} \\ ${SITE}_${EXTN}:port=${PORT} \\ ${SITE}_${EXTN}:certificate= \\ -f $CERT_PATH Often all sites in a sitegroup are requested SITEGROUP= for SITE in $(ah-site list % -w sitegroup=$SITEGROUP stage!=ra | paste -sd' ') ; do ah-log site edit ${SITE} -c \\ ${SITE}_${EXTN}:ip=${HOST} \\ ${SITE}_${EXTN}:port=${PORT} \\ ${SITE}_${EXTN}:certificate= \\ -f $CERT_PATH done NOTE The above command will enable log forwarding for all site environments except RA. If log forwarding also needs to be enabled for ra environment, please run the following command: for SITE in $(ah-site list % -w sitegroup=$SITEGROUP | paste -sd' ') ; do ah-log site edit ${SITE} -c \\ ${SITE}_${EXTN}:ip=${HOST} \\ ${SITE}_${EXTN}:port=${PORT} \\ ${SITE}_${EXTN}:certificate= \\ -f $CERT_PATH done Enabling Varnish logs on a dedicated balancer is almost the same as enabling forwarding for a site. You must run these commands for the customer's balancers regardless of whether or not you already enabled remote syslog forwarding for a site. Only proceed if the customer has specifically asked for varnish log forwarding. BALS=[bal1,bal2] ah-log server edit $BALS -c ${SITE}_${EXTN}:ip=$HOST ah-log server edit $BALS -c ${SITE}_${EXTN}:port=$PORT ah-log server edit $BALS -c ${SITE}_${EXTN}:certificate= -f $CERT_PATH ah-log server edit $BALS -c varnish:send_logs=1 fpdsh -l $BALS -c 'sudo ah-config-log' The send_logs option allows you to quickly enable and disable Varnish log forwarding in case the remote destination is overwhelmed by the traffic we send. You can set a custom prefix on a server log if a customer requests one. ah-log server edit $BALS -c ${SITE}_${EXTN}:prefix=$PREFIX","title":"ACSF"},{"location":"kanban_tickets/logforward/#verify","text":"","title":"Verify"},{"location":"kanban_tickets/logforward/#ace_1","text":"Use below command to check if New Log Forwarding is enabled and running ah-log forwarding list --query ${SITE} NOTE: Above command displays output only if the new log forwarding is configured for the customer.","title":"ACE"},{"location":"kanban_tickets/logforward/#acsf_1","text":"Ensure log_status is on: value=2 . ah-server list site:$SITE -w type=web -c log_status If its value is not 2 , then run the following to edit the server status ah-server edit site:$SITE -w type=web -s log_status=2 Run ah-config-log from the staging|web, or ded if single tier fpdsh -t site:$SITE -n 'web|ded|staging' -c \"sudo ah-config-log\" There should not be Error connecting to remote logging destination. If there is an error in ah-config-log then determine if client has their side certificate is correct/configured. openssl s_client -showcerts -connect $HOST:$PORT -CAfile $CERT_PATH openssl s_client -connect $HOST:$PORT -showcerts Review log location for i in $(ah-site list % -w sitegroup=${SITEGROUP} | paste -sd' '); do echo $i ah-site get $i | grep logs done Check if td-agent is active and running on all the servers related to the site. fpdsh -t site:$SITE -n 'web|ded|staging' -c \"sudo systemctl status td-agent | grep Active\" Check for the pos file, where we store the last position of the forwarded log and see if it is getting updated. cat /var/log/sites/${SITE}/logs/${SERVER}/access.log.pos NOTE: td-agent setup is being monitoring with signalfx, so if logs stop processing cloud team gets alerted.","title":"ACSF"},{"location":"kanban_tickets/logforward/#disable","text":"","title":"Disable"},{"location":"kanban_tickets/logforward/#ace_2","text":"First verify if new logrotate is configured and working fine. ah-log forwarding list --query ${SITE} NOTE: Above command displays only the details of new log forwarding. Unset the relevant variables to disable legacy log forwarding when you are sure that new log forwarding is enabled for the customer. ah-log site edit ${SITE} -c \\ ${SITE}_${EXTN}:certificate= \\ ${SITE}_${EXTN}:ip= \\ ${SITE}_${EXTN}:port=","title":"ACE"},{"location":"kanban_tickets/logforward/#acsf_2","text":"Unset the relevant variables. ah-log site edit ${SITE} -c \\ ${SITE}_${EXTN}:certificate= \\ ${SITE}_${EXTN}:ip= \\ ${SITE}_${EXTN}:port=","title":"ACSF"},{"location":"kanban_tickets/logforward/#restarting-log-forwarding-for-sumo-logic","text":"","title":"Restarting Log forwarding for Sumo Logic"},{"location":"kanban_tickets/logforward/#follow-these-steps-when-logs-forwarding-breaks-down-for-customer","text":"Update the configuration files for logs by running the following command: fpdsh -t site:$SITE -n web -c \"sudo ah-config-log\" restart td-agent service on all the related servers by running the following command: fpdsh -t site:$SITE -n 'web|ded|staging' -c \"sudo service td-agent restart\" NOTE: We noticed that logs are not forwarded to Sumo Logic if log forwarding breaks down for customer at their end. We need to restart the log forwarding at our end in that case, specifically for trex. Example ticket: OP-218100.","title":"Follow these steps when logs forwarding breaks down for customer"},{"location":"kanban_tickets/logforward/#diagnose-log-forwarding-for-sumo-logic","text":"","title":"Diagnose log forwarding for Sumo Logic"},{"location":"kanban_tickets/logforward/#follow-these-steps-when-logs-are-not-being-forwarded-to-sumo-logic","text":"Make sure that logging is enabled for the particular site by running following command: SITE= ah-server list site:$SITE -w type=web -c log_status If logging is not enabled or you get the output as 1 for the corresponding servers, then you should enable the logging by running the following command: ah-server edit site:$SITE -w type=web -s log_status=2 Check for the pos file, where we store the last position of the forwarded log and see if it is getting updated cat /var/log/sites/${SITE}/logs/${SERVER}/access.log.pos Update the configuration files for logs by running the following command: fpdsh -t site:$SITE -n web -c \"sudo ah-config-log\"","title":"Follow these steps when logs are not being forwarded to Sumo Logic"},{"location":"kanban_tickets/logforward/#troubleshooting-td-agent-and-new-log-forwarding-issues","text":"Follow the steps mentioned in below confluence link to troubleshoot issues on td-agent: Troubleshooting td-agent Follow below steps to troubleshoot issues on New Log Forwarding: Troubleshooting Log Forwarding NOTE: td-agent setup is being monitoring with signalfx, so if logs stop processing cloud team gets alerted.","title":"Troubleshooting td-agent and New Log Forwarding issues"},{"location":"kanban_tickets/manage_end_to_end_encryption/","text":"Manage End To End Encryption E2E Encryption provides an encrypted connection (https) in each layer from the balancer to the database. See https://confluence.acquia.com/display/CL/E2E+encryption for more information. Preparation Create a list of sites. If all the sites begin with the same first few letters, you can query all of them with the glob (%) character. SITE_PREFIX= SITES=$(ah-site list $SITE_PREFIX%) Create arrays of database servers PRIMARY_DBS=($(for SITE in $(ah-site list $SITE_PREFIX% ); do ah-site get $SITE | egrep \"^\\s+db.db_servers.[[:digit:]]+\\:\" | awk -F ': ' '{print $2}' | head -n 1 ; done | sort -V | uniq )) SECONDARY_DBS=($(for SITE in $(ah-site list $SITE_PREFIX% ); do ah-site get $SITE | egrep \"^\\s+db.db_servers.[[:digit:]]+\\:\" | awk -F ': ' '{print $2}' | tail -n 1 ; done | sort -V | uniq )) DBS=($(for SITE in $(ah-site list $SITE_PREFIX% ); do ah-site get $SITE | egrep \"^\\s+db.db_servers.[[:digit:]]+\\:\" | awk -F ': ' '{print $2}' ; done | sort -V | uniq )) Create comma-delimited string lists of database servers STR_PRIMARY_DBS=($(for SITE in $(ah-site list $SITE_PREFIX% ); do ah-site get $SITE | egrep \"^\\s+db.db_servers.[[:digit:]]+\\:\" | awk -F ': ' '{print $2}' | head -n 1 ; done | sort -V | uniq | paste -sd, - )) STR_SECONDARY_DBS=($(for SITE in $(ah-site list $SITE_PREFIX% ); do ah-site get $SITE | egrep \"^\\s+db.db_servers.[[:digit:]]+\\:\" | awk -F ': ' '{print $2}' | tail -n 1 ; done | sort -V | uniq | paste -sd, - )) STR_DBS=($(for SITE in $(ah-site list $SITE_PREFIX% ); do ah-site get $SITE | egrep \"^\\s+db.db_servers.[[:digit:]]+\\:\" | awk -F ': ' '{print $2}' ; done | sort -V | uniq | paste -sd, - )) Confirm the variables echo $SITE_PREFIX echo $SITES echo ${PRIMARY_DBS[@]} echo ${SECONDARY_DBS[@]} echo ${DBS[@]} echo $STR_PRIMARY_DBS echo $STR_SECONDARY_DBS echo $STR_DBS Preparation: Get sitegroup, site names and servers Run the commands to get the lists: SITEGROUP=__from_maintenance_ticket__ SITES=$(ah-site list sitegroup:${SITEGROUP} | paste -sd' ') SERVERS=$(ah-server list sitegroup:${SITEGROUP} | \\ egrep 'ded|fsdb|dbmaster|srv|staging' | paste -sd,) Confirm the sites and servers: echo ${SITES} echo ${SERVERS} Enable E2E Encryption Run the command: ah-site enable-e2e-encryption --site-names=${SITES} Running this command will output: \u2714 Enabled End to End Encryption for $SITES Run the DB settings client program to apply the new settings. Note that this has to be done only one time per server, once at least one site on that server has had end to end encryption enabled fpdsh -t site:$SITE_PREFIX% -n 'ded|fsdb|dbmaster|srv|staging' -c 'sudo ah-config-mysql configure' Restart Mysql on the secondary databases. fpdsh -l $STR_SECONDARY_DBS -c 'sudo service mysql restart' Fail over the secondary databases sv-dbmultifailover $STR_SECONDARY_DBS Restart Mysql on the primary databases. fpdsh -l $PRIMARY_DBS -c 'sudo service mysql restart' Fail over the primary databases for PRIMARY_DB in ${PRIMARY_DBS[@]}; do sv-dbmultifailover $PRIMARY_DB; done Checking the E2E Installation Check the health of the MySQL service fpdsh -l $STR_DBS -c 'sudo service mysql status | egrep \"mysql.service - LSB|active\"' Ensure that the sites and the servers have E2E key pair ids ah-site list $SITE_PREFIX% -c e2e_key_pair_id ah-server list $STR_DBS -c e2e_key_pair_id Validate the web keypairs with openssl fpdsh -t site:$SITE_PREFIX% -n 'ded|web' -c 'sudo openssl verify -CAfile /etc/ssl/e2e-ca.pem /etc/ssl/default-httpd-e2e.pem; sudo openssl x509 -noout -subject -in /etc/ssl/default-httpd-e2e.pem; sudo openssl rsa -noout -check -in /etc/ssl/default-httpd-e2e.key' Validate the database keypairs with openssl fpdsh -t site:$SITE_PREFIX% -n 'ded|fsdb|dbmaster|srv|staging' -c 'sudo openssl verify -CAfile /var/lib/mysql/mysql-server-e2e-ca.pem /var/lib/mysql/mysql-server-e2e.pem; sudo openssl x509 -noout -subject -in /var/lib/mysql/mysql-server-e2e.pem; sudo openssl rsa -noout -check -in /var/lib/mysql/mysql-server-e2e.key' Confirm that SSL is enabled in the MySQL configuration fpdsh -t site:$SITE_PREFIX% -n 'ded|fsdb|dbmaster|srv|staging' -c \"sudo mysql -u root --execute=\\\"show variables like '%ssl%';\\\" | grep -F 'YES'\" Disable E2E Encryption Run the command: ah-site disable-e2e-encryption --site-names=${SITES} Running this command will output: \u2714 Disabled End to End Encryption for ${SITES} Note that no mysql restart is required for disabling end to end encryption for a site. Rotate E2E Encryption Keys Run the command: ah-site rotate-e2e-encryption --site-names=${SITES} Running this command will output: \u2714 Rotated End to End Encryption for ${SITES} Verifying the e2e configuration Verify that these commands all return ids: ah-site list sitegroup:${SITEGROUP} -c e2e_key_pair_id ah-server list ${SERVERS} -c e2e_key_pair_id Verify this command returns \"RSA key ok\": fpdsh -t sitegroup:${SITEGROUP} -n 'ded|web|srv|staging' -c \\ \"cd /etc/ssl/; \\ openssl verify -CAfile e2e-ca.pem default-httpd-e2e.pem; \\ openssl x509 -noout -subject -in default-httpd-e2e.pem; \\ openssl rsa -noout -check -in default-httpd-e2e.key\" Verify this command returns \"have_ssl YES\": fpdsh -l ${SERVERS} -c \"sudo mysql -u root \\ --execute=\\\"show variables like '%ssl%';\\\" | grep -F 'YES'\" Verify that all sites return \"success\": $SSL_CERTS_DIR= $SITE_NAME= $SUBJECT=Acquia $WEB_FQHN= sudo openssl s_client -CAfile $SSL_CERTS_DIR/ssl_$SITE_NAME.pem \\ -showcerts -servername $SUBJECT \\ -quiet -no_ign_eof -connect \\ $WEB_FQHN:443 < /dev/null 2>&1 \\ | grep -F 'CN = $SUBJECT'","title":"Manage End To End Encryption"},{"location":"kanban_tickets/manage_end_to_end_encryption/#manage-end-to-end-encryption","text":"E2E Encryption provides an encrypted connection (https) in each layer from the balancer to the database. See https://confluence.acquia.com/display/CL/E2E+encryption for more information.","title":"Manage End To End Encryption"},{"location":"kanban_tickets/manage_end_to_end_encryption/#preparation","text":"Create a list of sites. If all the sites begin with the same first few letters, you can query all of them with the glob (%) character. SITE_PREFIX= SITES=$(ah-site list $SITE_PREFIX%) Create arrays of database servers PRIMARY_DBS=($(for SITE in $(ah-site list $SITE_PREFIX% ); do ah-site get $SITE | egrep \"^\\s+db.db_servers.[[:digit:]]+\\:\" | awk -F ': ' '{print $2}' | head -n 1 ; done | sort -V | uniq )) SECONDARY_DBS=($(for SITE in $(ah-site list $SITE_PREFIX% ); do ah-site get $SITE | egrep \"^\\s+db.db_servers.[[:digit:]]+\\:\" | awk -F ': ' '{print $2}' | tail -n 1 ; done | sort -V | uniq )) DBS=($(for SITE in $(ah-site list $SITE_PREFIX% ); do ah-site get $SITE | egrep \"^\\s+db.db_servers.[[:digit:]]+\\:\" | awk -F ': ' '{print $2}' ; done | sort -V | uniq )) Create comma-delimited string lists of database servers STR_PRIMARY_DBS=($(for SITE in $(ah-site list $SITE_PREFIX% ); do ah-site get $SITE | egrep \"^\\s+db.db_servers.[[:digit:]]+\\:\" | awk -F ': ' '{print $2}' | head -n 1 ; done | sort -V | uniq | paste -sd, - )) STR_SECONDARY_DBS=($(for SITE in $(ah-site list $SITE_PREFIX% ); do ah-site get $SITE | egrep \"^\\s+db.db_servers.[[:digit:]]+\\:\" | awk -F ': ' '{print $2}' | tail -n 1 ; done | sort -V | uniq | paste -sd, - )) STR_DBS=($(for SITE in $(ah-site list $SITE_PREFIX% ); do ah-site get $SITE | egrep \"^\\s+db.db_servers.[[:digit:]]+\\:\" | awk -F ': ' '{print $2}' ; done | sort -V | uniq | paste -sd, - )) Confirm the variables echo $SITE_PREFIX echo $SITES echo ${PRIMARY_DBS[@]} echo ${SECONDARY_DBS[@]} echo ${DBS[@]} echo $STR_PRIMARY_DBS echo $STR_SECONDARY_DBS echo $STR_DBS","title":"Preparation"},{"location":"kanban_tickets/manage_end_to_end_encryption/#preparation-get-sitegroup-site-names-and-servers","text":"Run the commands to get the lists: SITEGROUP=__from_maintenance_ticket__ SITES=$(ah-site list sitegroup:${SITEGROUP} | paste -sd' ') SERVERS=$(ah-server list sitegroup:${SITEGROUP} | \\ egrep 'ded|fsdb|dbmaster|srv|staging' | paste -sd,) Confirm the sites and servers: echo ${SITES} echo ${SERVERS}","title":"Preparation: Get sitegroup, site names and servers"},{"location":"kanban_tickets/manage_end_to_end_encryption/#enable-e2e-encryption","text":"Run the command: ah-site enable-e2e-encryption --site-names=${SITES} Running this command will output: \u2714 Enabled End to End Encryption for $SITES Run the DB settings client program to apply the new settings. Note that this has to be done only one time per server, once at least one site on that server has had end to end encryption enabled fpdsh -t site:$SITE_PREFIX% -n 'ded|fsdb|dbmaster|srv|staging' -c 'sudo ah-config-mysql configure' Restart Mysql on the secondary databases. fpdsh -l $STR_SECONDARY_DBS -c 'sudo service mysql restart' Fail over the secondary databases sv-dbmultifailover $STR_SECONDARY_DBS Restart Mysql on the primary databases. fpdsh -l $PRIMARY_DBS -c 'sudo service mysql restart' Fail over the primary databases for PRIMARY_DB in ${PRIMARY_DBS[@]}; do sv-dbmultifailover $PRIMARY_DB; done","title":"Enable E2E Encryption"},{"location":"kanban_tickets/manage_end_to_end_encryption/#checking-the-e2e-installation","text":"Check the health of the MySQL service fpdsh -l $STR_DBS -c 'sudo service mysql status | egrep \"mysql.service - LSB|active\"' Ensure that the sites and the servers have E2E key pair ids ah-site list $SITE_PREFIX% -c e2e_key_pair_id ah-server list $STR_DBS -c e2e_key_pair_id Validate the web keypairs with openssl fpdsh -t site:$SITE_PREFIX% -n 'ded|web' -c 'sudo openssl verify -CAfile /etc/ssl/e2e-ca.pem /etc/ssl/default-httpd-e2e.pem; sudo openssl x509 -noout -subject -in /etc/ssl/default-httpd-e2e.pem; sudo openssl rsa -noout -check -in /etc/ssl/default-httpd-e2e.key' Validate the database keypairs with openssl fpdsh -t site:$SITE_PREFIX% -n 'ded|fsdb|dbmaster|srv|staging' -c 'sudo openssl verify -CAfile /var/lib/mysql/mysql-server-e2e-ca.pem /var/lib/mysql/mysql-server-e2e.pem; sudo openssl x509 -noout -subject -in /var/lib/mysql/mysql-server-e2e.pem; sudo openssl rsa -noout -check -in /var/lib/mysql/mysql-server-e2e.key' Confirm that SSL is enabled in the MySQL configuration fpdsh -t site:$SITE_PREFIX% -n 'ded|fsdb|dbmaster|srv|staging' -c \"sudo mysql -u root --execute=\\\"show variables like '%ssl%';\\\" | grep -F 'YES'\"","title":"Checking the E2E Installation"},{"location":"kanban_tickets/manage_end_to_end_encryption/#disable-e2e-encryption","text":"Run the command: ah-site disable-e2e-encryption --site-names=${SITES} Running this command will output: \u2714 Disabled End to End Encryption for ${SITES} Note that no mysql restart is required for disabling end to end encryption for a site.","title":"Disable E2E Encryption"},{"location":"kanban_tickets/manage_end_to_end_encryption/#rotate-e2e-encryption-keys","text":"Run the command: ah-site rotate-e2e-encryption --site-names=${SITES} Running this command will output: \u2714 Rotated End to End Encryption for ${SITES}","title":"Rotate E2E Encryption Keys"},{"location":"kanban_tickets/manage_end_to_end_encryption/#verifying-the-e2e-configuration","text":"Verify that these commands all return ids: ah-site list sitegroup:${SITEGROUP} -c e2e_key_pair_id ah-server list ${SERVERS} -c e2e_key_pair_id Verify this command returns \"RSA key ok\": fpdsh -t sitegroup:${SITEGROUP} -n 'ded|web|srv|staging' -c \\ \"cd /etc/ssl/; \\ openssl verify -CAfile e2e-ca.pem default-httpd-e2e.pem; \\ openssl x509 -noout -subject -in default-httpd-e2e.pem; \\ openssl rsa -noout -check -in default-httpd-e2e.key\" Verify this command returns \"have_ssl YES\": fpdsh -l ${SERVERS} -c \"sudo mysql -u root \\ --execute=\\\"show variables like '%ssl%';\\\" | grep -F 'YES'\" Verify that all sites return \"success\": $SSL_CERTS_DIR= $SITE_NAME= $SUBJECT=Acquia $WEB_FQHN= sudo openssl s_client -CAfile $SSL_CERTS_DIR/ssl_$SITE_NAME.pem \\ -showcerts -servername $SUBJECT \\ -quiet -no_ign_eof -connect \\ $WEB_FQHN:443 < /dev/null 2>&1 \\ | grep -F 'CN = $SUBJECT'","title":"Verifying the e2e configuration"},{"location":"kanban_tickets/masterless_puppet/","text":"Masterless Puppet Masterless Puppet is when the server is able to run puppet on its own without communicating with a Puppet Master. How to tell if a Server is Masterless Until Puppet Masters are removed there may be a question whether a server has Masterless Puppet enabled. On the server itself, you can check for the existence of /usr/local/bin/run-puppet which is how you can run puppet on a Masterless Puppet server. Alternatively you can use the ah* tools : ah-server get $SERVER | grep masterless Which will output the following if Masterless Puppet is enabled server_settings.feature_flag.use_masterless_puppet_apply: true For more information see ah-puppet-manifest","title":"Masterless Puppet"},{"location":"kanban_tickets/masterless_puppet/#masterless-puppet","text":"Masterless Puppet is when the server is able to run puppet on its own without communicating with a Puppet Master.","title":"Masterless Puppet"},{"location":"kanban_tickets/masterless_puppet/#how-to-tell-if-a-server-is-masterless","text":"Until Puppet Masters are removed there may be a question whether a server has Masterless Puppet enabled. On the server itself, you can check for the existence of /usr/local/bin/run-puppet which is how you can run puppet on a Masterless Puppet server. Alternatively you can use the ah* tools : ah-server get $SERVER | grep masterless Which will output the following if Masterless Puppet is enabled server_settings.feature_flag.use_masterless_puppet_apply: true For more information see ah-puppet-manifest","title":"How to tell if a Server is Masterless"},{"location":"kanban_tickets/move_customer_repo/","text":"Move Sitegroup Repo Moving a sitegroup's VCS repo is done using the ah-sitegroup command. This has been tested against both SVN and GIT repo types, as well as cross-region moves. ah-sitegroup move-repos ${SITEGROUP} ${NEW_SVN_SERVER} The last line of the output will be Upgrade completed. if the move was successful. NOTE : Ignore any output similar to the following. This is just an issue with the debug output, the command still runs correctly. [2013-08-29 05:28:48] scp #<StringIO:0x348c918> svn-6098.prod.hosting.acquia.com:/var/lib/svn/sjc-from-svn-6098/hooks/pre-commit Make sure to run below command on svn server once the sites are done being moved fields-config-svn.php Verify the site is moved correctly by ensuring that f-c-w runs on it and ensuring their server list specifies the new svn. site-fcw ${SITEGROUP} ah-server list site:${SITEGROUP} -w type=svn | sort -u Log into the server and archive the moved sitegroup repos by using below commands SITEGROUP= find /vol/ebs1/home/ -maxdepth 2 -type d -name \"MOVED-${SITEGROUP}.git*\" \\ -execdir sh -c \"tar -zcvf MOVED-${SITEGROUP}.tar.gz --remove-files MOVED-${SITEGROUP}.git*\" \\; Create a TSR ticket to remove the backup after 7 days. rm $MOVED-${SITEGROUP}.tar.gz Debugging If a sitegroup move-repos command fails with below error, that means there could be a repo of vcs type SVN , and we should mark them as DELETABLE . Traceback (most recent call last): . . . 3: from /mnt/apps/fields/1.143/aq/lib/aq/hosting/vcs_repo.rb:359:in `block in disable_commits' 2: from /mnt/apps/fields/1.143/aq/lib/aq/system.rb:59:in `exec' 1: from /mnt/apps/fields/1.143/aq/lib/aq/remote_system_via_sudo.rb:127:in `perform_exec_with_stderr' /mnt/apps/fields/1.143/aq/lib/aq/remote_system.rb:311:in `perform_exec_with_stderr': Command returned exit code 1: TERM=dumb sudo -u root -H bash -c rm\\ /var/lib/svn/alshayasf-from-svn-25/hooks/pre-commit (Aq::System::NonZeroStatusError) stdout was: stderr was: rm: cannot remove '/var/lib/svn/<site-name>-from-svn-25/hooks/pre-commit': No such file or directory Mark the svn repo as DELETABLE Get the repo_id for the sitegroup where vcs type is SVN . SITEGROUP= ah-site get sitegroup:${SITEGROUP} | grep \"vcs_type: \" | sort | uniq -c Below is the sample output: 5 sitegroup_object.vcs.17140.vcs_type: svn 5 sitegroup_object.vcs.17141.vcs_type: git 5 svn.vcs_type: git NOTE : Use the repo_id where vcs_type is svn in the below VcsRepo.from_id() function. Goto the realm on which the site could be and do the following. $ pry [1] pry(main)> v = VcsRepo.from_id(17140); [2] pry(main)> v.record['name'] => \"<repo-name>\" [3] pry(main)> v.record['vcs_type'] => \"svn\" [4] pry(main)> v.record['status'] => \"2001\" [9] pry(main)> v['status'] = Aq::Hosting::OBJECT_DELETABLE => 2002 [10] pry(main)> v.save => \"763\" Verify if the status change is saved or not. [11] pry(main)> v = VcsRepo.from_id(17140); [12] pry(main)> v.record['status'] => \"2002\" Note: In above PRY commands, 2002 is DELETABLE and 2001 is CREATED. Retry move repo Once the status is updated, retry moving sitegroup repo. ah-sitegroup move-repos ${SITEGROUP} ${NEW_SVN_SERVER}","title":"Move Sitegroup Repo"},{"location":"kanban_tickets/move_customer_repo/#move-sitegroup-repo","text":"Moving a sitegroup's VCS repo is done using the ah-sitegroup command. This has been tested against both SVN and GIT repo types, as well as cross-region moves. ah-sitegroup move-repos ${SITEGROUP} ${NEW_SVN_SERVER} The last line of the output will be Upgrade completed. if the move was successful. NOTE : Ignore any output similar to the following. This is just an issue with the debug output, the command still runs correctly. [2013-08-29 05:28:48] scp #<StringIO:0x348c918> svn-6098.prod.hosting.acquia.com:/var/lib/svn/sjc-from-svn-6098/hooks/pre-commit Make sure to run below command on svn server once the sites are done being moved fields-config-svn.php Verify the site is moved correctly by ensuring that f-c-w runs on it and ensuring their server list specifies the new svn. site-fcw ${SITEGROUP} ah-server list site:${SITEGROUP} -w type=svn | sort -u Log into the server and archive the moved sitegroup repos by using below commands SITEGROUP= find /vol/ebs1/home/ -maxdepth 2 -type d -name \"MOVED-${SITEGROUP}.git*\" \\ -execdir sh -c \"tar -zcvf MOVED-${SITEGROUP}.tar.gz --remove-files MOVED-${SITEGROUP}.git*\" \\; Create a TSR ticket to remove the backup after 7 days. rm $MOVED-${SITEGROUP}.tar.gz","title":"Move Sitegroup Repo"},{"location":"kanban_tickets/move_customer_repo/#debugging","text":"If a sitegroup move-repos command fails with below error, that means there could be a repo of vcs type SVN , and we should mark them as DELETABLE . Traceback (most recent call last): . . . 3: from /mnt/apps/fields/1.143/aq/lib/aq/hosting/vcs_repo.rb:359:in `block in disable_commits' 2: from /mnt/apps/fields/1.143/aq/lib/aq/system.rb:59:in `exec' 1: from /mnt/apps/fields/1.143/aq/lib/aq/remote_system_via_sudo.rb:127:in `perform_exec_with_stderr' /mnt/apps/fields/1.143/aq/lib/aq/remote_system.rb:311:in `perform_exec_with_stderr': Command returned exit code 1: TERM=dumb sudo -u root -H bash -c rm\\ /var/lib/svn/alshayasf-from-svn-25/hooks/pre-commit (Aq::System::NonZeroStatusError) stdout was: stderr was: rm: cannot remove '/var/lib/svn/<site-name>-from-svn-25/hooks/pre-commit': No such file or directory","title":"Debugging"},{"location":"kanban_tickets/move_customer_repo/#mark-the-svn-repo-as-deletable","text":"Get the repo_id for the sitegroup where vcs type is SVN . SITEGROUP= ah-site get sitegroup:${SITEGROUP} | grep \"vcs_type: \" | sort | uniq -c Below is the sample output: 5 sitegroup_object.vcs.17140.vcs_type: svn 5 sitegroup_object.vcs.17141.vcs_type: git 5 svn.vcs_type: git NOTE : Use the repo_id where vcs_type is svn in the below VcsRepo.from_id() function. Goto the realm on which the site could be and do the following. $ pry [1] pry(main)> v = VcsRepo.from_id(17140); [2] pry(main)> v.record['name'] => \"<repo-name>\" [3] pry(main)> v.record['vcs_type'] => \"svn\" [4] pry(main)> v.record['status'] => \"2001\" [9] pry(main)> v['status'] = Aq::Hosting::OBJECT_DELETABLE => 2002 [10] pry(main)> v.save => \"763\" Verify if the status change is saved or not. [11] pry(main)> v = VcsRepo.from_id(17140); [12] pry(main)> v.record['status'] => \"2002\" Note: In above PRY commands, 2002 is DELETABLE and 2001 is CREATED.","title":"Mark the svn repo as DELETABLE"},{"location":"kanban_tickets/move_customer_repo/#retry-move-repo","text":"Once the status is updated, retry moving sitegroup repo. ah-sitegroup move-repos ${SITEGROUP} ${NEW_SVN_SERVER}","title":"Retry move repo"},{"location":"kanban_tickets/move_provisioning_pointer/","text":"Moving the Index Provisioning Pointer Information The Search Governor maintains a page that determines where new indexes in a given colony will be provisioned . If you have recently provisioned a new farm into a shared colony: Log into the Governor using the above URL. Find the colony in the list that you just provisioned a farm for. Select the farm ID that you have recently provisioned. Scroll to the bottom of the page and click \"Save\". This should ensure that new indexes that are created for a given colony are created on the selected farm.","title":"Moving the Index Provisioning Pointer"},{"location":"kanban_tickets/move_provisioning_pointer/#moving-the-index-provisioning-pointer","text":"","title":"Moving the Index Provisioning Pointer"},{"location":"kanban_tickets/move_provisioning_pointer/#information","text":"The Search Governor maintains a page that determines where new indexes in a given colony will be provisioned . If you have recently provisioned a new farm into a shared colony: Log into the Governor using the above URL. Find the colony in the list that you just provisioned a farm for. Select the farm ID that you have recently provisioned. Scroll to the bottom of the page and click \"Save\". This should ensure that new indexes that are created for a given colony are created on the selected farm.","title":"Information"},{"location":"kanban_tickets/multi_region_failover_testing/","text":"Performing a Multi-Region Failover Test Pre-Flight Notification should be sent to Operations Chat so that hotseat is aware of the failover test prior to the start time: @OpsBot alerts who Communication should be established with the TAM as they will be communicating with the customer not operations. Ensure balancers are ONLY assigned to the site being tested against! Set up some Variables SITE= JIRA= PRIMARY_REGION= SECONDARY_REGION= DRUSH_SITENAME=$(ah-site list ${SITE} -c sitegroup stage --no-name|sed 's/, /./') PRIMARY_REGION_PRIMARY_DB=$(ah-server list site:${SITE} \\ -w typeINfsdbmesh,dbmesh ec2_region=${PRIMARY_REGION} \\ | head -n1) PRIMARY_REGION_SECONDARY_DB=$(ah-server list site:${SITE} \\ -w typeINfsdbmesh,dbmesh ec2_region=${PRIMARY_REGION} \\ | tail -n1) SECONDARY_REGION_PRIMARY_DB=$(ah-server list site:${SITE} \\ -w typeINfsdbmesh,dbmesh ec2_region=${SECONDARY_REGION} \\ | head -n1) SECONDARY_REGION_SECONDARY_DB=$(ah-server list site:${SITE} \\ -w typeINfsdbmesh,dbmesh ec2_region=${SECONDARY_REGION} \\ | tail -n1) PRIMARY_WEBS=$(ah-server list site:${SITE} -w type=web ec2_region=${PRIMARY_REGION} status=0 | paste -sd,) SECONDARY_WEBS=$(ah-server list site:${SITE} -w type=web ec2_region=${SECONDARY_REGION} status=0 | paste -sd,) PRIMARY_WEB1=$(ah-server list site:${SITE} -w type=web ec2_region=${PRIMARY_REGION} status=0 | head -1) SECONDARY_WEB1=$(ah-server list site:${SITE} -w type=web ec2_region=${SECONDARY_REGION} status=0 | head -1) DRUPAL_VERSION=$(fssh ${PRIMARY_WEB1} \\ \"sudo su -c 'drush8 @${DRUSH_SITENAME} status' | awk '/Drupal version/ {print substr (\\$NF, 1, 1)}'\") Verify all of these variables before moving forward. Validate and Document that the Site is Healthy Prior to Initiating the Failover Gather the current hardware list esl ${SITE} Document the current ah-mrrsync cron task CRONJOB=$(ah-site cron2 list --site-name=${SITE} | grep ah-mrrsync | awk 'match($0, /[0-9a-fA-F]{8}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{12}/) {print substr( $0, RSTART, RLENGTH )}') ah-site cron2 list --site-name=${SITE} | grep ${CRONJOB} Verify Tungsten Replication Status site-tungstatus ${SITE} Ensure the cluster is not currently locked ah-db-cluster status ${PRIMARY_REGION_PRIMARY_DB} If it is currently locked or lagging, notify the TAM, ABORT , and investigate/escalate. Simulate a Region Outage, at this time the TAM should instruct the customer to fail over DNS to their Secondary Region Downtime the hosts so that hotseat is not alerted for bal in $(ah-server list site:${SITE} -w type=bal); do sv-downtime ${bal} 75 \"${JIRA} MR failover test\"; done Stop Services fpdsh -t site:${SITE} -n bal -r ${PRIMARY_REGION} -c \\ \"sudo puppet agent --disable '${JIRA} - MR failover test'; sudo service varnish stop; sudo service nginx stop\" OR in Masterless Puppet mode fpdsh -t site:${SITE} -n bal -r ${PRIMARY_REGION} -c \\ \"sudo ah-puppet-disable '${JIRA} - MR failover test'; sudo service varnish stop; sudo service nginx stop\" Initiate the Multi-Region Failover to the Secondary Region Failover to the Secondary Region ah-site edit ${SITE} -s active_region=${SECONDARY_REGION} Clear cache in the secondary region fpdsh -l ${SECONDARY_WEBS} -c 'sudo service memcached restart ; sudo fields-config-memcached.php' if [[ ${DRUPAL_VERSION} -ge 8 ]]; then fssh ${SECONDARY_WEB1} \"sudo su -c \\ '/mnt/users/${DRUSH_SITENAME%.*}/${DRUSH_SITENAME#*.}.shell drush @${DRUSH_SITENAME} cr' ${DRUSH_SITENAME}\" else fssh ${SECONDARY_WEB1} \"sudo su -c \\ '/mnt/users/${DRUSH_SITENAME%.*}/${DRUSH_SITENAME#*.}.shell drush @${DRUSH_SITENAME} cc all' ${DRUSH_SITENAME}\" fi Migrate Crons for ah-mrrsync , reset the cron variable, and document the change ah-site cron2 delete --uuid=${CRONJOB} UUID=$(ruby -e \"require 'securerandom' ; puts SecureRandom.uuid\") ah-site cron2 add --command=\"/usr/local/sbin/ah-mrrsync ${SITE}\" \\ --day-month=\"*\" --day-week=\"*\" --env-uuid=$(ah-site list ${SITE} -c uuid --no-name) --hour=\"*\" --minute=\"*/30\" --month=\"*\" --name= --uuid=${UUID} --server_name=${SECONDARY_WEB1} CRONJOB=$(ah-site cron2 list --site-name=${SITE} | grep ah-mrrsync | awk 'match($0, /[0-9a-fA-F]{8}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{12}/) {print substr( $0, RSTART, RLENGTH )}') ah-site cron2 list --site-name=${SITE} | grep ${CRONJOB} Initiate an ah-mrrsync from the Primary Region to the Secondary Region fssh ${PRIMARY_WEB1} su - ${SITE} /usr/local/sbin/ah-mrrsync ${SITE} Notify the TAM that any customer-specified cron jobs must be moved from PRIMARY_REGION to SECONDARY_REGION Begin the Multi-Region Fail-back to the Primary Region Reverse the test by bringing the site back to the Primary Region once the customer and TAM has confirmed a successful failover. Typically the customer or TAM will add content and validate that the rsync is working as expected. At this time the TAM should instruct the customer to also fail their DNS back to the Primary Region. Check that Tungsten Replication is okay site-tungstatus ${SITE} Document the current ah-mrrsync cron task CRONJOB=$(ah-site cron2 list --site-name=${SITE} | grep ah-mrrsync | awk 'match($0, /[0-9a-fA-F]{8}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{12}/) {print substr( $0, RSTART, RLENGTH )}') ah-site cron2 list --site-name=${SITE} | grep ${CRONJOB} Re-enable Services in the Primary Region fpdsh -t site:${SITE} -n bal -r ${PRIMARY_REGION} -c \\ \"sudo service nginx start; sudo service varnish start; sudo puppet agent --enable; sudo puppet agent -t\" OR in Masterless Puppet mode fpdsh -t site:${SITE} -n bal -r ${PRIMARY_REGION} -c \\ \"sudo service nginx start; sudo service varnish start; sudo ah-puppet-enable; sudo run-puppet\" Migrate Crons for ah-mrrsync , reset the cron variable, and document the change ah-site cron2 delete --uuid=${CRONJOB} UUID=$(ruby -e \"require 'securerandom' ; puts SecureRandom.uuid\") ah-site cron2 add --command=\"/usr/local/sbin/ah-mrrsync ${SITE}\" \\ --day-month=\"*\" --day-week=\"*\" --env-uuid=$(ah-site list ${SITE} -c uuid --no-name) --hour=\"*\" --minute=\"*/30\" --month=\"*\" --name= --uuid=${UUID} --server_name=${PRIMARY_WEB1} CRONJOB=$(ah-site cron2 list --site-name=${SITE} | grep ah-mrrsync | awk 'match($0, /[0-9a-fA-F]{8}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{12}/) {print substr( $0, RSTART, RLENGTH )}') ah-site cron2 list --site-name=${SITE} | grep ${CRONJOB} Set active_region back to primary region ah-site edit ${SITE} -s active_region=${PRIMARY_REGION} Clear Cache fpdsh -l ${PRIMARY_WEBS} -c 'sudo service memcached restart ; sudo fields-config-memcached.php' if [[ ${DRUPAL_VERSION} -ge 8 ]]; then fssh ${PRIMARY_WEB1} \"sudo su -c \\ '/mnt/users/${DRUSH_SITENAME%.*}/${DRUSH_SITENAME#*.}.shell drush @${DRUSH_SITENAME} cr' ${DRUSH_SITENAME}\" else fssh ${PRIMARY_WEB1} \"sudo su -c \\ '/mnt/users/${DRUSH_SITENAME%.*}/${DRUSH_SITENAME#*.}.shell drush @${DRUSH_SITENAME} cc all' ${DRUSH_SITENAME}\" fi Notify the TAM that any customer-specified cron jobs must be moved from SECONDARY_REGION to PRIMARY_REGION Perform Health Checks and Document the Output in the ticket Gather the Hardware list once again esl ${SITE} Validate Health Checks site-checkwebs ${SITE} site-checkgluster ${SITE} site-tungstatus ${SITE} ah-site list ${SITE} -c active_region Confirm with the TAM that testing is complete.","title":"Performing a Multi-Region Failover Test"},{"location":"kanban_tickets/multi_region_failover_testing/#performing-a-multi-region-failover-test","text":"","title":"Performing a Multi-Region Failover Test"},{"location":"kanban_tickets/multi_region_failover_testing/#pre-flight","text":"Notification should be sent to Operations Chat so that hotseat is aware of the failover test prior to the start time: @OpsBot alerts who Communication should be established with the TAM as they will be communicating with the customer not operations. Ensure balancers are ONLY assigned to the site being tested against!","title":"Pre-Flight"},{"location":"kanban_tickets/multi_region_failover_testing/#set-up-some-variables","text":"SITE= JIRA= PRIMARY_REGION= SECONDARY_REGION= DRUSH_SITENAME=$(ah-site list ${SITE} -c sitegroup stage --no-name|sed 's/, /./') PRIMARY_REGION_PRIMARY_DB=$(ah-server list site:${SITE} \\ -w typeINfsdbmesh,dbmesh ec2_region=${PRIMARY_REGION} \\ | head -n1) PRIMARY_REGION_SECONDARY_DB=$(ah-server list site:${SITE} \\ -w typeINfsdbmesh,dbmesh ec2_region=${PRIMARY_REGION} \\ | tail -n1) SECONDARY_REGION_PRIMARY_DB=$(ah-server list site:${SITE} \\ -w typeINfsdbmesh,dbmesh ec2_region=${SECONDARY_REGION} \\ | head -n1) SECONDARY_REGION_SECONDARY_DB=$(ah-server list site:${SITE} \\ -w typeINfsdbmesh,dbmesh ec2_region=${SECONDARY_REGION} \\ | tail -n1) PRIMARY_WEBS=$(ah-server list site:${SITE} -w type=web ec2_region=${PRIMARY_REGION} status=0 | paste -sd,) SECONDARY_WEBS=$(ah-server list site:${SITE} -w type=web ec2_region=${SECONDARY_REGION} status=0 | paste -sd,) PRIMARY_WEB1=$(ah-server list site:${SITE} -w type=web ec2_region=${PRIMARY_REGION} status=0 | head -1) SECONDARY_WEB1=$(ah-server list site:${SITE} -w type=web ec2_region=${SECONDARY_REGION} status=0 | head -1) DRUPAL_VERSION=$(fssh ${PRIMARY_WEB1} \\ \"sudo su -c 'drush8 @${DRUSH_SITENAME} status' | awk '/Drupal version/ {print substr (\\$NF, 1, 1)}'\") Verify all of these variables before moving forward.","title":"Set up some Variables"},{"location":"kanban_tickets/multi_region_failover_testing/#validate-and-document-that-the-site-is-healthy-prior-to-initiating-the-failover","text":"Gather the current hardware list esl ${SITE} Document the current ah-mrrsync cron task CRONJOB=$(ah-site cron2 list --site-name=${SITE} | grep ah-mrrsync | awk 'match($0, /[0-9a-fA-F]{8}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{12}/) {print substr( $0, RSTART, RLENGTH )}') ah-site cron2 list --site-name=${SITE} | grep ${CRONJOB} Verify Tungsten Replication Status site-tungstatus ${SITE} Ensure the cluster is not currently locked ah-db-cluster status ${PRIMARY_REGION_PRIMARY_DB} If it is currently locked or lagging, notify the TAM, ABORT , and investigate/escalate.","title":"Validate and Document that the Site is Healthy Prior to Initiating the Failover"},{"location":"kanban_tickets/multi_region_failover_testing/#simulate-a-region-outage-at-this-time-the-tam-should-instruct-the-customer-to-fail-over-dns-to-their-secondary-region","text":"Downtime the hosts so that hotseat is not alerted for bal in $(ah-server list site:${SITE} -w type=bal); do sv-downtime ${bal} 75 \"${JIRA} MR failover test\"; done Stop Services fpdsh -t site:${SITE} -n bal -r ${PRIMARY_REGION} -c \\ \"sudo puppet agent --disable '${JIRA} - MR failover test'; sudo service varnish stop; sudo service nginx stop\" OR in Masterless Puppet mode fpdsh -t site:${SITE} -n bal -r ${PRIMARY_REGION} -c \\ \"sudo ah-puppet-disable '${JIRA} - MR failover test'; sudo service varnish stop; sudo service nginx stop\"","title":"Simulate a Region Outage, at this time the TAM should instruct the customer to fail over DNS to their Secondary Region"},{"location":"kanban_tickets/multi_region_failover_testing/#initiate-the-multi-region-failover-to-the-secondary-region","text":"Failover to the Secondary Region ah-site edit ${SITE} -s active_region=${SECONDARY_REGION} Clear cache in the secondary region fpdsh -l ${SECONDARY_WEBS} -c 'sudo service memcached restart ; sudo fields-config-memcached.php' if [[ ${DRUPAL_VERSION} -ge 8 ]]; then fssh ${SECONDARY_WEB1} \"sudo su -c \\ '/mnt/users/${DRUSH_SITENAME%.*}/${DRUSH_SITENAME#*.}.shell drush @${DRUSH_SITENAME} cr' ${DRUSH_SITENAME}\" else fssh ${SECONDARY_WEB1} \"sudo su -c \\ '/mnt/users/${DRUSH_SITENAME%.*}/${DRUSH_SITENAME#*.}.shell drush @${DRUSH_SITENAME} cc all' ${DRUSH_SITENAME}\" fi Migrate Crons for ah-mrrsync , reset the cron variable, and document the change ah-site cron2 delete --uuid=${CRONJOB} UUID=$(ruby -e \"require 'securerandom' ; puts SecureRandom.uuid\") ah-site cron2 add --command=\"/usr/local/sbin/ah-mrrsync ${SITE}\" \\ --day-month=\"*\" --day-week=\"*\" --env-uuid=$(ah-site list ${SITE} -c uuid --no-name) --hour=\"*\" --minute=\"*/30\" --month=\"*\" --name= --uuid=${UUID} --server_name=${SECONDARY_WEB1} CRONJOB=$(ah-site cron2 list --site-name=${SITE} | grep ah-mrrsync | awk 'match($0, /[0-9a-fA-F]{8}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{12}/) {print substr( $0, RSTART, RLENGTH )}') ah-site cron2 list --site-name=${SITE} | grep ${CRONJOB} Initiate an ah-mrrsync from the Primary Region to the Secondary Region fssh ${PRIMARY_WEB1} su - ${SITE} /usr/local/sbin/ah-mrrsync ${SITE} Notify the TAM that any customer-specified cron jobs must be moved from PRIMARY_REGION to SECONDARY_REGION","title":"Initiate the Multi-Region Failover to the Secondary Region"},{"location":"kanban_tickets/multi_region_failover_testing/#begin-the-multi-region-fail-back-to-the-primary-region","text":"Reverse the test by bringing the site back to the Primary Region once the customer and TAM has confirmed a successful failover. Typically the customer or TAM will add content and validate that the rsync is working as expected. At this time the TAM should instruct the customer to also fail their DNS back to the Primary Region. Check that Tungsten Replication is okay site-tungstatus ${SITE} Document the current ah-mrrsync cron task CRONJOB=$(ah-site cron2 list --site-name=${SITE} | grep ah-mrrsync | awk 'match($0, /[0-9a-fA-F]{8}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{12}/) {print substr( $0, RSTART, RLENGTH )}') ah-site cron2 list --site-name=${SITE} | grep ${CRONJOB} Re-enable Services in the Primary Region fpdsh -t site:${SITE} -n bal -r ${PRIMARY_REGION} -c \\ \"sudo service nginx start; sudo service varnish start; sudo puppet agent --enable; sudo puppet agent -t\" OR in Masterless Puppet mode fpdsh -t site:${SITE} -n bal -r ${PRIMARY_REGION} -c \\ \"sudo service nginx start; sudo service varnish start; sudo ah-puppet-enable; sudo run-puppet\" Migrate Crons for ah-mrrsync , reset the cron variable, and document the change ah-site cron2 delete --uuid=${CRONJOB} UUID=$(ruby -e \"require 'securerandom' ; puts SecureRandom.uuid\") ah-site cron2 add --command=\"/usr/local/sbin/ah-mrrsync ${SITE}\" \\ --day-month=\"*\" --day-week=\"*\" --env-uuid=$(ah-site list ${SITE} -c uuid --no-name) --hour=\"*\" --minute=\"*/30\" --month=\"*\" --name= --uuid=${UUID} --server_name=${PRIMARY_WEB1} CRONJOB=$(ah-site cron2 list --site-name=${SITE} | grep ah-mrrsync | awk 'match($0, /[0-9a-fA-F]{8}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{12}/) {print substr( $0, RSTART, RLENGTH )}') ah-site cron2 list --site-name=${SITE} | grep ${CRONJOB} Set active_region back to primary region ah-site edit ${SITE} -s active_region=${PRIMARY_REGION} Clear Cache fpdsh -l ${PRIMARY_WEBS} -c 'sudo service memcached restart ; sudo fields-config-memcached.php' if [[ ${DRUPAL_VERSION} -ge 8 ]]; then fssh ${PRIMARY_WEB1} \"sudo su -c \\ '/mnt/users/${DRUSH_SITENAME%.*}/${DRUSH_SITENAME#*.}.shell drush @${DRUSH_SITENAME} cr' ${DRUSH_SITENAME}\" else fssh ${PRIMARY_WEB1} \"sudo su -c \\ '/mnt/users/${DRUSH_SITENAME%.*}/${DRUSH_SITENAME#*.}.shell drush @${DRUSH_SITENAME} cc all' ${DRUSH_SITENAME}\" fi Notify the TAM that any customer-specified cron jobs must be moved from SECONDARY_REGION to PRIMARY_REGION","title":"Begin the Multi-Region Fail-back to the Primary Region"},{"location":"kanban_tickets/multi_region_failover_testing/#perform-health-checks-and-document-the-output-in-the-ticket","text":"Gather the Hardware list once again esl ${SITE} Validate Health Checks site-checkwebs ${SITE} site-checkgluster ${SITE} site-tungstatus ${SITE} ah-site list ${SITE} -c active_region Confirm with the TAM that testing is complete.","title":"Perform Health Checks and Document the Output in the ticket"},{"location":"kanban_tickets/multi_tier_to_full_tier/","text":"Multi-tier to Full-tier Upsize Converting a customer's stack to full-tier (AKA super beef three-way ) is an involved process, during which a customer's site will not be available. Due to the historic difficulty of converting a stack to full-tier manually, Ops now prefers to perform these conversions by provisioning a new stack and moving affected sites to the new hardware. Prep Set up your variables: For most multi- to full-tier conversions, we can use the same variables as the FS server the customer is currently running on. SOURCE_SRV here should be one of the customer's storage servers (I.e. ded or fsdb ): SOURCE_SRV= SITES=($(ah-site list on:${SOURCE_SRV})) REGION=$(ah-server list ${SOURCE_SRV} --no-name -c ec2_region) FS_CLSTR=$(ah-server list ${SOURCE_SRV} --no-name -c fs_cluster_id) AZS=($(ah-server list % -w fs_cluster_id=${FS_CLSTR} --no-name -c ec2_availability_zone | sort -u)) VPC_ID=$(ah-server list ${SOURCE_SRV} --no-name -c vpc_id) VPC_NAME=$(ah-vpc list % -w id=${VPC_ID}) [[ -n ${VPC_NAME} ]] && VPC_OPTION=\"-V ${VPC_NAME}\" FS_NAME=$(date +%s) Volume and AMI specs need to be manually set. If the AMI types are not specified in the ticket or its dealsheet, ask the ticket requester for clarification before proceeding. Volume type must be either gp3 or standard . sv-vollist ${SOURCE_SRV} DB_AMI= DB_VOL_SIZE= DB_VOL_TYPE= FS_AMI= FS_VOL_SIZE= FS_VOL_TYPE= Set up the number and AMI type for the destination stack's webs. If these are not specified in the ticket or its dealsheet, template them off of the customer's current setup: WEB_AMI= WEB_NUM= Review the variables for accuracy and modify them appropriately to match the requirements of the ticket: echo \"{noformat:title=Variables}\" \\ && echo \"SOURCE_SRV=${SOURCE_SRV}\" \\ && echo \"SITES=(${SITES[@]})\" \\ && echo \"REGION=${REGION}\" \\ && echo \"AZS=(${AZS[@]})\" \\ && echo \"VPC_OPTION=\\\"${VPC_OPTION}\\\"\" \\ && echo \"DB_AMI=${DB_AMI}\" \\ && echo \"DB_VOL_SIZE=${DB_VOL_SIZE}\" \\ && echo \"DB_VOL_TYPE=${DB_VOL_TYPE}\" \\ && echo \"FS_AMI=${FS_AMI}\" \\ && echo \"FS_VOL_SIZE=${FS_VOL_SIZE}\" \\ && echo \"FS_VOL_TYPE=${FS_VOL_TYPE}\" \\ && echo \"FS_NAME=${FS_NAME}\" \\ && echo \"WEB_AMI=${WEB_AMI}\" \\ && echo \"WEB_NUM=${WEB_NUM}\" \\ && echo \"{noformat}\" Note : Make sure everything here is accurate before proceeding! Provision the new stack and save the output server names appropriately: ah-provision stack web-db-fs -r ${REGION} -z ${AZS[@]} ${VPC_OPTION} \\ -D ${DB_AMI} -d ${DB_VOL_SIZE} --de --database-storage-type=${DB_VOL_TYPE} \\ -f ${FS_AMI} -g ${FS_VOL_SIZE} --ge --gt ${FS_VOL_TYPE} -n ${FS_NAME} \\ -w ${WEB_AMI} -c ${WEB_NUM} NEW_SRVS= Verify! Verify that all the servers have the correct VPC, AMI types, availability zones: ah-server list ${NEW_SRVS} -c ami_type ec2_availability_zone vpc_id Verify that all volumes are encrypted and are the correct type and size: sv-vollist ${NEW_SRVS} Launch the stack: sv-taskrelaunch server -m1 ${NEW_SRVS} Follow this runbook to perform an initial rsync from the old FS volume to the new one. This will help speed up the workflow during the maintenance window. We use a temporary SSH key here because sv-rsync has difficulty handling large migrations. Notes: Make sure to run the rsync in a screen session, since it may take a while to complete for large FS volumes. Don't forget to clean up the temporary SSH key once the prepatory migration is complete. Use trailing slashes on the path names for rsync to preserve directory structure. For example: rsync -auvPe 'ssh -i KEY_PATH' /mnt/gfs/ DST_SRV:/mnt/gfs/ If you are doing this in a maintenance prep ticket, update the maintenance ticket with the following information: echo \"{noformat:title=New Stack}\" \\ && echo \"OLD_SRV=${SOURCE_SRV}\" \\ && echo \"NEW_SRVS=${NEW_SRVS}\" \\ && echo \"{noformat}\" Maintenance Window This maintenance procedure assumes that the customer's FS volume was rsync'd in preparation and is moderately sized. However, customers with especially large FS volumes and/or more than 1 million inodes risk running over the maintenance window, even in the best circumstances. There isn't much we can do to avoid this, so communicate this fact appropriately to the Ops Coordinators and Account Managers if it happens. Site Move Procedure Set up variables: Copy the server lists created in the prep ticket, if applicable. If not, set OLD_SRV to the primary FS/DB server in the old stack, and NEW_SRVS to comma-separated list of all newly provisioned servers to move the site(s) to: OLD_SRV= NEW_SRVS= Set up variables for the new stack for the site move: SITES=($(ah-site list on:${OLD_SRV})) NEW_WEBS=($(ah-server list ${NEW_SRVS} -w type=web)) NEW_DB=($(ah-server list ${NEW_SRVS} -w type=dbmaster | head -n1)) Also set up variables for the old stack so we can clean it up when we're done: OLD_FS_CLUSTER=$(ah-server list ${OLD_SRV} --no-name -c fs_cluster_id) OLD_SRVS=($(ah-server list % -w fs_cluster_id=${OLD_FS_CLUSTER})) Verify your variables and make sure they match the requirements of the maintenenace ticket. Move the sites to the new stack: for site in ${SITES[@]}; do ah-site move ${site} --webs ${NEW_WEBS[@]} --db ${NEW_DB} --force done Complete all follow-up steps as appropriate for a normal site-move, particularly for managing EIPs and ELBs by following the normal site move runbook . Cleanup Check the old servers to see if they have any sites left on them: site-list -s $(array-csv ${OLD_SRVS[@]}) If any servers no longer have sites on them, suspend them: SERVERS_CSV= ah-server suspend ${SERVERS_CSV} Create a TSR ticket to terminate these suspended servers in 7 days.","title":"Multi-tier to Full-tier Upsize"},{"location":"kanban_tickets/multi_tier_to_full_tier/#multi-tier-to-full-tier-upsize","text":"Converting a customer's stack to full-tier (AKA super beef three-way ) is an involved process, during which a customer's site will not be available. Due to the historic difficulty of converting a stack to full-tier manually, Ops now prefers to perform these conversions by provisioning a new stack and moving affected sites to the new hardware.","title":"Multi-tier to Full-tier Upsize"},{"location":"kanban_tickets/multi_tier_to_full_tier/#prep","text":"Set up your variables: For most multi- to full-tier conversions, we can use the same variables as the FS server the customer is currently running on. SOURCE_SRV here should be one of the customer's storage servers (I.e. ded or fsdb ): SOURCE_SRV= SITES=($(ah-site list on:${SOURCE_SRV})) REGION=$(ah-server list ${SOURCE_SRV} --no-name -c ec2_region) FS_CLSTR=$(ah-server list ${SOURCE_SRV} --no-name -c fs_cluster_id) AZS=($(ah-server list % -w fs_cluster_id=${FS_CLSTR} --no-name -c ec2_availability_zone | sort -u)) VPC_ID=$(ah-server list ${SOURCE_SRV} --no-name -c vpc_id) VPC_NAME=$(ah-vpc list % -w id=${VPC_ID}) [[ -n ${VPC_NAME} ]] && VPC_OPTION=\"-V ${VPC_NAME}\" FS_NAME=$(date +%s) Volume and AMI specs need to be manually set. If the AMI types are not specified in the ticket or its dealsheet, ask the ticket requester for clarification before proceeding. Volume type must be either gp3 or standard . sv-vollist ${SOURCE_SRV} DB_AMI= DB_VOL_SIZE= DB_VOL_TYPE= FS_AMI= FS_VOL_SIZE= FS_VOL_TYPE= Set up the number and AMI type for the destination stack's webs. If these are not specified in the ticket or its dealsheet, template them off of the customer's current setup: WEB_AMI= WEB_NUM= Review the variables for accuracy and modify them appropriately to match the requirements of the ticket: echo \"{noformat:title=Variables}\" \\ && echo \"SOURCE_SRV=${SOURCE_SRV}\" \\ && echo \"SITES=(${SITES[@]})\" \\ && echo \"REGION=${REGION}\" \\ && echo \"AZS=(${AZS[@]})\" \\ && echo \"VPC_OPTION=\\\"${VPC_OPTION}\\\"\" \\ && echo \"DB_AMI=${DB_AMI}\" \\ && echo \"DB_VOL_SIZE=${DB_VOL_SIZE}\" \\ && echo \"DB_VOL_TYPE=${DB_VOL_TYPE}\" \\ && echo \"FS_AMI=${FS_AMI}\" \\ && echo \"FS_VOL_SIZE=${FS_VOL_SIZE}\" \\ && echo \"FS_VOL_TYPE=${FS_VOL_TYPE}\" \\ && echo \"FS_NAME=${FS_NAME}\" \\ && echo \"WEB_AMI=${WEB_AMI}\" \\ && echo \"WEB_NUM=${WEB_NUM}\" \\ && echo \"{noformat}\" Note : Make sure everything here is accurate before proceeding! Provision the new stack and save the output server names appropriately: ah-provision stack web-db-fs -r ${REGION} -z ${AZS[@]} ${VPC_OPTION} \\ -D ${DB_AMI} -d ${DB_VOL_SIZE} --de --database-storage-type=${DB_VOL_TYPE} \\ -f ${FS_AMI} -g ${FS_VOL_SIZE} --ge --gt ${FS_VOL_TYPE} -n ${FS_NAME} \\ -w ${WEB_AMI} -c ${WEB_NUM} NEW_SRVS= Verify! Verify that all the servers have the correct VPC, AMI types, availability zones: ah-server list ${NEW_SRVS} -c ami_type ec2_availability_zone vpc_id Verify that all volumes are encrypted and are the correct type and size: sv-vollist ${NEW_SRVS} Launch the stack: sv-taskrelaunch server -m1 ${NEW_SRVS} Follow this runbook to perform an initial rsync from the old FS volume to the new one. This will help speed up the workflow during the maintenance window. We use a temporary SSH key here because sv-rsync has difficulty handling large migrations. Notes: Make sure to run the rsync in a screen session, since it may take a while to complete for large FS volumes. Don't forget to clean up the temporary SSH key once the prepatory migration is complete. Use trailing slashes on the path names for rsync to preserve directory structure. For example: rsync -auvPe 'ssh -i KEY_PATH' /mnt/gfs/ DST_SRV:/mnt/gfs/ If you are doing this in a maintenance prep ticket, update the maintenance ticket with the following information: echo \"{noformat:title=New Stack}\" \\ && echo \"OLD_SRV=${SOURCE_SRV}\" \\ && echo \"NEW_SRVS=${NEW_SRVS}\" \\ && echo \"{noformat}\"","title":"Prep"},{"location":"kanban_tickets/multi_tier_to_full_tier/#maintenance-window","text":"This maintenance procedure assumes that the customer's FS volume was rsync'd in preparation and is moderately sized. However, customers with especially large FS volumes and/or more than 1 million inodes risk running over the maintenance window, even in the best circumstances. There isn't much we can do to avoid this, so communicate this fact appropriately to the Ops Coordinators and Account Managers if it happens.","title":"Maintenance Window"},{"location":"kanban_tickets/multi_tier_to_full_tier/#site-move-procedure","text":"Set up variables: Copy the server lists created in the prep ticket, if applicable. If not, set OLD_SRV to the primary FS/DB server in the old stack, and NEW_SRVS to comma-separated list of all newly provisioned servers to move the site(s) to: OLD_SRV= NEW_SRVS= Set up variables for the new stack for the site move: SITES=($(ah-site list on:${OLD_SRV})) NEW_WEBS=($(ah-server list ${NEW_SRVS} -w type=web)) NEW_DB=($(ah-server list ${NEW_SRVS} -w type=dbmaster | head -n1)) Also set up variables for the old stack so we can clean it up when we're done: OLD_FS_CLUSTER=$(ah-server list ${OLD_SRV} --no-name -c fs_cluster_id) OLD_SRVS=($(ah-server list % -w fs_cluster_id=${OLD_FS_CLUSTER})) Verify your variables and make sure they match the requirements of the maintenenace ticket. Move the sites to the new stack: for site in ${SITES[@]}; do ah-site move ${site} --webs ${NEW_WEBS[@]} --db ${NEW_DB} --force done Complete all follow-up steps as appropriate for a normal site-move, particularly for managing EIPs and ELBs by following the normal site move runbook .","title":"Site Move Procedure"},{"location":"kanban_tickets/multi_tier_to_full_tier/#cleanup","text":"Check the old servers to see if they have any sites left on them: site-list -s $(array-csv ${OLD_SRVS[@]}) If any servers no longer have sites on them, suspend them: SERVERS_CSV= ah-server suspend ${SERVERS_CSV} Create a TSR ticket to terminate these suspended servers in 7 days.","title":"Cleanup"},{"location":"kanban_tickets/multi_tier_to_single_tier/","text":"Multi-tier to Single-tier Downsize This procedure is for returning a customers previously upsized multi-tier cluster back to a single-tier cluster. This can only be performed if the cluster contains DED servers. FSDBs can not be changed in to DEDs. Given the reduction of web capacity and the potential reduction of HA this should only be performed during a maintenance window. Traps These traps are the most common issues you will find when resizing a customers stack. The procedure below incorporates the handling of these gotchas. EIPs Multiple sites on a single stack Important Note We should never have a two sites using the same ded's while one site is single tier and the other site in multi tier. we should not remove the webs straight away. If removed, the other site may experience an outage. Set Variables Even though for the downsize you are about to perform there may only be one site, still declare the variables below as arrays where needed. This procedure expects there to be arrays. SITES=() DEDS=($(ah-server list site:${SITES[0]} -w type=ded)) DEDS_CSV=$(array-csv ${DEDS[@]}) WEBS=($(ah-server list site:on:${DEDS[0]} -w type=web status=0)) WEBS_CSV=$(array-csv ${WEBS[@]}) Get all sites running on same hardware: TOTAL_SITES=($(ah-site list on:${DEDS[0]})) SITES=($(echo ${TOTAL_SITES[@]})) Verify variable assignment: cat << EOF SITES=(${SITES[@]}) DEDS=(${DEDS[@]}) DEDS_CSV=${DEDS_CSV} WEBS=(${WEBS[@]}) WEBS_CSV=${WEBS_CSV} EOF Gather information Capture the output from these tools, for each of the sites affected, and paste the relevant parts into the Jira ticket. Ra, dev & test sites can be omitted esl ${DEDS[0]} ${RANDOM} for site in ${SITES[@]}; do echo ${site} site-getwebrotationstatus ${site} done Verify Server Settings Modify the ded servers' settings to match the webs. Since we are downsizing, some settings may no longer be sized appropriately. Ask Support for new values for settings like memcache. ah-server get ${DEDS[0]} | grep server_settings ah-server get ${WEBS[0]} | grep server_settings Transfer settings, but ignore: fcgi.conf puppet.newrelic% server.total_memory ah-server edit ${DEDS_CSV} -c file:key=value For example: $ ah-server edit ${DEDS_CSV} -c memcached.conf:-m=64 ded-13668 set config memcached.conf:-m=64 ded-13669 set config memcached.conf:-m=64 Updated 2 servers. Add DED SERVERS back to Site/s If the deds are not in balancer and/or site rotation, we need to make sure to enable them. If the deds are already in rotation for all sites, skip to managing EIPs . ah-server list ${DEDS_CSV} -c web_service_status for site in ${SITES[@]}; do echo ${site} site-getwebrotationstatus ${site} | grep -E 'ded-' done As the DEDs are already running we can set them back to active instead of deploy : sv-webdisable ${DEDS_CSV} for site in ${SITES[@]}; do ./fields-provision.php --site-set-web ${site}:active --webs ${DEDS_CSV} done site-fcw ${SITES[0]} One by one add the DEDs back in to balancer rotation with sv-webenable . After enabling each server watch the output of site-checkwebs for each site to ensure that the DED is correctly serving traffic. If it isn't, pull it from rotation immediately with sv-webdisable and investigate. for ded in ${DEDS[@]}; do sv-webenable ${ded} for site in ${SITES[@]}; do site-checkwebs ${site} done read -srp \"Press enter to continue. ^C to stop.\" echo done Check Replication Both DEDs must have zero seconds of lag before proceeding. fpdsh -l ${DEDS_CSV} -c \"sudo mysql -e 'show slave status\\G' \\ | grep -E 'Seconds_Behind_Master'\" Manage EIPs If the Webs you are reducing have EIPs attached, you will need to move two of them back to the DEDs. Please note that Acquia is charged for EIPs that are not in use. IMPORTANT : Moving EIPs back to the DEDs will cause ALL hosted services on the DED to become unavailable until the EIP is associated with it and firewall rules on all servers have been re-written. Typically this outage lasts for few seconds. NOTE : If you work with the primary DED first and there is an automatic DB failover then when you work with the secondary DB it should auto fail back; reducing the work you have to do :). Move EIP Migrate server EIPs to the deds manually. Scripting is not easily possible here. sv-webdisable ah-server help migrate-eip sv-webenable For example: $ sv-webdisable web-14309 web-14309 set web_service_status=1 Updated 1 servers. $ ah-server migrate-eip --source-server-name=web-14309 --destination-server-name=ded-596 $ sv-webenable ded-596 ded-596 set web_service_status=2 Updated 1 servers. Verify success by running site-checkwebs for each site until you have seen that all DEDs that should be in rotation are serving traffic. If there is a problem with any DED, pull it from rotation immediately and investigate. Rinse and repeat until the DEDs have EIPs. Clean Up Beware: Check the old web servers to see if they have any sites left on them or not. we should not remove the webs straight away. If removed, the other site may experience an outage. Remove sites from the webs: for site in ${SITES[@]}; do ah-site remove-webnode ${site} ${WEBS[@]} done Check for any sites remaining on the webs: site-list -s ${WEBS_CSV} If there are no sites remaining on the webs, take them out of balancer rotation and suspend them. Don't forget to create a TSR ticket to terminate these suspended servers in 7 days. Standard server termination commands will find and release any EIPs hanging around. sv-webdisable ${WEBS_CSV} ah-server suspend ${WEBS_CSV} If there are sites remaining on the webs, check if those sites need to be converted to single-tier as well. Leaving any sites active on these webs will make a sad snowflake cluster! End Show the new output in your Jira ticket. esl ${DEDS[0]} ${RANDOM} for site in $(ah-site list on:${DEDS[0]}); do echo ${site} site-getwebrotationstatus ${site} done","title":"Multi-tier to Single-tier Downsize"},{"location":"kanban_tickets/multi_tier_to_single_tier/#multi-tier-to-single-tier-downsize","text":"This procedure is for returning a customers previously upsized multi-tier cluster back to a single-tier cluster. This can only be performed if the cluster contains DED servers. FSDBs can not be changed in to DEDs. Given the reduction of web capacity and the potential reduction of HA this should only be performed during a maintenance window.","title":"Multi-tier to Single-tier Downsize"},{"location":"kanban_tickets/multi_tier_to_single_tier/#traps","text":"These traps are the most common issues you will find when resizing a customers stack. The procedure below incorporates the handling of these gotchas. EIPs Multiple sites on a single stack","title":"Traps"},{"location":"kanban_tickets/multi_tier_to_single_tier/#important-note","text":"We should never have a two sites using the same ded's while one site is single tier and the other site in multi tier. we should not remove the webs straight away. If removed, the other site may experience an outage.","title":"Important Note"},{"location":"kanban_tickets/multi_tier_to_single_tier/#set-variables","text":"Even though for the downsize you are about to perform there may only be one site, still declare the variables below as arrays where needed. This procedure expects there to be arrays. SITES=() DEDS=($(ah-server list site:${SITES[0]} -w type=ded)) DEDS_CSV=$(array-csv ${DEDS[@]}) WEBS=($(ah-server list site:on:${DEDS[0]} -w type=web status=0)) WEBS_CSV=$(array-csv ${WEBS[@]}) Get all sites running on same hardware: TOTAL_SITES=($(ah-site list on:${DEDS[0]})) SITES=($(echo ${TOTAL_SITES[@]})) Verify variable assignment: cat << EOF SITES=(${SITES[@]}) DEDS=(${DEDS[@]}) DEDS_CSV=${DEDS_CSV} WEBS=(${WEBS[@]}) WEBS_CSV=${WEBS_CSV} EOF","title":"Set Variables"},{"location":"kanban_tickets/multi_tier_to_single_tier/#gather-information","text":"Capture the output from these tools, for each of the sites affected, and paste the relevant parts into the Jira ticket. Ra, dev & test sites can be omitted esl ${DEDS[0]} ${RANDOM} for site in ${SITES[@]}; do echo ${site} site-getwebrotationstatus ${site} done","title":"Gather information"},{"location":"kanban_tickets/multi_tier_to_single_tier/#verify-server-settings","text":"Modify the ded servers' settings to match the webs. Since we are downsizing, some settings may no longer be sized appropriately. Ask Support for new values for settings like memcache. ah-server get ${DEDS[0]} | grep server_settings ah-server get ${WEBS[0]} | grep server_settings Transfer settings, but ignore: fcgi.conf puppet.newrelic% server.total_memory ah-server edit ${DEDS_CSV} -c file:key=value For example: $ ah-server edit ${DEDS_CSV} -c memcached.conf:-m=64 ded-13668 set config memcached.conf:-m=64 ded-13669 set config memcached.conf:-m=64 Updated 2 servers.","title":"Verify Server Settings"},{"location":"kanban_tickets/multi_tier_to_single_tier/#add-ded-servers-back-to-sites","text":"If the deds are not in balancer and/or site rotation, we need to make sure to enable them. If the deds are already in rotation for all sites, skip to managing EIPs . ah-server list ${DEDS_CSV} -c web_service_status for site in ${SITES[@]}; do echo ${site} site-getwebrotationstatus ${site} | grep -E 'ded-' done As the DEDs are already running we can set them back to active instead of deploy : sv-webdisable ${DEDS_CSV} for site in ${SITES[@]}; do ./fields-provision.php --site-set-web ${site}:active --webs ${DEDS_CSV} done site-fcw ${SITES[0]} One by one add the DEDs back in to balancer rotation with sv-webenable . After enabling each server watch the output of site-checkwebs for each site to ensure that the DED is correctly serving traffic. If it isn't, pull it from rotation immediately with sv-webdisable and investigate. for ded in ${DEDS[@]}; do sv-webenable ${ded} for site in ${SITES[@]}; do site-checkwebs ${site} done read -srp \"Press enter to continue. ^C to stop.\" echo done","title":"Add DED SERVERS back to Site/s"},{"location":"kanban_tickets/multi_tier_to_single_tier/#check-replication","text":"Both DEDs must have zero seconds of lag before proceeding. fpdsh -l ${DEDS_CSV} -c \"sudo mysql -e 'show slave status\\G' \\ | grep -E 'Seconds_Behind_Master'\"","title":"Check Replication"},{"location":"kanban_tickets/multi_tier_to_single_tier/#manage-eips","text":"If the Webs you are reducing have EIPs attached, you will need to move two of them back to the DEDs. Please note that Acquia is charged for EIPs that are not in use. IMPORTANT : Moving EIPs back to the DEDs will cause ALL hosted services on the DED to become unavailable until the EIP is associated with it and firewall rules on all servers have been re-written. Typically this outage lasts for few seconds. NOTE : If you work with the primary DED first and there is an automatic DB failover then when you work with the secondary DB it should auto fail back; reducing the work you have to do :).","title":"Manage EIPs"},{"location":"kanban_tickets/multi_tier_to_single_tier/#move-eip","text":"Migrate server EIPs to the deds manually. Scripting is not easily possible here. sv-webdisable ah-server help migrate-eip sv-webenable For example: $ sv-webdisable web-14309 web-14309 set web_service_status=1 Updated 1 servers. $ ah-server migrate-eip --source-server-name=web-14309 --destination-server-name=ded-596 $ sv-webenable ded-596 ded-596 set web_service_status=2 Updated 1 servers. Verify success by running site-checkwebs for each site until you have seen that all DEDs that should be in rotation are serving traffic. If there is a problem with any DED, pull it from rotation immediately and investigate. Rinse and repeat until the DEDs have EIPs.","title":"Move EIP"},{"location":"kanban_tickets/multi_tier_to_single_tier/#clean-up","text":"Beware: Check the old web servers to see if they have any sites left on them or not. we should not remove the webs straight away. If removed, the other site may experience an outage. Remove sites from the webs: for site in ${SITES[@]}; do ah-site remove-webnode ${site} ${WEBS[@]} done Check for any sites remaining on the webs: site-list -s ${WEBS_CSV} If there are no sites remaining on the webs, take them out of balancer rotation and suspend them. Don't forget to create a TSR ticket to terminate these suspended servers in 7 days. Standard server termination commands will find and release any EIPs hanging around. sv-webdisable ${WEBS_CSV} ah-server suspend ${WEBS_CSV} If there are sites remaining on the webs, check if those sites need to be converted to single-tier as well. Leaving any sites active on these webs will make a sad snowflake cluster!","title":"Clean Up"},{"location":"kanban_tickets/multi_tier_to_single_tier/#end","text":"Show the new output in your Jira ticket. esl ${DEDS[0]} ${RANDOM} for site in $(ah-site list on:${DEDS[0]}); do echo ${site} site-getwebrotationstatus ${site} done","title":"End"},{"location":"kanban_tickets/mysql-daily-replication-fix/","text":"MySQL Daily Replication Fix On a daily basis, at 10:00 UTC, a cron job executes fields-verify-replication.sh on all database for clusters in ACE & Network. If the said server is a secondary the script aborts. The script uses pt-checksum (mk-checksum in legacy Castle) to verify that the data in each database is identical. If it is not, an email is generated indicating the detected issues. Daily Automated replication fix At 14:00 UTC daily, a cron job executes on bastion-21 under the user shanevanhart. This job parses the emails sent by the above mentioned cron job. The script generates a TSR ticket with instructions on how to remedy the found discrepancies if the resolution to the issues is known. There are three main cases and someedge cases. This document pretty much focuses on the main cases. The first case is when discrepancies are detected on tables that are indexed. The second case is when discrepancies are detected on tables that are not indexed. The third scenario is the possilbility that replication was never initialized on the cluster, usually caused by one of the server launches borking on initial launch. If you run into this scenario, immediately escalate the issue to a DBA. One other rare scenario that you mau encounter is when trying to fix replication, you get an error message mentioning foreign-key constraints. If you run into this scenario the remedy is to do a dump-restore and to notify a DBA. NOTE: If you encounter any scenario not mentioned above, please escalate to a DBA. Manually finding list of servers This documents what the script does and how to perform the work manually if the need were to ever arise. First, you will need to search your gmail account using this search string: subject:(FAILURE replication from) after:$DATE where $DATE is yesterday's date in YYYY-MM-DD format. To make the process easier, you can just set up a gmail filter to label any email to hosting.admins@acquia.com with the subject of FAILURE: replication from, such as SQL. Attempting to fix the clusters You will need to review the content of the email to determine what action(s) you will need to take. For servers in which all of the issues are for tables with indexes Example: SQL to fix inconsistencies: REPLACE INTO .... ... do the following fpdsh -l $SERVERS -c \"sudo pt-table-sync --execute \\ --replicate acquia.checksum localhost \\ && sudo fields-verify-replication.sh 2>&1\" For servers in which the discrepancies are for tables that are not indexed Example: SQL to fix inconsistencies: Can't make changes on the master because no unique index exists at /usr/bin/pt-table-sync line 10641 ... do the following: fssh $SLAVE \"sudo pt-table-sync --no-bin-log \\ --execute h=$MASTER.prod.hosting.acquia.com,D=$DATABASE,t=$TABLE localhost\" NOTE : If you\u2019re syncing a table without a primary or unique key on a master-master pair, you must change the data on the destination server. Therefore, you need to specify --no-bin-log for safety (see --[no]bin-log). If you don\u2019t, the changes you make on the destination server will replicate back to the source server and change the data there! ( from the Percona Toolkit documentation ) We will occasionally see where the check reports that no slaves were found. This usually indicates one of two things, one the slave was not accessible at the time (i.e. server down) or two, replication has not been initialized. If you suspect the second you please escalate to a DBA . Any scenario not documented, please escalate to a DBA for assistance.","title":"MySQL Daily Replication Fix"},{"location":"kanban_tickets/mysql-daily-replication-fix/#mysql-daily-replication-fix","text":"On a daily basis, at 10:00 UTC, a cron job executes fields-verify-replication.sh on all database for clusters in ACE & Network. If the said server is a secondary the script aborts. The script uses pt-checksum (mk-checksum in legacy Castle) to verify that the data in each database is identical. If it is not, an email is generated indicating the detected issues.","title":"MySQL Daily Replication Fix"},{"location":"kanban_tickets/mysql-daily-replication-fix/#daily-automated-replication-fix","text":"At 14:00 UTC daily, a cron job executes on bastion-21 under the user shanevanhart. This job parses the emails sent by the above mentioned cron job. The script generates a TSR ticket with instructions on how to remedy the found discrepancies if the resolution to the issues is known. There are three main cases and someedge cases. This document pretty much focuses on the main cases. The first case is when discrepancies are detected on tables that are indexed. The second case is when discrepancies are detected on tables that are not indexed. The third scenario is the possilbility that replication was never initialized on the cluster, usually caused by one of the server launches borking on initial launch. If you run into this scenario, immediately escalate the issue to a DBA. One other rare scenario that you mau encounter is when trying to fix replication, you get an error message mentioning foreign-key constraints. If you run into this scenario the remedy is to do a dump-restore and to notify a DBA. NOTE: If you encounter any scenario not mentioned above, please escalate to a DBA.","title":"Daily Automated replication fix"},{"location":"kanban_tickets/mysql-daily-replication-fix/#manually-finding-list-of-servers","text":"This documents what the script does and how to perform the work manually if the need were to ever arise. First, you will need to search your gmail account using this search string: subject:(FAILURE replication from) after:$DATE where $DATE is yesterday's date in YYYY-MM-DD format. To make the process easier, you can just set up a gmail filter to label any email to hosting.admins@acquia.com with the subject of FAILURE: replication from, such as SQL.","title":"Manually finding list of servers"},{"location":"kanban_tickets/mysql-daily-replication-fix/#attempting-to-fix-the-clusters","text":"You will need to review the content of the email to determine what action(s) you will need to take. For servers in which all of the issues are for tables with indexes Example: SQL to fix inconsistencies: REPLACE INTO .... ... do the following fpdsh -l $SERVERS -c \"sudo pt-table-sync --execute \\ --replicate acquia.checksum localhost \\ && sudo fields-verify-replication.sh 2>&1\" For servers in which the discrepancies are for tables that are not indexed Example: SQL to fix inconsistencies: Can't make changes on the master because no unique index exists at /usr/bin/pt-table-sync line 10641 ... do the following: fssh $SLAVE \"sudo pt-table-sync --no-bin-log \\ --execute h=$MASTER.prod.hosting.acquia.com,D=$DATABASE,t=$TABLE localhost\" NOTE : If you\u2019re syncing a table without a primary or unique key on a master-master pair, you must change the data on the destination server. Therefore, you need to specify --no-bin-log for safety (see --[no]bin-log). If you don\u2019t, the changes you make on the destination server will replicate back to the source server and change the data there! ( from the Percona Toolkit documentation ) We will occasionally see where the check reports that no slaves were found. This usually indicates one of two things, one the slave was not accessible at the time (i.e. server down) or two, replication has not been initialized. If you suspect the second you please escalate to a DBA . Any scenario not documented, please escalate to a DBA for assistance.","title":"Attempting to fix the clusters"},{"location":"kanban_tickets/mysql_audit/","text":"Enabling or Disabling MySQL Auditing WARNING : This only applies to Classic Cloud. Occassionaly a customer may request to have MySQL auditing enabled on their database servers. Enabling auditing will result in the logging of MySQL connects, disconnects, and failed connects (including the error code) in /vol/ebs1/mysql/audit.log . This log is rotated once it reaches 100MB. NOTE: MySQL auditing is only supported in Xenial and above Enabling MySQL Auditing Enable the puppet:mysql_audit setting. ah-server edit fsdb-x -c puppet:mysql_audit='on' This will kick off a puppet task to enable the plugin. Disabling MySQL Auditing Disable the puppet:mysql_audit setting. ah-server edit fsdb-x -c puppet:mysql_audit='off' This will kick off a puppet task to disable the plugin.","title":"Enabling or Disabling MySQL Auditing"},{"location":"kanban_tickets/mysql_audit/#enabling-or-disabling-mysql-auditing","text":"WARNING : This only applies to Classic Cloud. Occassionaly a customer may request to have MySQL auditing enabled on their database servers. Enabling auditing will result in the logging of MySQL connects, disconnects, and failed connects (including the error code) in /vol/ebs1/mysql/audit.log . This log is rotated once it reaches 100MB. NOTE: MySQL auditing is only supported in Xenial and above","title":"Enabling or Disabling MySQL Auditing"},{"location":"kanban_tickets/mysql_audit/#enabling-mysql-auditing","text":"Enable the puppet:mysql_audit setting. ah-server edit fsdb-x -c puppet:mysql_audit='on' This will kick off a puppet task to enable the plugin.","title":"Enabling MySQL Auditing"},{"location":"kanban_tickets/mysql_audit/#disabling-mysql-auditing","text":"Disable the puppet:mysql_audit setting. ah-server edit fsdb-x -c puppet:mysql_audit='off' This will kick off a puppet task to disable the plugin.","title":"Disabling MySQL Auditing"},{"location":"kanban_tickets/mysql_upgrade_5733/","text":"MySQL / Percona Server 5.7.33 Upgrade Overview Non-clustered server upgrade Single-region cluster upgrade Multi-region cluster upgrade Client server upgrade Running upgrades in parallel Prep Bulk Upgrade Workflows Post-upgrade check Troubleshooting Escalation Overview This runbook describes the procedure to upgrade database servers from Percona Server 5.6 to 5.7. This procedure assumes that the upgrade has already been scheduled and approved. Upgrades should always be performed using the MySQL upgrade workflow but it is possible to manually execute all the steps in this workflow. The manual process should only be done in case the automated process fails and cannot be resumed even when the cause of the error has been fixed. In general this will require assistance from a DBA. The MySQL upgrade workflow will work for standalone database servers as well as clustered database servers. Multi-region clusters are not supported. The MySQL upgrade workflow supports upgrades to 5.7.33. The workflow can upgrade to 5.7.33 from 5.6.32, 5.6.41, 5.7.29, or 5.7.31. Database server upgrade workflow explanation The MySQL upgrade workflow can be started with ah-db-cluster upgrade-mysql command. The workflow can upgrade either a non-clustered server or a database cluster as a whole. To upgrade a cluster you only need to specify one of the servers in the cluster as the target for the upgrade. Multi-region cluster upgrades are currently not supported by the workflow. When upgrading a cluster the workflow takes care of upgrading the individual servers in the correct order as well as performing failovers and locking the cluster to the active server. Whether it's part of a cluster upgrade or it's a non-clustered server upgrade, the upgrade steps for the individual servers are the same: run automated pre-checks change fields mysql_version run puppet run mysql_upgrade restart MySQL For clusters the complete workflow looks like this: run automated pre-checks lock the cluster to the active server upgrade the passive unlock the cluster fail over to the upgraded server lock the cluster to active server upgrade the new passive server unlock the cluster fail back The failover works differently from our normal dns-based failover to minimize the possibility of split-brain but as a result it will cause downtime during the failover. Because this downtime impacts the SLA all upgrades will take place in maintenance windows and customers will be notified by Support. If the workflow fails a notification will be sent to PagerDuty and that failure needs to be handled within the maintenance window if possible. The upgrade tool will disable alerts for the servers in question at the start of the process and enable them again at the end. The mysql_upgrade script checks all tables for compatibility with the new version which can take a long time. A cluster upgrade can take anywhere between 10 minutes and 6 hours depending on a number of factors but the most important factor is the number of tables that the mysql_upgrade script has to check. During this check the database server is available for customers but at the end of this check MySQL will be restarted. For database clusters this has no impact since the server is passive at that time but for non-clustered servers it will interrupt the site. Non-clustered server upgrade Upgrading a non-clustered server will cause downtime since the mysqld process will be restarted multiple times during the upgrade process, both at the start and at the end. The total amount of downtime depends on the type of server and the size of the dataset. Most upgrades should take less than 1 hour. In cases of extremely high numbers of tables the upgrade can take several hours. The highest we've seen in testing is 3 hours for an individual server. The following steps need to be performed to upgrade a non-clustered database server. Run the upgrade command: ah-db-cluster upgrade-mysql <hostname> --version=5.7.33 --op-ticket <jira ticket id> Verify workflow has been successfully completed ah-workflow get <workflow id> --show-logs Single-region cluster upgrade Upgrading a database cluster will result in downtime during the failovers but not during the actual upgrade process for the individual servers. HA will not be available during the upgrade so if there is a problem with the active server the site will be down. The following steps need to be performed to upgrade a database cluster. Run the upgrade command The hostname can be either of the database servers in the cluster, the workflow will upgrade both servers in the cluster. ah-db-cluster upgrade-mysql <hostname> --version=5.7.33 --op-ticket <jira ticket id> Verify tasks have been completed ah-workflow get <workflow id> --show-logs Multi-region cluster upgrade Multi-region upgrades are not supported either manually or via the workflow. Client server upgrade Clients can be upgraded by setting the mysql_version server config setting. Set the mysql_version service config setting: ah-server edit $SERVERS -c puppet:mysql_version=5.7.31 Wait for puppet to run. Confirm that all mysql packages are the proper version: fpdsh -l $SERVERS -c '(sudo apt list --installed 2>&1 | grep \"percona.\\?server\" | grep -v \"5.7.31\" && echo \"INCORRECT mysql version found\") || /bin/true' Running upgrades in parallel Prep Before starting any work, verify the ticket and the list of servers that you will be upgrading. The OP ticket should have a list of DB servers to be upgraded. Set up the following variables and initialize a temp dir to capture workflow output: SERVERS=( ) SERVERS_CSV=$(array-csv ${SERVERS[@]}) DB_SERVERS=( $(ah-server list ${SERVERS_CSV} -w typeINstaging,ded,fsdb,dbmaster status=0 -c puppet:mysql_version | tr -d ',' | awk '$2!~/5.7.33/ {print $1}') ) JIRA=<OP ticket number> mkdir ${OPSTMP}/${JIRA} Refine the server list to exclude already-upgraded clusters and build a list of primary databases: sv-dbislocked ${DB_SERVERS[@]} eval $(sv-dbprisec ${DB_SERVERS[@]}) echo \"Number of DB clusters to upgrade: ${#PRIMARY_DBS[@]}\" echo \"${PRIMARY_DBS[@]}\" Make sure to investigate any locked database clusters and exclude them from your DB_SERVERS list, if appropriate. The eval statement above will set up a PRIMARY_DBS variable in your terminal. Bulk Upgrade Workflows Finally, start the upgrade workflows. CONCURRENCY sets how many workflows will be in progress at once. We default it to 20 here, but you should set it to a value you are comfortable with. CONCURRENCY=20 printf '%s\\n' ${PRIMARY_DBS[@]} \\ | xargs -n1 -P${CONCURRENCY} -I{} \\ bash -c \"ah-db-cluster upgrade-mysql {} --version=5.7.33 --op-ticket ${JIRA} |& tee -a ${OPSTMP}/${JIRA}/{}.log\" If you need to stop the upgrades for any reason (i.e. end of maintenance window, many erroring workflows, etc.), stop the process ( ^C should work), and get the ID of any incomplete workflows: WORKFLOW_IDS=( $(awk '$0~/Workflow.*is in status:/ {print $4}' ${OPSTMP}/${JIRA}/*.log | sort -u) ) ah-workflow list % -w idIN$(array-csv ${WORKFLOW_IDS[@]}) status!=completed -c status Monitor in-progress workflows with ah-workflow watch and investigate any workflows which have errored . If you later resume upgrades, make sure to redo the prep section to renew your server lists . It's also handy to keep an eye on the #workflow-events Slack room to check for progress and failures. Workflow failures are printed in the Operations room as well. Once all of the workflows are complete the output files can be checked for errors. grep -i err ${OPSTMP}/${JIRA}/*.log Post-Upgrade Check Run the following command on the upgraded server(s). If a single server was upgraded then you can just use fssh instead of fpdsh . fpdsh -l ${SERVERS_CSV} \\ -c \"sudo grep -v 'Checking\\|Upgrading\\|OK\\|Looking for\\|Running\\|Warning: Using a password on the command line interface can be insecure.' \\ \\$(sudo find /vol/ebs1/mysql/ -iname '*mysql_upgrade-*.log')\" The output should only include log entries indicating successful upgrades. dbmaster-133: Upgrade process completed successfully. If there are errors such as the example below contact a DBA immediately. dbmaster-133: Repairing tables dbmaster-133: g205626.search_index dbmaster-133: Error : Unknown collation '#253' in table 'search_index' definition dbmaster-133: error : Corrupt Troubleshooting Important Note Do not abort workflows! Whenever an upgrade workflow fails an alert is sent to ops on-call. There is a process defined below to escalate for MySQL upgrade support. If you encounter any problems other than those listed in this section of the runbook or those addressed in other Ops runbooks, please use the process to escalate the issue. Ensure that the workflow ID is included in the Jira ticket that is being worked. Automated pre-flight checks After resolving any of the below failing pre-flight checks, the workflow can be resumed with the following command: ah-workflow resume <workflow id> Puppet is disabled The workflow depends on being able to run puppet to upgrade the packages. You will need to investigate why puppet was disabled and whether or not it is safe to be re-enabled. If so, use this command to enable puppet on the server in question: fssh <hostname> 'sudo /usr/local/bin/ah-puppet-enable' Volume capacity There needs to be free space on both the /mnt and /vol/ebs1 volume for the upgrade to complete successfully. The check will fail if either of these volumes has less than 1 GB of space available. The space will need to be freed before starting the workflow or resize the volume. This check is done on all the servers in the cluster. Backup running For customers with very large databases, sometimes customer initiated backup maybe ongoing when we attempt to upgrade database cluster. If that is the case the upgrade workflow will fail in its pre-flight check. You can either wait for the customer backup is completed or kill it before proceeding to resume the workflow. Server status If any server in the database cluster is not in status NORMAL the automated server status check will fail. All servers in the cluster must be launched and operating normally before beginning the upgrade process. Instance status If any server's INSTANCE STATUS is not ok the automated instance status check will fail. If any AWS maintenance EVENTS are scheduled for the next 48 hours, the instance status check will fail. In either case, the server(s) will need to be relaunched before beginning the upgrade process. fields-verify-replication.sh running At 10AM UTC we run a script on database clusters that verifies replication between both masters. Performing an upgrade while this script is running will result in errors in the daily replication verification ticket. A pre-flight check verifies if it is currently running and fails if so. You can either wait for the script to complete execution or kill it before proceeding to resume the workflow. If the cron is scheduled to start the script right after we complete the pre-flight check, we handle that by stopping cron in the workflow. Unexpected output in workflow logs Upgrade workflow will archive all logs from previous upgrade workflow to the /vol/ebs1/mysql/mysql_upgrade-pre-5.7.33-logs-#{workflow_id}-#{timestamp}.tar.gz , and will check current workflow's log for the expected output. All lines in upgrade workflow's log should contain any of the following values: * Checking * Looking for * OK * Repairing tables * Running * Table rebuild required. * Upgrade process completed successfully. * Upgrading Any other lines not matching the rules will raise an exception with the following message: Unexpected output in <log-file-name>: <unexpected output> In that case investigate the unexpected output on the server. If Upgrade process completed successfully. appears near the end of the log then the error is false and you can continue the workflow. Set the workflow to the next step and resume: for primary server: ah-workflow set-step <workflow-id> restart_mysql_on_primary for secondary: ah-workflow set-step <workflow-id> restart_mysql_on_secondary for single-node: ah-workflow set-step <workflow-id> cleanup NOTE Repeat the set-step from secondary log check failure for primary if it happens again on primary. If Upgrade process completed successfully. does not appear in the log then reach out to DBA for further actions. Known failure modes Workflow fails to be created because another active workflow exists Hosting api allows only one mysql upgrade workflow to be created for a given db cluster id. It returns an error, Cannot have another mysql upgrade workflow running on the same cluster. Move workflows XX,YY to one of the final states(completed/aborted/failed) first. This means there are one or more workflows which are not in one of the final states of a workflow. Transition each of the listed workflows or abort them before proceeding to create a new one for the same cluster. Run ah-workflow help export JIRA=to get the list of commands to help you transition them. Upgrade fails during step prep_cluster_primary The workflow step prep_cluster_primary temporarily puts a custom setting in place. If that setting already exists that step will fail. The error in the workflow will look like this: [19:18:53] [19:18:53] Failure AH_TASK_CRITICAL: status: 1 [2016-11-08 19:18:52] mysql_upgrade_workflow workflow (69): Transitioning step to: prep_cluster_primary [2016-11-08 19:18:52] mysql_upgrade_workflow workflow (69): Executing step: prep_cluster_primary [2016-11-08 19:18:53] mysql_upgrade_workflow workflow (69): Step: prep_cluster_primary raised error RuntimeError [2016-11-08 19:18:53] ERROR: Caught RuntimeError while running workflow: mysql_upgrade script exited non-zero! The custom setting in question is skip-slave-start which prevents MySQL replication from starting when MySQL starts. The actual error message points to the mysql_upgrade script but that is a bug since mysql_upgrade does not get run during this step. To fix this error remove the custom setting from the server by executing the following command on bastion: ah-server edit <primary hostname> -c my.cnf:skip-slave-start= After that the workflow can be resumed. Upgrade fails due to puppet_run time out We've seen at least one instance where the puppet run took longer than the workflow task expected and caused the workflow to error stop. If the workflow fails, use ah-workflow <workflow id> --show-logs and look for this error. [2016-11-30 13:15:59] DEBUG: |Time taken for|upgrade_secondary|puppet_run|300 [2016-11-30 13:15:59] mysql_upgrade_workflow workflow (139): Step: upgrade_secondary raised error RuntimeError [2016-11-30 13:15:59] ERROR: Caught RuntimeError while running workflow: ah-apply for subsystem puppet did not return status=0 indicating successful changes being made. status: 66 The workflow should be able to be resumed and the upgrade will carry on without issue. If it fails again escalation will be necessary. Upgrade fails during wait_replication_before If one of the servers is behind in replication and it takes longer than 10 minutes catch back up the step wait_replication_before will fail with an error_pause . The output for ah-workflow <workflow id> --show-logs will contain an error similar to the one below. [2016-12-20 18:41:27] DEBUG: Current replication delay: 673 [2016-12-20 18:41:27] mysql_upgrade_workflow workflow (8): Step: wait_replication_before raised error Aq::RetryTimeoutException [2016-12-20 18:41:27] ERROR: Caught Aq::RetryTimeoutException while running workflow: timeout: 600 To correct this issue replication will need to be caught up or fixed for the cluster, which is out of scope for this document. The replication lag runbook is a good place to start. If replication can only be fixed by doing a dump and restore then the maintenance window may need to be rescheduled. Once replication has been restored the workflow can simply be resumed and should continue on normally. Upgrade fails unable to failover In clustered mysql upgrade workflow for database servers, we failover a couple of times. Once from primary to secondary after secondary is upgraded and again back to primary after primary is upgraded. Failover from primary to secondary uses a force flag as we know that secondary->primary replication is going to be behind. Workflow currently retries a total of 2 times with a delay of two minutes between each retry on DbClusterError . The output for ah-workflow <workflow id> --show-logs will contain an error similar to the one below. [2020-08-26 13:57:45] WARN: Fail over attempt unsuccessful. Unlocking tables and setting read_only to OFF on fsdb-6 [2020-08-26 13:57:45] Aq::RetryTimeoutException: at_most_n_times: 2 To correct the issue try to look at why workflow is unable to complete the action and resolve it. The workflow should be able to be resumed and the upgrade will carry on without issue. If it fails again DBAs will need to be notified. Free tier High I/O after upgrade The following may or may not apply to the MySQL 5.7 upgrade After the upgrade of free-tier servers during the MySQL 5.5 -> 5.6 upgrade, disk I/O increased. It turns out that the ah-db-optimized daemon got stuck in a loop based on files in the /var/acquia/db.optimize directory. To fix this you can remove those files and stop and start the daemon. Verify that the optimize process is really gone after stopping the daemon as it does not always kill it. To check if the optimize process is running use the following command: ps -ef | grep \"[a]h-db-optimized\" Escalation Ops - Internal Escalation The first level of escalation is within Ops. Follow the standard procedure for this type of escalation. When to escalate to Ops - Internal Internal Ops escalation should be used when an error occurs which cannot be resolved by following the troubleshooting steps in this runbook. DBA (& Senior Ops) The second level of escalation, for issues unresolved by Ops internal escalation is DBA. Follow the standard procedure for this type of escalation. When to escalate to DBA DBA escalation should be used to investigate MySQL related errors that cannot be resolved by Ops. DBAs are not expected to resolve general server launch failures or errors unrelated to MySQL (AWS errors, errors in the workflow system, non-MySQL service start failures, SSH failures, etc). Unresolvable MySQL errors may be further escalated to engineering. Cloud Engineering The third level of escalation, for issues unresolved by Ops internal escalation and unresolved by DBA escalation (or not directly applicable to MySQL), is Cloud Engineering. Follow the standard procedure for this type of escalation. Selecting the proper component based on the type of failure is critical for timely response. Not all failures during a MySQL Workflow upgrade should have the MySQL component. If the error is unrelated to the actual upgrade of MySQL itself (such as DNS errors, package mirror errors, component errors, etc) be certain to select an appropriate component when filing the Incident. When to escalate to Engineering Engineering escalation should be used for all errors which other escalation paths were unsuccessful at resolving. CL Incident Urgency CRITIAL, URGENT - May be filed with express approval of an Ops Manager . These priorities are to be reserved for instances of customer site outage or when a workflow upgrades only one of two servers in a cluster. These will result in paging an Engineer. TBD - May be filed for any unresolved upgrade failure. These will be triaged on the next business day.","title":"MySQL / Percona Server 5.7.33 Upgrade"},{"location":"kanban_tickets/mysql_upgrade_5733/#mysql-percona-server-5733-upgrade","text":"Overview Non-clustered server upgrade Single-region cluster upgrade Multi-region cluster upgrade Client server upgrade Running upgrades in parallel Prep Bulk Upgrade Workflows Post-upgrade check Troubleshooting Escalation","title":"MySQL / Percona Server 5.7.33 Upgrade"},{"location":"kanban_tickets/mysql_upgrade_5733/#overview","text":"This runbook describes the procedure to upgrade database servers from Percona Server 5.6 to 5.7. This procedure assumes that the upgrade has already been scheduled and approved. Upgrades should always be performed using the MySQL upgrade workflow but it is possible to manually execute all the steps in this workflow. The manual process should only be done in case the automated process fails and cannot be resumed even when the cause of the error has been fixed. In general this will require assistance from a DBA. The MySQL upgrade workflow will work for standalone database servers as well as clustered database servers. Multi-region clusters are not supported. The MySQL upgrade workflow supports upgrades to 5.7.33. The workflow can upgrade to 5.7.33 from 5.6.32, 5.6.41, 5.7.29, or 5.7.31.","title":"Overview"},{"location":"kanban_tickets/mysql_upgrade_5733/#database-server-upgrade-workflow-explanation","text":"The MySQL upgrade workflow can be started with ah-db-cluster upgrade-mysql command. The workflow can upgrade either a non-clustered server or a database cluster as a whole. To upgrade a cluster you only need to specify one of the servers in the cluster as the target for the upgrade. Multi-region cluster upgrades are currently not supported by the workflow. When upgrading a cluster the workflow takes care of upgrading the individual servers in the correct order as well as performing failovers and locking the cluster to the active server. Whether it's part of a cluster upgrade or it's a non-clustered server upgrade, the upgrade steps for the individual servers are the same: run automated pre-checks change fields mysql_version run puppet run mysql_upgrade restart MySQL For clusters the complete workflow looks like this: run automated pre-checks lock the cluster to the active server upgrade the passive unlock the cluster fail over to the upgraded server lock the cluster to active server upgrade the new passive server unlock the cluster fail back The failover works differently from our normal dns-based failover to minimize the possibility of split-brain but as a result it will cause downtime during the failover. Because this downtime impacts the SLA all upgrades will take place in maintenance windows and customers will be notified by Support. If the workflow fails a notification will be sent to PagerDuty and that failure needs to be handled within the maintenance window if possible. The upgrade tool will disable alerts for the servers in question at the start of the process and enable them again at the end. The mysql_upgrade script checks all tables for compatibility with the new version which can take a long time. A cluster upgrade can take anywhere between 10 minutes and 6 hours depending on a number of factors but the most important factor is the number of tables that the mysql_upgrade script has to check. During this check the database server is available for customers but at the end of this check MySQL will be restarted. For database clusters this has no impact since the server is passive at that time but for non-clustered servers it will interrupt the site.","title":"Database server upgrade workflow explanation"},{"location":"kanban_tickets/mysql_upgrade_5733/#non-clustered-server-upgrade","text":"Upgrading a non-clustered server will cause downtime since the mysqld process will be restarted multiple times during the upgrade process, both at the start and at the end. The total amount of downtime depends on the type of server and the size of the dataset. Most upgrades should take less than 1 hour. In cases of extremely high numbers of tables the upgrade can take several hours. The highest we've seen in testing is 3 hours for an individual server. The following steps need to be performed to upgrade a non-clustered database server. Run the upgrade command: ah-db-cluster upgrade-mysql <hostname> --version=5.7.33 --op-ticket <jira ticket id> Verify workflow has been successfully completed ah-workflow get <workflow id> --show-logs","title":"Non-clustered server upgrade"},{"location":"kanban_tickets/mysql_upgrade_5733/#single-region-cluster-upgrade","text":"Upgrading a database cluster will result in downtime during the failovers but not during the actual upgrade process for the individual servers. HA will not be available during the upgrade so if there is a problem with the active server the site will be down. The following steps need to be performed to upgrade a database cluster. Run the upgrade command The hostname can be either of the database servers in the cluster, the workflow will upgrade both servers in the cluster. ah-db-cluster upgrade-mysql <hostname> --version=5.7.33 --op-ticket <jira ticket id> Verify tasks have been completed ah-workflow get <workflow id> --show-logs","title":"Single-region cluster upgrade"},{"location":"kanban_tickets/mysql_upgrade_5733/#multi-region-cluster-upgrade","text":"Multi-region upgrades are not supported either manually or via the workflow.","title":"Multi-region cluster upgrade"},{"location":"kanban_tickets/mysql_upgrade_5733/#client-server-upgrade","text":"Clients can be upgraded by setting the mysql_version server config setting. Set the mysql_version service config setting: ah-server edit $SERVERS -c puppet:mysql_version=5.7.31 Wait for puppet to run. Confirm that all mysql packages are the proper version: fpdsh -l $SERVERS -c '(sudo apt list --installed 2>&1 | grep \"percona.\\?server\" | grep -v \"5.7.31\" && echo \"INCORRECT mysql version found\") || /bin/true'","title":"Client server upgrade"},{"location":"kanban_tickets/mysql_upgrade_5733/#running-upgrades-in-parallel","text":"","title":"Running upgrades in parallel"},{"location":"kanban_tickets/mysql_upgrade_5733/#prep","text":"Before starting any work, verify the ticket and the list of servers that you will be upgrading. The OP ticket should have a list of DB servers to be upgraded. Set up the following variables and initialize a temp dir to capture workflow output: SERVERS=( ) SERVERS_CSV=$(array-csv ${SERVERS[@]}) DB_SERVERS=( $(ah-server list ${SERVERS_CSV} -w typeINstaging,ded,fsdb,dbmaster status=0 -c puppet:mysql_version | tr -d ',' | awk '$2!~/5.7.33/ {print $1}') ) JIRA=<OP ticket number> mkdir ${OPSTMP}/${JIRA} Refine the server list to exclude already-upgraded clusters and build a list of primary databases: sv-dbislocked ${DB_SERVERS[@]} eval $(sv-dbprisec ${DB_SERVERS[@]}) echo \"Number of DB clusters to upgrade: ${#PRIMARY_DBS[@]}\" echo \"${PRIMARY_DBS[@]}\" Make sure to investigate any locked database clusters and exclude them from your DB_SERVERS list, if appropriate. The eval statement above will set up a PRIMARY_DBS variable in your terminal.","title":"Prep"},{"location":"kanban_tickets/mysql_upgrade_5733/#bulk-upgrade-workflows","text":"Finally, start the upgrade workflows. CONCURRENCY sets how many workflows will be in progress at once. We default it to 20 here, but you should set it to a value you are comfortable with. CONCURRENCY=20 printf '%s\\n' ${PRIMARY_DBS[@]} \\ | xargs -n1 -P${CONCURRENCY} -I{} \\ bash -c \"ah-db-cluster upgrade-mysql {} --version=5.7.33 --op-ticket ${JIRA} |& tee -a ${OPSTMP}/${JIRA}/{}.log\" If you need to stop the upgrades for any reason (i.e. end of maintenance window, many erroring workflows, etc.), stop the process ( ^C should work), and get the ID of any incomplete workflows: WORKFLOW_IDS=( $(awk '$0~/Workflow.*is in status:/ {print $4}' ${OPSTMP}/${JIRA}/*.log | sort -u) ) ah-workflow list % -w idIN$(array-csv ${WORKFLOW_IDS[@]}) status!=completed -c status Monitor in-progress workflows with ah-workflow watch and investigate any workflows which have errored . If you later resume upgrades, make sure to redo the prep section to renew your server lists . It's also handy to keep an eye on the #workflow-events Slack room to check for progress and failures. Workflow failures are printed in the Operations room as well. Once all of the workflows are complete the output files can be checked for errors. grep -i err ${OPSTMP}/${JIRA}/*.log","title":"Bulk Upgrade Workflows"},{"location":"kanban_tickets/mysql_upgrade_5733/#post-upgrade-check","text":"Run the following command on the upgraded server(s). If a single server was upgraded then you can just use fssh instead of fpdsh . fpdsh -l ${SERVERS_CSV} \\ -c \"sudo grep -v 'Checking\\|Upgrading\\|OK\\|Looking for\\|Running\\|Warning: Using a password on the command line interface can be insecure.' \\ \\$(sudo find /vol/ebs1/mysql/ -iname '*mysql_upgrade-*.log')\" The output should only include log entries indicating successful upgrades. dbmaster-133: Upgrade process completed successfully. If there are errors such as the example below contact a DBA immediately. dbmaster-133: Repairing tables dbmaster-133: g205626.search_index dbmaster-133: Error : Unknown collation '#253' in table 'search_index' definition dbmaster-133: error : Corrupt","title":"Post-Upgrade Check"},{"location":"kanban_tickets/mysql_upgrade_5733/#troubleshooting","text":"Important Note Do not abort workflows! Whenever an upgrade workflow fails an alert is sent to ops on-call. There is a process defined below to escalate for MySQL upgrade support. If you encounter any problems other than those listed in this section of the runbook or those addressed in other Ops runbooks, please use the process to escalate the issue. Ensure that the workflow ID is included in the Jira ticket that is being worked.","title":"Troubleshooting"},{"location":"kanban_tickets/mysql_upgrade_5733/#automated-pre-flight-checks","text":"After resolving any of the below failing pre-flight checks, the workflow can be resumed with the following command: ah-workflow resume <workflow id>","title":"Automated pre-flight checks"},{"location":"kanban_tickets/mysql_upgrade_5733/#puppet-is-disabled","text":"The workflow depends on being able to run puppet to upgrade the packages. You will need to investigate why puppet was disabled and whether or not it is safe to be re-enabled. If so, use this command to enable puppet on the server in question: fssh <hostname> 'sudo /usr/local/bin/ah-puppet-enable'","title":"Puppet is disabled"},{"location":"kanban_tickets/mysql_upgrade_5733/#volume-capacity","text":"There needs to be free space on both the /mnt and /vol/ebs1 volume for the upgrade to complete successfully. The check will fail if either of these volumes has less than 1 GB of space available. The space will need to be freed before starting the workflow or resize the volume. This check is done on all the servers in the cluster.","title":"Volume capacity"},{"location":"kanban_tickets/mysql_upgrade_5733/#backup-running","text":"For customers with very large databases, sometimes customer initiated backup maybe ongoing when we attempt to upgrade database cluster. If that is the case the upgrade workflow will fail in its pre-flight check. You can either wait for the customer backup is completed or kill it before proceeding to resume the workflow.","title":"Backup running"},{"location":"kanban_tickets/mysql_upgrade_5733/#server-status","text":"If any server in the database cluster is not in status NORMAL the automated server status check will fail. All servers in the cluster must be launched and operating normally before beginning the upgrade process.","title":"Server status"},{"location":"kanban_tickets/mysql_upgrade_5733/#instance-status","text":"If any server's INSTANCE STATUS is not ok the automated instance status check will fail. If any AWS maintenance EVENTS are scheduled for the next 48 hours, the instance status check will fail. In either case, the server(s) will need to be relaunched before beginning the upgrade process.","title":"Instance status"},{"location":"kanban_tickets/mysql_upgrade_5733/#fields-verify-replicationsh-running","text":"At 10AM UTC we run a script on database clusters that verifies replication between both masters. Performing an upgrade while this script is running will result in errors in the daily replication verification ticket. A pre-flight check verifies if it is currently running and fails if so. You can either wait for the script to complete execution or kill it before proceeding to resume the workflow. If the cron is scheduled to start the script right after we complete the pre-flight check, we handle that by stopping cron in the workflow.","title":"fields-verify-replication.sh running"},{"location":"kanban_tickets/mysql_upgrade_5733/#unexpected-output-in-workflow-logs","text":"Upgrade workflow will archive all logs from previous upgrade workflow to the /vol/ebs1/mysql/mysql_upgrade-pre-5.7.33-logs-#{workflow_id}-#{timestamp}.tar.gz , and will check current workflow's log for the expected output. All lines in upgrade workflow's log should contain any of the following values: * Checking * Looking for * OK * Repairing tables * Running * Table rebuild required. * Upgrade process completed successfully. * Upgrading Any other lines not matching the rules will raise an exception with the following message: Unexpected output in <log-file-name>: <unexpected output> In that case investigate the unexpected output on the server. If Upgrade process completed successfully. appears near the end of the log then the error is false and you can continue the workflow. Set the workflow to the next step and resume: for primary server: ah-workflow set-step <workflow-id> restart_mysql_on_primary for secondary: ah-workflow set-step <workflow-id> restart_mysql_on_secondary for single-node: ah-workflow set-step <workflow-id> cleanup NOTE Repeat the set-step from secondary log check failure for primary if it happens again on primary. If Upgrade process completed successfully. does not appear in the log then reach out to DBA for further actions.","title":"Unexpected output in workflow logs"},{"location":"kanban_tickets/mysql_upgrade_5733/#known-failure-modes","text":"","title":"Known failure modes"},{"location":"kanban_tickets/mysql_upgrade_5733/#workflow-fails-to-be-created-because-another-active-workflow-exists","text":"Hosting api allows only one mysql upgrade workflow to be created for a given db cluster id. It returns an error, Cannot have another mysql upgrade workflow running on the same cluster. Move workflows XX,YY to one of the final states(completed/aborted/failed) first. This means there are one or more workflows which are not in one of the final states of a workflow. Transition each of the listed workflows or abort them before proceeding to create a new one for the same cluster. Run ah-workflow help export JIRA=to get the list of commands to help you transition them.","title":"Workflow fails to be created because another active workflow exists"},{"location":"kanban_tickets/mysql_upgrade_5733/#upgrade-fails-during-step-prep_cluster_primary","text":"The workflow step prep_cluster_primary temporarily puts a custom setting in place. If that setting already exists that step will fail. The error in the workflow will look like this: [19:18:53] [19:18:53] Failure AH_TASK_CRITICAL: status: 1 [2016-11-08 19:18:52] mysql_upgrade_workflow workflow (69): Transitioning step to: prep_cluster_primary [2016-11-08 19:18:52] mysql_upgrade_workflow workflow (69): Executing step: prep_cluster_primary [2016-11-08 19:18:53] mysql_upgrade_workflow workflow (69): Step: prep_cluster_primary raised error RuntimeError [2016-11-08 19:18:53] ERROR: Caught RuntimeError while running workflow: mysql_upgrade script exited non-zero! The custom setting in question is skip-slave-start which prevents MySQL replication from starting when MySQL starts. The actual error message points to the mysql_upgrade script but that is a bug since mysql_upgrade does not get run during this step. To fix this error remove the custom setting from the server by executing the following command on bastion: ah-server edit <primary hostname> -c my.cnf:skip-slave-start= After that the workflow can be resumed.","title":"Upgrade fails during step prep_cluster_primary"},{"location":"kanban_tickets/mysql_upgrade_5733/#upgrade-fails-due-to-puppet_run-time-out","text":"We've seen at least one instance where the puppet run took longer than the workflow task expected and caused the workflow to error stop. If the workflow fails, use ah-workflow <workflow id> --show-logs and look for this error. [2016-11-30 13:15:59] DEBUG: |Time taken for|upgrade_secondary|puppet_run|300 [2016-11-30 13:15:59] mysql_upgrade_workflow workflow (139): Step: upgrade_secondary raised error RuntimeError [2016-11-30 13:15:59] ERROR: Caught RuntimeError while running workflow: ah-apply for subsystem puppet did not return status=0 indicating successful changes being made. status: 66 The workflow should be able to be resumed and the upgrade will carry on without issue. If it fails again escalation will be necessary.","title":"Upgrade fails due to puppet_run time out"},{"location":"kanban_tickets/mysql_upgrade_5733/#upgrade-fails-during-wait_replication_before","text":"If one of the servers is behind in replication and it takes longer than 10 minutes catch back up the step wait_replication_before will fail with an error_pause . The output for ah-workflow <workflow id> --show-logs will contain an error similar to the one below. [2016-12-20 18:41:27] DEBUG: Current replication delay: 673 [2016-12-20 18:41:27] mysql_upgrade_workflow workflow (8): Step: wait_replication_before raised error Aq::RetryTimeoutException [2016-12-20 18:41:27] ERROR: Caught Aq::RetryTimeoutException while running workflow: timeout: 600 To correct this issue replication will need to be caught up or fixed for the cluster, which is out of scope for this document. The replication lag runbook is a good place to start. If replication can only be fixed by doing a dump and restore then the maintenance window may need to be rescheduled. Once replication has been restored the workflow can simply be resumed and should continue on normally.","title":"Upgrade fails during wait_replication_before"},{"location":"kanban_tickets/mysql_upgrade_5733/#upgrade-fails-unable-to-failover","text":"In clustered mysql upgrade workflow for database servers, we failover a couple of times. Once from primary to secondary after secondary is upgraded and again back to primary after primary is upgraded. Failover from primary to secondary uses a force flag as we know that secondary->primary replication is going to be behind. Workflow currently retries a total of 2 times with a delay of two minutes between each retry on DbClusterError . The output for ah-workflow <workflow id> --show-logs will contain an error similar to the one below. [2020-08-26 13:57:45] WARN: Fail over attempt unsuccessful. Unlocking tables and setting read_only to OFF on fsdb-6 [2020-08-26 13:57:45] Aq::RetryTimeoutException: at_most_n_times: 2 To correct the issue try to look at why workflow is unable to complete the action and resolve it. The workflow should be able to be resumed and the upgrade will carry on without issue. If it fails again DBAs will need to be notified.","title":"Upgrade fails unable to failover"},{"location":"kanban_tickets/mysql_upgrade_5733/#free-tier-high-io-after-upgrade","text":"The following may or may not apply to the MySQL 5.7 upgrade After the upgrade of free-tier servers during the MySQL 5.5 -> 5.6 upgrade, disk I/O increased. It turns out that the ah-db-optimized daemon got stuck in a loop based on files in the /var/acquia/db.optimize directory. To fix this you can remove those files and stop and start the daemon. Verify that the optimize process is really gone after stopping the daemon as it does not always kill it. To check if the optimize process is running use the following command: ps -ef | grep \"[a]h-db-optimized\"","title":"Free tier High I/O after upgrade"},{"location":"kanban_tickets/mysql_upgrade_5733/#escalation","text":"","title":"Escalation"},{"location":"kanban_tickets/mysql_upgrade_5733/#ops-internal-escalation","text":"The first level of escalation is within Ops. Follow the standard procedure for this type of escalation.","title":"Ops - Internal Escalation"},{"location":"kanban_tickets/mysql_upgrade_5733/#when-to-escalate-to-ops-internal","text":"Internal Ops escalation should be used when an error occurs which cannot be resolved by following the troubleshooting steps in this runbook.","title":"When to escalate to Ops - Internal"},{"location":"kanban_tickets/mysql_upgrade_5733/#dba-senior-ops","text":"The second level of escalation, for issues unresolved by Ops internal escalation is DBA. Follow the standard procedure for this type of escalation.","title":"DBA (&amp; Senior Ops)"},{"location":"kanban_tickets/mysql_upgrade_5733/#when-to-escalate-to-dba","text":"DBA escalation should be used to investigate MySQL related errors that cannot be resolved by Ops. DBAs are not expected to resolve general server launch failures or errors unrelated to MySQL (AWS errors, errors in the workflow system, non-MySQL service start failures, SSH failures, etc). Unresolvable MySQL errors may be further escalated to engineering.","title":"When to escalate to DBA"},{"location":"kanban_tickets/mysql_upgrade_5733/#cloud-engineering","text":"The third level of escalation, for issues unresolved by Ops internal escalation and unresolved by DBA escalation (or not directly applicable to MySQL), is Cloud Engineering. Follow the standard procedure for this type of escalation. Selecting the proper component based on the type of failure is critical for timely response. Not all failures during a MySQL Workflow upgrade should have the MySQL component. If the error is unrelated to the actual upgrade of MySQL itself (such as DNS errors, package mirror errors, component errors, etc) be certain to select an appropriate component when filing the Incident.","title":"Cloud Engineering"},{"location":"kanban_tickets/mysql_upgrade_5733/#when-to-escalate-to-engineering","text":"Engineering escalation should be used for all errors which other escalation paths were unsuccessful at resolving.","title":"When to escalate to Engineering"},{"location":"kanban_tickets/mysql_upgrade_5733/#cl-incident-urgency","text":"CRITIAL, URGENT - May be filed with express approval of an Ops Manager . These priorities are to be reserved for instances of customer site outage or when a workflow upgrades only one of two servers in a cluster. These will result in paging an Engineer. TBD - May be filed for any unresolved upgrade failure. These will be triaged on the next business day.","title":"CL Incident Urgency"},{"location":"kanban_tickets/orphans/","text":"Orphans An orphan instance is an instance that is running in Amazon that fields has no knowledge of or its status is not zero in fields (i.e. launching), with the exception of masters which are not in fields but of course are required. Preparation Review the Instance Audit ticket that Otto Bot generated for the list of suspected orphans Procedure For each suspected orphan compare the instance id in the report to one in fields If the ID's do not match, then the instance is indeed an orphan Determine the orphan instance status Sometimes instances will get stuck in the shutting-down stage and take hours before Amazon reaps it. If it is in the shutting down state, we are not being charged, so we don't have to worry about it and can ignore it. To determine the state of the instance, run: INSTANCE_ID= REGION= aws ec2 describe-instances --instance-ids $INSTANCE_ID --region $REGION Determine when the server was launched Now if the ID's match, the instance isn't an orphan, it is running but is not showing as status=0 in fields. This could be because it was just recently relaunched and the relaunch hasn't completed. At this point we want to determine when the server was launched. We can accomplish this by running: sv-instancehistory $SERVER If the server was launched within the normal launch window for a server of its region, we will need to give it time to complete, so we will come back and check up on it a little bit later. If the server launched time is beyond the normal launch window, we are probably looking at a failed launch. Devcloud We need to find the task that launched it and check the logs to see if any errors occurred and then attempt to rectify them. We can check for tasks relating to a server by using: sv-task $SERVER All Other Environments We will need to attempt to log on to the server, run Puppet and the respective fields-config-*.php script to see what, if any errors are encountered and then attempt to fix them. Once the server is fixed, it will need to have its status changed to 0 and added back to monitoring, in the case of a web it will need to be added back into the web pool if it isn't already in it. If the orphan instance report is not showing a server name Then likely this instance was a failed launch. To determine if this is indeed the case: Get the public ip address ORPHAN_ID= REGION= aws ec2 describe-instances --instance-id $ORPHAN_ID --region $REGION Attempt to log on as the ubuntu user with the launcher key IP= ssh -i $FIELDS_SSH_ID ubuntu@$IP -p 22 Usually if it is a failed launch, the root user won't exist and you will get a message to use ubuntu. If this is the case you can safely terminate the instance. If you do not get the message to use the ubuntu user to log in, do not proceed with terminating this instance. Escalate this to either Amin Astaneh, Phil Ingram, Ricardo Amaro or Chad Odwazny as they are currently the only people that have access to ssh into servers with the \"emergency backup ssh keys\". Removing orphans nodes Once you have verified it is an orphan you can terminate the instance ORPHAN_ID= REGION= aws ec2 terminate-instances --instance-ids $ORPHAN_ID --region $REGION","title":"Orphans"},{"location":"kanban_tickets/orphans/#orphans","text":"An orphan instance is an instance that is running in Amazon that fields has no knowledge of or its status is not zero in fields (i.e. launching), with the exception of masters which are not in fields but of course are required.","title":"Orphans"},{"location":"kanban_tickets/orphans/#preparation","text":"Review the Instance Audit ticket that Otto Bot generated for the list of suspected orphans","title":"Preparation"},{"location":"kanban_tickets/orphans/#procedure","text":"For each suspected orphan compare the instance id in the report to one in fields If the ID's do not match, then the instance is indeed an orphan","title":"Procedure"},{"location":"kanban_tickets/orphans/#determine-the-orphan-instance-status","text":"Sometimes instances will get stuck in the shutting-down stage and take hours before Amazon reaps it. If it is in the shutting down state, we are not being charged, so we don't have to worry about it and can ignore it. To determine the state of the instance, run: INSTANCE_ID= REGION= aws ec2 describe-instances --instance-ids $INSTANCE_ID --region $REGION","title":"Determine the orphan instance status"},{"location":"kanban_tickets/orphans/#determine-when-the-server-was-launched","text":"Now if the ID's match, the instance isn't an orphan, it is running but is not showing as status=0 in fields. This could be because it was just recently relaunched and the relaunch hasn't completed. At this point we want to determine when the server was launched. We can accomplish this by running: sv-instancehistory $SERVER If the server was launched within the normal launch window for a server of its region, we will need to give it time to complete, so we will come back and check up on it a little bit later. If the server launched time is beyond the normal launch window, we are probably looking at a failed launch.","title":"Determine when the server was launched"},{"location":"kanban_tickets/orphans/#devcloud","text":"We need to find the task that launched it and check the logs to see if any errors occurred and then attempt to rectify them. We can check for tasks relating to a server by using: sv-task $SERVER","title":"Devcloud"},{"location":"kanban_tickets/orphans/#all-other-environments","text":"We will need to attempt to log on to the server, run Puppet and the respective fields-config-*.php script to see what, if any errors are encountered and then attempt to fix them. Once the server is fixed, it will need to have its status changed to 0 and added back to monitoring, in the case of a web it will need to be added back into the web pool if it isn't already in it.","title":"All Other Environments"},{"location":"kanban_tickets/orphans/#if-the-orphan-instance-report-is-not-showing-a-server-name","text":"Then likely this instance was a failed launch. To determine if this is indeed the case: Get the public ip address ORPHAN_ID= REGION= aws ec2 describe-instances --instance-id $ORPHAN_ID --region $REGION Attempt to log on as the ubuntu user with the launcher key IP= ssh -i $FIELDS_SSH_ID ubuntu@$IP -p 22 Usually if it is a failed launch, the root user won't exist and you will get a message to use ubuntu. If this is the case you can safely terminate the instance. If you do not get the message to use the ubuntu user to log in, do not proceed with terminating this instance. Escalate this to either Amin Astaneh, Phil Ingram, Ricardo Amaro or Chad Odwazny as they are currently the only people that have access to ssh into servers with the \"emergency backup ssh keys\".","title":"If the orphan instance report is not showing a server name"},{"location":"kanban_tickets/orphans/#removing-orphans-nodes","text":"Once you have verified it is an orphan you can terminate the instance ORPHAN_ID= REGION= aws ec2 terminate-instances --instance-ids $ORPHAN_ID --region $REGION","title":"Removing orphans nodes"},{"location":"kanban_tickets/overview/","text":"SSL Overview To reference specific SSL procedures, please see the menu on the left under the heading \"SSL\" or visit the index for SSL . Acquia provides SSL termination at the following locations: ELB Layer Nginx Layer (host type: bal-% ) In order for customers to properly use HTTP over SSL/TLS (HTTPS) to secure their website, they need a certificate (\"cert\") provisioned. Depending on their hosting setup, there are a few options: Self-service : Through the customer-facing UI, the customer can upload a cert which they purchased themselves. It will be deployed to an elastic load balancer (ELB). There is no ops involvement for this case. If the customer has shared balancers, they can have their domain name(s) added to one of Acquia's shared UCC certs. If the customer has dedicated balancers, they have two options: Purchase a cert on their own and have Ops install it Provide the organizational details for Ops to purchase and install a new cert. Acquia's certificate vendor is DigiCert . The below list is an incomplete list of SSL-related activities that Operations is responsible for: Ordering/Deploying certificates Providing certificates from Acquia's certificate vendor back to the customer (generally for deployment to Akamai or another CDN) Managing customer-supplied certificates including: Deploying certificates to the ELB layer from the Nginx layer Deploying certificates to the Nginx Layer directly from provided certs Important Note Our DigiCert account is upgraded recently where the new platform is called as CertCentral, hence please refer below Digicert Central UI confluence page for updated instructions: https://confluence.acquia.com/display/OE/DigiCert+-+CertCentral+UI Customer-facing Documentation on docs.ccquia.com Customers have access to basic information about Self-Service SSL and other SSL options on docs.acquia.com. Docs.Acquia.com - SSL and Acquia Cloud Technical details of how SSL/TLS cert chains work Security.StackExchange - How SSL Negotiation and Communication Works Security.StackExchange - How Certificate Chain Validation Works Ordering SSL Certificates Pre-flight Check Prior to ordering any SSL certificates, you should first understand the type of request. The below questions should help you identify the type of action you are being asked to take. Is the request from an internal Acquia group (Network, Search, etc.) or is it an external customer? If it's for an internal Acquia group, ensure the domain being requested is able to be covered by an existing certificate first (example: newservice.acquia.com can be covered by a duplicate cert of *.acquia.com ). If in doubt, ask a Tier 2. If it's for an external customer, continue. Is the domain already covered by another certificate? Is the certificate managed by Acquia or by the customer? Does the customer's cluster already have a balancer pair with an SSL certificate currently deployed? WHOIS Before starting the process to provision or reissue a cert, ensure that the WHOIS record for each of the customer's domains lists a true email address for the admin contact. This is mandatory for the whole certificate issuing process to work. If there is no admin contact email, or it does not look like an email that actually gets checked, such as a privacy address, ask support to have the customer update their WHOIS record to include this email address. Note there are some exceptions to this rule. To check WHOIS information, simply run the following command. WHOIS records apply only to the domain ( example.com ), so be sure to strip the address to it's bare domain to check. For example, use example.com instead of herp.derp.example.com . WHOIS records have no common format, so simply look for the admin contact email address. whois example.com Some TLDs, such as .co.uk and .gov do not have public WHOIS records. TODO: List gotchas and how to deal with them. Types of Actions Generally, management of SSL requests fall into one of the following categories: Adding/removing a domain on an Acquia-managed UCC certificate (fields tag: ssl_ucc* for shared UCC, fields tag: ssl_$CUSTOMER_IDENTIFIER for dedicated UCC) Purchase of a certificate of one of the below types: SSL Plus \u2014 A typical dedicated cert. Extended Validation \u2014 The ticket will explicitly state the customer wants extended validation or \"EV\". Unified Communications (UCC) \u2014 The customer wants multiple disparate domains on the same cert. EV Multi-Domain \u2014 UCC and EV together. Wildcard Plus \u2014 For all subdomains, such as *.example.com . Combining one or more certificates into a single certificate as a \"duplicate\" of an existing certificate (Vendor currently is able to perform this service for us on a case-by-case basis via emailing their support team, NOT GUARANTEED TO BE A FEATURE INDEFINITELY ) Trial Certs General Information/Process Ordering trial certs for individual domains (including individual sub-domains) is important for a number of reasons: Approving trial certs makes the certificate reissue process non-blocking in regards to reissue requests for UCC certificates. Allows the customer visibility into what domains are being approved at what specific times (if the customer/AM is concerned about launching specific sites or domains at specific times). Ordering trial certs with the same CSR as the desired certificate makes domain validation faster and easier to manage. Makes reissue requests less painful for Ops as there is less back-and-forth between Ops and Support/Account Management about which domains were approved and which were not. Ordering trial certs should proceed as-follows: Determine the fields tag of the balancer(s) that the certificate is going to be deployed to # To locate and list balancers and their tags for a given SITE: ah-server list site:${SITE} -w type=bal status=0 -c tags | egrep 'ssl_' # To view tags on a known list of balancers: ah-server tag list BAL1 [BAL2] ... If a CSR and Key pair exists in the Ops KPX Archive for the tag listed in the above command, use that CSR when ordering trial certs on DigiCert's website. If a CSR and Key pair does not exist in the Ops KPX Archive for the tag listed in the above command, check out Generating CSRs . Trial Certificate FAQ \"Do I REALLY have to order trial certs for ALL of these sub-domains?\" Short answer: yes. Long answer: YES . \"Why can't I just order a trial cert for the base domain ( example.com ) and have the customer click 'approve this request, all future requests, and all sub-domains'?\" This strategy may work for customers that are attentive and exercise a large amount of control over their IT staff and platform strategy. For customers that have distributed Business Units (BUs), Organizational Units (OUs), or centralized IT staff, this strategy often does not work. Some customers' BUs/OUs do not exercise direct control of their domains' WHOIS records or DNS and often do not have their domain admin email address send mail to a valid inbox. Customers like Pfizer , J&J , and Novartis have large, centralized IT groups who exercise complete control over their company's domain registrar, DNS, and WHOIS information. These customers may not be able to change this information quickly enough (or at all) to fulfill domain approval requests. That said, ordering individual trial certs is still the CORRECT way to do SSL for Acquia customers. If you have any questions or concerns, please reach out to Ops Management. \"Does Acquia support placing shared UCC certificates on dedicated balancers?\" Only on a case-by-case basis as-approved by Ops Management. \"Does Acquia support \"combined\" certificates (wildcard + UCC)? Only on a case-by-case basis as-approved by Ops Management. Generally, no. Not only is this technically against RFC/best practices, it also requires Ops to interact with DigiCert Support via email and chat to complete and is time-consuming.","title":"SSL Overview"},{"location":"kanban_tickets/overview/#ssl-overview","text":"To reference specific SSL procedures, please see the menu on the left under the heading \"SSL\" or visit the index for SSL . Acquia provides SSL termination at the following locations: ELB Layer Nginx Layer (host type: bal-% ) In order for customers to properly use HTTP over SSL/TLS (HTTPS) to secure their website, they need a certificate (\"cert\") provisioned. Depending on their hosting setup, there are a few options: Self-service : Through the customer-facing UI, the customer can upload a cert which they purchased themselves. It will be deployed to an elastic load balancer (ELB). There is no ops involvement for this case. If the customer has shared balancers, they can have their domain name(s) added to one of Acquia's shared UCC certs. If the customer has dedicated balancers, they have two options: Purchase a cert on their own and have Ops install it Provide the organizational details for Ops to purchase and install a new cert. Acquia's certificate vendor is DigiCert . The below list is an incomplete list of SSL-related activities that Operations is responsible for: Ordering/Deploying certificates Providing certificates from Acquia's certificate vendor back to the customer (generally for deployment to Akamai or another CDN) Managing customer-supplied certificates including: Deploying certificates to the ELB layer from the Nginx layer Deploying certificates to the Nginx Layer directly from provided certs","title":"SSL Overview"},{"location":"kanban_tickets/overview/#important-note","text":"Our DigiCert account is upgraded recently where the new platform is called as CertCentral, hence please refer below Digicert Central UI confluence page for updated instructions: https://confluence.acquia.com/display/OE/DigiCert+-+CertCentral+UI","title":"Important Note"},{"location":"kanban_tickets/overview/#customer-facing-documentation-on-docsccquiacom","text":"Customers have access to basic information about Self-Service SSL and other SSL options on docs.acquia.com. Docs.Acquia.com - SSL and Acquia Cloud","title":"Customer-facing Documentation on docs.ccquia.com"},{"location":"kanban_tickets/overview/#technical-details-of-how-ssltls-cert-chains-work","text":"Security.StackExchange - How SSL Negotiation and Communication Works Security.StackExchange - How Certificate Chain Validation Works","title":"Technical details of how SSL/TLS cert chains work"},{"location":"kanban_tickets/overview/#ordering-ssl-certificates","text":"","title":"Ordering SSL Certificates"},{"location":"kanban_tickets/overview/#pre-flight-check","text":"Prior to ordering any SSL certificates, you should first understand the type of request. The below questions should help you identify the type of action you are being asked to take. Is the request from an internal Acquia group (Network, Search, etc.) or is it an external customer? If it's for an internal Acquia group, ensure the domain being requested is able to be covered by an existing certificate first (example: newservice.acquia.com can be covered by a duplicate cert of *.acquia.com ). If in doubt, ask a Tier 2. If it's for an external customer, continue. Is the domain already covered by another certificate? Is the certificate managed by Acquia or by the customer? Does the customer's cluster already have a balancer pair with an SSL certificate currently deployed?","title":"Pre-flight Check"},{"location":"kanban_tickets/overview/#whois","text":"Before starting the process to provision or reissue a cert, ensure that the WHOIS record for each of the customer's domains lists a true email address for the admin contact. This is mandatory for the whole certificate issuing process to work. If there is no admin contact email, or it does not look like an email that actually gets checked, such as a privacy address, ask support to have the customer update their WHOIS record to include this email address. Note there are some exceptions to this rule. To check WHOIS information, simply run the following command. WHOIS records apply only to the domain ( example.com ), so be sure to strip the address to it's bare domain to check. For example, use example.com instead of herp.derp.example.com . WHOIS records have no common format, so simply look for the admin contact email address. whois example.com Some TLDs, such as .co.uk and .gov do not have public WHOIS records. TODO: List gotchas and how to deal with them.","title":"WHOIS"},{"location":"kanban_tickets/overview/#types-of-actions","text":"Generally, management of SSL requests fall into one of the following categories: Adding/removing a domain on an Acquia-managed UCC certificate (fields tag: ssl_ucc* for shared UCC, fields tag: ssl_$CUSTOMER_IDENTIFIER for dedicated UCC) Purchase of a certificate of one of the below types: SSL Plus \u2014 A typical dedicated cert. Extended Validation \u2014 The ticket will explicitly state the customer wants extended validation or \"EV\". Unified Communications (UCC) \u2014 The customer wants multiple disparate domains on the same cert. EV Multi-Domain \u2014 UCC and EV together. Wildcard Plus \u2014 For all subdomains, such as *.example.com . Combining one or more certificates into a single certificate as a \"duplicate\" of an existing certificate (Vendor currently is able to perform this service for us on a case-by-case basis via emailing their support team, NOT GUARANTEED TO BE A FEATURE INDEFINITELY )","title":"Types of Actions"},{"location":"kanban_tickets/overview/#trial-certs","text":"","title":"Trial Certs"},{"location":"kanban_tickets/overview/#general-informationprocess","text":"Ordering trial certs for individual domains (including individual sub-domains) is important for a number of reasons: Approving trial certs makes the certificate reissue process non-blocking in regards to reissue requests for UCC certificates. Allows the customer visibility into what domains are being approved at what specific times (if the customer/AM is concerned about launching specific sites or domains at specific times). Ordering trial certs with the same CSR as the desired certificate makes domain validation faster and easier to manage. Makes reissue requests less painful for Ops as there is less back-and-forth between Ops and Support/Account Management about which domains were approved and which were not. Ordering trial certs should proceed as-follows: Determine the fields tag of the balancer(s) that the certificate is going to be deployed to # To locate and list balancers and their tags for a given SITE: ah-server list site:${SITE} -w type=bal status=0 -c tags | egrep 'ssl_' # To view tags on a known list of balancers: ah-server tag list BAL1 [BAL2] ... If a CSR and Key pair exists in the Ops KPX Archive for the tag listed in the above command, use that CSR when ordering trial certs on DigiCert's website. If a CSR and Key pair does not exist in the Ops KPX Archive for the tag listed in the above command, check out Generating CSRs .","title":"General Information/Process"},{"location":"kanban_tickets/overview/#trial-certificate-faq","text":"\"Do I REALLY have to order trial certs for ALL of these sub-domains?\" Short answer: yes. Long answer: YES . \"Why can't I just order a trial cert for the base domain ( example.com ) and have the customer click 'approve this request, all future requests, and all sub-domains'?\" This strategy may work for customers that are attentive and exercise a large amount of control over their IT staff and platform strategy. For customers that have distributed Business Units (BUs), Organizational Units (OUs), or centralized IT staff, this strategy often does not work. Some customers' BUs/OUs do not exercise direct control of their domains' WHOIS records or DNS and often do not have their domain admin email address send mail to a valid inbox. Customers like Pfizer , J&J , and Novartis have large, centralized IT groups who exercise complete control over their company's domain registrar, DNS, and WHOIS information. These customers may not be able to change this information quickly enough (or at all) to fulfill domain approval requests. That said, ordering individual trial certs is still the CORRECT way to do SSL for Acquia customers. If you have any questions or concerns, please reach out to Ops Management. \"Does Acquia support placing shared UCC certificates on dedicated balancers?\" Only on a case-by-case basis as-approved by Ops Management. \"Does Acquia support \"combined\" certificates (wildcard + UCC)? Only on a case-by-case basis as-approved by Ops Management. Generally, no. Not only is this technically against RFC/best practices, it also requires Ops to interact with DigiCert Support via email and chat to complete and is time-consuming.","title":"Trial Certificate FAQ"},{"location":"kanban_tickets/point_in_time_recovery/","text":"MySQL Point in Time Recovery WARNING : This only applies to Classic Cloud. It is possible to replay a MySQL instances' binlogs to recover lost data. An example circumstance would be catastrophic data loss requiring a restore from offline backups, the binlogs from the damaged instance can be used to recreate the data missing from the time the backup was taken. This assumes the current binlogs are still accessible. Warning This procedure should be considered DBA only unless there are extreme extenuating circumstances where a DBA is not available. Also there is no expectation to perform these actions on a customer server, it's reserved for internal Acquia services only unless approved by management. Procedure First thing needed to do is preserve the current binlogs. Since backups are taken from the secondary instance in the cluster it's best to save those, although the binlogs from the primary can be used if the secondary is no longer available or had fallen behind in replication before the incident but the steps are slightly different. Space permitting, copy the binlogs to a safe place. Once binlogs are secure, restore the MySQL data directory from the most recent snapshot backup onto the secondary instance, the steps for which are documented elsewhere in the run books. Do not yet start MySQL once the volume is restored. We need to find the last position of the restored binlogs to have a starting point for the recovery from the preserved binlogs. Restoring With Binlogs From Secondary Instance Find latest binlog. root@fsdb-204.network:~# ls -l /vol/ebs1/mysql/binlog.* -rw-rw---- 1 mysql mysql 71048875 Oct 3 06:25 /vol/ebs1/mysql/binlog.002110 -rw-rw---- 1 mysql mysql 71117884 Oct 4 06:25 /vol/ebs1/mysql/binlog.002111 -rw-rw---- 1 mysql mysql 35155562 Oct 4 18:17 /vol/ebs1/mysql/binlog.002112 -rw-rw---- 1 mysql mysql 48 Oct 4 12:14 /vol/ebs1/mysql/binlog.index Look for last position, labeled as end_log_pos . root@fsdb-204.network:~# mysqlbinlog /vol/ebs1/mysql/binlog.002112 | tail Warning: mysqlbinlog: unknown variable 'loose-default-character-set=utf8' REPLACE INTO `acquia`.`heartbeat` (ts, server_id, file, position, relay_master_log_file, exec_master_log_pos) VALUES ('2019-10-04T18:19:13.001860', '2', 'binlog.002112', '35220246', 'binlog.002158', '51647074') /*!*/; # at 35220627 #191004 18:19:13 server id 2 end_log_pos 35220658 CRC32 0x457669dd Xid = 4196996 COMMIT/*!*/; DELIMITER ; # End of log file ROLLBACK /* added by mysqlbinlog */; /*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/; /*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/; For this binlog it is 35220658 . Start MySQL root@fsdb-204.network:~# systemctl start mysql Once MySQL is running you can begin the replay from the binlogs. root@fsdb-204.network:~# mysqlbinlog --start-position=35220658 /mnt/tmp/binlog.002112 | mysql Once that completes successfully use mysqlbinlog on the other higher numbered binlogs but without the --start-position argument. The other instance in the cluster should be restored from the one that was repaired. Restoring With Binlogs From Primary Instead of looking for the last position of the secondary's binlogs we need to find the position of the binlog from the primary. root@fsdb-204.network:~# cat /vol/ebs1/mysql/master.info | head -3 23 binlog.002158 54692251 Then use that position to replay from the primary's binlogs that we have transferred to the secondary. root@fsdb-204.network:~# mysqlbinlog --start-position=54692251 /mnt/tmp/binlog.002158 | mysql Continue with the rest of the available binlogs without the --start-position argument.","title":"MySQL Point in Time Recovery"},{"location":"kanban_tickets/point_in_time_recovery/#mysql-point-in-time-recovery","text":"WARNING : This only applies to Classic Cloud. It is possible to replay a MySQL instances' binlogs to recover lost data. An example circumstance would be catastrophic data loss requiring a restore from offline backups, the binlogs from the damaged instance can be used to recreate the data missing from the time the backup was taken. This assumes the current binlogs are still accessible.","title":"MySQL Point in Time Recovery"},{"location":"kanban_tickets/point_in_time_recovery/#warning","text":"This procedure should be considered DBA only unless there are extreme extenuating circumstances where a DBA is not available. Also there is no expectation to perform these actions on a customer server, it's reserved for internal Acquia services only unless approved by management.","title":"Warning"},{"location":"kanban_tickets/point_in_time_recovery/#procedure","text":"First thing needed to do is preserve the current binlogs. Since backups are taken from the secondary instance in the cluster it's best to save those, although the binlogs from the primary can be used if the secondary is no longer available or had fallen behind in replication before the incident but the steps are slightly different. Space permitting, copy the binlogs to a safe place. Once binlogs are secure, restore the MySQL data directory from the most recent snapshot backup onto the secondary instance, the steps for which are documented elsewhere in the run books. Do not yet start MySQL once the volume is restored. We need to find the last position of the restored binlogs to have a starting point for the recovery from the preserved binlogs.","title":"Procedure"},{"location":"kanban_tickets/point_in_time_recovery/#restoring-with-binlogs-from-secondary-instance","text":"Find latest binlog. root@fsdb-204.network:~# ls -l /vol/ebs1/mysql/binlog.* -rw-rw---- 1 mysql mysql 71048875 Oct 3 06:25 /vol/ebs1/mysql/binlog.002110 -rw-rw---- 1 mysql mysql 71117884 Oct 4 06:25 /vol/ebs1/mysql/binlog.002111 -rw-rw---- 1 mysql mysql 35155562 Oct 4 18:17 /vol/ebs1/mysql/binlog.002112 -rw-rw---- 1 mysql mysql 48 Oct 4 12:14 /vol/ebs1/mysql/binlog.index Look for last position, labeled as end_log_pos . root@fsdb-204.network:~# mysqlbinlog /vol/ebs1/mysql/binlog.002112 | tail Warning: mysqlbinlog: unknown variable 'loose-default-character-set=utf8' REPLACE INTO `acquia`.`heartbeat` (ts, server_id, file, position, relay_master_log_file, exec_master_log_pos) VALUES ('2019-10-04T18:19:13.001860', '2', 'binlog.002112', '35220246', 'binlog.002158', '51647074') /*!*/; # at 35220627 #191004 18:19:13 server id 2 end_log_pos 35220658 CRC32 0x457669dd Xid = 4196996 COMMIT/*!*/; DELIMITER ; # End of log file ROLLBACK /* added by mysqlbinlog */; /*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/; /*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/; For this binlog it is 35220658 . Start MySQL root@fsdb-204.network:~# systemctl start mysql Once MySQL is running you can begin the replay from the binlogs. root@fsdb-204.network:~# mysqlbinlog --start-position=35220658 /mnt/tmp/binlog.002112 | mysql Once that completes successfully use mysqlbinlog on the other higher numbered binlogs but without the --start-position argument. The other instance in the cluster should be restored from the one that was repaired.","title":"Restoring With Binlogs From Secondary Instance"},{"location":"kanban_tickets/point_in_time_recovery/#restoring-with-binlogs-from-primary","text":"Instead of looking for the last position of the secondary's binlogs we need to find the position of the binlog from the primary. root@fsdb-204.network:~# cat /vol/ebs1/mysql/master.info | head -3 23 binlog.002158 54692251 Then use that position to replay from the primary's binlogs that we have transferred to the secondary. root@fsdb-204.network:~# mysqlbinlog --start-position=54692251 /mnt/tmp/binlog.002158 | mysql Continue with the rest of the available binlogs without the --start-position argument.","title":"Restoring With Binlogs From Primary"},{"location":"kanban_tickets/preallocating_eips_for_webs/","text":"Preallocating EIPs for webs In most cases, a customer wants to have EIPs assigned to the servers in use by their site so they can be whitelisted. They may be whitelisted for integration with their Single Sign-On (SSO) solution or because they are using a partner, such as a payment gateway, that requires static IP addresses. A customer must whitelist EIPs before webs are added into rotation for a site. Therefore, we must provide EIPs to the customer before launching webs. Procedure Allocate the desired number of webs and launch them. If the customer already has webs, use clone-web with the --ignore-eip, where web-1 is the first traffic serving web and web-2 is the second traffic serving web of the site. ah-server clone-web web-1 --ignore-eip NEW_WEB_1= ah-server clone-web web-2 --ignore-eip NEW_WEB_2= ah-server launch ${NEW_WEB_1} ${NEW_WEB_2} If the customer is single-tier, then follow the upsize procedure for single-tier to multi-tier . Allocate and add EIPs to all the webs. REGION= ah-elastic-ip allocate ${REGION} vpc IP_ADDRESS_1= ah-elastic-ip add ${IP_ADDRESS_1} ${NEW_WEB_1} ah-elastic-ip allocate ${REGION} vpc IP_ADDRESS_2= ah-elastic-ip add ${IP_ADDRESS_2} ${NEW_WEB_2} Put all the newly launched webs out of roation until the customer whitelists the IPs of the new webs. SITES=($(ah-site list on:${NEW_WEB_1} | paste -sd ' ')) for site in ${SITES[@]}; do ./fields-provision.php --site-set-web ${site}:inactive --webs ${NEW_WEB_1},${NEW_WEB_2}; done Provide a list of the EIPs to support or the AM in the Jira ticket. After the customer confirms that the EIPs have been whitelisted, add the webs in rotation. SITES=($(ah-site list on:${NEW_WEB_1} | paste -sd ' ')) for site in ${SITES[@]}; do ./fields-provision.php --site-set-web ${site}:active --webs ${NEW_WEB_1},${NEW_WEB_2}; done Check that all the webs are in rotation and serving traffic. site-getwebrotationstatus ${SITE} site-checkwebs ${SITE}","title":"Preallocating EIPs for webs"},{"location":"kanban_tickets/preallocating_eips_for_webs/#preallocating-eips-for-webs","text":"In most cases, a customer wants to have EIPs assigned to the servers in use by their site so they can be whitelisted. They may be whitelisted for integration with their Single Sign-On (SSO) solution or because they are using a partner, such as a payment gateway, that requires static IP addresses. A customer must whitelist EIPs before webs are added into rotation for a site. Therefore, we must provide EIPs to the customer before launching webs.","title":"Preallocating EIPs for webs"},{"location":"kanban_tickets/preallocating_eips_for_webs/#procedure","text":"Allocate the desired number of webs and launch them. If the customer already has webs, use clone-web with the --ignore-eip, where web-1 is the first traffic serving web and web-2 is the second traffic serving web of the site. ah-server clone-web web-1 --ignore-eip NEW_WEB_1= ah-server clone-web web-2 --ignore-eip NEW_WEB_2= ah-server launch ${NEW_WEB_1} ${NEW_WEB_2} If the customer is single-tier, then follow the upsize procedure for single-tier to multi-tier . Allocate and add EIPs to all the webs. REGION= ah-elastic-ip allocate ${REGION} vpc IP_ADDRESS_1= ah-elastic-ip add ${IP_ADDRESS_1} ${NEW_WEB_1} ah-elastic-ip allocate ${REGION} vpc IP_ADDRESS_2= ah-elastic-ip add ${IP_ADDRESS_2} ${NEW_WEB_2} Put all the newly launched webs out of roation until the customer whitelists the IPs of the new webs. SITES=($(ah-site list on:${NEW_WEB_1} | paste -sd ' ')) for site in ${SITES[@]}; do ./fields-provision.php --site-set-web ${site}:inactive --webs ${NEW_WEB_1},${NEW_WEB_2}; done Provide a list of the EIPs to support or the AM in the Jira ticket. After the customer confirms that the EIPs have been whitelisted, add the webs in rotation. SITES=($(ah-site list on:${NEW_WEB_1} | paste -sd ' ')) for site in ${SITES[@]}; do ./fields-provision.php --site-set-web ${site}:active --webs ${NEW_WEB_1},${NEW_WEB_2}; done Check that all the webs are in rotation and serving traffic. site-getwebrotationstatus ${SITE} site-checkwebs ${SITE}","title":"Procedure"},{"location":"kanban_tickets/provision_ace/","text":"Gather Information A provisioning request should have been made via an Ops ticket. This request should contain the contents of a 'deal sheet'. If no deal sheet is provided, do not proceed unless instructed to by an Ops manager. The following information is required, which you can find in the deal sheet. If any information is missing, add a comment and ask for it. Sitename(s) / Docroot name(s) Hardware: Production: single-tier, multi-tier, full-tier Instance sizes? Staging: Shared or Dedicated? If dedicated, what size? Load Balancers: Shared or Dedicated? If dedicated, what size? Storage/Disk Space: DB size in GB FS size in GB Hosting Location Primary Technical Contact Email Anything special should be explained in the ticket Be willing to go back to the ticket requestor and ask them to clarify if something is confusing, especially if the provision request calls for something not supported in our architecture (read slaves, etc). The juno or ah-provision commands will by default use magnetic for backup volumes, clarify any request asking for different. It is better to ask extra questions than to provision the wrong thing and then have to do it over. The OPS Sales Cheatsheet can be used to map Acquia Cluster sizes to instance sizes. Provisioning With Juno All provisions in ACE should be done with Juno unless you are provisioning something not supported by it. Juno is a web-based provisioning tool. In order to use it, you need to set up a tunnel to the bastion. Accessing Juno Manual Provisioning of Customer Hardware Provisioning a Customer Stack Allocating Hardware VPC Hardware Creating Sites Launching Servers Dedicated Memcache Dedicated Cron Manual Provisioning of Infrastructure Hardware Shared SVN Shared Bals Shared Staging Shared RA servers Ossec servers Stats servers Mon servers Backup servers","title":"Gather Information"},{"location":"kanban_tickets/provision_ace/#gather-information","text":"A provisioning request should have been made via an Ops ticket. This request should contain the contents of a 'deal sheet'. If no deal sheet is provided, do not proceed unless instructed to by an Ops manager. The following information is required, which you can find in the deal sheet. If any information is missing, add a comment and ask for it. Sitename(s) / Docroot name(s) Hardware: Production: single-tier, multi-tier, full-tier Instance sizes? Staging: Shared or Dedicated? If dedicated, what size? Load Balancers: Shared or Dedicated? If dedicated, what size? Storage/Disk Space: DB size in GB FS size in GB Hosting Location Primary Technical Contact Email Anything special should be explained in the ticket Be willing to go back to the ticket requestor and ask them to clarify if something is confusing, especially if the provision request calls for something not supported in our architecture (read slaves, etc). The juno or ah-provision commands will by default use magnetic for backup volumes, clarify any request asking for different. It is better to ask extra questions than to provision the wrong thing and then have to do it over. The OPS Sales Cheatsheet can be used to map Acquia Cluster sizes to instance sizes.","title":"Gather Information"},{"location":"kanban_tickets/provision_ace/#provisioning-with-juno","text":"All provisions in ACE should be done with Juno unless you are provisioning something not supported by it. Juno is a web-based provisioning tool. In order to use it, you need to set up a tunnel to the bastion. Accessing Juno","title":"Provisioning With Juno"},{"location":"kanban_tickets/provision_ace/#manual-provisioning-of-customer-hardware","text":"Provisioning a Customer Stack Allocating Hardware VPC Hardware Creating Sites Launching Servers Dedicated Memcache Dedicated Cron","title":"Manual Provisioning of Customer Hardware"},{"location":"kanban_tickets/provision_ace/#manual-provisioning-of-infrastructure-hardware","text":"Shared SVN Shared Bals Shared Staging Shared RA servers Ossec servers Stats servers Mon servers Backup servers","title":"Manual Provisioning of Infrastructure Hardware"},{"location":"kanban_tickets/provision_ace_customer/","text":"Provision customer hardware and sites Manual instructions for provisioning ACE hardware. Allocating Hardware VPC Hardware Creating Sites Launching Servers Dedicated Memcache Dedicated Cron Allocating Hardware Do not provision anything in us-east-1a or us-east-1d. All new hardware should be defaulted to VPC. If a specific VPC is not specified in the ticket then provision with shared vpc. Determine if the VPC exists or needs to be created If the customer has purchased a dedicated VPC (Shield) then check to see if the VPC already exists ah-vpc list % | grep $sitegroup If the VPC already exists, you can move onto provisioning the hardware within the VPC. If not, you will need to create the VPC first. Those steps can be found here . Setting variables Region and AZs The region should be specified in the ticket. You can choose any AZs that support VPC, SSD and encryption. Region example value: us-east-1 AZ example values: us-east-1c us-east-1e Use the region-azfeatures tool to determine if the AZs you are provisioning in will support SSDs, VPC and encryption. region-azfeatures $REGION Note: In case of provisoning new bals ignore setting below variables if you have already set the variables mentioned in Hardware Allocation REGION= AZ1= AZ2= Volume Size These values can be found in the ticket and should be in the dealsheet Volume Size example value: 100 DB_SIZE= FS_SIZE= FS_VOL_TYPE=(gp3 or standard) DB_VOL_TYPE=(gp3 or standard) VPC If VPC varaible is going to be set, it should be set up in the following manner. VPC=\"VPC_NAME\" If VPC is not specified in a ticket you can default to a shared vpc unless Gen1 hardware. Site already has hardware in EC2 classic If you are unsure what VPC it needs to go in, please clarify with a Senior Ops Engineer. Default if no VPC is specified in the ticket VPC=\"shared-vpc-${REGION}\" VPC_TYPE=shared_vpc If Shared PII is specified in the ticket VPC=\"shared-pii-vpc-${REGION}\" VPC_TYPE=shared_vpc_pii If Shared HIPAA is specified in the ticket VPC=\"shared-hipaa-vpc-${REGION}\" VPC_TYPE=shared_vpc_hipaa If Shared PCI is specified in the ticket VPC=\"shared-pci-vpc-${REGION}\" VPC_TYPE=shared_vpc_pci If Shared PCI and Shared HIPAA is specified in the ticket VPC=\"shared-hipaa-pci-vpc-${REGION}\" VPC_TYPE=shared_vpc_hipaa_pci FS Cluster variables FS_CLUSTER_NAME=$(date +%s) STG_CLUSTER_NAME=\"$(date +%s)-stg\" Single-Tier AMI_TYPE= ah-provision stack ded \\ -d $DB_SIZE \\ -g $FS_SIZE \\ -i $AMI_TYPE \\ -n $FS_CLUSTER_NAME \\ -r $REGION \\ -z $AZ1 $AZ2 \\ --ge --de \\ -V $VPC \\ --files-storage-type $FS_VOL_TYPE --database-storage-type $DB_VOL_TYPE # DB=ded-aaa # WEBS=ded-aaa,ded-bbb DB= WEBS= Multi-Tier NUM_WEBS= FSDB_AMI_TYPE= WEB_AMI_TYPE= ah-provision stack web-fsdb \\ -c $NUM_WEBS \\ -d $DB_SIZE \\ -f $FSDB_AMI_TYPE \\ -g $FS_SIZE \\ -n $FS_CLUSTER_NAME \\ -r $REGION \\ -w $WEB_AMI_TYPE \\ -z $AZ1 $AZ2 \\ --ge --de \\ -V $VPC \\ --files-storage-type $FS_VOL_TYPE --database-storage-type $DB_VOL_TYPE # DB=fsdb-aaa # WEBS=web-ddd,web-eee,web-... DB= WEBS= Full-Tier NUM_WEBS= DB_AMI_TYPE= FS_AMI_TYPE= WEB_AMI_TYPE= ah-provision stack web-db-fs \\ -D $DB_AMI_TYPE \\ -c $NUM_WEBS \\ -d $DB_SIZE \\ -f $FS_AMI_TYPE \\ -g $FS_SIZE \\ -n $FS_CLUSTER_NAME \\ -r $REGION \\ -w $WEB_AMI_TYPE \\ -z $AZ1 $AZ2 \\ --ge --de \\ -V $VPC \\ --files-storage-type $FS_VOL_TYPE --database-storage-type $DB_VOL_TYPE # DB=dbmaster-aaa # WEBS=web-ddd,web-eee,web-... DB= WEBS= Get or allocate the Bals If dedicated BAL_AMI_TYPE= ah-provision stack bal \\ -i $BAL_AMI_TYPE \\ -r $REGION \\ -z $AZ1 $AZ2 \\ -V $VPC # BALS=bal-aaa,bal-bbb BALS= If shared get the shared bal servers that are active site-taglistactive bal $REGION $VPC_TYPE prod site-taglistactive bal $REGION $VPC_TYPE test site-taglistactive bal $REGION $VPC_TYPE dev Note: Make sure to verify if the existing hardware is in vpc or not before adding the new bals and provision the bals accordingly. NOTE ONLY FOR PFIZER: If the balancers are being assigned to pfizer sites (usually starts with pf - but confirm with TAM/AM) - make sure to apply pfizer-cloudflare VCL to the balancers before assigning balancers to the sites. ONLY FOR PFIZER ah-server edit $BALS -c puppet:varnish_config=pfizer-cloudflare fpdsh -l $BALS -c \"sudo run-puppet && sudo fields-config-bal.php\" ah-server list $BALS -c puppet:varnish_config If customer plans to use edge cluster bals In order to associate an edge cluster to an environment, you will need to find the appropriate edge cluster uuid and then associate it to the site using the proper command. But before that you must mind the customers site allocation on the given edge cluster. We have two special cases to observe here: RA and Polaris (Next Gen) sites. Please refer to the proper sections below: For RA sites We have hard limits enforced within HAPI but due to the last events about RA sites it is important to manage the load on those clusters. So, if you need to add a RA site, before, perform these steps. 1. Check if the edge cluster reached the limit of 200 RA sites: ```ah-edge describe-edge-cluster --uuid=UUID | grep ra | wc``` If the limit was reach, please add the tag ra_full to this cluster: ah-edge tag-edge-cluster --uuid=UUID --tag ra_full Now you will need to search for another cluster or create a new one, essentially going back to the first step here, please also mind: Edge Cluster capacity limits Right, if there is room for a RA site in the given edge cluster or you are adding another kind of site issue the command below: ah-edge add-environment-to-edge-cluster --environment-name=ENVIRONMENT_NAME --uuid=UUID Note: If you try to add a RA site with a edge cluster with the tag ra_full you will see the error: RequestError: This edge cluster is tagged ra_full and cannot have environments added to it For Polaris (Next Gen) sites We want this new type of sites in same edge cluster for a given realm. In order to coordinate that we will use the shared_polaris tag. So if you want to provision a Polaris site, search for an edge cluster with this tag. If you can't find a cluster like that probably means that you are creating the first Polaris cluster in the realm. In this case, create an edge cluster for those sites and tag it with shared_polaris tag before adding the environment. Check the steps below: Search for the tagged edge cluster. ah-edge list-edge-clusters | grep polaris If you found the edge cluster, check the limits on it. Polaris environments count as prod environments, e.g., one edge cluster has capacity for 80 Polaris/Prod environments, unless it was configured differently. Check edge cluster limits for details. If the cluster reached its limit or there is no edge cluster for Polaris yet, create the edge cluster using instructions: Create Edge Cluster Please add the tag shared_polaris and active to this cluster: ah-edge tag-edge-cluster --uuid=UUID --tag shared_polaris ah-edge tag-edge-cluster --uuid=UUID --tag active Finally add the polaris environment to the edge cluster: ah-edge add-environment-to-edge-cluster --environment-name=ENVIRONMENT_NAME --uuid=UUID For more info refer: Add Environment to Edge Cluster Get or allocate the Staging server(s) If dedicated STG_AMI_TYPE= ah-provision stack staging \\ -d $DB_SIZE \\ -g $FS_SIZE \\ -i $STG_AMI_TYPE \\ -n $STG_CLUSTER_NAME \\ -r $REGION \\ -z $AZ1 \\ --ge --de \\ -V $VPC \\ --files-storage-type $FS_VOL_TYPE --database-storage-type $DB_VOL_TYPE STAGING= If shared get the shared staging servers that are active site-taglistactive staging $REGION $VPC_TYPE test site-taglistactive staging $REGION $VPC_TYPE dev Change mntfs volume size on Gen3 instances You can change mntfs (/mnt) volume size on any Gen3 (EBS-backed) instance you have provisioned. Gen3 instance is an EBS-backed instance where all volumes are EBS. No attached ephemeral drive. mntfs volume type is EBS volume mounted to '/mnt' mount point on Gen3 instance. Default mntfs volume size is 40GB. NOTE: You can change EBS volume size only on an allocated server that has never been launched. If you need to change size on a running server, please follow the EBS volume resizing procedure. Get the volume id (volume id is the number in id field. Look for a volume with /mnt mount point): bash SERVER_NAME= sv-vollist ${SERVER_NAME} Please be sure that volume's ebs_id is 'create' which means this volume is allocated but not running. If you see a value that starts with 'vol-' in the ebs_id field for '/mnt' volume, please stop here, you can't change its size. If you don't see a volume with '/mnt' mount point in the output means that the current instance is not EBS-backed and you can't change mntfs volume size on it. Change the volume size using the volume id that you have found during the previous step: bash VOLUME_ID= VOLUME_SIZE_GB= ah-volume edit ${VOLUME_ID} -s=size=${VOLUME_SIZE_GB} You should see in the output that the volume has changes its size. Get the SVN (VCS) server SVN servers do not need to be in the VPC site-taglistactive svn $REGION ec2_classic prod SVN= Set opportunity ID to the dedicated hardware Once you have provisioned the hardware for a sitegroup, you need to set the Salesforce opportunity ID on the dedicated hardware for tracking the instances. You will get the opportunity ID in description of the provisioning ticket. NOTE: Don\u2019t set opportunity ID on shared hardware. OPPORTUNITY_ID= TAG_SERVERS=\u201cded-aaa ded-bbb web-ccc web-ddd\u201d #(space delimiter) ah-server tag add $TAG_SERVERS --tags opportunity:${OPPORTUNITY_ID} Creating sites Once we have the servers allocated we can create sites on them. Pass the ded servers to --webs when the stack is single tier --db only accepts the first database server There is no flag for fs servers. They are added automatically As a reminder, most sites should be provisioned via Juno . You should only provision a site manually if Juno does not support it. Note: Below manual site provisioning method does not work with edge cluster balancers. In order to add an edge cluster to a site, please refer to the section above. prod SITENAME= ./fields-provision.php --create-site ${SITENAME} --vcs ${SVN} \\ --bals ${BALS} --webs ${WEBS} --db $DB ; echo \"\" test ./fields-provision.php --create-site ${SITENAME}test --stage test \\ --bals ${BALS} --webs ${STAGING} --db ${STAGING} \\ --sitegroup ${SITENAME} ; echo \"\" dev ./fields-provision.php --create-site ${SITENAME}dev --stage dev \\ --bals ${BALS} --webs ${STAGING} --db ${STAGING} \\ --sitegroup ${SITENAME} ; echo \"\" ra Only provision this if the dealsheet specifies the customer has RA NOTE: RA sites should be placed on a RA specific servers only. For more information about RA environment, please go through this link Get the active RA bals and staging server site-taglistactive bal $REGION $VPC_TYPE ra site-taglistactive staging $REGION $VPC_TYPE ra # BALS=bal-aaa,bal-bbb RA_BALS= RA_STAGING= Create the RA site ./fields-provision.php --create-site ${SITENAME}ra --ra 1 \\ --sitegroup ${SITENAME} --stage ra --bals ${RA_BALS} \\ --webs ${RA_STAGING} --db ${RA_STAGING} Set the smtp return path for prod test and dev The email should be provided in the dealsheet or by the AM. EMAIL=\"technical-contact@domain.name\" ah-site edit ${SITENAME},${SITENAME}test,${SITENAME}dev \\ -c php.ini:sendmail_path=\"/usr/sbin/sendmail -t -i -f${EMAIL}\" Provisioning prod and ra sites with different stage names It is now possible to provision a prod or an ra site while using arbitrary stage names with an extra step: tagging. Any site tagged 'prod' is considered production, and any site tagged 'ra' is considered remote administration. Examples: tagged prod ./fields-provision.php --create-site ${SITEGROUP}mystage --stage mystage --bals ${BALS} --webs ${SRV} --db ${SRV} --sitegroup ${SITEGROUP} --vcs ${SVN} ah-site tag add ${SITEGROUP}mystage -t prod tagged ra You can either specify --ra 1 during provision ./fields-provision.php \\ --create-site ${SITEGROUP}admin --rand-name \\ --ra 1 --sitegroup ${SITEGROUP} \\ --stage admin \\ --bals bal-xxx,bal-yyy \\ --webs srv-zzz \\ --db srv-zzz OR add a tag later ah-site tag add ${SITEGROUP}admin -t ra The result is the same. Tagging consequences Tagging a site with prod or ra only means that HAPI and Cloud UI will consider that site production or remote administration. This means that the customer will have different settings available for these sites on the UI based on tags, and also the AH_PRODUCTION environment variable will be set for prod tag. A site can only be tagged with ra or prod . One of the tags needs to be removed before adding the other. Sites with prod stage names are tagged with prod and that tag can't be removed. Sites with ra stage names are tagged with ra and that tag can't be removed. Sites with any other stage name can freely be tagged and untagged with these tags. Tagging a site with ra will set the following configs on the site automatically: site:dynamic_process_limit=on site:systemd=1 php.ini:sendmail_path=/bin/true Setup FIPS - FIPS compliant stacks only Important! These steps are only required if the stack to create must be FIPS compliant! Skip the following two steps if it is not valid to the stack you provision! FIPS server config setting SERVER_NAMES= ah-server edit $SERVER_NAMES -c puppet:fips_enabled=1 MySQL Version Setting the MySQL version for a cluster is supported with the following server types: api, dbmaster, dbmesh, ded, free, fsdb, fsdbmesh, srv, staging, web FIPS Version 5.6.41 (client and server) is required to be used on FIPS compliant MySQL 5.6 servers. Launching FIPS compliant servers requires setting this value. MYSQL_VERSION=5.6.41 MySQL 5.6 Version 5.6.41 may be set manually to force the launch of a MySQL 5.6 server after MySQL 5.7 becomes the default. MYSQL_VERSION=5.6.41 MySQL 5.7 Version 5.7.29 may be set to manually force the launch of a MySQL 5.7 server before MySQL 5.7 becomes the default. MYSQL_VERSION=5.7.29 Setting the MySQL Version After setting the MYSQL_VERSION environment variable as specified above, run the following command: SERVERS= ah-server edit $SERVERS -c puppet:mysql_version=$MYSQL_VERSION Launching Servers Run esl on the site to verify it looks correct before launching Then launch the servers with sv-taskrelaunch Example launching for single tier with dedicated bals and staging sv-taskrelaunch server ded-aaa,ded-bbb,bal-ccc,bal-ddd,staging-eee If Launching A DB Server Initially Should Fail First verify that replication has not been initialized on the DB cluster you have launched. Depending on where the launch failed, and if the server is 'online' you should run the following: fpdsh -l $DB -c \"sudo mysql -e \"show slave status\\G\" The above command will return an empty result set if replication has not been initialized If and only if one of the ded/fsdb/dbmaster/etc servers fails to launch for the first time and you need to relaunch it, replication may not be initialized. NOTE This can run ONLY when you are launching a new customer for the first time. Once replication has successfully run on a DB cluster, this tool should never be used on that DB cluster anymore as this command will format the cluster of all data. After the server has successfully launched, run: ah-db-cluster init-replication ${DB} Verification Verify the site looks configured properly. esl $SITENAME Make sure all the webs have memcached set (unless the ticket specifies dedicated memcached webs). Also check that staging has memcached set as well. ah-server edit ${WEBS},${STAGING} -c memcached.conf:-m=64 Add production sites to Monitoring Variable: SITENAME= Before you add a site to monitoring, check to ensure DNS is setup properly: DNS_IP=$(dig ${SITENAME}.${FIELDS_STAGE}.acquia-sites.com +short) BAL_IP=$(ah-server list site:${SITENAME} --no-name -w type=bal status=0 eip_id!=nil -c external_ip | head -1) if [[ ${DNS_IP} ]] || [[ ${BAL_IP} ]]; then if [[ ${DNS_IP} == ${BAL_IP} ]]; then errecho \"DNS is properly set for ${SITENAME}\" else errecho \"ERROR: DNS needs setting for ${SITENAME}.${FIELDS_STAGE}.acquia-sites.com\" \\ \"to the active bal EIP '${BAL_IP}'\" errecho \"ah-dns help set\" ah-dns help set fi else errecho \"ERROR: The site's bal doesn't have an EIP and there is no DNS entry.\" fi Ensure that ACQUIA_MONITOR loads: site-check ${SITENAME} Ensure that site-checkwebs is returning success by running the following: site-checkwebs ${SITENAME} If you are adding a site to an existing stack, check that no other sites are already in monitoring: SERVER=$(ah-server list site:${SITENAME} -w typeINweb,ded | head -1) SITES=($(ah-site list on:${SERVER})) for site in ${SITES[@]}; do site-mon get ${site} done If the checks pass, add the site to monitoring. site-mon add ${SITENAME}","title":"Provision customer hardware and sites"},{"location":"kanban_tickets/provision_ace_customer/#provision-customer-hardware-and-sites","text":"Manual instructions for provisioning ACE hardware. Allocating Hardware VPC Hardware Creating Sites Launching Servers Dedicated Memcache Dedicated Cron","title":"Provision customer hardware and sites"},{"location":"kanban_tickets/provision_ace_customer/#allocating-hardware","text":"Do not provision anything in us-east-1a or us-east-1d. All new hardware should be defaulted to VPC. If a specific VPC is not specified in the ticket then provision with shared vpc.","title":"Allocating Hardware"},{"location":"kanban_tickets/provision_ace_customer/#determine-if-the-vpc-exists-or-needs-to-be-created","text":"If the customer has purchased a dedicated VPC (Shield) then check to see if the VPC already exists ah-vpc list % | grep $sitegroup If the VPC already exists, you can move onto provisioning the hardware within the VPC. If not, you will need to create the VPC first. Those steps can be found here .","title":"Determine if the VPC exists or needs to be created"},{"location":"kanban_tickets/provision_ace_customer/#setting-variables","text":"","title":"Setting variables"},{"location":"kanban_tickets/provision_ace_customer/#region-and-azs","text":"The region should be specified in the ticket. You can choose any AZs that support VPC, SSD and encryption. Region example value: us-east-1 AZ example values: us-east-1c us-east-1e Use the region-azfeatures tool to determine if the AZs you are provisioning in will support SSDs, VPC and encryption. region-azfeatures $REGION Note: In case of provisoning new bals ignore setting below variables if you have already set the variables mentioned in Hardware Allocation REGION= AZ1= AZ2=","title":"Region and AZs"},{"location":"kanban_tickets/provision_ace_customer/#volume-size","text":"These values can be found in the ticket and should be in the dealsheet Volume Size example value: 100 DB_SIZE= FS_SIZE= FS_VOL_TYPE=(gp3 or standard) DB_VOL_TYPE=(gp3 or standard)","title":"Volume Size"},{"location":"kanban_tickets/provision_ace_customer/#vpc","text":"If VPC varaible is going to be set, it should be set up in the following manner. VPC=\"VPC_NAME\" If VPC is not specified in a ticket you can default to a shared vpc unless Gen1 hardware. Site already has hardware in EC2 classic If you are unsure what VPC it needs to go in, please clarify with a Senior Ops Engineer. Default if no VPC is specified in the ticket VPC=\"shared-vpc-${REGION}\" VPC_TYPE=shared_vpc If Shared PII is specified in the ticket VPC=\"shared-pii-vpc-${REGION}\" VPC_TYPE=shared_vpc_pii If Shared HIPAA is specified in the ticket VPC=\"shared-hipaa-vpc-${REGION}\" VPC_TYPE=shared_vpc_hipaa If Shared PCI is specified in the ticket VPC=\"shared-pci-vpc-${REGION}\" VPC_TYPE=shared_vpc_pci If Shared PCI and Shared HIPAA is specified in the ticket VPC=\"shared-hipaa-pci-vpc-${REGION}\" VPC_TYPE=shared_vpc_hipaa_pci","title":"VPC"},{"location":"kanban_tickets/provision_ace_customer/#fs-cluster-variables","text":"FS_CLUSTER_NAME=$(date +%s) STG_CLUSTER_NAME=\"$(date +%s)-stg\"","title":"FS Cluster variables"},{"location":"kanban_tickets/provision_ace_customer/#single-tier","text":"AMI_TYPE= ah-provision stack ded \\ -d $DB_SIZE \\ -g $FS_SIZE \\ -i $AMI_TYPE \\ -n $FS_CLUSTER_NAME \\ -r $REGION \\ -z $AZ1 $AZ2 \\ --ge --de \\ -V $VPC \\ --files-storage-type $FS_VOL_TYPE --database-storage-type $DB_VOL_TYPE # DB=ded-aaa # WEBS=ded-aaa,ded-bbb DB= WEBS=","title":"Single-Tier"},{"location":"kanban_tickets/provision_ace_customer/#multi-tier","text":"NUM_WEBS= FSDB_AMI_TYPE= WEB_AMI_TYPE= ah-provision stack web-fsdb \\ -c $NUM_WEBS \\ -d $DB_SIZE \\ -f $FSDB_AMI_TYPE \\ -g $FS_SIZE \\ -n $FS_CLUSTER_NAME \\ -r $REGION \\ -w $WEB_AMI_TYPE \\ -z $AZ1 $AZ2 \\ --ge --de \\ -V $VPC \\ --files-storage-type $FS_VOL_TYPE --database-storage-type $DB_VOL_TYPE # DB=fsdb-aaa # WEBS=web-ddd,web-eee,web-... DB= WEBS=","title":"Multi-Tier"},{"location":"kanban_tickets/provision_ace_customer/#full-tier","text":"NUM_WEBS= DB_AMI_TYPE= FS_AMI_TYPE= WEB_AMI_TYPE= ah-provision stack web-db-fs \\ -D $DB_AMI_TYPE \\ -c $NUM_WEBS \\ -d $DB_SIZE \\ -f $FS_AMI_TYPE \\ -g $FS_SIZE \\ -n $FS_CLUSTER_NAME \\ -r $REGION \\ -w $WEB_AMI_TYPE \\ -z $AZ1 $AZ2 \\ --ge --de \\ -V $VPC \\ --files-storage-type $FS_VOL_TYPE --database-storage-type $DB_VOL_TYPE # DB=dbmaster-aaa # WEBS=web-ddd,web-eee,web-... DB= WEBS=","title":"Full-Tier"},{"location":"kanban_tickets/provision_ace_customer/#get-or-allocate-the-bals","text":"","title":"Get or allocate the Bals"},{"location":"kanban_tickets/provision_ace_customer/#if-dedicated","text":"BAL_AMI_TYPE= ah-provision stack bal \\ -i $BAL_AMI_TYPE \\ -r $REGION \\ -z $AZ1 $AZ2 \\ -V $VPC # BALS=bal-aaa,bal-bbb BALS= If shared get the shared bal servers that are active site-taglistactive bal $REGION $VPC_TYPE prod site-taglistactive bal $REGION $VPC_TYPE test site-taglistactive bal $REGION $VPC_TYPE dev Note: Make sure to verify if the existing hardware is in vpc or not before adding the new bals and provision the bals accordingly. NOTE ONLY FOR PFIZER: If the balancers are being assigned to pfizer sites (usually starts with pf - but confirm with TAM/AM) - make sure to apply pfizer-cloudflare VCL to the balancers before assigning balancers to the sites. ONLY FOR PFIZER ah-server edit $BALS -c puppet:varnish_config=pfizer-cloudflare fpdsh -l $BALS -c \"sudo run-puppet && sudo fields-config-bal.php\" ah-server list $BALS -c puppet:varnish_config","title":"If dedicated"},{"location":"kanban_tickets/provision_ace_customer/#if-customer-plans-to-use-edge-cluster-bals","text":"In order to associate an edge cluster to an environment, you will need to find the appropriate edge cluster uuid and then associate it to the site using the proper command. But before that you must mind the customers site allocation on the given edge cluster. We have two special cases to observe here: RA and Polaris (Next Gen) sites. Please refer to the proper sections below:","title":"If customer plans to use edge cluster bals"},{"location":"kanban_tickets/provision_ace_customer/#for-ra-sites","text":"We have hard limits enforced within HAPI but due to the last events about RA sites it is important to manage the load on those clusters. So, if you need to add a RA site, before, perform these steps. 1. Check if the edge cluster reached the limit of 200 RA sites: ```ah-edge describe-edge-cluster --uuid=UUID | grep ra | wc``` If the limit was reach, please add the tag ra_full to this cluster: ah-edge tag-edge-cluster --uuid=UUID --tag ra_full Now you will need to search for another cluster or create a new one, essentially going back to the first step here, please also mind: Edge Cluster capacity limits Right, if there is room for a RA site in the given edge cluster or you are adding another kind of site issue the command below: ah-edge add-environment-to-edge-cluster --environment-name=ENVIRONMENT_NAME --uuid=UUID Note: If you try to add a RA site with a edge cluster with the tag ra_full you will see the error: RequestError: This edge cluster is tagged ra_full and cannot have environments added to it","title":"For RA sites"},{"location":"kanban_tickets/provision_ace_customer/#for-polaris-next-gen-sites","text":"We want this new type of sites in same edge cluster for a given realm. In order to coordinate that we will use the shared_polaris tag. So if you want to provision a Polaris site, search for an edge cluster with this tag. If you can't find a cluster like that probably means that you are creating the first Polaris cluster in the realm. In this case, create an edge cluster for those sites and tag it with shared_polaris tag before adding the environment. Check the steps below: Search for the tagged edge cluster. ah-edge list-edge-clusters | grep polaris If you found the edge cluster, check the limits on it. Polaris environments count as prod environments, e.g., one edge cluster has capacity for 80 Polaris/Prod environments, unless it was configured differently. Check edge cluster limits for details. If the cluster reached its limit or there is no edge cluster for Polaris yet, create the edge cluster using instructions: Create Edge Cluster Please add the tag shared_polaris and active to this cluster: ah-edge tag-edge-cluster --uuid=UUID --tag shared_polaris ah-edge tag-edge-cluster --uuid=UUID --tag active Finally add the polaris environment to the edge cluster: ah-edge add-environment-to-edge-cluster --environment-name=ENVIRONMENT_NAME --uuid=UUID For more info refer: Add Environment to Edge Cluster","title":"For Polaris (Next Gen) sites"},{"location":"kanban_tickets/provision_ace_customer/#get-or-allocate-the-staging-servers","text":"If dedicated STG_AMI_TYPE= ah-provision stack staging \\ -d $DB_SIZE \\ -g $FS_SIZE \\ -i $STG_AMI_TYPE \\ -n $STG_CLUSTER_NAME \\ -r $REGION \\ -z $AZ1 \\ --ge --de \\ -V $VPC \\ --files-storage-type $FS_VOL_TYPE --database-storage-type $DB_VOL_TYPE STAGING= If shared get the shared staging servers that are active site-taglistactive staging $REGION $VPC_TYPE test site-taglistactive staging $REGION $VPC_TYPE dev","title":"Get or allocate the Staging server(s)"},{"location":"kanban_tickets/provision_ace_customer/#change-mntfs-volume-size-on-gen3-instances","text":"You can change mntfs (/mnt) volume size on any Gen3 (EBS-backed) instance you have provisioned. Gen3 instance is an EBS-backed instance where all volumes are EBS. No attached ephemeral drive. mntfs volume type is EBS volume mounted to '/mnt' mount point on Gen3 instance. Default mntfs volume size is 40GB. NOTE: You can change EBS volume size only on an allocated server that has never been launched. If you need to change size on a running server, please follow the EBS volume resizing procedure. Get the volume id (volume id is the number in id field. Look for a volume with /mnt mount point): bash SERVER_NAME= sv-vollist ${SERVER_NAME} Please be sure that volume's ebs_id is 'create' which means this volume is allocated but not running. If you see a value that starts with 'vol-' in the ebs_id field for '/mnt' volume, please stop here, you can't change its size. If you don't see a volume with '/mnt' mount point in the output means that the current instance is not EBS-backed and you can't change mntfs volume size on it. Change the volume size using the volume id that you have found during the previous step: bash VOLUME_ID= VOLUME_SIZE_GB= ah-volume edit ${VOLUME_ID} -s=size=${VOLUME_SIZE_GB} You should see in the output that the volume has changes its size.","title":"Change mntfs volume size on Gen3 instances"},{"location":"kanban_tickets/provision_ace_customer/#get-the-svn-vcs-server","text":"SVN servers do not need to be in the VPC site-taglistactive svn $REGION ec2_classic prod SVN=","title":"Get the SVN (VCS) server"},{"location":"kanban_tickets/provision_ace_customer/#set-opportunity-id-to-the-dedicated-hardware","text":"Once you have provisioned the hardware for a sitegroup, you need to set the Salesforce opportunity ID on the dedicated hardware for tracking the instances. You will get the opportunity ID in description of the provisioning ticket. NOTE: Don\u2019t set opportunity ID on shared hardware. OPPORTUNITY_ID= TAG_SERVERS=\u201cded-aaa ded-bbb web-ccc web-ddd\u201d #(space delimiter) ah-server tag add $TAG_SERVERS --tags opportunity:${OPPORTUNITY_ID}","title":"Set opportunity ID to the dedicated hardware"},{"location":"kanban_tickets/provision_ace_customer/#creating-sites","text":"Once we have the servers allocated we can create sites on them. Pass the ded servers to --webs when the stack is single tier --db only accepts the first database server There is no flag for fs servers. They are added automatically As a reminder, most sites should be provisioned via Juno . You should only provision a site manually if Juno does not support it. Note: Below manual site provisioning method does not work with edge cluster balancers. In order to add an edge cluster to a site, please refer to the section above.","title":"Creating sites"},{"location":"kanban_tickets/provision_ace_customer/#prod","text":"SITENAME= ./fields-provision.php --create-site ${SITENAME} --vcs ${SVN} \\ --bals ${BALS} --webs ${WEBS} --db $DB ; echo \"\"","title":"prod"},{"location":"kanban_tickets/provision_ace_customer/#test","text":"./fields-provision.php --create-site ${SITENAME}test --stage test \\ --bals ${BALS} --webs ${STAGING} --db ${STAGING} \\ --sitegroup ${SITENAME} ; echo \"\"","title":"test"},{"location":"kanban_tickets/provision_ace_customer/#dev","text":"./fields-provision.php --create-site ${SITENAME}dev --stage dev \\ --bals ${BALS} --webs ${STAGING} --db ${STAGING} \\ --sitegroup ${SITENAME} ; echo \"\"","title":"dev"},{"location":"kanban_tickets/provision_ace_customer/#ra","text":"Only provision this if the dealsheet specifies the customer has RA NOTE: RA sites should be placed on a RA specific servers only. For more information about RA environment, please go through this link Get the active RA bals and staging server site-taglistactive bal $REGION $VPC_TYPE ra site-taglistactive staging $REGION $VPC_TYPE ra # BALS=bal-aaa,bal-bbb RA_BALS= RA_STAGING= Create the RA site ./fields-provision.php --create-site ${SITENAME}ra --ra 1 \\ --sitegroup ${SITENAME} --stage ra --bals ${RA_BALS} \\ --webs ${RA_STAGING} --db ${RA_STAGING}","title":"ra"},{"location":"kanban_tickets/provision_ace_customer/#set-the-smtp-return-path-for-prod-test-and-dev","text":"The email should be provided in the dealsheet or by the AM. EMAIL=\"technical-contact@domain.name\" ah-site edit ${SITENAME},${SITENAME}test,${SITENAME}dev \\ -c php.ini:sendmail_path=\"/usr/sbin/sendmail -t -i -f${EMAIL}\"","title":"Set the smtp return path for prod test and dev"},{"location":"kanban_tickets/provision_ace_customer/#provisioning-prod-and-ra-sites-with-different-stage-names","text":"It is now possible to provision a prod or an ra site while using arbitrary stage names with an extra step: tagging. Any site tagged 'prod' is considered production, and any site tagged 'ra' is considered remote administration. Examples:","title":"Provisioning prod and ra sites with different stage names"},{"location":"kanban_tickets/provision_ace_customer/#tagged-prod","text":"./fields-provision.php --create-site ${SITEGROUP}mystage --stage mystage --bals ${BALS} --webs ${SRV} --db ${SRV} --sitegroup ${SITEGROUP} --vcs ${SVN} ah-site tag add ${SITEGROUP}mystage -t prod","title":"tagged prod"},{"location":"kanban_tickets/provision_ace_customer/#tagged-ra","text":"You can either specify --ra 1 during provision ./fields-provision.php \\ --create-site ${SITEGROUP}admin --rand-name \\ --ra 1 --sitegroup ${SITEGROUP} \\ --stage admin \\ --bals bal-xxx,bal-yyy \\ --webs srv-zzz \\ --db srv-zzz OR add a tag later ah-site tag add ${SITEGROUP}admin -t ra The result is the same.","title":"tagged ra"},{"location":"kanban_tickets/provision_ace_customer/#tagging-consequences","text":"Tagging a site with prod or ra only means that HAPI and Cloud UI will consider that site production or remote administration. This means that the customer will have different settings available for these sites on the UI based on tags, and also the AH_PRODUCTION environment variable will be set for prod tag. A site can only be tagged with ra or prod . One of the tags needs to be removed before adding the other. Sites with prod stage names are tagged with prod and that tag can't be removed. Sites with ra stage names are tagged with ra and that tag can't be removed. Sites with any other stage name can freely be tagged and untagged with these tags. Tagging a site with ra will set the following configs on the site automatically: site:dynamic_process_limit=on site:systemd=1 php.ini:sendmail_path=/bin/true","title":"Tagging consequences"},{"location":"kanban_tickets/provision_ace_customer/#setup-fips-fips-compliant-stacks-only","text":"Important! These steps are only required if the stack to create must be FIPS compliant! Skip the following two steps if it is not valid to the stack you provision!","title":"Setup FIPS - FIPS compliant stacks only"},{"location":"kanban_tickets/provision_ace_customer/#fips-server-config-setting","text":"SERVER_NAMES= ah-server edit $SERVER_NAMES -c puppet:fips_enabled=1","title":"FIPS server config setting"},{"location":"kanban_tickets/provision_ace_customer/#mysql-version","text":"Setting the MySQL version for a cluster is supported with the following server types: api, dbmaster, dbmesh, ded, free, fsdb, fsdbmesh, srv, staging, web","title":"MySQL Version"},{"location":"kanban_tickets/provision_ace_customer/#fips","text":"Version 5.6.41 (client and server) is required to be used on FIPS compliant MySQL 5.6 servers. Launching FIPS compliant servers requires setting this value. MYSQL_VERSION=5.6.41","title":"FIPS"},{"location":"kanban_tickets/provision_ace_customer/#mysql-56","text":"Version 5.6.41 may be set manually to force the launch of a MySQL 5.6 server after MySQL 5.7 becomes the default. MYSQL_VERSION=5.6.41","title":"MySQL 5.6"},{"location":"kanban_tickets/provision_ace_customer/#mysql-57","text":"Version 5.7.29 may be set to manually force the launch of a MySQL 5.7 server before MySQL 5.7 becomes the default. MYSQL_VERSION=5.7.29","title":"MySQL 5.7"},{"location":"kanban_tickets/provision_ace_customer/#setting-the-mysql-version","text":"After setting the MYSQL_VERSION environment variable as specified above, run the following command: SERVERS= ah-server edit $SERVERS -c puppet:mysql_version=$MYSQL_VERSION","title":"Setting the MySQL Version"},{"location":"kanban_tickets/provision_ace_customer/#launching-servers","text":"Run esl on the site to verify it looks correct before launching Then launch the servers with sv-taskrelaunch Example launching for single tier with dedicated bals and staging sv-taskrelaunch server ded-aaa,ded-bbb,bal-ccc,bal-ddd,staging-eee","title":"Launching Servers"},{"location":"kanban_tickets/provision_ace_customer/#if-launching-a-db-server-initially-should-fail","text":"First verify that replication has not been initialized on the DB cluster you have launched. Depending on where the launch failed, and if the server is 'online' you should run the following: fpdsh -l $DB -c \"sudo mysql -e \"show slave status\\G\" The above command will return an empty result set if replication has not been initialized If and only if one of the ded/fsdb/dbmaster/etc servers fails to launch for the first time and you need to relaunch it, replication may not be initialized.","title":"If Launching A DB Server Initially Should Fail"},{"location":"kanban_tickets/provision_ace_customer/#note","text":"This can run ONLY when you are launching a new customer for the first time. Once replication has successfully run on a DB cluster, this tool should never be used on that DB cluster anymore as this command will format the cluster of all data. After the server has successfully launched, run: ah-db-cluster init-replication ${DB}","title":"NOTE"},{"location":"kanban_tickets/provision_ace_customer/#verification","text":"Verify the site looks configured properly. esl $SITENAME Make sure all the webs have memcached set (unless the ticket specifies dedicated memcached webs). Also check that staging has memcached set as well. ah-server edit ${WEBS},${STAGING} -c memcached.conf:-m=64","title":"Verification"},{"location":"kanban_tickets/provision_ace_customer/#add-production-sites-to-monitoring","text":"Variable: SITENAME= Before you add a site to monitoring, check to ensure DNS is setup properly: DNS_IP=$(dig ${SITENAME}.${FIELDS_STAGE}.acquia-sites.com +short) BAL_IP=$(ah-server list site:${SITENAME} --no-name -w type=bal status=0 eip_id!=nil -c external_ip | head -1) if [[ ${DNS_IP} ]] || [[ ${BAL_IP} ]]; then if [[ ${DNS_IP} == ${BAL_IP} ]]; then errecho \"DNS is properly set for ${SITENAME}\" else errecho \"ERROR: DNS needs setting for ${SITENAME}.${FIELDS_STAGE}.acquia-sites.com\" \\ \"to the active bal EIP '${BAL_IP}'\" errecho \"ah-dns help set\" ah-dns help set fi else errecho \"ERROR: The site's bal doesn't have an EIP and there is no DNS entry.\" fi Ensure that ACQUIA_MONITOR loads: site-check ${SITENAME} Ensure that site-checkwebs is returning success by running the following: site-checkwebs ${SITENAME} If you are adding a site to an existing stack, check that no other sites are already in monitoring: SERVER=$(ah-server list site:${SITENAME} -w typeINweb,ded | head -1) SITES=($(ah-site list on:${SERVER})) for site in ${SITES[@]}; do site-mon get ${site} done If the checks pass, add the site to monitoring. site-mon add ${SITENAME}","title":"Add production sites to Monitoring"},{"location":"kanban_tickets/provision_ace_dedicated_cron/","text":"Dedicated Cron By default, customer crons run on the first web. So generally we provision a dedicated cron web by cloning a web, launching it, and changing the existing first web to be the dedicated cron server. Please use below tool for automatic provisioning of cron web for multi tier sites. SITENAME= AMI_TYPE= site-setcron ${SITENAME} ${AMI_TYPE} Please use below steps for manual provisioning of cron web for multi tier sites. SITENAME= AMI_TYPE= FIRST_WEB=$(ah-server list site:${SITENAME} -w type=web status=0 | head -1) SITES=($(ah-site list on:${FIRST_WEB})) Clone the first web to make a new one: ah-server clone-web ${FIRST_WEB} 1 NEW_WEB= Note: If the cron web doesn't require EIP use --ignore-eip option,else add a new EIP after web relaunch and communicate the new EIP to the ticket requester. Launch the new web: sv-taskrelaunch server ${NEW_WEB} Note: If the FIRST_WEB have EIP, move it to NEW_WEB. ah-server migrate-eip --source-server-name=$FIRST_WEB --destination-server-name=$NEW_WEB Continue by setting the first web to inactive and tagging it: for site in ${SITES[@]}; do ./fields-provision.php --site-set-web ${site}:inactive --webs ${FIRST_WEB} | head -n 1 done ah-server tag add ${FIRST_WEB} --tags oob crons ah-server edit ${FIRST_WEB} -s web_service_status=1 ah-server edit ${FIRST_WEB} -c apache2.conf:PoolSize=2 memcached.conf:-m= If the ami_type is different, change the cron server to the new ami_type : sv-taskrelaunch server ${FIRST_WEB} -a suspend ah-server edit ${FIRST_WEB} -s ami_type=${AMI_TYPE} sv-taskrelaunch server ${FIRST_WEB} For Single Tier Sites Provision the cron web: SITENAME= AMI_TYPE= REGION= AZ= DEDS=($(ah-server list site:${SITENAME} -w type=ded)) DEDS_CSV=$(echo ${DEDS[@]} | tr ' ' ',') DED_PRIMARY=${DEDS[0]} VPC_ID=$(ah-server list ${DED_PRIMARY} -c vpc_id | awk '{print $2}') SITES=($(ah-site list on:${DED_PRIMARY})) ah-server allocate web --ami-type ${AMI_TYPE} --region ${REGION} --avail-zone ${AZ} --vpc-id $VPC_ID CRON_WEB=web-xxxx (new allocated web) Make sure gluster versions is same on deds and cron web. ah-server list ${DEDS_CSV} -c puppet:gluster_version ah-server list ${CRON_WEB} -c puppet:gluster_version If gluster version is different, set the correct version on cron web. ah-server edit ${CRON_WEB} -c puppet:gluster_version=$(ah-server list ${DED_PRIMARY} --no-name -c puppet:gluster_version) Setting FS cluster id on cron web: ah-server edit ${CRON_WEB} -s fs_cluster_id=$(ah-server list ${DED_PRIMARY} --no-name -c fs_cluster_id) Setting the site status to deploy and taking out of bals rotation: for site in ${SITES[@]}; do ./fields-provision.php --site-set-web ${site}:deploy \u2013webs ${CRON_WEB} | head -n 5 done sv-webdisable ${CRON_WEB} Relaunch the server: sv-taskrelaunch server ${CRON_WEB} Continue by setting the cron web to inactive and tagging it: for site in ${SITES[@]}; do ./fields-provision.php --site-set-web ${site}:inactive --webs ${CRON_WEB} | head -n 1 done ah-server tag add ${CRON_WEB} --tags oob crons ah-server edit ${CRON_WEB} -c apache2.conf:PoolSize=2 memcached.conf:-m= Note: Perform sanity check, like verify site checks are passing on deds.","title":"Dedicated Cron"},{"location":"kanban_tickets/provision_ace_dedicated_cron/#dedicated-cron","text":"By default, customer crons run on the first web. So generally we provision a dedicated cron web by cloning a web, launching it, and changing the existing first web to be the dedicated cron server. Please use below tool for automatic provisioning of cron web for multi tier sites. SITENAME= AMI_TYPE= site-setcron ${SITENAME} ${AMI_TYPE} Please use below steps for manual provisioning of cron web for multi tier sites. SITENAME= AMI_TYPE= FIRST_WEB=$(ah-server list site:${SITENAME} -w type=web status=0 | head -1) SITES=($(ah-site list on:${FIRST_WEB})) Clone the first web to make a new one: ah-server clone-web ${FIRST_WEB} 1 NEW_WEB= Note: If the cron web doesn't require EIP use --ignore-eip option,else add a new EIP after web relaunch and communicate the new EIP to the ticket requester. Launch the new web: sv-taskrelaunch server ${NEW_WEB} Note: If the FIRST_WEB have EIP, move it to NEW_WEB. ah-server migrate-eip --source-server-name=$FIRST_WEB --destination-server-name=$NEW_WEB Continue by setting the first web to inactive and tagging it: for site in ${SITES[@]}; do ./fields-provision.php --site-set-web ${site}:inactive --webs ${FIRST_WEB} | head -n 1 done ah-server tag add ${FIRST_WEB} --tags oob crons ah-server edit ${FIRST_WEB} -s web_service_status=1 ah-server edit ${FIRST_WEB} -c apache2.conf:PoolSize=2 memcached.conf:-m= If the ami_type is different, change the cron server to the new ami_type : sv-taskrelaunch server ${FIRST_WEB} -a suspend ah-server edit ${FIRST_WEB} -s ami_type=${AMI_TYPE} sv-taskrelaunch server ${FIRST_WEB}","title":"Dedicated Cron"},{"location":"kanban_tickets/provision_ace_dedicated_cron/#for-single-tier-sites","text":"Provision the cron web: SITENAME= AMI_TYPE= REGION= AZ= DEDS=($(ah-server list site:${SITENAME} -w type=ded)) DEDS_CSV=$(echo ${DEDS[@]} | tr ' ' ',') DED_PRIMARY=${DEDS[0]} VPC_ID=$(ah-server list ${DED_PRIMARY} -c vpc_id | awk '{print $2}') SITES=($(ah-site list on:${DED_PRIMARY})) ah-server allocate web --ami-type ${AMI_TYPE} --region ${REGION} --avail-zone ${AZ} --vpc-id $VPC_ID CRON_WEB=web-xxxx (new allocated web) Make sure gluster versions is same on deds and cron web. ah-server list ${DEDS_CSV} -c puppet:gluster_version ah-server list ${CRON_WEB} -c puppet:gluster_version If gluster version is different, set the correct version on cron web. ah-server edit ${CRON_WEB} -c puppet:gluster_version=$(ah-server list ${DED_PRIMARY} --no-name -c puppet:gluster_version) Setting FS cluster id on cron web: ah-server edit ${CRON_WEB} -s fs_cluster_id=$(ah-server list ${DED_PRIMARY} --no-name -c fs_cluster_id) Setting the site status to deploy and taking out of bals rotation: for site in ${SITES[@]}; do ./fields-provision.php --site-set-web ${site}:deploy \u2013webs ${CRON_WEB} | head -n 5 done sv-webdisable ${CRON_WEB} Relaunch the server: sv-taskrelaunch server ${CRON_WEB} Continue by setting the cron web to inactive and tagging it: for site in ${SITES[@]}; do ./fields-provision.php --site-set-web ${site}:inactive --webs ${CRON_WEB} | head -n 1 done ah-server tag add ${CRON_WEB} --tags oob crons ah-server edit ${CRON_WEB} -c apache2.conf:PoolSize=2 memcached.conf:-m= Note: Perform sanity check, like verify site checks are passing on deds.","title":"For Single Tier Sites"},{"location":"kanban_tickets/provision_ace_empfree/","text":"Provisioning employee free sites Employee free sites must be provisioned only on the already allocated hardware provisioned for employee sites. Currently, the employee free sites in us-east-1 and ap-southeast-1 regions are supported. Region information is provided in the requested ticket. You may use JUNO for provisioning the site or manually from command line. NOTE : Make sure to enable HSD post provisioning as per the steps outlined here Find the hardware available in the requested region Find the available hardware (deds,staging) in the supported region as mentioned below: REGION= site-taglistactive empfree $REGION ec2_classic prod WEBS= DB= site-taglistactive empfree $REGION ec2_classic stg STG_SRV= site-taglistactive empfree $REGION ec2_classic dev DEV_SRV= NOTE There are 2 sets of deds available in us-east-1 region for employee site i.e ded-3545/ded-3546 and ded-5409/ded-5410. Verify the site count on them and use the pair to keep them balanced. Bals available in the requested region Bals in us-east-1 BALS=(bal-29982,bal-29983) NONPROD_BALS=(bal-21743,bal-21744) Bals in ap-southeast-1 region BALS=(bal-17548,bal-17549) NONPROD_BALS=(bal-13379,bal-13380) SVN SERVER Find the active SVN server in that region using site-taglistactive command: site-taglistactive svn $REGION shared_vpc Create SITES Prod site SITENAME= ./fields-provision.php --create-site ${SITENAME} --vcs ${SVN} \\ --bals ${BALS} --webs ${WEBS} --db $DB ; echo \"\" test ./fields-provision.php --create-site ${SITENAME}test --stage test \\ --bals ${NONPROD_BALS} --webs ${STG_SRV} --db ${STG_SRV} \\ --sitegroup ${SITENAME} ; echo \"\" dev ./fields-provision.php --create-site ${SITENAME}dev --stage dev \\ --bals ${NONPROD_BALS} --webs ${DEV_SRV} --db ${DEV_SRV} \\ --sitegroup ${SITENAME} ; echo \"\" Enable HSD on the SITES Since employee free sites are available to test the features of Acquia Cloud and have been using shared hardware, it is important to enable HSD after creating those sites. Enable the HSD as follows: ah-site edit ${SITENAME},${SITENAME}test,${SITENAME}dev -c site:dynamic_process_limit=on site:systemd=1 fpm.conf:pm.max_children= And verify, it is enabled: ah-site list ${SITENAME},${SITENAME}test,${SITENAME}dev -c site:dynamic_process_limit site:systemd","title":"Provisioning employee free sites"},{"location":"kanban_tickets/provision_ace_empfree/#provisioning-employee-free-sites","text":"Employee free sites must be provisioned only on the already allocated hardware provisioned for employee sites. Currently, the employee free sites in us-east-1 and ap-southeast-1 regions are supported. Region information is provided in the requested ticket. You may use JUNO for provisioning the site or manually from command line. NOTE : Make sure to enable HSD post provisioning as per the steps outlined here","title":"Provisioning employee free sites"},{"location":"kanban_tickets/provision_ace_empfree/#find-the-hardware-available-in-the-requested-region","text":"Find the available hardware (deds,staging) in the supported region as mentioned below: REGION= site-taglistactive empfree $REGION ec2_classic prod WEBS= DB= site-taglistactive empfree $REGION ec2_classic stg STG_SRV= site-taglistactive empfree $REGION ec2_classic dev DEV_SRV= NOTE There are 2 sets of deds available in us-east-1 region for employee site i.e ded-3545/ded-3546 and ded-5409/ded-5410. Verify the site count on them and use the pair to keep them balanced.","title":"Find the hardware available in the requested region"},{"location":"kanban_tickets/provision_ace_empfree/#bals-available-in-the-requested-region","text":"","title":"Bals available in the requested region"},{"location":"kanban_tickets/provision_ace_empfree/#bals-in-us-east-1","text":"BALS=(bal-29982,bal-29983) NONPROD_BALS=(bal-21743,bal-21744)","title":"Bals in us-east-1"},{"location":"kanban_tickets/provision_ace_empfree/#bals-in-ap-southeast-1-region","text":"BALS=(bal-17548,bal-17549) NONPROD_BALS=(bal-13379,bal-13380)","title":"Bals in ap-southeast-1 region"},{"location":"kanban_tickets/provision_ace_empfree/#svn-server","text":"Find the active SVN server in that region using site-taglistactive command: site-taglistactive svn $REGION shared_vpc","title":"SVN SERVER"},{"location":"kanban_tickets/provision_ace_empfree/#create-sites","text":"","title":"Create SITES"},{"location":"kanban_tickets/provision_ace_empfree/#prod-site","text":"SITENAME= ./fields-provision.php --create-site ${SITENAME} --vcs ${SVN} \\ --bals ${BALS} --webs ${WEBS} --db $DB ; echo \"\"","title":"Prod site"},{"location":"kanban_tickets/provision_ace_empfree/#test","text":"./fields-provision.php --create-site ${SITENAME}test --stage test \\ --bals ${NONPROD_BALS} --webs ${STG_SRV} --db ${STG_SRV} \\ --sitegroup ${SITENAME} ; echo \"\"","title":"test"},{"location":"kanban_tickets/provision_ace_empfree/#dev","text":"./fields-provision.php --create-site ${SITENAME}dev --stage dev \\ --bals ${NONPROD_BALS} --webs ${DEV_SRV} --db ${DEV_SRV} \\ --sitegroup ${SITENAME} ; echo \"\"","title":"dev"},{"location":"kanban_tickets/provision_ace_empfree/#enable-hsd-on-the-sites","text":"Since employee free sites are available to test the features of Acquia Cloud and have been using shared hardware, it is important to enable HSD after creating those sites. Enable the HSD as follows: ah-site edit ${SITENAME},${SITENAME}test,${SITENAME}dev -c site:dynamic_process_limit=on site:systemd=1 fpm.conf:pm.max_children= And verify, it is enabled: ah-site list ${SITENAME},${SITENAME}test,${SITENAME}dev -c site:dynamic_process_limit site:systemd","title":"Enable HSD on the SITES"},{"location":"kanban_tickets/provision_ace_infra/","text":"Provision shared and infra hardware Shared SVN Set some variables. OLD_SVN= AZ=$(ah-server list ${OLD_SVN} --no-name -c ec2_availability_zone) REGION=${AZ%?} VPC_ID=$(ruby -e \"require 'aq' ; puts Aq::Hosting::Vpc.region_default('$REGION').id\") Provision the new server NEW_SVN=$(ah-server allocate svn --ami-type c4.xlarge --region ${REGION} \\ --avail-zone ${AZ} --primary-volume-size 200 --secondary-volume-size 200 -v $VPC_ID) ah-server tag add ${NEW_SVN} -t shared ah-server edit ${NEW_SVN} -c puppet:fips_enabled=1 Add a new EIP: set the IP_ADDRESS variable to the new EIP ah-elastic-ip allocate ${REGION} classic/vpc IP_ADDRESS= ah-elastic-ip add ${IP_ADDRESS} ${NEW_SVN} Launch the server sv-taskrelaunch server ${NEW_SVN} -m 1 Move the active tag ah-server tag remove ${OLD_SVN} -t activesvn ah-server tag add ${NEW_SVN} -t activesvn Shared Edge Clustered Balancers NOTE: There is a special process to provision Edge cluster balancers. Edge clusters balancers get provisioned while creating an Edge Cluster. Refer: Create Edge Cluster Shared Staging Set some variables. The \"old\" staging server is the one currently full. OLD_STAGING= REGION=$(ah-server list $OLD_STAGING -c ec2_region --no-name) AZ=$(ah-server list $OLD_STAGING -c ec2_availability_zone --no-name) STG_CLUSTER_NAME=\"$(date +%s)-stg\" Provision a new server. EC2 Classic ah-provision stack staging \\ -i m5.xlarge \\ -r $REGION -z $AZ \\ -d 500 \\ -g 500 -n $STG_CLUSTER_NAME \\ --gt gp3 --ge --de NEW_STAGING= VPC VPC=$(ah-vpc list shared-vpc-${REGION}) ah-provision stack staging \\ -i i2.xlarge \\ -r $REGION -z $AZ \\ -d 500 \\ -g 500 -n $STG_CLUSTER_NAME --gt gp3 \\ -V $VPC \\ --ge \\ --de NEW_STAGING= Edit server config ah-server edit $NEW_STAGING -c \\ apache2.conf:PoolSize=50 \\ memcached.conf:-m=64 \\ my.cnf:innodb_buffer_pool_size=5G \\ puppet:php5-xhprof=add Launch it. sv-taskrelaunch server $NEW_STAGING See if the old server was tagged for dev, test, or both. Set TAGS to match. (There are two tags for test: activestagingstg and activestagingtest ) ah-server tag list $OLD_STAGING EC2 Classic Tags: activestagingdev activestagingstg activestagingtest VPC Tags: activestagingdev activestagingstg activestagingtest shared_vpc Compliance VPC tags: shared_vpc_pci shared_vpc_hipaa shared_vpc_hipaa_pci shared_vpc_pii Move the active tags. ah-server tag remove $OLD_STAGING --tags activestaging $TAGS ah-server tag add $NEW_STAGING --tags shared activestaging $TAGS Shared RA servers Set some variables AZ= REGION=${AZ%?} STG_CLUSTER_NAME=$(date +%s) OLD_RA_SERVER=$(site-taglistactive staging ${REGION} ra) Provision the server: RA_SERVER=$(ah-provision stack staging -d 1000 -g 10 -i m5.large -n ${STG_CLUSTER_NAME} \\ -r ${REGION} -z ${AZ} --ge --de --gt gp3) Set some things ah-server tag add ${RA_SERVER} --tags shared ra_server ./fields-provision.php --fs-cluster-remove-servers ${STG_CLUSTER_NAME}:${RA_SERVER} ah-server edit ${RA_SERVER} -c puppet:gluster_version=3.0 ./fields-provision.php --fs-cluster-add-servers ${STG_CLUSTER_NAME}:${RA_SERVER} Launch the server sv-taskrelaunch server ${RA_SERVER} Move the activestagingra tag to the new server ah-server tag remove ${OLD_RA_SERVER} --tags activestagingra ah-server tag add ${RA_SERVER} --tags activestagingra NOTE: RA sites should be placed on a RA specific servers only. For more information about RA environment, please go through this link RA within VPC us-east-1 is the default region, so should be used unless otherwise stated. The database volume is not an SSD due to the fact we do not run MySQL with durability, so it is strictly forbidden, for now. Set some variables. AMI_TYPE will be set to i2.xlarge unless the customer has a dedicated VPC, in which case AMI_TYPE gets set to the same as their dedicated staging server. AZ should be set to one of the common AZs from region-azfeatures ${REGION} . OLD_RA_SERVER is optional if you are creating a dedicated RA server. SITEGROUP= AMI_TYPE= OLD_RA_SERVER= REGION= AZ= STG_CLUSTER_NAME=$(date +%s) Set the VPC server with one of: PCI VPC RA servers: VPC=$(ah-vpc list shared-pci-vpc-${REGION}) VPC_TAGS=\"shared_vpc_pci\" HIPAA VPC RA servers: VPC=$(ah-vpc list shared-hipaa-vpc-${REGION}) VPC_TAGS=\"shared_vpc_hipaa\" HIPAA PCI VPC RA servers: VPC=$(ah-vpc list shared-hipaa-vpc-${REGION}) VPC_TAGS=\"shared_vpc_hipaa_pci\" Default VPC RA servers: VPC=$(ah-vpc list shared-vpc-${REGION}) VPC_TAGS=\"shared_vpc shared_vpc_pii\" PII VPC RA servers (use the region default VPCs for PII): VPC=$(ah-vpc list shared-vpc-${REGION}) VPC_TAGS=\"shared_vpc shared_vpc_pii\" Dedicated VPC customers (Acquia Shield) get an RA server inside their dedicated vpc. The server should be the same size as their dev/staging server. VPC=$(ah-vpc list ${SITEGROUP}) VPC_TAGS=\"dedicated_vpc_shield\" Create the things SERVER=$(ah-provision stack staging -d 1000 -g 10 -i ${AMI_TYPE} -n ${STG_CLUSTER_NAME} \\ -r ${REGION} -z ${AZ} --ge --de --gt gp3 -V ${VPC}) ah-server tag add ${SERVER} --tags shared ra_server ./fields-provision.php --fs-cluster-remove-servers ${STG_CLUSTER_NAME}:${SERVER} ah-server edit ${SERVER} -c puppet:gluster_version=3.0 ./fields-provision.php --fs-cluster-add-servers ${STG_CLUSTER_NAME}:${SERVER} Add the relevant tag(s) for the VPC type ah-server tag add ${SERVER} --tags ${VPC_TAGS} Launch the server. sv-taskrelaunch server ${SERVER} Move the activestagingra tag to the new server. (Only applies to non-dedicated VPC RA servers) ah-server tag remove ${OLD_RA_SERVER} --tags activestagingra ah-server tag add ${SERVER} --tags activestagingra Ossec servers ah-server allocate ossec --ami-type c4.large --region us-east-1 \\ --avail-zone us-east-1e --primary-volume-size 500 \\ --secondary-volume-size 500 SERVER= sv-taskrelaunch server $SERVER Mon servers Select a mon server in the same region (but DIFFERENT AZ) that will monitor the new mon server ah-server list mon-% -w ec2_region=${REGION} status=0 -c ec2_availability_zone MON_SERVER_NAME=<Monitor server that's monitoring the MON> Allocate and launch the server. REGION= AZ= ah-server allocate mon --ami-type c5.large --region ${REGION} \\ --avail-zone ${AZ} --primary-volume-size 100 \\ --secondary-volume-size 1 --mon-server ${MON_SERVER_NAME} SERVER= OLD_SERVER= sv-taskrelaunch server $SERVER ah-server tag add $SERVER --tags active ah-server tag remove $OLD_SERVER --tags active Rebalance the mons if necessary mon-moveactive $ALERTING_FULL_MON_SERVER Backup servers Allocate and launch backup server ah-server allocate backup --region us-east-1 --avail-zone us-east-1e --ami-type c4.large SERVER= ah-server launch ${SERVER} Allocate and add dedicated EIP ah-elastic-ip allocate us-east-1 classic EIP_ADDRESS= ah-elastic-ip add ${EIP_ADDRESS} ${SERVER} Set the backup status ah-server edit ${SERVER} -s status_as_backup_server=2","title":"Provision shared and infra hardware"},{"location":"kanban_tickets/provision_ace_infra/#provision-shared-and-infra-hardware","text":"","title":"Provision shared and infra hardware"},{"location":"kanban_tickets/provision_ace_infra/#shared-svn","text":"Set some variables. OLD_SVN= AZ=$(ah-server list ${OLD_SVN} --no-name -c ec2_availability_zone) REGION=${AZ%?} VPC_ID=$(ruby -e \"require 'aq' ; puts Aq::Hosting::Vpc.region_default('$REGION').id\") Provision the new server NEW_SVN=$(ah-server allocate svn --ami-type c4.xlarge --region ${REGION} \\ --avail-zone ${AZ} --primary-volume-size 200 --secondary-volume-size 200 -v $VPC_ID) ah-server tag add ${NEW_SVN} -t shared ah-server edit ${NEW_SVN} -c puppet:fips_enabled=1 Add a new EIP: set the IP_ADDRESS variable to the new EIP ah-elastic-ip allocate ${REGION} classic/vpc IP_ADDRESS= ah-elastic-ip add ${IP_ADDRESS} ${NEW_SVN} Launch the server sv-taskrelaunch server ${NEW_SVN} -m 1 Move the active tag ah-server tag remove ${OLD_SVN} -t activesvn ah-server tag add ${NEW_SVN} -t activesvn","title":"Shared SVN"},{"location":"kanban_tickets/provision_ace_infra/#shared-edge-clustered-balancers","text":"NOTE: There is a special process to provision Edge cluster balancers. Edge clusters balancers get provisioned while creating an Edge Cluster. Refer: Create Edge Cluster","title":"Shared Edge Clustered Balancers"},{"location":"kanban_tickets/provision_ace_infra/#shared-staging","text":"Set some variables. The \"old\" staging server is the one currently full. OLD_STAGING= REGION=$(ah-server list $OLD_STAGING -c ec2_region --no-name) AZ=$(ah-server list $OLD_STAGING -c ec2_availability_zone --no-name) STG_CLUSTER_NAME=\"$(date +%s)-stg\" Provision a new server. EC2 Classic ah-provision stack staging \\ -i m5.xlarge \\ -r $REGION -z $AZ \\ -d 500 \\ -g 500 -n $STG_CLUSTER_NAME \\ --gt gp3 --ge --de NEW_STAGING= VPC VPC=$(ah-vpc list shared-vpc-${REGION}) ah-provision stack staging \\ -i i2.xlarge \\ -r $REGION -z $AZ \\ -d 500 \\ -g 500 -n $STG_CLUSTER_NAME --gt gp3 \\ -V $VPC \\ --ge \\ --de NEW_STAGING= Edit server config ah-server edit $NEW_STAGING -c \\ apache2.conf:PoolSize=50 \\ memcached.conf:-m=64 \\ my.cnf:innodb_buffer_pool_size=5G \\ puppet:php5-xhprof=add Launch it. sv-taskrelaunch server $NEW_STAGING See if the old server was tagged for dev, test, or both. Set TAGS to match. (There are two tags for test: activestagingstg and activestagingtest ) ah-server tag list $OLD_STAGING EC2 Classic Tags: activestagingdev activestagingstg activestagingtest VPC Tags: activestagingdev activestagingstg activestagingtest shared_vpc Compliance VPC tags: shared_vpc_pci shared_vpc_hipaa shared_vpc_hipaa_pci shared_vpc_pii Move the active tags. ah-server tag remove $OLD_STAGING --tags activestaging $TAGS ah-server tag add $NEW_STAGING --tags shared activestaging $TAGS","title":"Shared Staging"},{"location":"kanban_tickets/provision_ace_infra/#shared-ra-servers","text":"Set some variables AZ= REGION=${AZ%?} STG_CLUSTER_NAME=$(date +%s) OLD_RA_SERVER=$(site-taglistactive staging ${REGION} ra) Provision the server: RA_SERVER=$(ah-provision stack staging -d 1000 -g 10 -i m5.large -n ${STG_CLUSTER_NAME} \\ -r ${REGION} -z ${AZ} --ge --de --gt gp3) Set some things ah-server tag add ${RA_SERVER} --tags shared ra_server ./fields-provision.php --fs-cluster-remove-servers ${STG_CLUSTER_NAME}:${RA_SERVER} ah-server edit ${RA_SERVER} -c puppet:gluster_version=3.0 ./fields-provision.php --fs-cluster-add-servers ${STG_CLUSTER_NAME}:${RA_SERVER} Launch the server sv-taskrelaunch server ${RA_SERVER} Move the activestagingra tag to the new server ah-server tag remove ${OLD_RA_SERVER} --tags activestagingra ah-server tag add ${RA_SERVER} --tags activestagingra NOTE: RA sites should be placed on a RA specific servers only. For more information about RA environment, please go through this link","title":"Shared RA servers"},{"location":"kanban_tickets/provision_ace_infra/#ra-within-vpc","text":"us-east-1 is the default region, so should be used unless otherwise stated. The database volume is not an SSD due to the fact we do not run MySQL with durability, so it is strictly forbidden, for now. Set some variables. AMI_TYPE will be set to i2.xlarge unless the customer has a dedicated VPC, in which case AMI_TYPE gets set to the same as their dedicated staging server. AZ should be set to one of the common AZs from region-azfeatures ${REGION} . OLD_RA_SERVER is optional if you are creating a dedicated RA server. SITEGROUP= AMI_TYPE= OLD_RA_SERVER= REGION= AZ= STG_CLUSTER_NAME=$(date +%s) Set the VPC server with one of: PCI VPC RA servers: VPC=$(ah-vpc list shared-pci-vpc-${REGION}) VPC_TAGS=\"shared_vpc_pci\" HIPAA VPC RA servers: VPC=$(ah-vpc list shared-hipaa-vpc-${REGION}) VPC_TAGS=\"shared_vpc_hipaa\" HIPAA PCI VPC RA servers: VPC=$(ah-vpc list shared-hipaa-vpc-${REGION}) VPC_TAGS=\"shared_vpc_hipaa_pci\" Default VPC RA servers: VPC=$(ah-vpc list shared-vpc-${REGION}) VPC_TAGS=\"shared_vpc shared_vpc_pii\" PII VPC RA servers (use the region default VPCs for PII): VPC=$(ah-vpc list shared-vpc-${REGION}) VPC_TAGS=\"shared_vpc shared_vpc_pii\" Dedicated VPC customers (Acquia Shield) get an RA server inside their dedicated vpc. The server should be the same size as their dev/staging server. VPC=$(ah-vpc list ${SITEGROUP}) VPC_TAGS=\"dedicated_vpc_shield\" Create the things SERVER=$(ah-provision stack staging -d 1000 -g 10 -i ${AMI_TYPE} -n ${STG_CLUSTER_NAME} \\ -r ${REGION} -z ${AZ} --ge --de --gt gp3 -V ${VPC}) ah-server tag add ${SERVER} --tags shared ra_server ./fields-provision.php --fs-cluster-remove-servers ${STG_CLUSTER_NAME}:${SERVER} ah-server edit ${SERVER} -c puppet:gluster_version=3.0 ./fields-provision.php --fs-cluster-add-servers ${STG_CLUSTER_NAME}:${SERVER} Add the relevant tag(s) for the VPC type ah-server tag add ${SERVER} --tags ${VPC_TAGS} Launch the server. sv-taskrelaunch server ${SERVER} Move the activestagingra tag to the new server. (Only applies to non-dedicated VPC RA servers) ah-server tag remove ${OLD_RA_SERVER} --tags activestagingra ah-server tag add ${SERVER} --tags activestagingra","title":"RA within VPC"},{"location":"kanban_tickets/provision_ace_infra/#ossec-servers","text":"ah-server allocate ossec --ami-type c4.large --region us-east-1 \\ --avail-zone us-east-1e --primary-volume-size 500 \\ --secondary-volume-size 500 SERVER= sv-taskrelaunch server $SERVER","title":"Ossec servers"},{"location":"kanban_tickets/provision_ace_infra/#mon-servers","text":"Select a mon server in the same region (but DIFFERENT AZ) that will monitor the new mon server ah-server list mon-% -w ec2_region=${REGION} status=0 -c ec2_availability_zone MON_SERVER_NAME=<Monitor server that's monitoring the MON> Allocate and launch the server. REGION= AZ= ah-server allocate mon --ami-type c5.large --region ${REGION} \\ --avail-zone ${AZ} --primary-volume-size 100 \\ --secondary-volume-size 1 --mon-server ${MON_SERVER_NAME} SERVER= OLD_SERVER= sv-taskrelaunch server $SERVER ah-server tag add $SERVER --tags active ah-server tag remove $OLD_SERVER --tags active Rebalance the mons if necessary mon-moveactive $ALERTING_FULL_MON_SERVER","title":"Mon servers"},{"location":"kanban_tickets/provision_ace_infra/#backup-servers","text":"Allocate and launch backup server ah-server allocate backup --region us-east-1 --avail-zone us-east-1e --ami-type c4.large SERVER= ah-server launch ${SERVER} Allocate and add dedicated EIP ah-elastic-ip allocate us-east-1 classic EIP_ADDRESS= ah-elastic-ip add ${EIP_ADDRESS} ${SERVER} Set the backup status ah-server edit ${SERVER} -s status_as_backup_server=2","title":"Backup servers"},{"location":"kanban_tickets/provision_acp/","text":"Manually Provision a DevCloud Site & Server Provision and creation Because people don't want to use credit cards, we now get requests to create devcloud site/servers. These requests are typically filed by Ready, and will contain the required information below. If any of this information is not included in the ticket, add a comment and ask for it. Region (us-east-1, eu-west-1, eu-west-2, ap-southeast-1, and ap-southeast-2 are the only choices) Sitegroup Instance type (ex: m5.large) Storage Volume Size (see sizes below) Subscription tag ID (ex: ABCD-1234) REGION= SITEGROUP= TYPE= SIZE= SUBSCRIPTION= SUBSCRIPTION can also be found from the CCI. The task created by the following command is the same as would be created via automation in ACP. The remaining sections of this runbook outline how to manually provision a site in ACP if something is broken. ah-task submit create-developer-server-and-site --body '{\"sitegroup\":\"'${SITEGROUP}'\",\"ami_type\":\"'${TYPE}'\", \"vol1_size\":\"'${SIZE}'\",\"backup_size\":\"'${SIZE}'\",\"subscription\":\"'${SUBSCRIPTION}'\", \"region\":\"'${REGION}'\"}' --description \"Create Dev Cloud site '${SITEGROUP}'\" Volume sizes are as follows: 10 20 22 25 50 100 200 250 500 1000 Provision a dedicated SRV server AZ= Allocate a dedicated srv server: ah-server allocate srv -r ${REGION} -t ${TYPE} -z ${AZ} --primary-volume-size ${SIZE} --subscription-tag=${SUBSCRIPTION} SRV= Allocate a DB cluster for the srv server: ./fields-provision.php --db-cluster-allocate ${SRV} Relaunch srv server: sv-taskrelaunch server -m 1 ${SRV} Manual steps for sites creation If the customer already has sites in ACP, you can provision the new site on the same hardware as their other sites. OTHER_SITE= BALS=$(ah-server list site:${OTHER_SITE} -w status=0 type=bal | paste -sd,) SVN=$(ah-server list site:${OTHER_SITE} -w status=0 type=svn) Otherwise, provision the new site on the correct bal and svn servers for the requested region and VPC, which are tagged devcloud-shared . (There are no dedicated bal / svn servers in ACP.) VPC= BALS=$(ah-server list tag:devcloud-shared -w status=0 type=bal ec2_region=${REGION} vpc_id=${VPC} | paste -sd,) SVN=$(ah-server list tag:devcloud-shared -w status=0 type=svn ec2_region=${REGION}) prod ./fields-provision.php --create-site ${SITEGROUP} --stage prod --bals ${BALS} --webs ${SRV} --db ${SRV} --sitegroup ${SITEGROUP} --vcs ${SVN} dev ./fields-provision.php --create-site ${SITEGROUP}dev --stage dev --bals ${BALS} --webs ${SRV} --db ${SRV} --sitegroup ${SITEGROUP} --vcs ${SVN} staging ./fields-provision.php --create-site ${SITEGROUP}stg --stage test --bals ${BALS} --webs ${SRV} --db ${SRV} --sitegroup ${SITEGROUP} --vcs ${SVN} ra When a ra site is optionally requested, devcloud places the ra site on the same hardware as the rest of the sitegroup, which typically includes among other stages the dev/stg stage. The site name follows the convention set for dev/stg sites: ${SITEGROUP}ra . It will generate random name for ra. ./fields-provision.php \\ --create-site ${SITEGROUP}ra --rand-name \\ --ra 1 --sitegroup ${SITEGROUP} \\ --stage ra \\ --bals ${BALS} \\ --webs ${SRV} \\ --db ${SRV} SITEGROUPRA=(paste the random name generated above) ah-site edit ${SITEGROUPRA} -c \\ site:dynamic_process_limit=on \\ site:systemd=1 Provisioning prod and ra sites with different stage names It is now possible to provision a prod or an ra site while using arbitrary stage names with an extra step: tagging. Any site tagged 'prod' is considered production, and any site tagged 'ra' is considered remote administration. Examples: tagged prod ./fields-provision.php --create-site ${SITEGROUP}mystage --stage mystage --bals ${BALS} --webs ${SRV} --db ${SRV} --sitegroup ${SITEGROUP} --vcs ${SVN} ah-site tag add ${SITEGROUP}mystage -t prod tagged ra You can either specify --ra 1 during provision ./fields-provision.php \\ --create-site ${SITEGROUP}admin --rand-name \\ --ra 1 --sitegroup ${SITEGROUP} \\ --stage admin \\ --bals bal-xxx,bal-yyy \\ --webs srv-zzz \\ --db srv-zzz OR add a tag later ah-site tag add ${SITEGROUP}admin -t ra The result is the same. Tagging consequences Tagging a site with prod or ra only means that HAPI and Cloud UI will consider that site production or remote administration. This means that the customer will have different settings available for these sites on the UI based on tags, and also the AH_PRODUCTION environment variable will be set for prod tag. A site can only be tagged with ra or prod . One of the tags needs to be removed before adding the other. Sites with prod stage names are tagged with prod and that tag can't be removed. Sites with ra stage names are tagged with ra and that tag can't be removed. Sites with any other stage name can freely be tagged and untagged with these tags. Tagging a site with ra will set the following configs on the site automatically: site:dynamic_process_limit=on site:systemd=1 php.ini:sendmail_path=/bin/true Add production sites to monitoring Variable: SITENAME= Before you add a site to monitoring, make sure it is pointing to either the ELB or the balancer EIP and passes the following checks. Ensure that ACQUIA_MONITOR loads: site-check ${SITENAME} Ensure that site-checkwebs is returning success by running the following: site-checkwebs ${SITENAME} If the checks pass, add the site to monitoring: site-monenable ${SITENAME}","title":"Manually Provision a DevCloud Site & Server"},{"location":"kanban_tickets/provision_acp/#manually-provision-a-devcloud-site-server","text":"","title":"Manually Provision a DevCloud Site &amp; Server"},{"location":"kanban_tickets/provision_acp/#provision-and-creation","text":"Because people don't want to use credit cards, we now get requests to create devcloud site/servers. These requests are typically filed by Ready, and will contain the required information below. If any of this information is not included in the ticket, add a comment and ask for it. Region (us-east-1, eu-west-1, eu-west-2, ap-southeast-1, and ap-southeast-2 are the only choices) Sitegroup Instance type (ex: m5.large) Storage Volume Size (see sizes below) Subscription tag ID (ex: ABCD-1234) REGION= SITEGROUP= TYPE= SIZE= SUBSCRIPTION= SUBSCRIPTION can also be found from the CCI. The task created by the following command is the same as would be created via automation in ACP. The remaining sections of this runbook outline how to manually provision a site in ACP if something is broken. ah-task submit create-developer-server-and-site --body '{\"sitegroup\":\"'${SITEGROUP}'\",\"ami_type\":\"'${TYPE}'\", \"vol1_size\":\"'${SIZE}'\",\"backup_size\":\"'${SIZE}'\",\"subscription\":\"'${SUBSCRIPTION}'\", \"region\":\"'${REGION}'\"}' --description \"Create Dev Cloud site '${SITEGROUP}'\" Volume sizes are as follows: 10 20 22 25 50 100 200 250 500 1000","title":"Provision and creation"},{"location":"kanban_tickets/provision_acp/#provision-a-dedicated-srv-server","text":"AZ= Allocate a dedicated srv server: ah-server allocate srv -r ${REGION} -t ${TYPE} -z ${AZ} --primary-volume-size ${SIZE} --subscription-tag=${SUBSCRIPTION} SRV= Allocate a DB cluster for the srv server: ./fields-provision.php --db-cluster-allocate ${SRV} Relaunch srv server: sv-taskrelaunch server -m 1 ${SRV}","title":"Provision a dedicated SRV server"},{"location":"kanban_tickets/provision_acp/#manual-steps-for-sites-creation","text":"If the customer already has sites in ACP, you can provision the new site on the same hardware as their other sites. OTHER_SITE= BALS=$(ah-server list site:${OTHER_SITE} -w status=0 type=bal | paste -sd,) SVN=$(ah-server list site:${OTHER_SITE} -w status=0 type=svn) Otherwise, provision the new site on the correct bal and svn servers for the requested region and VPC, which are tagged devcloud-shared . (There are no dedicated bal / svn servers in ACP.) VPC= BALS=$(ah-server list tag:devcloud-shared -w status=0 type=bal ec2_region=${REGION} vpc_id=${VPC} | paste -sd,) SVN=$(ah-server list tag:devcloud-shared -w status=0 type=svn ec2_region=${REGION})","title":"Manual steps for sites creation"},{"location":"kanban_tickets/provision_acp/#prod","text":"./fields-provision.php --create-site ${SITEGROUP} --stage prod --bals ${BALS} --webs ${SRV} --db ${SRV} --sitegroup ${SITEGROUP} --vcs ${SVN}","title":"prod"},{"location":"kanban_tickets/provision_acp/#dev","text":"./fields-provision.php --create-site ${SITEGROUP}dev --stage dev --bals ${BALS} --webs ${SRV} --db ${SRV} --sitegroup ${SITEGROUP} --vcs ${SVN}","title":"dev"},{"location":"kanban_tickets/provision_acp/#staging","text":"./fields-provision.php --create-site ${SITEGROUP}stg --stage test --bals ${BALS} --webs ${SRV} --db ${SRV} --sitegroup ${SITEGROUP} --vcs ${SVN}","title":"staging"},{"location":"kanban_tickets/provision_acp/#ra","text":"When a ra site is optionally requested, devcloud places the ra site on the same hardware as the rest of the sitegroup, which typically includes among other stages the dev/stg stage. The site name follows the convention set for dev/stg sites: ${SITEGROUP}ra . It will generate random name for ra. ./fields-provision.php \\ --create-site ${SITEGROUP}ra --rand-name \\ --ra 1 --sitegroup ${SITEGROUP} \\ --stage ra \\ --bals ${BALS} \\ --webs ${SRV} \\ --db ${SRV} SITEGROUPRA=(paste the random name generated above) ah-site edit ${SITEGROUPRA} -c \\ site:dynamic_process_limit=on \\ site:systemd=1","title":"ra"},{"location":"kanban_tickets/provision_acp/#provisioning-prod-and-ra-sites-with-different-stage-names","text":"It is now possible to provision a prod or an ra site while using arbitrary stage names with an extra step: tagging. Any site tagged 'prod' is considered production, and any site tagged 'ra' is considered remote administration. Examples:","title":"Provisioning prod and ra sites with different stage names"},{"location":"kanban_tickets/provision_acp/#tagged-prod","text":"./fields-provision.php --create-site ${SITEGROUP}mystage --stage mystage --bals ${BALS} --webs ${SRV} --db ${SRV} --sitegroup ${SITEGROUP} --vcs ${SVN} ah-site tag add ${SITEGROUP}mystage -t prod","title":"tagged prod"},{"location":"kanban_tickets/provision_acp/#tagged-ra","text":"You can either specify --ra 1 during provision ./fields-provision.php \\ --create-site ${SITEGROUP}admin --rand-name \\ --ra 1 --sitegroup ${SITEGROUP} \\ --stage admin \\ --bals bal-xxx,bal-yyy \\ --webs srv-zzz \\ --db srv-zzz OR add a tag later ah-site tag add ${SITEGROUP}admin -t ra The result is the same.","title":"tagged ra"},{"location":"kanban_tickets/provision_acp/#tagging-consequences","text":"Tagging a site with prod or ra only means that HAPI and Cloud UI will consider that site production or remote administration. This means that the customer will have different settings available for these sites on the UI based on tags, and also the AH_PRODUCTION environment variable will be set for prod tag. A site can only be tagged with ra or prod . One of the tags needs to be removed before adding the other. Sites with prod stage names are tagged with prod and that tag can't be removed. Sites with ra stage names are tagged with ra and that tag can't be removed. Sites with any other stage name can freely be tagged and untagged with these tags. Tagging a site with ra will set the following configs on the site automatically: site:dynamic_process_limit=on site:systemd=1 php.ini:sendmail_path=/bin/true","title":"Tagging consequences"},{"location":"kanban_tickets/provision_acp/#add-production-sites-to-monitoring","text":"Variable: SITENAME= Before you add a site to monitoring, make sure it is pointing to either the ELB or the balancer EIP and passes the following checks. Ensure that ACQUIA_MONITOR loads: site-check ${SITENAME} Ensure that site-checkwebs is returning success by running the following: site-checkwebs ${SITENAME} If the checks pass, add the site to monitoring: site-monenable ${SITENAME}","title":"Add production sites to monitoring"},{"location":"kanban_tickets/provision_acsf/","text":"Site Factory provisioning Preparation Site Factory Sizes come in 4 cluster sizes micro, small, medium and large. Look at the dealsheet to determine which region and cluster size to use. Procedure We have a script that will output the commands you need to provision a customer's site factory Enter the Site Factory stage aenterpriseg1 Run the acsf-provisioningtool CUSTOMER= REGION= CLUSTER_SIZE= VPC_NAME= acsf-provisioningtool ${CUSTOMER} ${REGION} \\ ${CLUSTER_SIZE} ${VPC_NAME} In many cases VPC_NAME could be something shared, such as shared-vpc-us-east-1. Unless specified ask clarification in the ticket. Run the commands outputted by the tool Creating additional environments If the environment you wish to add ends with 'x' and matches an existing environment e.g. prodx , testx or begins with a numerical index e.g. 01live , 02dev , please contact the ACSF team via a DG ticket. This is due to proxy naming. The formal list including non-standard names is located here in the environment_for_snowflakes method. The stage variable within that method is equivalent to environment in this runbook's context. Enter the Site Factory stage aenterpriseg1 Set Variables for the acsf-additionalenvironment tool CUSTOMER= ENVIRONMENT_NAME= REGION= CLUSTER_SIZE= VPC_NAME= Note: If the additional environment that is being requested for the purposes of RA (remote administration), it must use 'acqra' as the environment name parameter to the acsf-additionalenvironment tool ENVIRONMENT_NAME=acqra Run the acsf-additionalenvironment tool acsf-additionalenvironment ${CUSTOMER} ${ENVIRONMENT_NAME} \\ ${REGION} ${CLUSTER_SIZE} ${VPC_NAME} Run the commands outputted by the tool In additional for 'acqra' environment, we need to delete the backup cron and change the APC settings ah-site edit ${CUSTOMER}sfacqra -c php.ini:apc.shm_size=256 ah-site cron2 list --site-name=${CUSTOMER}01acqra | grep ah-db-backup | awk 'match($0, /[0-9a-fA-F]{8}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{12}/) {print substr( $0, RSTART, RLENGTH )}' ah-site cron2 list --site-name=${CUSTOMER}01acqraup | grep ah-db-backup | awk 'match($0, /[0-9a-fA-F]{8}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{12}/) {print substr( $0, RSTART, RLENGTH )}' ah-site cron2 list --site-name=${CUSTOMER}sfacqra | grep ah-db-backup | awk 'match($0, /[0-9a-fA-F]{8}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{12}/) {print substr( $0, RSTART, RLENGTH )}' ah-site cron2 delete --uuid=CRON_UUID_1; ah-site cron2 delete --uuid=CRON_UUID_2; ah-site cron2 delete --uuid=CRON_UUID_3 For each site provisioned, run site-check to ensure that DNS is properly set. DNS_IP=$(dig ${SITENAME}.${FIELDS_STAGE}.acquia-sites.com +short) BAL_IP=$(ah-server list site:${SITENAME} --no-name -w type=bal status=0 eip_id!=nil -c external_ip | head -1) if [[ ${DNS_IP} ]] || [[ ${BAL_IP} ]]; then if [[ ${DNS_IP} == ${BAL_IP} ]]; then errecho \"DNS is properly set for ${SITENAME}\" else errecho \"ERROR: DNS needs setting for ${SITENAME}.${FIELDS_STAGE}.acquia-sites.com\" \\ \"to the active bal EIP '${BAL_IP}'\" errecho \"ah-dns help set\" ah-dns help set fi else errecho \"ERROR: The site's bal doesn't have an EIP and there is no DNS entry.\" fi Ensure that ACQUIA_MONITOR loads: site-check ${SITENAME} Ensure that the site is returning 200 OK's by running the following: site-checkwebs ${SITENAME} Check Nagios for any alerts related to the servers you just launched Refer to AWS Certificate Manager to add new domains to the ACM certificate on the ELB. Creating an ELB for the site factory Request a cert. Alt names are additional domains that you would like added to the cert and should be separated by spaces CUSTOMER= SITE=\"${CUSTOMER}sf\" REGION=$(ah-server list site:$SITE -c ec2_region --no-name | head -1) DOMAIN=\"www.${CUSTOMER}.acsitefactory.com\" VALIDATION_DOMAIN=\"acsitefactory.com\" NON_PROD_SITES=($(ah-site list % -w sitegroup=${SITE} stage!=prod -c stage --no-name)) SANS=() for SUB in ${NON_PROD_SITES[@]}; do SANS+=( www.${SUB}-${CUSTOMER}.${VALIDATION_DOMAIN} ); done aws acm request-certificate --domain-name ${DOMAIN} \\ --subject-alternative-names ${SANS[@]} \\ --region ${REGION} --validation-method DNS You will need to set a value for the CNAME on each domain requested on the certificate. The VALUE will end in acm-validations.aws , whereas the NAME will have an aws hash before the domain name. Remove any periods at the end when copy pasting to avoid errors. ARN= aws acm describe-certificate --certificate-arn ${ARN} --region ${REGION} | egrep \"DomainName|Name|Value\" ah-dns set -t CNAME -v $VALUE -h $NAME Verify the cert is ready. It should say status is ISSUED aws acm describe-certificate --certificate-arn ${ARN} \\ --region ${REGION} | grep Status If you need to recover the ARN number you can run list-certificates aws acm list-certificates --region ${REGION} Create elb on the SF Dashboard site: It's usually called ${customer}sf or gardener (legacy). KEY=${OPSTMP}/$CUSTOMER.key CERT=${OPSTMP}/$CUSTOMER.pem openssl req -nodes -sha256 -newkey rsa:2048 \\ -keyout ${KEY} -out ${OPSTMP}/${CUSTOMER}.csr -subj \\ \"/C=US/ST=Massachusetts/L=Boston/O=Acquia Inc./OU=Acquia/CN=${DOMAIN}\" openssl x509 -req -days 365 -in ${OPSTMP}/$CUSTOMER.csr \\ -signkey ${KEY} -out ${CERT} ah-site ssl create-elb ${CUSTOMER}sf --ca ${CERT} --cert ${CERT} --key ${KEY} Get the ELB name site-elbdescribe ${CUSTOMER}sf ELB= OLD_IAM_CERT=$(aws elb describe-load-balancers --region ${REGION} \\ --load-balancer-name ${ELB} | grep SSLCertificateId \\ | cut -d '\"' -f 4) Set the ELB to use the ACM cert aws elb set-load-balancer-listener-ssl-certificate --load-balancer-name \\ ${ELB} --load-balancer-port 443 --ssl-certificate-id ${ARN} \\ --region ${REGION} Delete the IAM cert that is no longer being used by the ELB IAM_CERT_NAME=$(echo $OLD_IAM_CERT | cut -d '/' -f 2) aws iam delete-server-certificate --server-certificate-name $IAM_CERT_NAME If you get a DeleteConflict wait a few seconds and try again. Update DNS for test and dev sf to point at the ELB. ELB_FQDN= TEST_DOMAIN=www.test-${CUSTOMER}.acsitefactory.com DEV_DOMAIN=www.dev-${CUSTOMER}.acsitefactory.com ah-dns set -t CNAME -v ${ELB_FQDN} -h ${TEST_DOMAIN} ah-dns set -t CNAME -v ${ELB_FQDN} -h ${DEV_DOMAIN} Adding a \"Stack\" A \"Stack\" is a package sold to customers that gives them an additional hardware cluster for hosted sites attached to their original factory. It can be used if they want to use more than one codebase for their ACSF sites. Use the same provisioning tool and procedure as for a full Site Factory setup (above), but for stacks, the final 2 arguments are required. There will be no ELB/ACM setup required for a stack, as that only applies to the factory domains. Enter the Site Factory stage aenterpriseg1 Run the acsf-provisioningtool for adding a stack CUSTOMER= REGION= CLUSTER_SIZE= VPC_NAME= STACK_SITEGROUP= ENVIRONMENT_INDEX= acsf-provisioningtool $CUSTOMER $REGION $CLUSTER_SIZE $VPC_NAME \\ $STACK_SITEGROUP $ENVIRONMENT_INDEX The information you will need (which should be provided in the ticket are): CUSTOMER: The customer name - this must exactly match the name of the customer originally provisioned. It will in almost all cases be the sitegroup name of the factory with the trailing \"sf\" stripped off, so for example in the case of a factory sitegroup \"nestleinfantsf\", the customer name is \"nestleinfant\". If unsure, get clarification in the ticket. REGION: The AWS region to provision in. In many cases, this will be the same as the original factory. CLUSTER_SIZE: The cluster size for the new stack. Nano is not a supported size for stacks and will not be accepted by the tool for adding stacks. Micro is only likely if this is an Acquia internal provision. VPC_NAME The VPC name. In many cases, this will be the same as for the original factory if the new stack is in the same region as the original factory . STACK_SITEGROUP: The name of the new stack sitegroup - this is prescribed by the CCI subscriptions that have been created. You may see 2 sitegroup names in the ticket called sitegroup and sitegroup theme. The one you need for this parameter is the one that does not end with \"theme\". ENVIRONMENT_INDEX: A serial number between 1 and 99. If not provided in the ticket, use \"1\". This changes the serial number used in the environment names, but has no other interesting effects. It is arbitrarily chosen and would normally only be used if adding a new stack with the same sitegroup as a previous one, meaning that \"1\" (and possibly subsequent numbers) had already been taken and cannot be reused. As with a full factory provision, the procedure is to run the tool, then run the commands that it outputs. Paste the outputs of both the tool itself and commands into the OP ticket - this is helpful for finding bugs in the tooling, or in case a handoff is needed. Adding a \"Load test environment\" Use cases A \"Load test environment\" empowers customers to load test on ACSF in a temporary added environment, that has similar hardware to a customer's production environment provisioned by the acsf-loadtestenvironment tool. A customer uses this to see how their application will stand up to load in a setup similar to their production environment without load testing on actual production hardware (which might impact running sites). The scope is limited to the following cases: Customer has an existing factory, with just a single default stack . Just run the acsf-loadtestenvironment tool. Customer has a factory with multiple stacks and we want to add a load test environment. In this case: Specify the [STACK_SITEGROUP] to add the load test environment to. Give the correct [ENVIRONMENT_INDEX]. First run the acsf-loadtestenvironment tool, which will correctly handle one stack, Then run the acsf-additionalenvironment tool, needed to fill in the environment for the rest of the stacks. Customer has a factory and needs to add a regular (non load test) environment. In this case, just run the acsf-additionalenvironment tool above, instead. Arguments needed In any of the cases we need to make sure all the arguments are right or we could end up with a broken environment setup. The information you will need to provide is similar to the acsf-provisioningtool above, plus: STACK_SITEGROUP: This is the sitegroup of the stack , created with the provisioning tool, that the load test environment is being applied to. It is used to determine which stack will receive the load test hardware and we assume the rest will get standard hardware for an added environment. ENVIRONMENT_INDEX: Is an integer shared across the entire stack for all environments - a serially-incrementing number for tangles/stacks (stack 1, 2, 3 etc). If you are not 100% sure of this value, please have the ACSF team review each ticket and supply the right value. ENVIRONMENT_NAME: Is meant to define a name for the load testing environment. Should be supplied by the customer (via the AM), and has a maximum of 6 chars. As with the other provision tools above, the procedure is to run the tool, then run the commands that it outputs. Paste the outputs of both the tool itself and commands into the OP ticket. Commands creating a load test environment for a customer Get the stack sitegroup from the ACSF's customer registry and keep note if this is a multi-stack rm -rf ~/.gittools/ git clone -q --depth 1 --single-branch git@github.com:acquia/gittools.git ~/.gittools acsf-findcustomerstacks.rb ${CUSTOMER} ~/.gittools/build-tools/customers_info_v2.yml Example run of acsf-findcustomerstacks.rb : $ acsf-findcustomerstacks.rb fanniemaesf ~/.gittools/build-tools/customers_info_v2.yml fanniemaesf 01 prod test dev uat prev fnmmultifamily 02 prod test dev uat prev where fanniemaesf and fnmmultifamily are stack sitegroups for customer fanniemaesf , with 01 and 02 as the respective environment indexes of each stack, followed by the environments. Enter the Site Factory stage and specify variables aenterpriseg1 CUSTOMER= REGION= CLUSTER_SIZE= [small|medium|large] VPC_NAME= [shared-vpc-|shared-hipaa-vpc-|...] STACK_SITEGROUP= ENVIRONMENT_INDEX= ENVIRONMENT_NAME= Run the acsf-loadtestenvironment tool acsf-loadtestenvironment ${CUSTOMER} ${REGION} \\ ${CLUSTER_SIZE} \\ ${VPC_NAME} \\ ${STACK_SITEGROUP} \\ ${ENVIRONMENT_INDEX} \\ ${ENVIRONMENT_NAME} Run the commands outputted by the tool Based on the output of acsf-findcustomerstacks.rb above, if the customer has a single default stack , you can skip next steps. Otherwise, if the customer is multi-stack , then run the following steps, to add the environment for all other stacks: Run the acsf-additionalenvironment tool acsf-additionalenvironment ${CUSTOMER} ${ENVIRONMENT_NAME} \\ ${REGION} ${CLUSTER_SIZE} ${VPC_NAME} Run the commands outputted by the tool","title":"Site Factory provisioning"},{"location":"kanban_tickets/provision_acsf/#site-factory-provisioning","text":"","title":"Site Factory provisioning"},{"location":"kanban_tickets/provision_acsf/#preparation","text":"Site Factory Sizes come in 4 cluster sizes micro, small, medium and large. Look at the dealsheet to determine which region and cluster size to use.","title":"Preparation"},{"location":"kanban_tickets/provision_acsf/#procedure","text":"We have a script that will output the commands you need to provision a customer's site factory Enter the Site Factory stage aenterpriseg1 Run the acsf-provisioningtool CUSTOMER= REGION= CLUSTER_SIZE= VPC_NAME= acsf-provisioningtool ${CUSTOMER} ${REGION} \\ ${CLUSTER_SIZE} ${VPC_NAME} In many cases VPC_NAME could be something shared, such as shared-vpc-us-east-1. Unless specified ask clarification in the ticket. Run the commands outputted by the tool","title":"Procedure"},{"location":"kanban_tickets/provision_acsf/#creating-additional-environments","text":"If the environment you wish to add ends with 'x' and matches an existing environment e.g. prodx , testx or begins with a numerical index e.g. 01live , 02dev , please contact the ACSF team via a DG ticket. This is due to proxy naming. The formal list including non-standard names is located here in the environment_for_snowflakes method. The stage variable within that method is equivalent to environment in this runbook's context. Enter the Site Factory stage aenterpriseg1 Set Variables for the acsf-additionalenvironment tool CUSTOMER= ENVIRONMENT_NAME= REGION= CLUSTER_SIZE= VPC_NAME= Note: If the additional environment that is being requested for the purposes of RA (remote administration), it must use 'acqra' as the environment name parameter to the acsf-additionalenvironment tool ENVIRONMENT_NAME=acqra Run the acsf-additionalenvironment tool acsf-additionalenvironment ${CUSTOMER} ${ENVIRONMENT_NAME} \\ ${REGION} ${CLUSTER_SIZE} ${VPC_NAME} Run the commands outputted by the tool In additional for 'acqra' environment, we need to delete the backup cron and change the APC settings ah-site edit ${CUSTOMER}sfacqra -c php.ini:apc.shm_size=256 ah-site cron2 list --site-name=${CUSTOMER}01acqra | grep ah-db-backup | awk 'match($0, /[0-9a-fA-F]{8}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{12}/) {print substr( $0, RSTART, RLENGTH )}' ah-site cron2 list --site-name=${CUSTOMER}01acqraup | grep ah-db-backup | awk 'match($0, /[0-9a-fA-F]{8}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{12}/) {print substr( $0, RSTART, RLENGTH )}' ah-site cron2 list --site-name=${CUSTOMER}sfacqra | grep ah-db-backup | awk 'match($0, /[0-9a-fA-F]{8}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{4}\\-[0-9a-fA-F]{12}/) {print substr( $0, RSTART, RLENGTH )}' ah-site cron2 delete --uuid=CRON_UUID_1; ah-site cron2 delete --uuid=CRON_UUID_2; ah-site cron2 delete --uuid=CRON_UUID_3 For each site provisioned, run site-check to ensure that DNS is properly set. DNS_IP=$(dig ${SITENAME}.${FIELDS_STAGE}.acquia-sites.com +short) BAL_IP=$(ah-server list site:${SITENAME} --no-name -w type=bal status=0 eip_id!=nil -c external_ip | head -1) if [[ ${DNS_IP} ]] || [[ ${BAL_IP} ]]; then if [[ ${DNS_IP} == ${BAL_IP} ]]; then errecho \"DNS is properly set for ${SITENAME}\" else errecho \"ERROR: DNS needs setting for ${SITENAME}.${FIELDS_STAGE}.acquia-sites.com\" \\ \"to the active bal EIP '${BAL_IP}'\" errecho \"ah-dns help set\" ah-dns help set fi else errecho \"ERROR: The site's bal doesn't have an EIP and there is no DNS entry.\" fi Ensure that ACQUIA_MONITOR loads: site-check ${SITENAME} Ensure that the site is returning 200 OK's by running the following: site-checkwebs ${SITENAME} Check Nagios for any alerts related to the servers you just launched Refer to AWS Certificate Manager to add new domains to the ACM certificate on the ELB.","title":"Creating additional environments"},{"location":"kanban_tickets/provision_acsf/#creating-an-elb-for-the-site-factory","text":"Request a cert. Alt names are additional domains that you would like added to the cert and should be separated by spaces CUSTOMER= SITE=\"${CUSTOMER}sf\" REGION=$(ah-server list site:$SITE -c ec2_region --no-name | head -1) DOMAIN=\"www.${CUSTOMER}.acsitefactory.com\" VALIDATION_DOMAIN=\"acsitefactory.com\" NON_PROD_SITES=($(ah-site list % -w sitegroup=${SITE} stage!=prod -c stage --no-name)) SANS=() for SUB in ${NON_PROD_SITES[@]}; do SANS+=( www.${SUB}-${CUSTOMER}.${VALIDATION_DOMAIN} ); done aws acm request-certificate --domain-name ${DOMAIN} \\ --subject-alternative-names ${SANS[@]} \\ --region ${REGION} --validation-method DNS You will need to set a value for the CNAME on each domain requested on the certificate. The VALUE will end in acm-validations.aws , whereas the NAME will have an aws hash before the domain name. Remove any periods at the end when copy pasting to avoid errors. ARN= aws acm describe-certificate --certificate-arn ${ARN} --region ${REGION} | egrep \"DomainName|Name|Value\" ah-dns set -t CNAME -v $VALUE -h $NAME Verify the cert is ready. It should say status is ISSUED aws acm describe-certificate --certificate-arn ${ARN} \\ --region ${REGION} | grep Status If you need to recover the ARN number you can run list-certificates aws acm list-certificates --region ${REGION} Create elb on the SF Dashboard site: It's usually called ${customer}sf or gardener (legacy). KEY=${OPSTMP}/$CUSTOMER.key CERT=${OPSTMP}/$CUSTOMER.pem openssl req -nodes -sha256 -newkey rsa:2048 \\ -keyout ${KEY} -out ${OPSTMP}/${CUSTOMER}.csr -subj \\ \"/C=US/ST=Massachusetts/L=Boston/O=Acquia Inc./OU=Acquia/CN=${DOMAIN}\" openssl x509 -req -days 365 -in ${OPSTMP}/$CUSTOMER.csr \\ -signkey ${KEY} -out ${CERT} ah-site ssl create-elb ${CUSTOMER}sf --ca ${CERT} --cert ${CERT} --key ${KEY} Get the ELB name site-elbdescribe ${CUSTOMER}sf ELB= OLD_IAM_CERT=$(aws elb describe-load-balancers --region ${REGION} \\ --load-balancer-name ${ELB} | grep SSLCertificateId \\ | cut -d '\"' -f 4) Set the ELB to use the ACM cert aws elb set-load-balancer-listener-ssl-certificate --load-balancer-name \\ ${ELB} --load-balancer-port 443 --ssl-certificate-id ${ARN} \\ --region ${REGION} Delete the IAM cert that is no longer being used by the ELB IAM_CERT_NAME=$(echo $OLD_IAM_CERT | cut -d '/' -f 2) aws iam delete-server-certificate --server-certificate-name $IAM_CERT_NAME If you get a DeleteConflict wait a few seconds and try again. Update DNS for test and dev sf to point at the ELB. ELB_FQDN= TEST_DOMAIN=www.test-${CUSTOMER}.acsitefactory.com DEV_DOMAIN=www.dev-${CUSTOMER}.acsitefactory.com ah-dns set -t CNAME -v ${ELB_FQDN} -h ${TEST_DOMAIN} ah-dns set -t CNAME -v ${ELB_FQDN} -h ${DEV_DOMAIN}","title":"Creating an ELB for the site factory"},{"location":"kanban_tickets/provision_acsf/#adding-a-stack","text":"A \"Stack\" is a package sold to customers that gives them an additional hardware cluster for hosted sites attached to their original factory. It can be used if they want to use more than one codebase for their ACSF sites. Use the same provisioning tool and procedure as for a full Site Factory setup (above), but for stacks, the final 2 arguments are required. There will be no ELB/ACM setup required for a stack, as that only applies to the factory domains. Enter the Site Factory stage aenterpriseg1 Run the acsf-provisioningtool for adding a stack CUSTOMER= REGION= CLUSTER_SIZE= VPC_NAME= STACK_SITEGROUP= ENVIRONMENT_INDEX= acsf-provisioningtool $CUSTOMER $REGION $CLUSTER_SIZE $VPC_NAME \\ $STACK_SITEGROUP $ENVIRONMENT_INDEX The information you will need (which should be provided in the ticket are): CUSTOMER: The customer name - this must exactly match the name of the customer originally provisioned. It will in almost all cases be the sitegroup name of the factory with the trailing \"sf\" stripped off, so for example in the case of a factory sitegroup \"nestleinfantsf\", the customer name is \"nestleinfant\". If unsure, get clarification in the ticket. REGION: The AWS region to provision in. In many cases, this will be the same as the original factory. CLUSTER_SIZE: The cluster size for the new stack. Nano is not a supported size for stacks and will not be accepted by the tool for adding stacks. Micro is only likely if this is an Acquia internal provision. VPC_NAME The VPC name. In many cases, this will be the same as for the original factory if the new stack is in the same region as the original factory . STACK_SITEGROUP: The name of the new stack sitegroup - this is prescribed by the CCI subscriptions that have been created. You may see 2 sitegroup names in the ticket called sitegroup and sitegroup theme. The one you need for this parameter is the one that does not end with \"theme\". ENVIRONMENT_INDEX: A serial number between 1 and 99. If not provided in the ticket, use \"1\". This changes the serial number used in the environment names, but has no other interesting effects. It is arbitrarily chosen and would normally only be used if adding a new stack with the same sitegroup as a previous one, meaning that \"1\" (and possibly subsequent numbers) had already been taken and cannot be reused. As with a full factory provision, the procedure is to run the tool, then run the commands that it outputs. Paste the outputs of both the tool itself and commands into the OP ticket - this is helpful for finding bugs in the tooling, or in case a handoff is needed.","title":"Adding a \"Stack\""},{"location":"kanban_tickets/provision_acsf/#adding-a-load-test-environment","text":"","title":"Adding a \"Load test environment\""},{"location":"kanban_tickets/provision_acsf/#use-cases","text":"A \"Load test environment\" empowers customers to load test on ACSF in a temporary added environment, that has similar hardware to a customer's production environment provisioned by the acsf-loadtestenvironment tool. A customer uses this to see how their application will stand up to load in a setup similar to their production environment without load testing on actual production hardware (which might impact running sites). The scope is limited to the following cases: Customer has an existing factory, with just a single default stack . Just run the acsf-loadtestenvironment tool. Customer has a factory with multiple stacks and we want to add a load test environment. In this case: Specify the [STACK_SITEGROUP] to add the load test environment to. Give the correct [ENVIRONMENT_INDEX]. First run the acsf-loadtestenvironment tool, which will correctly handle one stack, Then run the acsf-additionalenvironment tool, needed to fill in the environment for the rest of the stacks. Customer has a factory and needs to add a regular (non load test) environment. In this case, just run the acsf-additionalenvironment tool above, instead.","title":"Use cases"},{"location":"kanban_tickets/provision_acsf/#arguments-needed","text":"In any of the cases we need to make sure all the arguments are right or we could end up with a broken environment setup. The information you will need to provide is similar to the acsf-provisioningtool above, plus: STACK_SITEGROUP: This is the sitegroup of the stack , created with the provisioning tool, that the load test environment is being applied to. It is used to determine which stack will receive the load test hardware and we assume the rest will get standard hardware for an added environment. ENVIRONMENT_INDEX: Is an integer shared across the entire stack for all environments - a serially-incrementing number for tangles/stacks (stack 1, 2, 3 etc). If you are not 100% sure of this value, please have the ACSF team review each ticket and supply the right value. ENVIRONMENT_NAME: Is meant to define a name for the load testing environment. Should be supplied by the customer (via the AM), and has a maximum of 6 chars. As with the other provision tools above, the procedure is to run the tool, then run the commands that it outputs. Paste the outputs of both the tool itself and commands into the OP ticket.","title":"Arguments needed"},{"location":"kanban_tickets/provision_acsf/#commands-creating-a-load-test-environment-for-a-customer","text":"Get the stack sitegroup from the ACSF's customer registry and keep note if this is a multi-stack rm -rf ~/.gittools/ git clone -q --depth 1 --single-branch git@github.com:acquia/gittools.git ~/.gittools acsf-findcustomerstacks.rb ${CUSTOMER} ~/.gittools/build-tools/customers_info_v2.yml Example run of acsf-findcustomerstacks.rb : $ acsf-findcustomerstacks.rb fanniemaesf ~/.gittools/build-tools/customers_info_v2.yml fanniemaesf 01 prod test dev uat prev fnmmultifamily 02 prod test dev uat prev where fanniemaesf and fnmmultifamily are stack sitegroups for customer fanniemaesf , with 01 and 02 as the respective environment indexes of each stack, followed by the environments. Enter the Site Factory stage and specify variables aenterpriseg1 CUSTOMER= REGION= CLUSTER_SIZE= [small|medium|large] VPC_NAME= [shared-vpc-|shared-hipaa-vpc-|...] STACK_SITEGROUP= ENVIRONMENT_INDEX= ENVIRONMENT_NAME= Run the acsf-loadtestenvironment tool acsf-loadtestenvironment ${CUSTOMER} ${REGION} \\ ${CLUSTER_SIZE} \\ ${VPC_NAME} \\ ${STACK_SITEGROUP} \\ ${ENVIRONMENT_INDEX} \\ ${ENVIRONMENT_NAME} Run the commands outputted by the tool Based on the output of acsf-findcustomerstacks.rb above, if the customer has a single default stack , you can skip next steps. Otherwise, if the customer is multi-stack , then run the following steps, to add the environment for all other stacks: Run the acsf-additionalenvironment tool acsf-additionalenvironment ${CUSTOMER} ${ENVIRONMENT_NAME} \\ ${REGION} ${CLUSTER_SIZE} ${VPC_NAME} Run the commands outputted by the tool","title":"Commands creating a load test environment for a customer"},{"location":"kanban_tickets/provision_bastion/","text":"Provisioning This should only ever be done by a Tier 2, as the bastion sudo privilege is required. Provisioning bastions is reasonably straight forward, Phil documented as much as possible in the ticket to create bastion-133 . The most important thing to note for launching is that your keys will not exist on the new server yet so during launch you MUST log in as root; see the relaunch guide . Once the new server is launched you will need to create an SSH key as root for the purpose of rsyncing /vol/ebs1 from another bastion.","title":"Provisioning"},{"location":"kanban_tickets/provision_bastion/#provisioning","text":"This should only ever be done by a Tier 2, as the bastion sudo privilege is required. Provisioning bastions is reasonably straight forward, Phil documented as much as possible in the ticket to create bastion-133 . The most important thing to note for launching is that your keys will not exist on the new server yet so during launch you MUST log in as root; see the relaunch guide . Once the new server is launched you will need to create an SSH key as root for the purpose of rsyncing /vol/ebs1 from another bastion.","title":"Provisioning"},{"location":"kanban_tickets/provision_log_server/","text":"Log Servers Arch Docs - fields/doc/arch/sumologic.md Introduction Log clusters are groupings of hosts that are configured behind an ELB in a given stage's region to forward logs to Sumologic. The logs that are forwarded to Sumologic are controlled via https://github.com/acquia/fields acquia/fields and are subject to change. Hosts that are allocated post-1.84 have their log_cluster_id values specified automatically on a per-region basis. Hosts that are allocated on versions prior to this will likely need this value set explicitly. Pre-requisites Before launching log host types, you must ensure that your .netrc files for the stage in which you are operating are populated with Sumologic credentials. Please see the Ops KeePassX archive for the credentials appropriate to the stage you are operating in. Provision Log Servers If you are about to create a new log cluster, the default number of servers you should create is 3, please distribute the servers among all AZs. There should only ever be one log cluster per region, please only add servers to log clusters instead of creating duplicates Find all log clusters and their regions: ah-server list % -w type=log -c log_cluster_id ec2_region For example: $ ah-server list % -w type=log -c log_cluster_id ec2_region log-9284, 1, us-east-1 log-9285, 1, us-east-1 log-9286, 1, us-east-1 log-10014, 2, ap-southeast-1 log-10015, 2, ap-southeast-1 log-10016, 2, ap-southeast-1 log-10089, 3, ap-southeast-2 log-10090, 3, ap-southeast-2 log-10091, 3, ap-southeast-2 log-10100, 4, us-west-2 <output omitted> Set some variables: REGION= AZS=() # e.g. AZS=(us-east-1a us-east-1b us-east-1c) VPC_ID= # Logclusters should be provisioned in the shared VPC for the region. # ah-vpc list % -c id | grep ${REGION} Create the log servers. LOGS=($(for AZ in ${AZS[@]}; do ah-server \\ allocate log \\ --region ${REGION} \\ --avail-zone ${AZ} \\ --ami-type m5.large \\ -v ${VPC_ID} done)) Once this is complete, launch the hosts: ah-server launch ${LOGS[@]} Manage A New Cluster Once the new hosts are launched, use ah-log to allocate the logical cluster (which will also launch the ELB for it as well): ah-log cluster allocate ${REGION} ${LOGS[@]} Once the log cluster has been allocated successfully, take note of the id field in the task output from the above command. This will be your '''log_cluster_id''' Here's an example of the output you should see: $ ah-log cluster allocate us-west-2 log-10100 log-10101 log-10102 [2014-08-22 16:09:00] AWS: describe_regions() -> OK (200 9739eb3d-060d-4112... [2014-08-22 16:09:00] Task 18539024 submitted. Waiting for completion. [2014-08-22 16:09:00] State change submitted -> waiting. [2014-08-22 16:09:05] State change waiting -> started. [2014-08-22 16:10:45] State change started -> done. [2014-08-22 16:10:45] Task 18539024 completed successfully. dns_name: ec2_region: us-west-2 elb_name: id: 4 log_servers: (SNIP) You can also view this information through with ah-log cluster list $ ah-log cluster list 1: log-9284, log-9285, log-9286, log-10880 2: log-10014, log-10015, log-10016 3: log-10089, log-10090, log-10091 4: log-10100, log-10101, log-10102 5: log-10111, log-10112, log-10113 8: log-10436, log-10437, log-10438 Manage An Existing Cluster To add/remove clients to/from log clusters all servers must be status=0 . The options and use of the ah-log tool are too extensive for this procedure, so please view the output of ah-log help cluster . The command's help output is detailed enough to help you perform the following actions: Get cluster info List clusters List members of a cluster Allocate a cluster Deallocate a cluster Add servers to a cluster Remove servers from a cluster Manage Clients Now that the cluster is allocated, add your host(s) to the cluster one at a time. The following command only takes a single host as an argument . WARNING : You will need to throttle this command if you are adding more than 20 servers at a time, as each invocation will issue a callback task and may cause a task-flood. ah-log server add ${LOG_CLUSTER_ID} ${HOST} Now verify that all instances on the log cluster elb are reporting healthy by logging into the AWS console or using the awscli.","title":"Log Servers"},{"location":"kanban_tickets/provision_log_server/#log-servers","text":"Arch Docs - fields/doc/arch/sumologic.md","title":"Log Servers"},{"location":"kanban_tickets/provision_log_server/#introduction","text":"Log clusters are groupings of hosts that are configured behind an ELB in a given stage's region to forward logs to Sumologic. The logs that are forwarded to Sumologic are controlled via https://github.com/acquia/fields acquia/fields and are subject to change. Hosts that are allocated post-1.84 have their log_cluster_id values specified automatically on a per-region basis. Hosts that are allocated on versions prior to this will likely need this value set explicitly.","title":"Introduction"},{"location":"kanban_tickets/provision_log_server/#pre-requisites","text":"Before launching log host types, you must ensure that your .netrc files for the stage in which you are operating are populated with Sumologic credentials. Please see the Ops KeePassX archive for the credentials appropriate to the stage you are operating in.","title":"Pre-requisites"},{"location":"kanban_tickets/provision_log_server/#provision-log-servers","text":"If you are about to create a new log cluster, the default number of servers you should create is 3, please distribute the servers among all AZs. There should only ever be one log cluster per region, please only add servers to log clusters instead of creating duplicates Find all log clusters and their regions: ah-server list % -w type=log -c log_cluster_id ec2_region For example: $ ah-server list % -w type=log -c log_cluster_id ec2_region log-9284, 1, us-east-1 log-9285, 1, us-east-1 log-9286, 1, us-east-1 log-10014, 2, ap-southeast-1 log-10015, 2, ap-southeast-1 log-10016, 2, ap-southeast-1 log-10089, 3, ap-southeast-2 log-10090, 3, ap-southeast-2 log-10091, 3, ap-southeast-2 log-10100, 4, us-west-2 <output omitted> Set some variables: REGION= AZS=() # e.g. AZS=(us-east-1a us-east-1b us-east-1c) VPC_ID= # Logclusters should be provisioned in the shared VPC for the region. # ah-vpc list % -c id | grep ${REGION} Create the log servers. LOGS=($(for AZ in ${AZS[@]}; do ah-server \\ allocate log \\ --region ${REGION} \\ --avail-zone ${AZ} \\ --ami-type m5.large \\ -v ${VPC_ID} done)) Once this is complete, launch the hosts: ah-server launch ${LOGS[@]}","title":"Provision Log Servers"},{"location":"kanban_tickets/provision_log_server/#manage-a-new-cluster","text":"Once the new hosts are launched, use ah-log to allocate the logical cluster (which will also launch the ELB for it as well): ah-log cluster allocate ${REGION} ${LOGS[@]} Once the log cluster has been allocated successfully, take note of the id field in the task output from the above command. This will be your '''log_cluster_id''' Here's an example of the output you should see: $ ah-log cluster allocate us-west-2 log-10100 log-10101 log-10102 [2014-08-22 16:09:00] AWS: describe_regions() -> OK (200 9739eb3d-060d-4112... [2014-08-22 16:09:00] Task 18539024 submitted. Waiting for completion. [2014-08-22 16:09:00] State change submitted -> waiting. [2014-08-22 16:09:05] State change waiting -> started. [2014-08-22 16:10:45] State change started -> done. [2014-08-22 16:10:45] Task 18539024 completed successfully. dns_name: ec2_region: us-west-2 elb_name: id: 4 log_servers: (SNIP) You can also view this information through with ah-log cluster list $ ah-log cluster list 1: log-9284, log-9285, log-9286, log-10880 2: log-10014, log-10015, log-10016 3: log-10089, log-10090, log-10091 4: log-10100, log-10101, log-10102 5: log-10111, log-10112, log-10113 8: log-10436, log-10437, log-10438","title":"Manage A New Cluster"},{"location":"kanban_tickets/provision_log_server/#manage-an-existing-cluster","text":"To add/remove clients to/from log clusters all servers must be status=0 . The options and use of the ah-log tool are too extensive for this procedure, so please view the output of ah-log help cluster . The command's help output is detailed enough to help you perform the following actions: Get cluster info List clusters List members of a cluster Allocate a cluster Deallocate a cluster Add servers to a cluster Remove servers from a cluster","title":"Manage An Existing Cluster"},{"location":"kanban_tickets/provision_log_server/#manage-clients","text":"Now that the cluster is allocated, add your host(s) to the cluster one at a time. The following command only takes a single host as an argument . WARNING : You will need to throttle this command if you are adding more than 20 servers at a time, as each invocation will issue a callback task and may cause a task-flood. ah-log server add ${LOG_CLUSTER_ID} ${HOST} Now verify that all instances on the log cluster elb are reporting healthy by logging into the AWS console or using the awscli.","title":"Manage Clients"},{"location":"kanban_tickets/provision_multi_region/","text":"Multi-Region Provisioning There are two styles of multi regional configurations, multi-tier-mr and full-tier-mr. While a majority of the steps are identical there are some details that must be accounted for. It would be prudent to prepare your commands in a text file prior to starting the provision to make sure that you have all of the required information. NOTE: We do not support multiple sites on same MR stack. This document should be followed to deploy one site per MR stack. Preparation We are going to set up some variables for the full provision. The standard for any multi-region provision should have 'mr' added to the sitegroup (ex, myawesomesitegroupmr), if the requested sitegroup already has mr at the end we do not need to add it again. In the event this is a customers second multi-region site we can append mr# to the end(ex, myawesomesitegroupmr2). If the customer is adding a multi-region stage to an existing sitegroup make sure to specify it with only alphanumeric characters (E.g. 'ibmcom.ltprod' should be 'ibmcomltprod'). SITENAME= Since this is multi-region we have an active and a passive region which also means we have active and passive VPCs. In the event a dedicated set of VPCs was not requested we will use the default VPCs for each region we are going to use. VPC variables should be the VPC_NAME of the VPCs and also get their ID's in the appropriate variables. REGION1= REGION1_AZ1= REGION1_AZ2= VPC_ACTIVE= VPC_ACTIVE_ID=$(ah-vpc list ${VPC_ACTIVE} -c id --no-name) REGION2= REGION2_AZ1= REGION2_AZ2= VPC_PASSIVE= VPC_PASSIVE_ID=$(ah-vpc list ${VPC_PASSIVE} -c id --no-name) Common variables that we require, please keep in mind that WEB_COUNT is the number of webs per region. BAL_AMI_TYPE= WEB_COUNT= WEB_AMI_TYPE= DB_STORAGE_SIZE= FS_STORAGE_SIZE= SVN=$(site-taglistactive svn ${REGION1} ${VPC_ACTIVE}) If you are not able to find the SVN in the shared/dedicated( VPC_ACTIVE ) VPC then you must try for ec2_classic VPC. SVN=$(site-taglistactive svn ${REGION1} ec2_classic) Configuration based Variables, for multi-tier-mr configurations we only require FSDBMESH_AMI_TYPE FSDBMESH_AMI_TYPE= However, for full-tier-mr configurations we must use both FS_AMI_TYPE and DBMESH_AMI_TYPE FS_AMI_TYPE= DBMESH_AMI_TYPE= Provision the Balancers Allocate the bals for both regions and define BALS as a CSV of all balancers. ah-provision stack bal -i ${BAL_AMI_TYPE} -r ${REGION1} -z \\ ${REGION1_AZ1} ${REGION1_AZ2} -V ${VPC_ACTIVE} ah-provision stack bal -i ${BAL_AMI_TYPE} -r ${REGION2} -z \\ ${REGION2_AZ1} ${REGION2_AZ2} -V ${VPC_PASSIVE} BALS= Provision a Multi-Tier-MR Cluster For multi-tier-mr clusters we can use ah-provision, this is the default requirements but in the event we need to customize it further, volume types for example, we can check our available opsions with 'ah-provision stack help web-fsdbmesh' ah-provision stack web-fsdbmesh -c ${WEB_COUNT} -w ${WEB_AMI_TYPE} -f ${FSDBMESH_AMI_TYPE} \\ -g ${FS_STORAGE_SIZE} -d ${DB_STORAGE_SIZE} -n $(date +%s) --gt gp3 \\ -r ${REGION1} ${REGION2} -z ${REGION1_AZ1} ${REGION1_AZ2} ${REGION2_AZ1} ${REGION2_AZ2} \\ -V ${VPC_ACTIVE} ${VPC_PASSIVE} Once the servers are allocated define WEBS and MESH as CSVs of all webs and fsdbmesh servers. Set MESH1 as the primary fsdbmesh server in REGION1 and MESH2 as primary fsdbmesh server in REGION2 . WEBS= MESH= MESH1= MESH2= Provision a Full-Tier-MR Cluster TODO: Refactor once AUTO-1094 is actioned so that we have an ah-provision stack command for web-dbmesh-fs For full-tier-mr cluster we must manually provision our hardware cluster, we will start with the dbmesh servers ah-server allocate dbmesh -r ${REGION1} -z ${REGION1_AZ1} \\ -t ${DBMESH_AMI_TYPE} -v ${VPC_ACTIVE_ID} -p ${DB_STORAGE_SIZE} --pt gp3 --pe \\ -s 1 --st gp3 --se ah-server allocate dbmesh -r ${REGION1} -z ${REGION1_AZ2} \\ -t ${DBMESH_AMI_TYPE} -v ${VPC_ACTIVE_ID} -p ${DB_STORAGE_SIZE} --pt gp3 --pe \\ -s 1 --st gp3 --se ah-server allocate dbmesh -r ${REGION2} -z ${REGION2_AZ1} \\ -t ${DBMESH_AMI_TYPE} -v ${VPC_PASSIVE_ID} -p ${DB_STORAGE_SIZE} --pt gp3 --pe \\ -s 1 --st gp3 --se ah-server allocate dbmesh -r ${REGION2} -z ${REGION2_AZ2} \\ -t ${DBMESH_AMI_TYPE} -v ${VPC_PASSIVE_ID} -p ${DB_STORAGE_SIZE} --pt gp3 --pe \\ -s 1 --st gp3 --se Once the servers are allocated define MESH as CSVs of all dbmesh servers. Set MESH1 as the primary dbmesh server in REGION1 and MESH2 as primary dbmesh server in REGION2 . MESH= MESH1= MESH2= Allocate db-cluster-id once the dbmesh servers are provisioned: DB_CLUSTER_ID=$(./fields-provision.php --db-cluster-allocate ${MESH}) Next we will provision our 4 fs servers in their respective regions one set at a time to reduce confusion ah-server allocate fs -r ${REGION1} -z ${REGION1_AZ1} \\ -t ${FS_AMI_TYPE} -v ${VPC_ACTIVE_ID} -p 1 --pt gp3 --pe \\ -s ${FS_STORAGE_SIZE} --st gp3 --se ah-server allocate fs -r ${REGION1} -z ${REGION1_AZ2} \\ -t ${FS_AMI_TYPE} -v ${VPC_ACTIVE_ID} -p 1 --pt gp3 --pe \\ -s ${FS_STORAGE_SIZE} --st gp3 --se ah-server allocate fs -r ${REGION2} -z ${REGION2_AZ1} \\ -t ${FS_AMI_TYPE} -v ${VPC_PASSIVE_ID} -p 1 --pt gp3 --pe \\ -s ${FS_STORAGE_SIZE} --st gp3 --se ah-server allocate fs -r ${REGION2} -z ${REGION2_AZ2} \\ -t ${FS_AMI_TYPE} -v ${VPC_PASSIVE_ID} -p 1 --pt gp3 --pe \\ -s ${FS_STORAGE_SIZE} --st gp3 --se We will now create our fs clusters by region and set our regional fs_cluster_id variables REGION1_FS= REGION2_FS= ./fields-provision.php --fs-cluster-allocate ${SITENAME}-${REGION1}:${REGION1_FS} ./fields-provision.php --fs-cluster-allocate ${SITENAME}-${REGION2}:${REGION2_FS} REGION1_FS_CLUSTER_ID=$(ah-server list ${REGION1_FS} -c fs_cluster_id --no-name) REGION2_FS_CLUSTER_ID=$(ah-server list ${REGION2_FS} -c fs_cluster_id --no-name) Due to a bug in ah-server allocate , bricks aren't added to the fs cluster by default for fs servers and that needs to be done manually. Run the following command for each of the FS servers allocated above: FS_SERVER= ah-server add-brick --server=${FS_SERVER} --set-encrypted --size=${FS_STORAGE_SIZE} --ebs-volume-type=gp3 Next we will create our webs for the ACTIVE region, alternate availability zones until the desired number of webs is reached. If the cluster is expecting to have dedicated crons please add an additional web to account for this. ah-server allocate web -r ${REGION1} -z ${REGION1_AZ1} -t ${WEB_AMI_TYPE} \\ -v ${VPC_ACTIVE_ID} --fs-cluster-id ${REGION1_FS_CLUSTER_ID} ah-server allocate web -r ${REGION1} -z ${REGION1_AZ2} -t ${WEB_AMI_TYPE} \\ -v ${VPC_ACTIVE_ID} --fs-cluster-id ${REGION1_FS_CLUSTER_ID} Now we will create our webs for the PASSIVE region, alternate availability zones until the desired number of webs is reached. If the cluster is expecting to have dedicated crons please add an additional web to account for this. ah-server allocate web -r ${REGION2} -z ${REGION2_AZ1} -t ${WEB_AMI_TYPE} \\ -v ${VPC_PASSIVE_ID} --fs-cluster-id ${REGION2_FS_CLUSTER_ID} ah-server allocate web -r ${REGION2} -z ${REGION2_AZ2} -t ${WEB_AMI_TYPE} \\ -v ${VPC_PASSIVE_D} --fs-cluster-id ${REGION2_FS_CLUSTER_ID} Once the servers are allocated define WEBS as CSVs of all webs WEBS= Create the site Even though there are two configurations we can use the same site creation command ./fields-provision.php --create-site ${SITENAME} --vcs ${SVN} \\ --bals ${BALS} --db ${MESH1} --webs ${WEBS} --multi-region \\ --active-region ${REGION1} In case of provisioning additional environment for existing sitegroup (for example loadtest environment), use the below command: STAGE= SITEGROUP= ./fields-provision.php --create-site ${SITENAME} --stage ${STAGE} \\ --sitegroup ${SITEGROUP} --vcs ${SVN} --bals ${BALS} --db ${MESH1} \\ --webs ${WEBS} --multi-region --active-region ${REGION1} Customize and tune the Cluster At this point we can customize the cluster, this includes adding dedicated memcache . For memcache duplicate the above web allocation in each region so that the memcache servers are the highest numbered webs. Tune the webs accordingly, if the cluster will have dedicated memcache servers please adjust the settings as necessary. Default with no dedicated memcache would be '64' MEMCACHE= # Memcache Value MEMCACHE_WEBS= # web-xxx,web-yyy ah-server edit ${MEMCACHE_WEBS} -c memcached.conf:-m=${MEMCACHE} apache2.conf:PoolSize=60 Launch the cluster Launch the servers for WEB-FSDBMESH sv-taskrelaunch server ${BALS},${MESH},${WEBS} Launch the servers for WEB-DBMESH-FS sv-taskrelaunch server ${BALS},${MESH},${WEBS},${REGION1_FS},${REGION2_FS} Install Tungsten Send the Tungsten setup task ah-task submit tungsten-setup --body \"{\\\"server\\\": \\\"${MESH1}\\\"}\" Verify DB connectivity fpdsh -l ${MESH} -c 'sudo fields-config-db.php' Check the db cluster status using ah-db-cluster status ${MESH1} . If the secondary region DB is pointing to active DB in primary region, update this using the following command: dns-update ${DB_CLUSTER_ID} ${MESH2} Setup File Replication NOTE: If you are provisioning another environment, besides prod (such as load test), be careful that you do not overwrite the prod key or ah-mrrsync will break. On the first web (lowest numbered web in that region) in each region, execute the following to create a valid ssh directory structure for rsync file replication: WEB1=$(ah-server list site:${SITENAME} -w ec2_region=${REGION1} type=web status=0 | head -1) WEB2=$(ah-server list site:${SITENAME} -w ec2_region=${REGION2} type=web status=0 | head -1) fpdsh -l ${WEB1},${WEB2} -c \\ \"sudo su -c 'mkdir -p /mnt/gfs/${SITENAME}/.ssh && chmod 750 /mnt/gfs/${SITENAME}/.ssh' ${SITENAME}\" Create an rsync ssh key on the first web in the active region as the site user: fssh ${WEB1} \"sudo su -c 'ssh-keygen -b 4096 -f /mnt/gfs/${SITENAME}/.ssh/rsync' ${SITENAME}\" Copy the pub key from the web to the bastion you are working from: PUB_KEY=\"$(fssh ${WEB1} sudo cat /mnt/gfs/${SITENAME}/.ssh/rsync.pub)\" echo \"${PUB_KEY}\" > ${OPSTMP}/${SITENAME}-rsync.pub Append the pub key to the site using fields-provision.php : SITEGROUP=$(ah-site list ${SITENAME} --no-name -c sitegroup) ./fields-provision.php --user-setpubkey ${SITEGROUP}:${SITENAME}:${OPSTMP}/${SITENAME}-rsync.pub Install the cron job: ENV_UUID=$(ah-site list ${SITENAME} -c uuid --no-name) UUID=$(ruby -e \"require 'securerandom' ; puts SecureRandom.uuid\") ah-site cron2 add --command=\"/usr/local/sbin/ah-mrrsync ${SITENAME}\" \\ --day-month=\"*\" --day-week=\"*\" --env-uuid=${ENV_UUID} --hour=\"*\" --minute=\"*/30\" --month=\"*\" --name= --uuid=${UUID} --server_name=${WEB1} Verify the cron works: fssh ${WEB1} \"sudo su -c '/usr/local/sbin/ah-mrrsync ${SITENAME}' ${SITENAME}\" Add the site to monitoring Ensure that the site is responding correctly: site-check ${SITENAME} site-checkwebs ${SITENAME} Add the site to monitoring: site-mon add ${SITENAME} Verification Make sure all alerts have cleared in Nagios/PagerDuty. Run esl ${SITENAME} and verify the stack provisioned matches the dealsheet.","title":"Multi-Region Provisioning"},{"location":"kanban_tickets/provision_multi_region/#multi-region-provisioning","text":"There are two styles of multi regional configurations, multi-tier-mr and full-tier-mr. While a majority of the steps are identical there are some details that must be accounted for. It would be prudent to prepare your commands in a text file prior to starting the provision to make sure that you have all of the required information. NOTE: We do not support multiple sites on same MR stack. This document should be followed to deploy one site per MR stack.","title":"Multi-Region Provisioning"},{"location":"kanban_tickets/provision_multi_region/#preparation","text":"We are going to set up some variables for the full provision. The standard for any multi-region provision should have 'mr' added to the sitegroup (ex, myawesomesitegroupmr), if the requested sitegroup already has mr at the end we do not need to add it again. In the event this is a customers second multi-region site we can append mr# to the end(ex, myawesomesitegroupmr2). If the customer is adding a multi-region stage to an existing sitegroup make sure to specify it with only alphanumeric characters (E.g. 'ibmcom.ltprod' should be 'ibmcomltprod'). SITENAME= Since this is multi-region we have an active and a passive region which also means we have active and passive VPCs. In the event a dedicated set of VPCs was not requested we will use the default VPCs for each region we are going to use. VPC variables should be the VPC_NAME of the VPCs and also get their ID's in the appropriate variables. REGION1= REGION1_AZ1= REGION1_AZ2= VPC_ACTIVE= VPC_ACTIVE_ID=$(ah-vpc list ${VPC_ACTIVE} -c id --no-name) REGION2= REGION2_AZ1= REGION2_AZ2= VPC_PASSIVE= VPC_PASSIVE_ID=$(ah-vpc list ${VPC_PASSIVE} -c id --no-name) Common variables that we require, please keep in mind that WEB_COUNT is the number of webs per region. BAL_AMI_TYPE= WEB_COUNT= WEB_AMI_TYPE= DB_STORAGE_SIZE= FS_STORAGE_SIZE= SVN=$(site-taglistactive svn ${REGION1} ${VPC_ACTIVE}) If you are not able to find the SVN in the shared/dedicated( VPC_ACTIVE ) VPC then you must try for ec2_classic VPC. SVN=$(site-taglistactive svn ${REGION1} ec2_classic) Configuration based Variables, for multi-tier-mr configurations we only require FSDBMESH_AMI_TYPE FSDBMESH_AMI_TYPE= However, for full-tier-mr configurations we must use both FS_AMI_TYPE and DBMESH_AMI_TYPE FS_AMI_TYPE= DBMESH_AMI_TYPE=","title":"Preparation"},{"location":"kanban_tickets/provision_multi_region/#provision-the-balancers","text":"Allocate the bals for both regions and define BALS as a CSV of all balancers. ah-provision stack bal -i ${BAL_AMI_TYPE} -r ${REGION1} -z \\ ${REGION1_AZ1} ${REGION1_AZ2} -V ${VPC_ACTIVE} ah-provision stack bal -i ${BAL_AMI_TYPE} -r ${REGION2} -z \\ ${REGION2_AZ1} ${REGION2_AZ2} -V ${VPC_PASSIVE} BALS=","title":"Provision the Balancers"},{"location":"kanban_tickets/provision_multi_region/#provision-a-multi-tier-mr-cluster","text":"For multi-tier-mr clusters we can use ah-provision, this is the default requirements but in the event we need to customize it further, volume types for example, we can check our available opsions with 'ah-provision stack help web-fsdbmesh' ah-provision stack web-fsdbmesh -c ${WEB_COUNT} -w ${WEB_AMI_TYPE} -f ${FSDBMESH_AMI_TYPE} \\ -g ${FS_STORAGE_SIZE} -d ${DB_STORAGE_SIZE} -n $(date +%s) --gt gp3 \\ -r ${REGION1} ${REGION2} -z ${REGION1_AZ1} ${REGION1_AZ2} ${REGION2_AZ1} ${REGION2_AZ2} \\ -V ${VPC_ACTIVE} ${VPC_PASSIVE} Once the servers are allocated define WEBS and MESH as CSVs of all webs and fsdbmesh servers. Set MESH1 as the primary fsdbmesh server in REGION1 and MESH2 as primary fsdbmesh server in REGION2 . WEBS= MESH= MESH1= MESH2=","title":"Provision a Multi-Tier-MR Cluster"},{"location":"kanban_tickets/provision_multi_region/#provision-a-full-tier-mr-cluster","text":"TODO: Refactor once AUTO-1094 is actioned so that we have an ah-provision stack command for web-dbmesh-fs For full-tier-mr cluster we must manually provision our hardware cluster, we will start with the dbmesh servers ah-server allocate dbmesh -r ${REGION1} -z ${REGION1_AZ1} \\ -t ${DBMESH_AMI_TYPE} -v ${VPC_ACTIVE_ID} -p ${DB_STORAGE_SIZE} --pt gp3 --pe \\ -s 1 --st gp3 --se ah-server allocate dbmesh -r ${REGION1} -z ${REGION1_AZ2} \\ -t ${DBMESH_AMI_TYPE} -v ${VPC_ACTIVE_ID} -p ${DB_STORAGE_SIZE} --pt gp3 --pe \\ -s 1 --st gp3 --se ah-server allocate dbmesh -r ${REGION2} -z ${REGION2_AZ1} \\ -t ${DBMESH_AMI_TYPE} -v ${VPC_PASSIVE_ID} -p ${DB_STORAGE_SIZE} --pt gp3 --pe \\ -s 1 --st gp3 --se ah-server allocate dbmesh -r ${REGION2} -z ${REGION2_AZ2} \\ -t ${DBMESH_AMI_TYPE} -v ${VPC_PASSIVE_ID} -p ${DB_STORAGE_SIZE} --pt gp3 --pe \\ -s 1 --st gp3 --se Once the servers are allocated define MESH as CSVs of all dbmesh servers. Set MESH1 as the primary dbmesh server in REGION1 and MESH2 as primary dbmesh server in REGION2 . MESH= MESH1= MESH2= Allocate db-cluster-id once the dbmesh servers are provisioned: DB_CLUSTER_ID=$(./fields-provision.php --db-cluster-allocate ${MESH}) Next we will provision our 4 fs servers in their respective regions one set at a time to reduce confusion ah-server allocate fs -r ${REGION1} -z ${REGION1_AZ1} \\ -t ${FS_AMI_TYPE} -v ${VPC_ACTIVE_ID} -p 1 --pt gp3 --pe \\ -s ${FS_STORAGE_SIZE} --st gp3 --se ah-server allocate fs -r ${REGION1} -z ${REGION1_AZ2} \\ -t ${FS_AMI_TYPE} -v ${VPC_ACTIVE_ID} -p 1 --pt gp3 --pe \\ -s ${FS_STORAGE_SIZE} --st gp3 --se ah-server allocate fs -r ${REGION2} -z ${REGION2_AZ1} \\ -t ${FS_AMI_TYPE} -v ${VPC_PASSIVE_ID} -p 1 --pt gp3 --pe \\ -s ${FS_STORAGE_SIZE} --st gp3 --se ah-server allocate fs -r ${REGION2} -z ${REGION2_AZ2} \\ -t ${FS_AMI_TYPE} -v ${VPC_PASSIVE_ID} -p 1 --pt gp3 --pe \\ -s ${FS_STORAGE_SIZE} --st gp3 --se We will now create our fs clusters by region and set our regional fs_cluster_id variables REGION1_FS= REGION2_FS= ./fields-provision.php --fs-cluster-allocate ${SITENAME}-${REGION1}:${REGION1_FS} ./fields-provision.php --fs-cluster-allocate ${SITENAME}-${REGION2}:${REGION2_FS} REGION1_FS_CLUSTER_ID=$(ah-server list ${REGION1_FS} -c fs_cluster_id --no-name) REGION2_FS_CLUSTER_ID=$(ah-server list ${REGION2_FS} -c fs_cluster_id --no-name) Due to a bug in ah-server allocate , bricks aren't added to the fs cluster by default for fs servers and that needs to be done manually. Run the following command for each of the FS servers allocated above: FS_SERVER= ah-server add-brick --server=${FS_SERVER} --set-encrypted --size=${FS_STORAGE_SIZE} --ebs-volume-type=gp3 Next we will create our webs for the ACTIVE region, alternate availability zones until the desired number of webs is reached. If the cluster is expecting to have dedicated crons please add an additional web to account for this. ah-server allocate web -r ${REGION1} -z ${REGION1_AZ1} -t ${WEB_AMI_TYPE} \\ -v ${VPC_ACTIVE_ID} --fs-cluster-id ${REGION1_FS_CLUSTER_ID} ah-server allocate web -r ${REGION1} -z ${REGION1_AZ2} -t ${WEB_AMI_TYPE} \\ -v ${VPC_ACTIVE_ID} --fs-cluster-id ${REGION1_FS_CLUSTER_ID} Now we will create our webs for the PASSIVE region, alternate availability zones until the desired number of webs is reached. If the cluster is expecting to have dedicated crons please add an additional web to account for this. ah-server allocate web -r ${REGION2} -z ${REGION2_AZ1} -t ${WEB_AMI_TYPE} \\ -v ${VPC_PASSIVE_ID} --fs-cluster-id ${REGION2_FS_CLUSTER_ID} ah-server allocate web -r ${REGION2} -z ${REGION2_AZ2} -t ${WEB_AMI_TYPE} \\ -v ${VPC_PASSIVE_D} --fs-cluster-id ${REGION2_FS_CLUSTER_ID} Once the servers are allocated define WEBS as CSVs of all webs WEBS=","title":"Provision a Full-Tier-MR Cluster"},{"location":"kanban_tickets/provision_multi_region/#create-the-site","text":"Even though there are two configurations we can use the same site creation command ./fields-provision.php --create-site ${SITENAME} --vcs ${SVN} \\ --bals ${BALS} --db ${MESH1} --webs ${WEBS} --multi-region \\ --active-region ${REGION1} In case of provisioning additional environment for existing sitegroup (for example loadtest environment), use the below command: STAGE= SITEGROUP= ./fields-provision.php --create-site ${SITENAME} --stage ${STAGE} \\ --sitegroup ${SITEGROUP} --vcs ${SVN} --bals ${BALS} --db ${MESH1} \\ --webs ${WEBS} --multi-region --active-region ${REGION1}","title":"Create the site"},{"location":"kanban_tickets/provision_multi_region/#customize-and-tune-the-cluster","text":"At this point we can customize the cluster, this includes adding dedicated memcache . For memcache duplicate the above web allocation in each region so that the memcache servers are the highest numbered webs. Tune the webs accordingly, if the cluster will have dedicated memcache servers please adjust the settings as necessary. Default with no dedicated memcache would be '64' MEMCACHE= # Memcache Value MEMCACHE_WEBS= # web-xxx,web-yyy ah-server edit ${MEMCACHE_WEBS} -c memcached.conf:-m=${MEMCACHE} apache2.conf:PoolSize=60","title":"Customize and tune the Cluster"},{"location":"kanban_tickets/provision_multi_region/#launch-the-cluster","text":"Launch the servers for WEB-FSDBMESH sv-taskrelaunch server ${BALS},${MESH},${WEBS} Launch the servers for WEB-DBMESH-FS sv-taskrelaunch server ${BALS},${MESH},${WEBS},${REGION1_FS},${REGION2_FS}","title":"Launch the cluster"},{"location":"kanban_tickets/provision_multi_region/#install-tungsten","text":"Send the Tungsten setup task ah-task submit tungsten-setup --body \"{\\\"server\\\": \\\"${MESH1}\\\"}\" Verify DB connectivity fpdsh -l ${MESH} -c 'sudo fields-config-db.php' Check the db cluster status using ah-db-cluster status ${MESH1} . If the secondary region DB is pointing to active DB in primary region, update this using the following command: dns-update ${DB_CLUSTER_ID} ${MESH2}","title":"Install Tungsten"},{"location":"kanban_tickets/provision_multi_region/#setup-file-replication","text":"NOTE: If you are provisioning another environment, besides prod (such as load test), be careful that you do not overwrite the prod key or ah-mrrsync will break. On the first web (lowest numbered web in that region) in each region, execute the following to create a valid ssh directory structure for rsync file replication: WEB1=$(ah-server list site:${SITENAME} -w ec2_region=${REGION1} type=web status=0 | head -1) WEB2=$(ah-server list site:${SITENAME} -w ec2_region=${REGION2} type=web status=0 | head -1) fpdsh -l ${WEB1},${WEB2} -c \\ \"sudo su -c 'mkdir -p /mnt/gfs/${SITENAME}/.ssh && chmod 750 /mnt/gfs/${SITENAME}/.ssh' ${SITENAME}\" Create an rsync ssh key on the first web in the active region as the site user: fssh ${WEB1} \"sudo su -c 'ssh-keygen -b 4096 -f /mnt/gfs/${SITENAME}/.ssh/rsync' ${SITENAME}\" Copy the pub key from the web to the bastion you are working from: PUB_KEY=\"$(fssh ${WEB1} sudo cat /mnt/gfs/${SITENAME}/.ssh/rsync.pub)\" echo \"${PUB_KEY}\" > ${OPSTMP}/${SITENAME}-rsync.pub Append the pub key to the site using fields-provision.php : SITEGROUP=$(ah-site list ${SITENAME} --no-name -c sitegroup) ./fields-provision.php --user-setpubkey ${SITEGROUP}:${SITENAME}:${OPSTMP}/${SITENAME}-rsync.pub Install the cron job: ENV_UUID=$(ah-site list ${SITENAME} -c uuid --no-name) UUID=$(ruby -e \"require 'securerandom' ; puts SecureRandom.uuid\") ah-site cron2 add --command=\"/usr/local/sbin/ah-mrrsync ${SITENAME}\" \\ --day-month=\"*\" --day-week=\"*\" --env-uuid=${ENV_UUID} --hour=\"*\" --minute=\"*/30\" --month=\"*\" --name= --uuid=${UUID} --server_name=${WEB1} Verify the cron works: fssh ${WEB1} \"sudo su -c '/usr/local/sbin/ah-mrrsync ${SITENAME}' ${SITENAME}\"","title":"Setup File Replication"},{"location":"kanban_tickets/provision_multi_region/#add-the-site-to-monitoring","text":"Ensure that the site is responding correctly: site-check ${SITENAME} site-checkwebs ${SITENAME} Add the site to monitoring: site-mon add ${SITENAME}","title":"Add the site to monitoring"},{"location":"kanban_tickets/provision_multi_region/#verification","text":"Make sure all alerts have cleared in Nagios/PagerDuty. Run esl ${SITENAME} and verify the stack provisioned matches the dealsheet.","title":"Verification"},{"location":"kanban_tickets/provision_search_colony/","text":"Provisioning a Search Colony Note: To login Search jumpboxes, follow these instructions Provisioning a search colony consists of: Allocating and launching load balancers Creating a site to hold the configuration of these balancers Initialising the configuration of the site Creating an ELB and installing a shared certificate Creating a CNAME record in AWS Route53 Adding the completed colony to the Governor All Search is provisioned in the search-service realm. Allocate and launch load balancers Load balancers are type nxephem . They do not get an EIP and are not clustered since they are behind an ELB. Refer to the Search Tiers page on Confluence to determine the balancer instance type and count. If no tier is specified in the ticket, assume tier one. Make sure to set the bash to error out if any unset variable is used before proceeding with actual provisioning: set -u Set some variables. REGION , AZ1 , and AZ2 are all the full names. REGION= AZ1= AZ2= BAL_SIZE= Allocate the servers. BAL1=$(./fields-provision.php --server-allocate nxephem \\ --instance-type $BAL_SIZE --region $REGION --availability-zone $AZ1) BAL2=$(./fields-provision.php --server-allocate nxephem \\ --instance-type $BAL_SIZE --region $REGION --availability-zone $AZ2) Currently the default OS is still Precise in legacy search, but the nxephems have been updated to Trusty, so before launching the servers, you will need to change the OS type. ah-server edit ${BAL1},${BAL2} -s os=trusty Launch them. ah-server launch ${BAL1},${BAL2} Create the site Set these variables if not still set from above. REGION= BAL1= BAL2= Ensure you have the following entry in your netrc file for the realm. Here, \"dummy\" is literal, not a placeholder. machine acquia.support.svn.production login dummy password dummy Determine the sitegroup name. This will be the region identifier followed by \"bal\". The region identifier is the region with dashes removed and is sometimes shortened. Unless this is a new region, the sitegroup should already exist. Examples: useast1bal euwest1bal apseast1bal uswest1bal uswest2bal apsoutheast2bal ah-sitegroup list %bal SITEGROUP= Determine the stage name. This is the letter \"c\" followed by a number incremented for each colony provisioned, regardless of region. Find the highest colony number and increment it. Examples: c1 c50 c666 STAGE=c$(($(ah-site list %balc%+ -c stage --no-name | grep -v 'extract' | \\ sort -n -k 1.2 | tail -n1 | cut -d'c' -f2) + 1)) Due to AS-5939 , we need to validate if stage name conflicts with git commit hash convention. This is mainly affecting uswest2bal but it would be great to validate for other sitegroups too to avoid re-doing all the steps. Follow these steps to validate the stage name isn't conflicting with git commit hash: SEARCHGIT=svn-3.search-service.hosting.acquia.com git clone $SITEGROUP@$SEARCHGIT:$SITEGROUP.git cd $SITEGROUP git rev-parse --verify $STAGE NOTE If you have already cloned the repo for the concerned sitegroup during earlier provisionings - make sure to checkout master branch and run git pull to keep the local copy updated. We should get the following error if there is no conflict between the Stage number and git commit hash: fatal: Needed a single revision If we get the output like below (with c107 as stage example), then we will need to proceed to the next number available: [cloudservicesdev|search-service:search-service] ~/uswest2bal$ git rev-parse --verify c107 c10772b5d793942d37cb4eb8b2ebc32f3849d45f Otherwise, we will need to increase the number in STAGE until we get the above output. Also, make sure to update the STAGE variable as given below: STAGE=c$(($(echo $STAGE | cut -d'c' -f2) + 1)) This would no longer be needed once AS-5939 is completed. Create the site. Note the balancers are set as both balancers and webs. There is only one VCS server in Search. ./fields-provision.php --create-site ${SITEGROUP}${STAGE} \\ --sitegroup $SITEGROUP --stage $STAGE \\ --app-type nxweb --bals $BAL1,$BAL2 --webs $BAL1,$BAL2 \\ --vcs-type git --vcs svn-3 Configure the site Set these variables if not still set from above. SITEGROUP= STAGE= Change the site to use this non-public vhost port. ah-site edit ${SITEGROUP}${STAGE} -c vhost:port=30209 Choose a method to get yourself access to the sitegroup repository. You only need to do this once per region. Local method : Generally simpler. You add your local SSH public key to the sitegroup and perform Git operations on your local computer. Bastion method : Useful if you have problems with the local method. You add your public key from the bastion to the sitegroup and work from the bastion. Local method: Copy your local SSH public key to the bastion and add it to the sitegroup. PUBKEY= ./fields-provision --user-setpubkey $SITEGROUP:$LOGNAME:$PUBKEY On your local computer, clone the repository. SITEGROUP= STAGE= SEARCHGIT=svn-3.search-service.hosting.acquia.com git clone $SITEGROUP@$SEARCHGIT:$SITEGROUP.git Bastion method: Generate a public key if you do not already have one. cd ~/.ssh ssh-keygen -y -f id_rsa Add it to the sitegroup. ./fields-provision --user-setpubkey \\ $SITEGROUP:$LOGNAME:$HOME/.ssh/id_rsa.pub Add an entry for the VCS server to your SSH configuration ( ~/.ssh/config ) above the entry for other fields hosts so Git will use port 22. Replace LOGNAME with your username. Host search-git Hostname svn-3.search-service.hosting.acquia.com Port 22 IdentitiesOnly yes IdentityFile /home/LOGNAME/.ssh/id_rsa In your home directory on the bastion, clone the repository. git clone $SITEGROUP@search-git:$SITEGROUP.git Create and configure a branch for the colony. Within the Git checkout: git checkout -b $STAGE git rm -rf nginx git commit --allow-empty -m \"Add new colony $STAGE.\" mkdir nginx touch nginx/upstream.conf mkdir nginx/server.conf.d touch nginx/server.conf.d/test.conf git add nginx git commit -m \"Add empty nginx configuration for $STAGE.\" git push origin $STAGE Back on the bastion, set the site to use the branch you just created. ah-site edit ${SITEGROUP}${STAGE} -s vcs_path=$STAGE Create the ELB Set these variables if not still set from above. Region is the real name, not the shortened identifier. REGION= BAL1= BAL2= SITEGROUP= STAGE= Restart nginx on the balancers. fpdsh -l $BAL1,$BAL2 -c 'sudo service nginx restart' Generate a temporary certificate and key. openssl req -nodes -sha256 -newkey rsa:2048 -keyout temp.key \\ -out temp.csr -subj \"/CN=**TEMPORARY**\" openssl x509 -req -days 365 -in temp.csr -signkey temp.key \\ -out temp.pem Create an ELB using the temporary certificate created above. You must pass the certificate's path to both the --cert and --ca arguments. Do not attempt to create the ELB until after nginx has been restarted. Otherwise, the ELB health checks will fail. The script outputs a task ID; save it. CERT= KEY= ./tools/site-install-ssl --sitegroup $SITEGROUP --env $STAGE \\ --cert $CERT --key $KEY --ca $CERT TASK= Wait for the ELB to be created. ah-task wait-for-task $TASK View the task output and find the ELB ID and URL. The ID will looks like 'search-service-12345'. ah-task get $TASK ELB_ID=${FIELDS_STAGE}-$(ah-site list ${SITEGROUP}.${STAGE} -c id --no-name) ELB_URL=$(aws elb describe-load-balancers --region ${REGION} --load-balancer-names ${ELB_ID} \\ --query 'LoadBalancerDescriptions[].DNSName' --output text); echo $ELB_URL Get a list of *.acquia-search.com certificates and record the ARN of the one with the most recent date. ARNs start with \"arn\" and are in the second column of the output. aws iam list-server-certificates --output text \\ | grep star_acquia-search CERT_ARN= Set the ELB to use this certificate. aws elb set-load-balancer-listener-ssl-certificate \\ --region $REGION \\ --load-balancer-name $ELB_ID \\ --load-balancer-port 443 \\ --ssl-certificate-id $CERT_ARN Create the CNAME in AWS Route53 You will need to know the values of these variables from above: SITEGROUP , COLONY , and ELB_URL . Create the record entry name. Use the region identifier ( SITEGROUP minus \"bal\"), followed by a dash, then COLONY . Example: \"apseast1-c60\". RECORD_NAME= RECORD_NAME_DNS=\"${RECORD_NAME}.acquia-search.com\" Get credentials and token to elevate temporarily and be able to write DNS records: aws sts assume-role \\ --output json \\ --role-arn 'arn:aws:iam::345874614325:role/Search-R53-Access' \\ --role-session-name \"colony-creation-$(whoami)\" Populate the following variables from the output of the previous command: export AWS_ACCESS_KEY_ID= export AWS_SECRET_ACCESS_KEY= export AWS_SESSION_TOKEN= Find the id of the acquia-search.com zone, and populate the proper variable: AS_ZONE=$(aws route53 list-hosted-zones --output json | \\ jq '.HostedZones' | \\ jq '.[] | select(.Name == \"acquia-search.com.\")' | \\ jq '.Id' | \\ sed 's/\"//g') (Note: if AS_ZONE isn't being populated, just run the aws command to list zones above and find the id of the acquia-search.com zone to populate the variable manually) Prepare the record json: ELB_CNAME=\"{ \\\"Comment\\\": \\\"Ops runbook https://runbook.ops.acquia.com/master/search/provision_search_colony\\\", \\\"Changes\\\": [ { \\\"Action\\\": \\\"CREATE\\\", \\\"ResourceRecordSet\\\": { \\\"Name\\\": \\\"${RECORD_NAME_DNS}\\\", \\\"Type\\\": \\\"CNAME\\\", \\\"TTL\\\": 30, \\\"ResourceRecords\\\": [ { \\\"Value\\\": \\\"${ELB_URL}\\\" } ] } } ] }\" Print the zone and record and review that everything looks good: echo ${AS_ZONE} echo ${ELB_CNAME} | jq Create the record and capture the change id to query it: CHANGE_ID=$(aws route53 change-resource-record-sets \\ --output json \\ --hosted-zone-id ${AS_ZONE} \\ --change-batch \"${ELB_CNAME}\" | jq '.ChangeInfo.Id' | sed 's/\"//g') Lastly, check that the record was properly created (in INSYNC status, may take a couple of minutes): aws route53 get-change --id ${CHANGE_ID} Add the colony to the Governor You will need to know the values of these variables from above: REGION , SITEGROUP , COLONY , SEARCHGIT and ELB_URL . Log in to the Acquia Search Governor . Navigate to the Create Colony page, fill out the form as follows, and hit \"Save\". Title : The region identifier ( SITEGROUP minus \"bal\"), followed by a dash, then COLONY . Same as in the CNAME above. Example: \"apseast1-c60\" NOTE If it is dedicated search colony - make sure to mention the customer name after the colony. Example: \"useast1-c95(charter)\" Availability Zone : Actually just the REGION . Git repo : \" SITEGROUP @ SEARCHGIT : SITEGROUP .git\". Same as used to clone the repository above. Example: \"useast1bal@svn-3.search-service.hosting.acquia.com:useast1bal.git\". Or use the following command to get the exact URL (provide the variables are still stored in your terminal) echo \"${SITEGROUP}@${SEARCHGIT}:${SITEGROUP}.git\" Hosting Site Name : SITEGROUP followed by STAGE . Same as the site name above. Request Zones : Leave the default. ELB Url : CNAME Created on AWS Route53 . This field should point to the colony's URL rather than the physical ELB URL. For example, it should point to euwest1-c83.acquia-search.com rather than search-service-628-1791117540.eu-west-1.elb.amazonaws.com. Git branch : COLONY . Same branch committed to above. Hosting Location : \"hosting\". Should be the default. Balancer Servers : Leave empty. cloudapi_user and cloudapi_pass : Retrieve these values from the shared KeePassX archive.","title":"Provisioning a Search Colony"},{"location":"kanban_tickets/provision_search_colony/#provisioning-a-search-colony","text":"Note: To login Search jumpboxes, follow these instructions Provisioning a search colony consists of: Allocating and launching load balancers Creating a site to hold the configuration of these balancers Initialising the configuration of the site Creating an ELB and installing a shared certificate Creating a CNAME record in AWS Route53 Adding the completed colony to the Governor All Search is provisioned in the search-service realm.","title":"Provisioning a Search Colony"},{"location":"kanban_tickets/provision_search_colony/#allocate-and-launch-load-balancers","text":"Load balancers are type nxephem . They do not get an EIP and are not clustered since they are behind an ELB. Refer to the Search Tiers page on Confluence to determine the balancer instance type and count. If no tier is specified in the ticket, assume tier one. Make sure to set the bash to error out if any unset variable is used before proceeding with actual provisioning: set -u Set some variables. REGION , AZ1 , and AZ2 are all the full names. REGION= AZ1= AZ2= BAL_SIZE= Allocate the servers. BAL1=$(./fields-provision.php --server-allocate nxephem \\ --instance-type $BAL_SIZE --region $REGION --availability-zone $AZ1) BAL2=$(./fields-provision.php --server-allocate nxephem \\ --instance-type $BAL_SIZE --region $REGION --availability-zone $AZ2) Currently the default OS is still Precise in legacy search, but the nxephems have been updated to Trusty, so before launching the servers, you will need to change the OS type. ah-server edit ${BAL1},${BAL2} -s os=trusty Launch them. ah-server launch ${BAL1},${BAL2}","title":"Allocate and launch load balancers"},{"location":"kanban_tickets/provision_search_colony/#create-the-site","text":"Set these variables if not still set from above. REGION= BAL1= BAL2= Ensure you have the following entry in your netrc file for the realm. Here, \"dummy\" is literal, not a placeholder. machine acquia.support.svn.production login dummy password dummy Determine the sitegroup name. This will be the region identifier followed by \"bal\". The region identifier is the region with dashes removed and is sometimes shortened. Unless this is a new region, the sitegroup should already exist. Examples: useast1bal euwest1bal apseast1bal uswest1bal uswest2bal apsoutheast2bal ah-sitegroup list %bal SITEGROUP= Determine the stage name. This is the letter \"c\" followed by a number incremented for each colony provisioned, regardless of region. Find the highest colony number and increment it. Examples: c1 c50 c666 STAGE=c$(($(ah-site list %balc%+ -c stage --no-name | grep -v 'extract' | \\ sort -n -k 1.2 | tail -n1 | cut -d'c' -f2) + 1)) Due to AS-5939 , we need to validate if stage name conflicts with git commit hash convention. This is mainly affecting uswest2bal but it would be great to validate for other sitegroups too to avoid re-doing all the steps. Follow these steps to validate the stage name isn't conflicting with git commit hash: SEARCHGIT=svn-3.search-service.hosting.acquia.com git clone $SITEGROUP@$SEARCHGIT:$SITEGROUP.git cd $SITEGROUP git rev-parse --verify $STAGE NOTE If you have already cloned the repo for the concerned sitegroup during earlier provisionings - make sure to checkout master branch and run git pull to keep the local copy updated. We should get the following error if there is no conflict between the Stage number and git commit hash: fatal: Needed a single revision If we get the output like below (with c107 as stage example), then we will need to proceed to the next number available: [cloudservicesdev|search-service:search-service] ~/uswest2bal$ git rev-parse --verify c107 c10772b5d793942d37cb4eb8b2ebc32f3849d45f Otherwise, we will need to increase the number in STAGE until we get the above output. Also, make sure to update the STAGE variable as given below: STAGE=c$(($(echo $STAGE | cut -d'c' -f2) + 1)) This would no longer be needed once AS-5939 is completed. Create the site. Note the balancers are set as both balancers and webs. There is only one VCS server in Search. ./fields-provision.php --create-site ${SITEGROUP}${STAGE} \\ --sitegroup $SITEGROUP --stage $STAGE \\ --app-type nxweb --bals $BAL1,$BAL2 --webs $BAL1,$BAL2 \\ --vcs-type git --vcs svn-3","title":"Create the site"},{"location":"kanban_tickets/provision_search_colony/#configure-the-site","text":"Set these variables if not still set from above. SITEGROUP= STAGE= Change the site to use this non-public vhost port. ah-site edit ${SITEGROUP}${STAGE} -c vhost:port=30209 Choose a method to get yourself access to the sitegroup repository. You only need to do this once per region. Local method : Generally simpler. You add your local SSH public key to the sitegroup and perform Git operations on your local computer. Bastion method : Useful if you have problems with the local method. You add your public key from the bastion to the sitegroup and work from the bastion. Local method: Copy your local SSH public key to the bastion and add it to the sitegroup. PUBKEY= ./fields-provision --user-setpubkey $SITEGROUP:$LOGNAME:$PUBKEY On your local computer, clone the repository. SITEGROUP= STAGE= SEARCHGIT=svn-3.search-service.hosting.acquia.com git clone $SITEGROUP@$SEARCHGIT:$SITEGROUP.git Bastion method: Generate a public key if you do not already have one. cd ~/.ssh ssh-keygen -y -f id_rsa Add it to the sitegroup. ./fields-provision --user-setpubkey \\ $SITEGROUP:$LOGNAME:$HOME/.ssh/id_rsa.pub Add an entry for the VCS server to your SSH configuration ( ~/.ssh/config ) above the entry for other fields hosts so Git will use port 22. Replace LOGNAME with your username. Host search-git Hostname svn-3.search-service.hosting.acquia.com Port 22 IdentitiesOnly yes IdentityFile /home/LOGNAME/.ssh/id_rsa In your home directory on the bastion, clone the repository. git clone $SITEGROUP@search-git:$SITEGROUP.git Create and configure a branch for the colony. Within the Git checkout: git checkout -b $STAGE git rm -rf nginx git commit --allow-empty -m \"Add new colony $STAGE.\" mkdir nginx touch nginx/upstream.conf mkdir nginx/server.conf.d touch nginx/server.conf.d/test.conf git add nginx git commit -m \"Add empty nginx configuration for $STAGE.\" git push origin $STAGE Back on the bastion, set the site to use the branch you just created. ah-site edit ${SITEGROUP}${STAGE} -s vcs_path=$STAGE","title":"Configure the site"},{"location":"kanban_tickets/provision_search_colony/#create-the-elb","text":"Set these variables if not still set from above. Region is the real name, not the shortened identifier. REGION= BAL1= BAL2= SITEGROUP= STAGE= Restart nginx on the balancers. fpdsh -l $BAL1,$BAL2 -c 'sudo service nginx restart' Generate a temporary certificate and key. openssl req -nodes -sha256 -newkey rsa:2048 -keyout temp.key \\ -out temp.csr -subj \"/CN=**TEMPORARY**\" openssl x509 -req -days 365 -in temp.csr -signkey temp.key \\ -out temp.pem Create an ELB using the temporary certificate created above. You must pass the certificate's path to both the --cert and --ca arguments. Do not attempt to create the ELB until after nginx has been restarted. Otherwise, the ELB health checks will fail. The script outputs a task ID; save it. CERT= KEY= ./tools/site-install-ssl --sitegroup $SITEGROUP --env $STAGE \\ --cert $CERT --key $KEY --ca $CERT TASK= Wait for the ELB to be created. ah-task wait-for-task $TASK View the task output and find the ELB ID and URL. The ID will looks like 'search-service-12345'. ah-task get $TASK ELB_ID=${FIELDS_STAGE}-$(ah-site list ${SITEGROUP}.${STAGE} -c id --no-name) ELB_URL=$(aws elb describe-load-balancers --region ${REGION} --load-balancer-names ${ELB_ID} \\ --query 'LoadBalancerDescriptions[].DNSName' --output text); echo $ELB_URL Get a list of *.acquia-search.com certificates and record the ARN of the one with the most recent date. ARNs start with \"arn\" and are in the second column of the output. aws iam list-server-certificates --output text \\ | grep star_acquia-search CERT_ARN= Set the ELB to use this certificate. aws elb set-load-balancer-listener-ssl-certificate \\ --region $REGION \\ --load-balancer-name $ELB_ID \\ --load-balancer-port 443 \\ --ssl-certificate-id $CERT_ARN","title":"Create the ELB"},{"location":"kanban_tickets/provision_search_colony/#create-the-cname-in-aws-route53","text":"You will need to know the values of these variables from above: SITEGROUP , COLONY , and ELB_URL . Create the record entry name. Use the region identifier ( SITEGROUP minus \"bal\"), followed by a dash, then COLONY . Example: \"apseast1-c60\". RECORD_NAME= RECORD_NAME_DNS=\"${RECORD_NAME}.acquia-search.com\" Get credentials and token to elevate temporarily and be able to write DNS records: aws sts assume-role \\ --output json \\ --role-arn 'arn:aws:iam::345874614325:role/Search-R53-Access' \\ --role-session-name \"colony-creation-$(whoami)\" Populate the following variables from the output of the previous command: export AWS_ACCESS_KEY_ID= export AWS_SECRET_ACCESS_KEY= export AWS_SESSION_TOKEN= Find the id of the acquia-search.com zone, and populate the proper variable: AS_ZONE=$(aws route53 list-hosted-zones --output json | \\ jq '.HostedZones' | \\ jq '.[] | select(.Name == \"acquia-search.com.\")' | \\ jq '.Id' | \\ sed 's/\"//g') (Note: if AS_ZONE isn't being populated, just run the aws command to list zones above and find the id of the acquia-search.com zone to populate the variable manually) Prepare the record json: ELB_CNAME=\"{ \\\"Comment\\\": \\\"Ops runbook https://runbook.ops.acquia.com/master/search/provision_search_colony\\\", \\\"Changes\\\": [ { \\\"Action\\\": \\\"CREATE\\\", \\\"ResourceRecordSet\\\": { \\\"Name\\\": \\\"${RECORD_NAME_DNS}\\\", \\\"Type\\\": \\\"CNAME\\\", \\\"TTL\\\": 30, \\\"ResourceRecords\\\": [ { \\\"Value\\\": \\\"${ELB_URL}\\\" } ] } } ] }\" Print the zone and record and review that everything looks good: echo ${AS_ZONE} echo ${ELB_CNAME} | jq Create the record and capture the change id to query it: CHANGE_ID=$(aws route53 change-resource-record-sets \\ --output json \\ --hosted-zone-id ${AS_ZONE} \\ --change-batch \"${ELB_CNAME}\" | jq '.ChangeInfo.Id' | sed 's/\"//g') Lastly, check that the record was properly created (in INSYNC status, may take a couple of minutes): aws route53 get-change --id ${CHANGE_ID}","title":"Create the CNAME in AWS Route53"},{"location":"kanban_tickets/provision_search_colony/#add-the-colony-to-the-governor","text":"You will need to know the values of these variables from above: REGION , SITEGROUP , COLONY , SEARCHGIT and ELB_URL . Log in to the Acquia Search Governor . Navigate to the Create Colony page, fill out the form as follows, and hit \"Save\". Title : The region identifier ( SITEGROUP minus \"bal\"), followed by a dash, then COLONY . Same as in the CNAME above. Example: \"apseast1-c60\" NOTE If it is dedicated search colony - make sure to mention the customer name after the colony. Example: \"useast1-c95(charter)\" Availability Zone : Actually just the REGION . Git repo : \" SITEGROUP @ SEARCHGIT : SITEGROUP .git\". Same as used to clone the repository above. Example: \"useast1bal@svn-3.search-service.hosting.acquia.com:useast1bal.git\". Or use the following command to get the exact URL (provide the variables are still stored in your terminal) echo \"${SITEGROUP}@${SEARCHGIT}:${SITEGROUP}.git\" Hosting Site Name : SITEGROUP followed by STAGE . Same as the site name above. Request Zones : Leave the default. ELB Url : CNAME Created on AWS Route53 . This field should point to the colony's URL rather than the physical ELB URL. For example, it should point to euwest1-c83.acquia-search.com rather than search-service-628-1791117540.eu-west-1.elb.amazonaws.com. Git branch : COLONY . Same branch committed to above. Hosting Location : \"hosting\". Should be the default. Balancer Servers : Leave empty. cloudapi_user and cloudapi_pass : Retrieve these values from the shared KeePassX archive.","title":"Add the colony to the Governor"},{"location":"kanban_tickets/provision_search_farm/","text":"Provision a Search Farm Note: To login Search jumpboxes, follow these instructions Manually provisioning a search farm involves the following: Allocate and launch one javasrv (Solr master), one or more javaephem (Solr slave), and, if necessary, one additional javaephem (Solr extractor). Create three \"sites\" in the same sitegroup, and associate them with the javasrv/javaephem servers. Set the needed site configuration values. First time preparation If this is your first time provisioning a search farm, you will need to download the id_search keypair from the Ops KeePassX and store it in ${SECURE}/ec2/search-service/ssh/default . If you do not have access to this repository, and need to provision a search farm, please contact an Operations Manager. If this is your first time provisioning a search farm or colony, you will also need to get the \"Governor\" pubkey and store it somewhere in your home directory on the bastion: Go to https://governor.acquia-search.com/admin/config/services/ssh-helper Copy the pubkey and save it to ${SECURE}/governor.pub . Sizing Search now uses \"tiered\" provisioning similar to Site Factory. This Confluence page contains the most up-to-date information on what instance sizes to use. If no tier is specified in the ticket, assume tier one. Deploying an extractor If you are creating the first search farm in a colony, you will need to allocate and launch an extractor alongside the farm. The sizing document includes extractor sizes. Solr version Assume Solr 4 unless the ticket specifies Solr 3. Solr version is applied by the VCS path and in the Governor. 2.2 for Solr 3.5.1 4.x for Solr 4.5.1 Extractors should continue to use the 2.2 branch (Solr 3.5) even for Solr 4 farms. Allocate and launch servers Make sure to set the bash to error out if any unset variable is used before proceeding with actual provisioning: set -u Set variables. The first two AZs must be different. REGION= AZ_0= AZ_1= AZ_2= MASTER_SIZE= SLAVE_SIZE= EXTRACTOR_SIZE= VOLUME_SIZE= Allocate the master. ./fields-provision.php --server-allocate javasrv \\ --instance-type ${MASTER_SIZE} \\ --region ${REGION} --availability-zone ${AZ_0} \\ --primary-volume-size ${VOLUME_SIZE} --secondary-volume-size ${VOLUME_SIZE} MASTER_SERVER= ah-server tag add ${MASTER_SERVER} --tags solrmaster Allocate the slave. ./fields-provision.php --server-allocate javaephem \\ --instance-type ${SLAVE_SIZE} \\ --region ${REGION} --availability-zone ${AZ_1} SLAVE_SERVER= ah-server tag add ${SLAVE_SERVER} --tags solrslave Allocate the extractor, if needed. ./fields-provision.php --server-allocate javaephem \\ --instance-type ${EXTRACTOR_SIZE} \\ --region ${REGION} --availability-zone ${AZ_2} EXTRACTOR_SERVER= ah-server tag add ${EXTRACTOR_SERVER} --tags solrextractor Currently the default OS is still Precise in legacy search, but the javasrvs and javaephems have been updated to Trusty, so before launching the servers, you will need to change the OS type. ah-server edit ${MASTER_SERVER},${SLAVE_SERVER},${EXTRACTOR_SERVER} -s os=trusty Launch. ah-server launch ${MASTER_SERVER},${SLAVE_SERVER},${EXTRACTOR_SERVER} Determine names Determine the sitegroup name. This will be the region identifier followed by \"as\". (That stands for \"Acquia Search\".) The region identifier is the region with dashes removed and is sometimes shortened. Unless this is a new region, the sitegroup should already exist. Examples: useast1as euwest1as apseast1as uswest1as uswest2as apsoutheast2as ah-sitegroup list %as SITEGROUP= Also save the region identifier, which is the region without dashes. (Ex. \"useast1\".) REGION_ID= Find the next farm ID. This is the letter \"s\" followed by a number incremented for every farm provisioned. (Not per region.) FARM=s$(($(ah-site list %ass% \\ | sed 's/^[a-z0-9-]*ass\\([0-9]*\\)[a-z]*$/\\1/g' \\ | sort -n \\ | tail -n 1) + 1)) echo ${FARM} Determine the colony this farm is part of, and save the ID. (Such as \"c5\".) COLONY= Info : Environment names are the farm ID followed by \"master\" for masters and \"slave\" for slaves. For extractors, this the colony ID followed by \"extract\". ( Not \"extractor\".) Info : Site names are the sitegroup followed by the farm ID followed by just \"m\" for masters or \"s\" for slaves. For extractors, this is the colony ID followed by just \"e\". Example Component Sitegroup Environment Site Master useast1as s20master useast1ass20m Slave useast1as s20slave useast1ass20s Extractor useast1as c5extract useast1asc5e Create and configure sites Make sure these variables are set from the sections above: MASTER_SERVER= SLAVE_SERVER= EXTRACTOR_SERVER= SITEGROUP= COLONY= FARM= REGION_ID= Set a variable for the VCS branch based on the Solr version . VCS_PATH=2.2 NOTE: We should use Solr 4.5 for new farms by default except for extractors. Create and configure the master site. SITE=${SITEGROUP}${FARM}m ./fields-provision.php --create-site ${SITE} \\ --sitegroup ${SITEGROUP} \\ --stage ${FARM}master \\ --app-type war \\ --webs ${MASTER_SERVER} && echo ah-site edit $SITE -s vcs_path=$VCS_PATH If this is the first farm in the region , add the Governor pubkey. ./fields-provision.php --user-setpubkey \\ ${SITE}:guv:${SECURE}/governor.pub Continue with the master site. ah-site edit $SITE -c vhost:port=8080 \\ tomcat:extra_ports=8081 ./fields-provision.php --set-site-config \\ ${SITE}:tomcat6_context_environment:solr/home:/mnt/gfs/${SITEGROUP}.${FARM}master/files/solr ./fields-provision.php \\ --cron-add ${SITE}:\"*\":\"*\":\"*\":\"*\":\"*\" \\ --cmd \"/var/www/html/${SITE}/scripts/register-server.rb \\ --colony '${REGION_ID}bal${COLONY}' \\ >> /mnt/tmp/${SITE}/register.log 2>&1\" \\ --server-filter all Create and configure the slave site. SITE=${SITEGROUP}${FARM}s ./fields-provision.php --create-site ${SITE} \\ --sitegroup ${SITEGROUP} \\ --stage ${FARM}slave \\ --app-type war \\ --webs ${SLAVE_SERVER} && echo ah-site edit $SITE -s vcs_path=$VCS_PATH ah-site edit $SITE -c vhost:port=8080 \\ tomcat:extra_ports=8081 ./fields-provision.php --set-site-config \\ ${SITE}:tomcat6_context_environment:solr/home:/mnt/gfs/${SITEGROUP}.${FARM}slave/files/solr ./fields-provision.php \\ --cron-add ${SITE}:\"*\":\"*\":\"*\":\"*\":\"*\" \\ --cmd \"/var/www/html/${SITE}/scripts/register-server.rb \\ --colony '${REGION_ID}bal${COLONY}' \\ >> /mnt/tmp/${SITE}/register.log 2>&1\" \\ --server-filter all Create and configure the extractor site, if needed. SITE=${SITEGROUP}${COLONY}e ./fields-provision.php --create-site ${SITE} \\ --sitegroup ${SITEGROUP} \\ --stage ${COLONY}extract \\ --app-type war \\ --webs $EXTRACTOR_SERVER ah-site edit $SITE -s vcs_path=2.2 ah-site edit $SITE -c vhost:port=8080 \\ tomcat:extra_ports=8081 ./fields-provision.php --set-site-config \\ ${SITE}:tomcat6_context_environment:solr/home:/mnt/gfs/${SITEGROUP}.${COLONY}extract/files/solr ./fields-provision.php \\ --cron-add ${SITE}:\"*\":\"*\":\"*\":\"*\":\"*\" \\ --cmd \"/var/www/html/${SITE}/scripts/register-server.rb \\ --colony '${REGION_ID}bal${COLONY}' \\ >> /mnt/tmp/${SITE}/register.log 2>&1\" \\ --server-filter all Verify that the cron jobs work. fpdsh -l ${MASTER_SERVER},${SLAVE_SERVER},${EXTRACTOR_SERVER} -c \\ 'sudo tail -n1 /mnt/tmp/${REGION_ID}*/register.log' Extra: If this farm should be the default farm of the colony Log into the governor. Go to colony configuration page. Under Set the default farm for specific colonies , look for the colony the farm belongs to. Check whether the farm is selected in the dropdown. If not, select the farm and click Save Configuration button. Note: If the colony is also newly created, it is always good to do a configuration resave so that the colony configurations are pushed correctly. As the page says, It never hurts to re-save the values! , without changing values in other colonies of course. Extra: If you are deploying Solr 4 Log into the governor. On the front page, for each of the sites you created: Search for it by sitegroup.stage. Open the link and \"edit\" it. Set \"Solr Version\" to the correct version in the drop-down. Save the node. Extra: If you are deploying the farm on dedicated hardware for a customer Log into the governor. On the front page, for each of the sites you created: Search for it by sitegroup.stage. Open the link and \"edit\" it. Tick the \"Dedicated\" check box at the bottom of the page Save the node.","title":"Provision a Search Farm"},{"location":"kanban_tickets/provision_search_farm/#provision-a-search-farm","text":"Note: To login Search jumpboxes, follow these instructions Manually provisioning a search farm involves the following: Allocate and launch one javasrv (Solr master), one or more javaephem (Solr slave), and, if necessary, one additional javaephem (Solr extractor). Create three \"sites\" in the same sitegroup, and associate them with the javasrv/javaephem servers. Set the needed site configuration values.","title":"Provision a Search Farm"},{"location":"kanban_tickets/provision_search_farm/#first-time-preparation","text":"If this is your first time provisioning a search farm, you will need to download the id_search keypair from the Ops KeePassX and store it in ${SECURE}/ec2/search-service/ssh/default . If you do not have access to this repository, and need to provision a search farm, please contact an Operations Manager. If this is your first time provisioning a search farm or colony, you will also need to get the \"Governor\" pubkey and store it somewhere in your home directory on the bastion: Go to https://governor.acquia-search.com/admin/config/services/ssh-helper Copy the pubkey and save it to ${SECURE}/governor.pub .","title":"First time preparation"},{"location":"kanban_tickets/provision_search_farm/#sizing","text":"Search now uses \"tiered\" provisioning similar to Site Factory. This Confluence page contains the most up-to-date information on what instance sizes to use. If no tier is specified in the ticket, assume tier one.","title":"Sizing"},{"location":"kanban_tickets/provision_search_farm/#deploying-an-extractor","text":"If you are creating the first search farm in a colony, you will need to allocate and launch an extractor alongside the farm. The sizing document includes extractor sizes.","title":"Deploying an extractor"},{"location":"kanban_tickets/provision_search_farm/#solr-version","text":"Assume Solr 4 unless the ticket specifies Solr 3. Solr version is applied by the VCS path and in the Governor. 2.2 for Solr 3.5.1 4.x for Solr 4.5.1 Extractors should continue to use the 2.2 branch (Solr 3.5) even for Solr 4 farms.","title":"Solr version"},{"location":"kanban_tickets/provision_search_farm/#allocate-and-launch-servers","text":"Make sure to set the bash to error out if any unset variable is used before proceeding with actual provisioning: set -u Set variables. The first two AZs must be different. REGION= AZ_0= AZ_1= AZ_2= MASTER_SIZE= SLAVE_SIZE= EXTRACTOR_SIZE= VOLUME_SIZE= Allocate the master. ./fields-provision.php --server-allocate javasrv \\ --instance-type ${MASTER_SIZE} \\ --region ${REGION} --availability-zone ${AZ_0} \\ --primary-volume-size ${VOLUME_SIZE} --secondary-volume-size ${VOLUME_SIZE} MASTER_SERVER= ah-server tag add ${MASTER_SERVER} --tags solrmaster Allocate the slave. ./fields-provision.php --server-allocate javaephem \\ --instance-type ${SLAVE_SIZE} \\ --region ${REGION} --availability-zone ${AZ_1} SLAVE_SERVER= ah-server tag add ${SLAVE_SERVER} --tags solrslave Allocate the extractor, if needed. ./fields-provision.php --server-allocate javaephem \\ --instance-type ${EXTRACTOR_SIZE} \\ --region ${REGION} --availability-zone ${AZ_2} EXTRACTOR_SERVER= ah-server tag add ${EXTRACTOR_SERVER} --tags solrextractor Currently the default OS is still Precise in legacy search, but the javasrvs and javaephems have been updated to Trusty, so before launching the servers, you will need to change the OS type. ah-server edit ${MASTER_SERVER},${SLAVE_SERVER},${EXTRACTOR_SERVER} -s os=trusty Launch. ah-server launch ${MASTER_SERVER},${SLAVE_SERVER},${EXTRACTOR_SERVER}","title":"Allocate and launch servers"},{"location":"kanban_tickets/provision_search_farm/#determine-names","text":"Determine the sitegroup name. This will be the region identifier followed by \"as\". (That stands for \"Acquia Search\".) The region identifier is the region with dashes removed and is sometimes shortened. Unless this is a new region, the sitegroup should already exist. Examples: useast1as euwest1as apseast1as uswest1as uswest2as apsoutheast2as ah-sitegroup list %as SITEGROUP= Also save the region identifier, which is the region without dashes. (Ex. \"useast1\".) REGION_ID= Find the next farm ID. This is the letter \"s\" followed by a number incremented for every farm provisioned. (Not per region.) FARM=s$(($(ah-site list %ass% \\ | sed 's/^[a-z0-9-]*ass\\([0-9]*\\)[a-z]*$/\\1/g' \\ | sort -n \\ | tail -n 1) + 1)) echo ${FARM} Determine the colony this farm is part of, and save the ID. (Such as \"c5\".) COLONY= Info : Environment names are the farm ID followed by \"master\" for masters and \"slave\" for slaves. For extractors, this the colony ID followed by \"extract\". ( Not \"extractor\".) Info : Site names are the sitegroup followed by the farm ID followed by just \"m\" for masters or \"s\" for slaves. For extractors, this is the colony ID followed by just \"e\".","title":"Determine names"},{"location":"kanban_tickets/provision_search_farm/#example","text":"Component Sitegroup Environment Site Master useast1as s20master useast1ass20m Slave useast1as s20slave useast1ass20s Extractor useast1as c5extract useast1asc5e","title":"Example"},{"location":"kanban_tickets/provision_search_farm/#create-and-configure-sites","text":"Make sure these variables are set from the sections above: MASTER_SERVER= SLAVE_SERVER= EXTRACTOR_SERVER= SITEGROUP= COLONY= FARM= REGION_ID= Set a variable for the VCS branch based on the Solr version . VCS_PATH=2.2 NOTE: We should use Solr 4.5 for new farms by default except for extractors. Create and configure the master site. SITE=${SITEGROUP}${FARM}m ./fields-provision.php --create-site ${SITE} \\ --sitegroup ${SITEGROUP} \\ --stage ${FARM}master \\ --app-type war \\ --webs ${MASTER_SERVER} && echo ah-site edit $SITE -s vcs_path=$VCS_PATH If this is the first farm in the region , add the Governor pubkey. ./fields-provision.php --user-setpubkey \\ ${SITE}:guv:${SECURE}/governor.pub Continue with the master site. ah-site edit $SITE -c vhost:port=8080 \\ tomcat:extra_ports=8081 ./fields-provision.php --set-site-config \\ ${SITE}:tomcat6_context_environment:solr/home:/mnt/gfs/${SITEGROUP}.${FARM}master/files/solr ./fields-provision.php \\ --cron-add ${SITE}:\"*\":\"*\":\"*\":\"*\":\"*\" \\ --cmd \"/var/www/html/${SITE}/scripts/register-server.rb \\ --colony '${REGION_ID}bal${COLONY}' \\ >> /mnt/tmp/${SITE}/register.log 2>&1\" \\ --server-filter all Create and configure the slave site. SITE=${SITEGROUP}${FARM}s ./fields-provision.php --create-site ${SITE} \\ --sitegroup ${SITEGROUP} \\ --stage ${FARM}slave \\ --app-type war \\ --webs ${SLAVE_SERVER} && echo ah-site edit $SITE -s vcs_path=$VCS_PATH ah-site edit $SITE -c vhost:port=8080 \\ tomcat:extra_ports=8081 ./fields-provision.php --set-site-config \\ ${SITE}:tomcat6_context_environment:solr/home:/mnt/gfs/${SITEGROUP}.${FARM}slave/files/solr ./fields-provision.php \\ --cron-add ${SITE}:\"*\":\"*\":\"*\":\"*\":\"*\" \\ --cmd \"/var/www/html/${SITE}/scripts/register-server.rb \\ --colony '${REGION_ID}bal${COLONY}' \\ >> /mnt/tmp/${SITE}/register.log 2>&1\" \\ --server-filter all Create and configure the extractor site, if needed. SITE=${SITEGROUP}${COLONY}e ./fields-provision.php --create-site ${SITE} \\ --sitegroup ${SITEGROUP} \\ --stage ${COLONY}extract \\ --app-type war \\ --webs $EXTRACTOR_SERVER ah-site edit $SITE -s vcs_path=2.2 ah-site edit $SITE -c vhost:port=8080 \\ tomcat:extra_ports=8081 ./fields-provision.php --set-site-config \\ ${SITE}:tomcat6_context_environment:solr/home:/mnt/gfs/${SITEGROUP}.${COLONY}extract/files/solr ./fields-provision.php \\ --cron-add ${SITE}:\"*\":\"*\":\"*\":\"*\":\"*\" \\ --cmd \"/var/www/html/${SITE}/scripts/register-server.rb \\ --colony '${REGION_ID}bal${COLONY}' \\ >> /mnt/tmp/${SITE}/register.log 2>&1\" \\ --server-filter all Verify that the cron jobs work. fpdsh -l ${MASTER_SERVER},${SLAVE_SERVER},${EXTRACTOR_SERVER} -c \\ 'sudo tail -n1 /mnt/tmp/${REGION_ID}*/register.log'","title":"Create and configure sites"},{"location":"kanban_tickets/provision_search_farm/#extra-if-this-farm-should-be-the-default-farm-of-the-colony","text":"Log into the governor. Go to colony configuration page. Under Set the default farm for specific colonies , look for the colony the farm belongs to. Check whether the farm is selected in the dropdown. If not, select the farm and click Save Configuration button. Note: If the colony is also newly created, it is always good to do a configuration resave so that the colony configurations are pushed correctly. As the page says, It never hurts to re-save the values! , without changing values in other colonies of course.","title":"Extra: If this farm should be the default farm of the colony"},{"location":"kanban_tickets/provision_search_farm/#extra-if-you-are-deploying-solr-4","text":"Log into the governor. On the front page, for each of the sites you created: Search for it by sitegroup.stage. Open the link and \"edit\" it. Set \"Solr Version\" to the correct version in the drop-down. Save the node.","title":"Extra: If you are deploying Solr 4"},{"location":"kanban_tickets/provision_search_farm/#extra-if-you-are-deploying-the-farm-on-dedicated-hardware-for-a-customer","text":"Log into the governor. On the front page, for each of the sites you created: Search for it by sitegroup.stage. Open the link and \"edit\" it. Tick the \"Dedicated\" check box at the bottom of the page Save the node.","title":"Extra: If you are deploying the farm on dedicated hardware for a customer"},{"location":"kanban_tickets/provision_site/","text":"Site Provision By Realm ACE ACP ACSF Tiers Read the ACE instructions before using these shortcut links for the manual provisioning instructions. Single Tier Multi Tier Full Tier Multi Region","title":"Site Provision"},{"location":"kanban_tickets/provision_site/#site-provision","text":"","title":"Site Provision"},{"location":"kanban_tickets/provision_site/#by-realm","text":"ACE ACP ACSF","title":"By Realm"},{"location":"kanban_tickets/provision_site/#tiers","text":"Read the ACE instructions before using these shortcut links for the manual provisioning instructions. Single Tier Multi Tier Full Tier Multi Region","title":"Tiers"},{"location":"kanban_tickets/provisioning_a_fedramp_site_with_acquia_shield/","text":"Provision FedRAMP Customer Site with Acquia Cloud Shield Manual instructions for provisioning ACE hardware. Allocating Hardware VPC Hardware Creating Sites Launching Servers Verification Allocating Hardware FedRAMP customers must use series 4 hardware (c4, m4, etc) and be in a VPC. Make sure that the deal sheet uses series 4 hardware and that the AZs you use are compatible with this hardware. Go through this link Shield for more info about Acquia Cloud Shield. Create the VPC FedRAMP customers, who have purchased Acquia Cloud Shield, must be in a dedicated VPC. The customer should fill out the VPC questionnaire to provide you with the information that you need to provision their dedicated VPC. Follow the VPC provision instructions . Setting variables Region and AZs The region should be specified in the ticket. You can choose any AZs that support VPC, SSD, encryption, and series 4 hardware. Region example value: us-east-1 AZ example values: us-east-1c us-east-1e Use the region-azfeatures tool to determine if the AZs you are provisioning in will support SSDs, VPC and encryption. region-azfeatures $REGION REGION= AZ1= AZ2= Volume Size These values can be found in the ticket and should be in the dealsheet Volume Size example value: 100 DB_SIZE= FS_SIZE= FS_VOL_TYPE=(gp3 or standard) DB_VOL_TYPE=(gp3 or standard) VPC Set the VPC variable. VPC=\"VPC_NAME\" FS Cluster variables FS_CLUSTER_NAME=$(date +%s) STG_CLUSTER_NAME=\"$(date +%s)-stg\" Single-Tier AMI_TYPE= ah-provision stack ded \\ -d $DB_SIZE \\ -g $FS_SIZE \\ -i $AMI_TYPE \\ -n $FS_CLUSTER_NAME \\ -r $REGION \\ -z $AZ1 $AZ2 \\ --ge --de \\ -V $VPC \\ --files-storage-type $FS_VOL_TYPE --database-storage-type $DB_VOL_TYPE # DB=ded-aaa # WEBS=ded-aaa,ded-bbb DB= WEBS= Multi-Tier NUM_WEBS= FSDB_AMI_TYPE= WEB_AMI_TYPE= ah-provision stack web-fsdb \\ -c $NUM_WEBS \\ -d $DB_SIZE \\ -f $FSDB_AMI_TYPE \\ -g $FS_SIZE \\ -n $FS_CLUSTER_NAME \\ -r $REGION \\ -w $WEB_AMI_TYPE \\ -z $AZ1 $AZ2 \\ --ge --de \\ -V $VPC \\ --files-storage-type $FS_VOL_TYPE --database-storage-type $DB_VOL_TYPE # DB=fsdb-aaa # WEBS=web-ddd,web-eee,web-... DB= WEBS= Full-Tier NUM_WEBS= DB_AMI_TYPE= FS_AMI_TYPE= WEB_AMI_TYPE= ah-provision stack web-db-fs \\ -D $DB_AMI_TYPE \\ -c $NUM_WEBS \\ -d $DB_SIZE \\ -f $FS_AMI_TYPE \\ -g $FS_SIZE \\ -n $FS_CLUSTER_NAME \\ -r $REGION \\ -w $WEB_AMI_TYPE \\ -z $AZ1 $AZ2 \\ --ge --de \\ -V $VPC \\ --files-storage-type $FS_VOL_TYPE --database-storage-type $DB_VOL_TYPE # DB=dbmaster-aaa # WEBS=web-ddd,web-eee,web-... DB= WEBS= Allocate the Bals Provision dedicated bals BAL_AMI_TYPE= ah-provision stack bal \\ -i $BAL_AMI_TYPE \\ -r $REGION \\ -z $AZ1 $AZ2 \\ -V $VPC # BALS=bal-aaa,bal-bbb BALS= Note: Make sure to verify if the existing hardware is in vpc or not before adding the new bals and provision the bals accordingly. The customer's balancers must be configured to support only TLSv1.2 via an SSL security policy. To do so, use the following commands: BALS= ah-server edit $BALS --config nginx.conf:ssl_security_policy=\"TLS-1-2-2017-01\" You can verify with: fpdsh -l $BALS -c \"sudo grep -i tls /etc/nginx/nginx.conf\" Allocate the Staging server(s) Create dedicated staging server STG_AMI_TYPE= ah-provision stack staging \\ -d $DB_SIZE \\ -g $FS_SIZE \\ -i $STG_AMI_TYPE \\ -n $STG_CLUSTER_NAME \\ -r $REGION \\ -z $AZ1 \\ --ge --de \\ -V $VPC \\ --files-storage-type $FS_VOL_TYPE --database-storage-type $DB_VOL_TYPE STAGING= Change mntfs volume size on Gen3 instances You can change mntfs (/mnt) volume size on any Gen3 (EBS-backed) instance you have provisioned. Gen3 instance is an EBS-backed instance where all volumes are EBS. No attached ephemeral drive. mntfs volume type is EBS volume mounted to '/mnt' mount point on Gen3 instance. Default mntfs volume size is 40GB. NOTE: You can change EBS volume size only on an allocated server that has never been launched. If you need to change size on a running server, please follow the EBS volume resizing procedure. Get the volume id (volume id is the number in id field. Look for a volume with /mnt mount point): bash SERVER_NAME= sv-vollist ${SERVER_NAME} Please be sure that volume's ebs_id is 'create' which means this volume is allocated but not running. If you see a value that starts with 'vol-' in the ebs_id field for '/mnt' volume, please stop here, you can't change its size. If you don't see a volume with '/mnt' mount point in the output means that the current instance is not EBS-backed and you can't change mntfs volume size on it. Change the volume size using the volume id that you have found during the previous step: bash VOLUME_ID= VOLUME_SIZE_GB= ah-volume edit ${VOLUME_ID} -s=size=${VOLUME_SIZE_GB} You should see in the output that the volume has changes its size. Get the SVN (VCS) server SVN servers do not need to be in the VPC site-taglistactive svn $REGION ec2_classic prod SVN= Set opportunity ID to the dedicated hardware Once you have provisioned the hardware for a sitegroup, you need to set the Salesforce opportunity ID on the dedicated hardware for tracking the instances. You will get the opportunity ID in description of the provisioning ticket. NOTE: Don\u2019t set opportunity ID on shared hardware. OPPORTUNITY_ID= TAG_SERVERS=\u201cded-aaa ded-bbb web-ccc web-ddd\u201d #(space delimiter) ah-server tag add $TAG_SERVERS --tags opportunity:${OPPORTUNITY_ID} Creating sites Once we have the servers allocated we can create sites on them. Pass the ded servers to --webs when the stack is single tier --db only accepts the first database server There is no flag for fs servers. They are added automatically prod SITENAME= ./fields-provision.php --create-site ${SITENAME} --vcs ${SVN} \\ --bals ${BALS} --webs ${WEBS} --db $DB ; echo \"\" test ./fields-provision.php --create-site ${SITENAME}test --stage test \\ --bals ${BALS} --webs ${STAGING} --db ${STAGING} \\ --sitegroup ${SITENAME} ; echo \"\" dev ./fields-provision.php --create-site ${SITENAME}dev --stage dev \\ --bals ${BALS} --webs ${STAGING} --db ${STAGING} \\ --sitegroup ${SITENAME} ; echo \"\" ra Only provision this if the dealsheet specifies the customer has RA. For FedRAMP customers, RA environments should be provisioned on their dedicated staging server and (non-prod if available) bals. ./fields-provision.php --create-site ${SITENAME}ra --ra 1 \\ --sitegroup ${SITENAME} --stage ra --bals ${BALS} \\ --webs ${STAGING} --db ${STAGING} Set the smtp return path for prod test and dev The email should be provided in the dealsheet or by the AM. EMAIL=\"technical-contact@domain.name\" ah-site edit ${SITENAME},${SITENAME}test,${SITENAME}dev \\ -c php.ini:sendmail_path=\"/usr/sbin/sendmail -t -i -f${EMAIL}\" Setup FIPS These steps are required for FedRAMP customers. FIPS server config setting ah-server edit $SERVERS -c puppet:fips_enabled=1 Mysql version server config setting Note: A specific version of mysql (client and server) is required to be used on FIPS compliant servers. Therefore activating FIPS on server types api, dbmaster, dbmesh, ded, free, fsdb, fsdbmesh, srv, staging, web requires an additional server config setting: DB_SERVERS= MYSQL_VERSION=5.7.29 ah-server edit $DB_SERVERS -c puppet:mysql_version=$MYSQL_VERSION Launching Servers Note: FIPS must be enabled before launching servers Run esl on the site to verify it looks correct before launching Then launch the servers with sv-taskrelaunch Example launching for single tier with dedicated bals and staging sv-taskrelaunch server $SERVERS If Launching A DB Server Initially Should Fail First verify that replication has not been initialized on the DB cluster you have launched. Depending on where the launch failed, and if the server is 'online' you should run the following: fpdsh -l $DB -c \"sudo mysql -e \"show slave status\\G\" The above command will return an empty result set if replication has not been initialized If and only if one of the ded/fsdb/dbmaster/etc servers fails to launch for the first time and you need to relaunch it, replication may not be initialized. NOTE This can run ONLY when you are launching a new customer for the first time. Once replication has successfully run on a DB cluster, this tool should never be used on that DB cluster anymore as this command will format the cluster of all data. After the server has successfully launched, run: ah-db-cluster init-replication ${DB} Verification Verify the site looks configured properly. esl $SITENAME Make sure all the webs have memcached set (unless the ticket specifies dedicated memcached webs). Also check that staging has memcached set as well. ah-server edit ${WEBS},${STAGING} -c memcached.conf:-m=64 SAML Support FedRAMP sites also require SAML support. Once the site move is complete, file a ticket with the CX Eng Team to get that set up: https://confluence.acquia.com/display/CXE/Customer+Experience+Engineering . Enable the Network Boundary for the VPC Follow the VPC IP whitelisting runbook to set this up for the dedicated VPC. Create an ELB FedRAMP customers require an ELB. Follow the ELB provision runbook to provision one. Add production sites to Monitoring Variable: SITENAME= Before you add a site to monitoring, check to ensure DNS is setup properly: DNS_IP=$(dig ${SITENAME}.${FIELDS_STAGE}.acquia-sites.com +short) BAL_IP=$(ah-server list site:${SITENAME} --no-name -w type=bal status=0 eip_id!=nil -c external_ip | head -1) if [[ ${DNS_IP} ]] || [[ ${BAL_IP} ]]; then if [[ ${DNS_IP} == ${BAL_IP} ]]; then errecho \"DNS is properly set for ${SITENAME}\" else errecho \"ERROR: DNS needs setting for ${SITENAME}.${FIELDS_STAGE}.acquia-sites.com\" \\ \"to the active bal EIP '${BAL_IP}'\" errecho \"ah-dns help set\" ah-dns help set fi else errecho \"ERROR: The site's bal doesn't have an EIP and there is no DNS entry.\" fi Ensure that ACQUIA_MONITOR loads: site-check ${SITENAME} Ensure that site-checkwebs is returning success by running the following: site-checkwebs ${SITENAME} If you are adding a site to an existing stack, check that no other sites are already in monitoring: SERVER=$(ah-server list site:${SITENAME} -w typeINweb,ded | head -1) SITES=($(ah-site list on:${SERVER})) for site in ${SITES[@]}; do site-mon get ${site} done If the checks pass, add the site to monitoring. site-mon add ${SITENAME}","title":"Provision FedRAMP Customer Site with Acquia Cloud Shield"},{"location":"kanban_tickets/provisioning_a_fedramp_site_with_acquia_shield/#provision-fedramp-customer-site-with-acquia-cloud-shield","text":"Manual instructions for provisioning ACE hardware. Allocating Hardware VPC Hardware Creating Sites Launching Servers Verification","title":"Provision FedRAMP Customer Site with Acquia Cloud Shield"},{"location":"kanban_tickets/provisioning_a_fedramp_site_with_acquia_shield/#allocating-hardware","text":"FedRAMP customers must use series 4 hardware (c4, m4, etc) and be in a VPC. Make sure that the deal sheet uses series 4 hardware and that the AZs you use are compatible with this hardware. Go through this link Shield for more info about Acquia Cloud Shield.","title":"Allocating Hardware"},{"location":"kanban_tickets/provisioning_a_fedramp_site_with_acquia_shield/#create-the-vpc","text":"FedRAMP customers, who have purchased Acquia Cloud Shield, must be in a dedicated VPC. The customer should fill out the VPC questionnaire to provide you with the information that you need to provision their dedicated VPC. Follow the VPC provision instructions .","title":"Create the VPC"},{"location":"kanban_tickets/provisioning_a_fedramp_site_with_acquia_shield/#setting-variables","text":"","title":"Setting variables"},{"location":"kanban_tickets/provisioning_a_fedramp_site_with_acquia_shield/#region-and-azs","text":"The region should be specified in the ticket. You can choose any AZs that support VPC, SSD, encryption, and series 4 hardware. Region example value: us-east-1 AZ example values: us-east-1c us-east-1e Use the region-azfeatures tool to determine if the AZs you are provisioning in will support SSDs, VPC and encryption. region-azfeatures $REGION REGION= AZ1= AZ2=","title":"Region and AZs"},{"location":"kanban_tickets/provisioning_a_fedramp_site_with_acquia_shield/#volume-size","text":"These values can be found in the ticket and should be in the dealsheet Volume Size example value: 100 DB_SIZE= FS_SIZE= FS_VOL_TYPE=(gp3 or standard) DB_VOL_TYPE=(gp3 or standard)","title":"Volume Size"},{"location":"kanban_tickets/provisioning_a_fedramp_site_with_acquia_shield/#vpc","text":"Set the VPC variable. VPC=\"VPC_NAME\"","title":"VPC"},{"location":"kanban_tickets/provisioning_a_fedramp_site_with_acquia_shield/#fs-cluster-variables","text":"FS_CLUSTER_NAME=$(date +%s) STG_CLUSTER_NAME=\"$(date +%s)-stg\"","title":"FS Cluster variables"},{"location":"kanban_tickets/provisioning_a_fedramp_site_with_acquia_shield/#single-tier","text":"AMI_TYPE= ah-provision stack ded \\ -d $DB_SIZE \\ -g $FS_SIZE \\ -i $AMI_TYPE \\ -n $FS_CLUSTER_NAME \\ -r $REGION \\ -z $AZ1 $AZ2 \\ --ge --de \\ -V $VPC \\ --files-storage-type $FS_VOL_TYPE --database-storage-type $DB_VOL_TYPE # DB=ded-aaa # WEBS=ded-aaa,ded-bbb DB= WEBS=","title":"Single-Tier"},{"location":"kanban_tickets/provisioning_a_fedramp_site_with_acquia_shield/#multi-tier","text":"NUM_WEBS= FSDB_AMI_TYPE= WEB_AMI_TYPE= ah-provision stack web-fsdb \\ -c $NUM_WEBS \\ -d $DB_SIZE \\ -f $FSDB_AMI_TYPE \\ -g $FS_SIZE \\ -n $FS_CLUSTER_NAME \\ -r $REGION \\ -w $WEB_AMI_TYPE \\ -z $AZ1 $AZ2 \\ --ge --de \\ -V $VPC \\ --files-storage-type $FS_VOL_TYPE --database-storage-type $DB_VOL_TYPE # DB=fsdb-aaa # WEBS=web-ddd,web-eee,web-... DB= WEBS=","title":"Multi-Tier"},{"location":"kanban_tickets/provisioning_a_fedramp_site_with_acquia_shield/#full-tier","text":"NUM_WEBS= DB_AMI_TYPE= FS_AMI_TYPE= WEB_AMI_TYPE= ah-provision stack web-db-fs \\ -D $DB_AMI_TYPE \\ -c $NUM_WEBS \\ -d $DB_SIZE \\ -f $FS_AMI_TYPE \\ -g $FS_SIZE \\ -n $FS_CLUSTER_NAME \\ -r $REGION \\ -w $WEB_AMI_TYPE \\ -z $AZ1 $AZ2 \\ --ge --de \\ -V $VPC \\ --files-storage-type $FS_VOL_TYPE --database-storage-type $DB_VOL_TYPE # DB=dbmaster-aaa # WEBS=web-ddd,web-eee,web-... DB= WEBS=","title":"Full-Tier"},{"location":"kanban_tickets/provisioning_a_fedramp_site_with_acquia_shield/#allocate-the-bals","text":"Provision dedicated bals BAL_AMI_TYPE= ah-provision stack bal \\ -i $BAL_AMI_TYPE \\ -r $REGION \\ -z $AZ1 $AZ2 \\ -V $VPC # BALS=bal-aaa,bal-bbb BALS= Note: Make sure to verify if the existing hardware is in vpc or not before adding the new bals and provision the bals accordingly. The customer's balancers must be configured to support only TLSv1.2 via an SSL security policy. To do so, use the following commands: BALS= ah-server edit $BALS --config nginx.conf:ssl_security_policy=\"TLS-1-2-2017-01\" You can verify with: fpdsh -l $BALS -c \"sudo grep -i tls /etc/nginx/nginx.conf\"","title":"Allocate the Bals"},{"location":"kanban_tickets/provisioning_a_fedramp_site_with_acquia_shield/#allocate-the-staging-servers","text":"Create dedicated staging server STG_AMI_TYPE= ah-provision stack staging \\ -d $DB_SIZE \\ -g $FS_SIZE \\ -i $STG_AMI_TYPE \\ -n $STG_CLUSTER_NAME \\ -r $REGION \\ -z $AZ1 \\ --ge --de \\ -V $VPC \\ --files-storage-type $FS_VOL_TYPE --database-storage-type $DB_VOL_TYPE STAGING=","title":"Allocate the Staging server(s)"},{"location":"kanban_tickets/provisioning_a_fedramp_site_with_acquia_shield/#change-mntfs-volume-size-on-gen3-instances","text":"You can change mntfs (/mnt) volume size on any Gen3 (EBS-backed) instance you have provisioned. Gen3 instance is an EBS-backed instance where all volumes are EBS. No attached ephemeral drive. mntfs volume type is EBS volume mounted to '/mnt' mount point on Gen3 instance. Default mntfs volume size is 40GB. NOTE: You can change EBS volume size only on an allocated server that has never been launched. If you need to change size on a running server, please follow the EBS volume resizing procedure. Get the volume id (volume id is the number in id field. Look for a volume with /mnt mount point): bash SERVER_NAME= sv-vollist ${SERVER_NAME} Please be sure that volume's ebs_id is 'create' which means this volume is allocated but not running. If you see a value that starts with 'vol-' in the ebs_id field for '/mnt' volume, please stop here, you can't change its size. If you don't see a volume with '/mnt' mount point in the output means that the current instance is not EBS-backed and you can't change mntfs volume size on it. Change the volume size using the volume id that you have found during the previous step: bash VOLUME_ID= VOLUME_SIZE_GB= ah-volume edit ${VOLUME_ID} -s=size=${VOLUME_SIZE_GB} You should see in the output that the volume has changes its size.","title":"Change mntfs volume size on Gen3 instances"},{"location":"kanban_tickets/provisioning_a_fedramp_site_with_acquia_shield/#get-the-svn-vcs-server","text":"SVN servers do not need to be in the VPC site-taglistactive svn $REGION ec2_classic prod SVN=","title":"Get the SVN (VCS) server"},{"location":"kanban_tickets/provisioning_a_fedramp_site_with_acquia_shield/#set-opportunity-id-to-the-dedicated-hardware","text":"Once you have provisioned the hardware for a sitegroup, you need to set the Salesforce opportunity ID on the dedicated hardware for tracking the instances. You will get the opportunity ID in description of the provisioning ticket. NOTE: Don\u2019t set opportunity ID on shared hardware. OPPORTUNITY_ID= TAG_SERVERS=\u201cded-aaa ded-bbb web-ccc web-ddd\u201d #(space delimiter) ah-server tag add $TAG_SERVERS --tags opportunity:${OPPORTUNITY_ID}","title":"Set opportunity ID to the dedicated hardware"},{"location":"kanban_tickets/provisioning_a_fedramp_site_with_acquia_shield/#creating-sites","text":"Once we have the servers allocated we can create sites on them. Pass the ded servers to --webs when the stack is single tier --db only accepts the first database server There is no flag for fs servers. They are added automatically","title":"Creating sites"},{"location":"kanban_tickets/provisioning_a_fedramp_site_with_acquia_shield/#prod","text":"SITENAME= ./fields-provision.php --create-site ${SITENAME} --vcs ${SVN} \\ --bals ${BALS} --webs ${WEBS} --db $DB ; echo \"\"","title":"prod"},{"location":"kanban_tickets/provisioning_a_fedramp_site_with_acquia_shield/#test","text":"./fields-provision.php --create-site ${SITENAME}test --stage test \\ --bals ${BALS} --webs ${STAGING} --db ${STAGING} \\ --sitegroup ${SITENAME} ; echo \"\"","title":"test"},{"location":"kanban_tickets/provisioning_a_fedramp_site_with_acquia_shield/#dev","text":"./fields-provision.php --create-site ${SITENAME}dev --stage dev \\ --bals ${BALS} --webs ${STAGING} --db ${STAGING} \\ --sitegroup ${SITENAME} ; echo \"\"","title":"dev"},{"location":"kanban_tickets/provisioning_a_fedramp_site_with_acquia_shield/#ra","text":"Only provision this if the dealsheet specifies the customer has RA. For FedRAMP customers, RA environments should be provisioned on their dedicated staging server and (non-prod if available) bals. ./fields-provision.php --create-site ${SITENAME}ra --ra 1 \\ --sitegroup ${SITENAME} --stage ra --bals ${BALS} \\ --webs ${STAGING} --db ${STAGING}","title":"ra"},{"location":"kanban_tickets/provisioning_a_fedramp_site_with_acquia_shield/#set-the-smtp-return-path-for-prod-test-and-dev","text":"The email should be provided in the dealsheet or by the AM. EMAIL=\"technical-contact@domain.name\" ah-site edit ${SITENAME},${SITENAME}test,${SITENAME}dev \\ -c php.ini:sendmail_path=\"/usr/sbin/sendmail -t -i -f${EMAIL}\"","title":"Set the smtp return path for prod test and dev"},{"location":"kanban_tickets/provisioning_a_fedramp_site_with_acquia_shield/#setup-fips","text":"These steps are required for FedRAMP customers.","title":"Setup FIPS"},{"location":"kanban_tickets/provisioning_a_fedramp_site_with_acquia_shield/#fips-server-config-setting","text":"ah-server edit $SERVERS -c puppet:fips_enabled=1","title":"FIPS server config setting"},{"location":"kanban_tickets/provisioning_a_fedramp_site_with_acquia_shield/#mysql-version-server-config-setting","text":"Note: A specific version of mysql (client and server) is required to be used on FIPS compliant servers. Therefore activating FIPS on server types api, dbmaster, dbmesh, ded, free, fsdb, fsdbmesh, srv, staging, web requires an additional server config setting: DB_SERVERS= MYSQL_VERSION=5.7.29 ah-server edit $DB_SERVERS -c puppet:mysql_version=$MYSQL_VERSION","title":"Mysql version server config setting"},{"location":"kanban_tickets/provisioning_a_fedramp_site_with_acquia_shield/#launching-servers","text":"Note: FIPS must be enabled before launching servers Run esl on the site to verify it looks correct before launching Then launch the servers with sv-taskrelaunch Example launching for single tier with dedicated bals and staging sv-taskrelaunch server $SERVERS","title":"Launching Servers"},{"location":"kanban_tickets/provisioning_a_fedramp_site_with_acquia_shield/#if-launching-a-db-server-initially-should-fail","text":"First verify that replication has not been initialized on the DB cluster you have launched. Depending on where the launch failed, and if the server is 'online' you should run the following: fpdsh -l $DB -c \"sudo mysql -e \"show slave status\\G\" The above command will return an empty result set if replication has not been initialized If and only if one of the ded/fsdb/dbmaster/etc servers fails to launch for the first time and you need to relaunch it, replication may not be initialized.","title":"If Launching A DB Server Initially Should Fail"},{"location":"kanban_tickets/provisioning_a_fedramp_site_with_acquia_shield/#note","text":"This can run ONLY when you are launching a new customer for the first time. Once replication has successfully run on a DB cluster, this tool should never be used on that DB cluster anymore as this command will format the cluster of all data. After the server has successfully launched, run: ah-db-cluster init-replication ${DB}","title":"NOTE"},{"location":"kanban_tickets/provisioning_a_fedramp_site_with_acquia_shield/#verification","text":"Verify the site looks configured properly. esl $SITENAME Make sure all the webs have memcached set (unless the ticket specifies dedicated memcached webs). Also check that staging has memcached set as well. ah-server edit ${WEBS},${STAGING} -c memcached.conf:-m=64","title":"Verification"},{"location":"kanban_tickets/provisioning_a_fedramp_site_with_acquia_shield/#saml-support","text":"FedRAMP sites also require SAML support. Once the site move is complete, file a ticket with the CX Eng Team to get that set up: https://confluence.acquia.com/display/CXE/Customer+Experience+Engineering .","title":"SAML Support"},{"location":"kanban_tickets/provisioning_a_fedramp_site_with_acquia_shield/#enable-the-network-boundary-for-the-vpc","text":"Follow the VPC IP whitelisting runbook to set this up for the dedicated VPC.","title":"Enable the Network Boundary for the VPC"},{"location":"kanban_tickets/provisioning_a_fedramp_site_with_acquia_shield/#create-an-elb","text":"FedRAMP customers require an ELB. Follow the ELB provision runbook to provision one.","title":"Create an ELB"},{"location":"kanban_tickets/provisioning_a_fedramp_site_with_acquia_shield/#add-production-sites-to-monitoring","text":"Variable: SITENAME= Before you add a site to monitoring, check to ensure DNS is setup properly: DNS_IP=$(dig ${SITENAME}.${FIELDS_STAGE}.acquia-sites.com +short) BAL_IP=$(ah-server list site:${SITENAME} --no-name -w type=bal status=0 eip_id!=nil -c external_ip | head -1) if [[ ${DNS_IP} ]] || [[ ${BAL_IP} ]]; then if [[ ${DNS_IP} == ${BAL_IP} ]]; then errecho \"DNS is properly set for ${SITENAME}\" else errecho \"ERROR: DNS needs setting for ${SITENAME}.${FIELDS_STAGE}.acquia-sites.com\" \\ \"to the active bal EIP '${BAL_IP}'\" errecho \"ah-dns help set\" ah-dns help set fi else errecho \"ERROR: The site's bal doesn't have an EIP and there is no DNS entry.\" fi Ensure that ACQUIA_MONITOR loads: site-check ${SITENAME} Ensure that site-checkwebs is returning success by running the following: site-checkwebs ${SITENAME} If you are adding a site to an existing stack, check that no other sites are already in monitoring: SERVER=$(ah-server list site:${SITENAME} -w typeINweb,ded | head -1) SITES=($(ah-site list on:${SERVER})) for site in ${SITES[@]}; do site-mon get ${site} done If the checks pass, add the site to monitoring. site-mon add ${SITENAME}","title":"Add production sites to Monitoring"},{"location":"kanban_tickets/provisioning_a_fedramp_site_without_acquia_shield/","text":"Provision FedRAMP Customer Site without Acquia Cloud Shield Manual instructions for provisioning ACE hardware. Allocating Hardware VPC Hardware Creating Sites Launching Servers Verification Allocating Hardware FedRAMP customers must use series 4 hardware (c4, m4, etc) and be in a VPC. Make sure that the deal sheet uses series 4 hardware and that the AZs you use are compatible with this hardware. Create the VPC FedRAMP customers, who have not purchased Acquia Cloud Shield, must be provisioned into a shared FedRAMP VPC if available. If a new one needs to be provisioned, follow the VPC provision instructions . Setting variables Region and AZs The region should be specified in the ticket. You can choose any AZs that support VPC, SSD, encryption, and series 4 hardware. Region example value: us-east-1 AZ example values: us-east-1c us-east-1e Use the region-azfeatures tool to determine if the AZs you are provisioning in will support SSDs, VPC and encryption. region-azfeatures $REGION REGION= AZ1= AZ2= Volume Size These values can be found in the ticket and should be in the dealsheet Volume Size example value: 100 DB_SIZE= FS_SIZE= FS_VOL_TYPE=(gp3 or standard) DB_VOL_TYPE=(gp3 or standard) VPC Set the VPC variable. VPC=\"VPC_NAME\" FS Cluster variables FS_CLUSTER_NAME=$(date +%s) STG_CLUSTER_NAME=\"$(date +%s)-stg\" Single-Tier AMI_TYPE= ah-provision stack ded \\ -d $DB_SIZE \\ -g $FS_SIZE \\ -i $AMI_TYPE \\ -n $FS_CLUSTER_NAME \\ -r $REGION \\ -z $AZ1 $AZ2 \\ --ge --de \\ -V $VPC \\ --files-storage-type $FS_VOL_TYPE --database-storage-type $DB_VOL_TYPE # DB=ded-aaa # WEBS=ded-aaa,ded-bbb DB= WEBS= Multi-Tier NUM_WEBS= FSDB_AMI_TYPE= WEB_AMI_TYPE= ah-provision stack web-fsdb \\ -c $NUM_WEBS \\ -d $DB_SIZE \\ -f $FSDB_AMI_TYPE \\ -g $FS_SIZE \\ -n $FS_CLUSTER_NAME \\ -r $REGION \\ -w $WEB_AMI_TYPE \\ -z $AZ1 $AZ2 \\ --ge --de \\ -V $VPC \\ --files-storage-type $FS_VOL_TYPE --database-storage-type $DB_VOL_TYPE # DB=fsdb-aaa # WEBS=web-ddd,web-eee,web-... DB= WEBS= Full-Tier NUM_WEBS= DB_AMI_TYPE= FS_AMI_TYPE= WEB_AMI_TYPE= ah-provision stack web-db-fs \\ -D $DB_AMI_TYPE \\ -c $NUM_WEBS \\ -d $DB_SIZE \\ -f $FS_AMI_TYPE \\ -g $FS_SIZE \\ -n $FS_CLUSTER_NAME \\ -r $REGION \\ -w $WEB_AMI_TYPE \\ -z $AZ1 $AZ2 \\ --ge --de \\ -V $VPC \\ --files-storage-type $FS_VOL_TYPE --database-storage-type $DB_VOL_TYPE # DB=dbmaster-aaa # WEBS=web-ddd,web-eee,web-... DB= WEBS= Allocate the Bals Provision dedicated bals BAL_AMI_TYPE= ah-provision stack bal \\ -i $BAL_AMI_TYPE \\ -r $REGION \\ -z $AZ1 $AZ2 \\ -V $VPC # BALS=bal-aaa,bal-bbb BALS= Note: Make sure to verify if the existing hardware is in vpc or not before adding the new bals and provision the bals accordingly. The customer's balancers must be configured to support TLSv1.2 only, via an SSL security policy. To do so, use the following commands: BALS= ah-server edit $BALS --config nginx.conf:ssl_security_policy=\"TLS-1-2-2017-01\" You can verify with: fpdsh -l $BALS -c \"sudo grep -i tls /etc/nginx/nginx.conf\" You must also configure TLS on the customer's ELB in the same manner. Instructions on how to do so are in the below ELB section. Allocate the Staging server(s) Create dedicated staging server STG_AMI_TYPE= ah-provision stack staging \\ -d $DB_SIZE \\ -g $FS_SIZE \\ -i $STG_AMI_TYPE \\ -n $STG_CLUSTER_NAME \\ -r $REGION \\ -z $AZ1 \\ --ge --de \\ -V $VPC \\ --files-storage-type $FS_VOL_TYPE --database-storage-type $DB_VOL_TYPE STAGING= Change mntfs volume size on Gen3 instances You can change mntfs (/mnt) volume size on any Gen3 (EBS-backed) instance you have provisioned. Gen3 instance is an EBS-backed instance where all volumes are EBS. No attached ephemeral drive. mntfs volume type is EBS volume mounted to '/mnt' mount point on Gen3 instance. Default mntfs volume size is 40GB. NOTE: You can change EBS volume size only on an allocated server that has never been launched. If you need to change size on a running server, please follow the EBS volume resizing procedure. Get the volume id (volume id is the number in id field. Look for a volume with /mnt mount point): bash SERVER_NAME= sv-vollist ${SERVER_NAME} Please be sure that volume's ebs_id is 'create' which means this volume is allocated but not running. If you see a value that starts with 'vol-' in the ebs_id field for '/mnt' volume, please stop here, you can't change its size. If you don't see a volume with '/mnt' mount point in the output means that the current instance is not EBS-backed and you can't change mntfs volume size on it. Change the volume size using the volume id that you have found during the previous step: bash VOLUME_ID= VOLUME_SIZE_GB= ah-volume edit ${VOLUME_ID} -s=size=${VOLUME_SIZE_GB} You should see in the output that the volume has changes its size. Get the SVN (VCS) server SVN servers do not need to be in the VPC site-taglistactive svn $REGION ec2_classic prod SVN= Set opportunity ID to the dedicated hardware Once you have provisioned the hardware for a sitegroup, you need to set the Salesforce opportunity ID on the dedicated hardware for tracking the instances. You will get the opportunity ID in description of the provisioning ticket. NOTE: Don\u2019t set opportunity ID on shared hardware. OPPORTUNITY_ID= TAG_SERVERS=\u201cded-aaa ded-bbb web-ccc web-ddd\u201d #(space delimiter) ah-server tag add $TAG_SERVERS --tags opportunity:${OPPORTUNITY_ID} Creating sites Once we have the servers allocated we can create sites on them. Pass the ded servers to --webs when the stack is single tier --db only accepts the first database server There is no flag for fs servers. They are added automatically prod SITENAME= ./fields-provision.php --create-site ${SITENAME} --vcs ${SVN} \\ --bals ${BALS} --webs ${WEBS} --db $DB ; echo \"\" test ./fields-provision.php --create-site ${SITENAME}test --stage test \\ --bals ${BALS} --webs ${STAGING} --db ${STAGING} \\ --sitegroup ${SITENAME} ; echo \"\" dev ./fields-provision.php --create-site ${SITENAME}dev --stage dev \\ --bals ${BALS} --webs ${STAGING} --db ${STAGING} \\ --sitegroup ${SITENAME} ; echo \"\" ra Only provision this if the dealsheet specifies the customer has RA. ./fields-provision.php --create-site ${SITENAME}ra --ra 1 \\ --sitegroup ${SITENAME} --stage ra --bals ${BALS} \\ --webs ${STAGING} --db ${STAGING} Set the smtp return path for prod test and dev The email should be provided in the dealsheet or by the AM. EMAIL=\"technical-contact@domain.name\" ah-site edit ${SITENAME},${SITENAME}test,${SITENAME}dev \\ -c php.ini:sendmail_path=\"/usr/sbin/sendmail -t -i -f${EMAIL}\" Setup FIPS These steps are required for FedRAMP customers. FIPS server config setting ah-server edit $SERVERS -c puppet:fips_enabled=1 MySQL version server config setting Note: A specific version of mysql (client and server) is required to be used on FIPS compliant servers. Therefore activating FIPS on server types api, dbmaster, dbmesh, ded, free, fsdb, fsdbmesh, srv, staging, web requires an additional server config setting: DB_SERVERS= MYSQL_VERSION=5.7.29 ah-server edit $DB_SERVERS -c puppet:mysql_version=$MYSQL_VERSION Launching Servers Note: FIPS must be enabled before launching servers Run esl on the site to verify it looks correct before launching Then launch the servers with sv-taskrelaunch Example launching for single tier with dedicated bals and staging sv-taskrelaunch server $SERVERS If Launching A DB Server Initially Should Fail First verify that replication has not been initialized on the DB cluster you have launched. Depending on where the launch failed, and if the server is 'online' you should run the following: fpdsh -l $DB -c \"sudo mysql -e \"show slave status\\G\" The above command will return an empty result set if replication has not been initialized If and only if one of the ded/fsdb/dbmaster/etc servers fails to launch for the first time and you need to relaunch it, replication may not be initialized. NOTE This can run ONLY when you are launching a new customer for the first time. Once replication has successfully run on a DB cluster, this tool should never be used on that DB cluster anymore as this command will format the cluster of all data. After the server has successfully launched, run: ah-db-cluster init-replication ${DB} Verification Verify the site looks configured properly. esl $SITENAME Make sure all the webs have memcached set (unless the ticket specifies dedicated memcached webs). Also check that staging has memcached set as well. ah-server edit ${WEBS},${STAGING} -c memcached.conf:-m=64 SAML Support FedRAMP sites also require SAML support. Once the site move is complete, file a ticket with the CX Eng Team to get that set up: https://confluence.acquia.com/display/CXE/Customer+Experience+Engineering . Create an ELB FedRAMP customers require an ELB. Follow the ELB provision runbook to provision one. After creating the ELB, you must configure the ELB to support TLSv1.2 only. Until this is supported by the platform, it must be done manually in the AWS UI. Login to the AWS console. Select EC2 under services. Select Load Balancers on the left menu. Search for the customer's ELB in the search bar. For example \"mc-12555\". Click the Listeners tab at the bottom, then Cipher . Click \"Custom Security Policy\", and then ensure that only Protocol-TLSv1.2 is selected on the right under SSL Protocols. Save. Add production sites to Monitoring Variable: SITENAME= Before you add a site to monitoring, check to ensure DNS is setup properly: DNS_IP=$(dig ${SITENAME}.${FIELDS_STAGE}.acquia-sites.com +short) BAL_IP=$(ah-server list site:${SITENAME} --no-name -w type=bal status=0 eip_id!=nil -c external_ip | head -1) if [[ ${DNS_IP} ]] || [[ ${BAL_IP} ]]; then if [[ ${DNS_IP} == ${BAL_IP} ]]; then errecho \"DNS is properly set for ${SITENAME}\" else errecho \"ERROR: DNS needs setting for ${SITENAME}.${FIELDS_STAGE}.acquia-sites.com\" \\ \"to the active bal EIP '${BAL_IP}'\" errecho \"ah-dns help set\" ah-dns help set fi else errecho \"ERROR: The site's bal doesn't have an EIP and there is no DNS entry.\" fi Ensure that ACQUIA_MONITOR loads: site-check ${SITENAME} Ensure that site-checkwebs is returning success by running the following: site-checkwebs ${SITENAME} If you are adding a site to an existing stack, check that no other sites are already in monitoring: SERVER=$(ah-server list site:${SITENAME} -w typeINweb,ded | head -1) SITES=($(ah-site list on:${SERVER})) for site in ${SITES[@]}; do site-mon get ${site} done If the checks pass, add the site to monitoring. site-mon add ${SITENAME}","title":"Provision FedRAMP Customer Site without Acquia Cloud Shield"},{"location":"kanban_tickets/provisioning_a_fedramp_site_without_acquia_shield/#provision-fedramp-customer-site-without-acquia-cloud-shield","text":"Manual instructions for provisioning ACE hardware. Allocating Hardware VPC Hardware Creating Sites Launching Servers Verification","title":"Provision FedRAMP Customer Site without Acquia Cloud Shield"},{"location":"kanban_tickets/provisioning_a_fedramp_site_without_acquia_shield/#allocating-hardware","text":"FedRAMP customers must use series 4 hardware (c4, m4, etc) and be in a VPC. Make sure that the deal sheet uses series 4 hardware and that the AZs you use are compatible with this hardware.","title":"Allocating Hardware"},{"location":"kanban_tickets/provisioning_a_fedramp_site_without_acquia_shield/#create-the-vpc","text":"FedRAMP customers, who have not purchased Acquia Cloud Shield, must be provisioned into a shared FedRAMP VPC if available. If a new one needs to be provisioned, follow the VPC provision instructions .","title":"Create the VPC"},{"location":"kanban_tickets/provisioning_a_fedramp_site_without_acquia_shield/#setting-variables","text":"","title":"Setting variables"},{"location":"kanban_tickets/provisioning_a_fedramp_site_without_acquia_shield/#region-and-azs","text":"The region should be specified in the ticket. You can choose any AZs that support VPC, SSD, encryption, and series 4 hardware. Region example value: us-east-1 AZ example values: us-east-1c us-east-1e Use the region-azfeatures tool to determine if the AZs you are provisioning in will support SSDs, VPC and encryption. region-azfeatures $REGION REGION= AZ1= AZ2=","title":"Region and AZs"},{"location":"kanban_tickets/provisioning_a_fedramp_site_without_acquia_shield/#volume-size","text":"These values can be found in the ticket and should be in the dealsheet Volume Size example value: 100 DB_SIZE= FS_SIZE= FS_VOL_TYPE=(gp3 or standard) DB_VOL_TYPE=(gp3 or standard)","title":"Volume Size"},{"location":"kanban_tickets/provisioning_a_fedramp_site_without_acquia_shield/#vpc","text":"Set the VPC variable. VPC=\"VPC_NAME\"","title":"VPC"},{"location":"kanban_tickets/provisioning_a_fedramp_site_without_acquia_shield/#fs-cluster-variables","text":"FS_CLUSTER_NAME=$(date +%s) STG_CLUSTER_NAME=\"$(date +%s)-stg\"","title":"FS Cluster variables"},{"location":"kanban_tickets/provisioning_a_fedramp_site_without_acquia_shield/#single-tier","text":"AMI_TYPE= ah-provision stack ded \\ -d $DB_SIZE \\ -g $FS_SIZE \\ -i $AMI_TYPE \\ -n $FS_CLUSTER_NAME \\ -r $REGION \\ -z $AZ1 $AZ2 \\ --ge --de \\ -V $VPC \\ --files-storage-type $FS_VOL_TYPE --database-storage-type $DB_VOL_TYPE # DB=ded-aaa # WEBS=ded-aaa,ded-bbb DB= WEBS=","title":"Single-Tier"},{"location":"kanban_tickets/provisioning_a_fedramp_site_without_acquia_shield/#multi-tier","text":"NUM_WEBS= FSDB_AMI_TYPE= WEB_AMI_TYPE= ah-provision stack web-fsdb \\ -c $NUM_WEBS \\ -d $DB_SIZE \\ -f $FSDB_AMI_TYPE \\ -g $FS_SIZE \\ -n $FS_CLUSTER_NAME \\ -r $REGION \\ -w $WEB_AMI_TYPE \\ -z $AZ1 $AZ2 \\ --ge --de \\ -V $VPC \\ --files-storage-type $FS_VOL_TYPE --database-storage-type $DB_VOL_TYPE # DB=fsdb-aaa # WEBS=web-ddd,web-eee,web-... DB= WEBS=","title":"Multi-Tier"},{"location":"kanban_tickets/provisioning_a_fedramp_site_without_acquia_shield/#full-tier","text":"NUM_WEBS= DB_AMI_TYPE= FS_AMI_TYPE= WEB_AMI_TYPE= ah-provision stack web-db-fs \\ -D $DB_AMI_TYPE \\ -c $NUM_WEBS \\ -d $DB_SIZE \\ -f $FS_AMI_TYPE \\ -g $FS_SIZE \\ -n $FS_CLUSTER_NAME \\ -r $REGION \\ -w $WEB_AMI_TYPE \\ -z $AZ1 $AZ2 \\ --ge --de \\ -V $VPC \\ --files-storage-type $FS_VOL_TYPE --database-storage-type $DB_VOL_TYPE # DB=dbmaster-aaa # WEBS=web-ddd,web-eee,web-... DB= WEBS=","title":"Full-Tier"},{"location":"kanban_tickets/provisioning_a_fedramp_site_without_acquia_shield/#allocate-the-bals","text":"Provision dedicated bals BAL_AMI_TYPE= ah-provision stack bal \\ -i $BAL_AMI_TYPE \\ -r $REGION \\ -z $AZ1 $AZ2 \\ -V $VPC # BALS=bal-aaa,bal-bbb BALS= Note: Make sure to verify if the existing hardware is in vpc or not before adding the new bals and provision the bals accordingly. The customer's balancers must be configured to support TLSv1.2 only, via an SSL security policy. To do so, use the following commands: BALS= ah-server edit $BALS --config nginx.conf:ssl_security_policy=\"TLS-1-2-2017-01\" You can verify with: fpdsh -l $BALS -c \"sudo grep -i tls /etc/nginx/nginx.conf\" You must also configure TLS on the customer's ELB in the same manner. Instructions on how to do so are in the below ELB section.","title":"Allocate the Bals"},{"location":"kanban_tickets/provisioning_a_fedramp_site_without_acquia_shield/#allocate-the-staging-servers","text":"Create dedicated staging server STG_AMI_TYPE= ah-provision stack staging \\ -d $DB_SIZE \\ -g $FS_SIZE \\ -i $STG_AMI_TYPE \\ -n $STG_CLUSTER_NAME \\ -r $REGION \\ -z $AZ1 \\ --ge --de \\ -V $VPC \\ --files-storage-type $FS_VOL_TYPE --database-storage-type $DB_VOL_TYPE STAGING=","title":"Allocate the Staging server(s)"},{"location":"kanban_tickets/provisioning_a_fedramp_site_without_acquia_shield/#change-mntfs-volume-size-on-gen3-instances","text":"You can change mntfs (/mnt) volume size on any Gen3 (EBS-backed) instance you have provisioned. Gen3 instance is an EBS-backed instance where all volumes are EBS. No attached ephemeral drive. mntfs volume type is EBS volume mounted to '/mnt' mount point on Gen3 instance. Default mntfs volume size is 40GB. NOTE: You can change EBS volume size only on an allocated server that has never been launched. If you need to change size on a running server, please follow the EBS volume resizing procedure. Get the volume id (volume id is the number in id field. Look for a volume with /mnt mount point): bash SERVER_NAME= sv-vollist ${SERVER_NAME} Please be sure that volume's ebs_id is 'create' which means this volume is allocated but not running. If you see a value that starts with 'vol-' in the ebs_id field for '/mnt' volume, please stop here, you can't change its size. If you don't see a volume with '/mnt' mount point in the output means that the current instance is not EBS-backed and you can't change mntfs volume size on it. Change the volume size using the volume id that you have found during the previous step: bash VOLUME_ID= VOLUME_SIZE_GB= ah-volume edit ${VOLUME_ID} -s=size=${VOLUME_SIZE_GB} You should see in the output that the volume has changes its size.","title":"Change mntfs volume size on Gen3 instances"},{"location":"kanban_tickets/provisioning_a_fedramp_site_without_acquia_shield/#get-the-svn-vcs-server","text":"SVN servers do not need to be in the VPC site-taglistactive svn $REGION ec2_classic prod SVN=","title":"Get the SVN (VCS) server"},{"location":"kanban_tickets/provisioning_a_fedramp_site_without_acquia_shield/#set-opportunity-id-to-the-dedicated-hardware","text":"Once you have provisioned the hardware for a sitegroup, you need to set the Salesforce opportunity ID on the dedicated hardware for tracking the instances. You will get the opportunity ID in description of the provisioning ticket. NOTE: Don\u2019t set opportunity ID on shared hardware. OPPORTUNITY_ID= TAG_SERVERS=\u201cded-aaa ded-bbb web-ccc web-ddd\u201d #(space delimiter) ah-server tag add $TAG_SERVERS --tags opportunity:${OPPORTUNITY_ID}","title":"Set opportunity ID to the dedicated hardware"},{"location":"kanban_tickets/provisioning_a_fedramp_site_without_acquia_shield/#creating-sites","text":"Once we have the servers allocated we can create sites on them. Pass the ded servers to --webs when the stack is single tier --db only accepts the first database server There is no flag for fs servers. They are added automatically","title":"Creating sites"},{"location":"kanban_tickets/provisioning_a_fedramp_site_without_acquia_shield/#prod","text":"SITENAME= ./fields-provision.php --create-site ${SITENAME} --vcs ${SVN} \\ --bals ${BALS} --webs ${WEBS} --db $DB ; echo \"\"","title":"prod"},{"location":"kanban_tickets/provisioning_a_fedramp_site_without_acquia_shield/#test","text":"./fields-provision.php --create-site ${SITENAME}test --stage test \\ --bals ${BALS} --webs ${STAGING} --db ${STAGING} \\ --sitegroup ${SITENAME} ; echo \"\"","title":"test"},{"location":"kanban_tickets/provisioning_a_fedramp_site_without_acquia_shield/#dev","text":"./fields-provision.php --create-site ${SITENAME}dev --stage dev \\ --bals ${BALS} --webs ${STAGING} --db ${STAGING} \\ --sitegroup ${SITENAME} ; echo \"\"","title":"dev"},{"location":"kanban_tickets/provisioning_a_fedramp_site_without_acquia_shield/#ra","text":"Only provision this if the dealsheet specifies the customer has RA. ./fields-provision.php --create-site ${SITENAME}ra --ra 1 \\ --sitegroup ${SITENAME} --stage ra --bals ${BALS} \\ --webs ${STAGING} --db ${STAGING}","title":"ra"},{"location":"kanban_tickets/provisioning_a_fedramp_site_without_acquia_shield/#set-the-smtp-return-path-for-prod-test-and-dev","text":"The email should be provided in the dealsheet or by the AM. EMAIL=\"technical-contact@domain.name\" ah-site edit ${SITENAME},${SITENAME}test,${SITENAME}dev \\ -c php.ini:sendmail_path=\"/usr/sbin/sendmail -t -i -f${EMAIL}\"","title":"Set the smtp return path for prod test and dev"},{"location":"kanban_tickets/provisioning_a_fedramp_site_without_acquia_shield/#setup-fips","text":"These steps are required for FedRAMP customers.","title":"Setup FIPS"},{"location":"kanban_tickets/provisioning_a_fedramp_site_without_acquia_shield/#fips-server-config-setting","text":"ah-server edit $SERVERS -c puppet:fips_enabled=1","title":"FIPS server config setting"},{"location":"kanban_tickets/provisioning_a_fedramp_site_without_acquia_shield/#mysql-version-server-config-setting","text":"Note: A specific version of mysql (client and server) is required to be used on FIPS compliant servers. Therefore activating FIPS on server types api, dbmaster, dbmesh, ded, free, fsdb, fsdbmesh, srv, staging, web requires an additional server config setting: DB_SERVERS= MYSQL_VERSION=5.7.29 ah-server edit $DB_SERVERS -c puppet:mysql_version=$MYSQL_VERSION","title":"MySQL version server config setting"},{"location":"kanban_tickets/provisioning_a_fedramp_site_without_acquia_shield/#launching-servers","text":"Note: FIPS must be enabled before launching servers Run esl on the site to verify it looks correct before launching Then launch the servers with sv-taskrelaunch Example launching for single tier with dedicated bals and staging sv-taskrelaunch server $SERVERS","title":"Launching Servers"},{"location":"kanban_tickets/provisioning_a_fedramp_site_without_acquia_shield/#if-launching-a-db-server-initially-should-fail","text":"First verify that replication has not been initialized on the DB cluster you have launched. Depending on where the launch failed, and if the server is 'online' you should run the following: fpdsh -l $DB -c \"sudo mysql -e \"show slave status\\G\" The above command will return an empty result set if replication has not been initialized If and only if one of the ded/fsdb/dbmaster/etc servers fails to launch for the first time and you need to relaunch it, replication may not be initialized.","title":"If Launching A DB Server Initially Should Fail"},{"location":"kanban_tickets/provisioning_a_fedramp_site_without_acquia_shield/#note","text":"This can run ONLY when you are launching a new customer for the first time. Once replication has successfully run on a DB cluster, this tool should never be used on that DB cluster anymore as this command will format the cluster of all data. After the server has successfully launched, run: ah-db-cluster init-replication ${DB}","title":"NOTE"},{"location":"kanban_tickets/provisioning_a_fedramp_site_without_acquia_shield/#verification","text":"Verify the site looks configured properly. esl $SITENAME Make sure all the webs have memcached set (unless the ticket specifies dedicated memcached webs). Also check that staging has memcached set as well. ah-server edit ${WEBS},${STAGING} -c memcached.conf:-m=64","title":"Verification"},{"location":"kanban_tickets/provisioning_a_fedramp_site_without_acquia_shield/#saml-support","text":"FedRAMP sites also require SAML support. Once the site move is complete, file a ticket with the CX Eng Team to get that set up: https://confluence.acquia.com/display/CXE/Customer+Experience+Engineering .","title":"SAML Support"},{"location":"kanban_tickets/provisioning_a_fedramp_site_without_acquia_shield/#create-an-elb","text":"FedRAMP customers require an ELB. Follow the ELB provision runbook to provision one. After creating the ELB, you must configure the ELB to support TLSv1.2 only. Until this is supported by the platform, it must be done manually in the AWS UI. Login to the AWS console. Select EC2 under services. Select Load Balancers on the left menu. Search for the customer's ELB in the search bar. For example \"mc-12555\". Click the Listeners tab at the bottom, then Cipher . Click \"Custom Security Policy\", and then ensure that only Protocol-TLSv1.2 is selected on the right under SSL Protocols. Save.","title":"Create an ELB"},{"location":"kanban_tickets/provisioning_a_fedramp_site_without_acquia_shield/#add-production-sites-to-monitoring","text":"Variable: SITENAME= Before you add a site to monitoring, check to ensure DNS is setup properly: DNS_IP=$(dig ${SITENAME}.${FIELDS_STAGE}.acquia-sites.com +short) BAL_IP=$(ah-server list site:${SITENAME} --no-name -w type=bal status=0 eip_id!=nil -c external_ip | head -1) if [[ ${DNS_IP} ]] || [[ ${BAL_IP} ]]; then if [[ ${DNS_IP} == ${BAL_IP} ]]; then errecho \"DNS is properly set for ${SITENAME}\" else errecho \"ERROR: DNS needs setting for ${SITENAME}.${FIELDS_STAGE}.acquia-sites.com\" \\ \"to the active bal EIP '${BAL_IP}'\" errecho \"ah-dns help set\" ah-dns help set fi else errecho \"ERROR: The site's bal doesn't have an EIP and there is no DNS entry.\" fi Ensure that ACQUIA_MONITOR loads: site-check ${SITENAME} Ensure that site-checkwebs is returning success by running the following: site-checkwebs ${SITENAME} If you are adding a site to an existing stack, check that no other sites are already in monitoring: SERVER=$(ah-server list site:${SITENAME} -w typeINweb,ded | head -1) SITES=($(ah-site list on:${SERVER})) for site in ${SITES[@]}; do site-mon get ${site} done If the checks pass, add the site to monitoring. site-mon add ${SITENAME}","title":"Add production sites to Monitoring"},{"location":"kanban_tickets/provisioning_mail_server/","text":"Provisioning a mail server for Acquia Hosting Platform This runbook documents the process of spinning up a new mail server in the event of outages/blacklists which may take long time to resolve. Cloning an existing mail server Log into Rackspace with the shared creds that can be located under Ops infrastructure credentials file in google drive. From the menu in the top left, choose \"Rackspace Cloud\". From the Servers menu item, choose \"Cloud Servers\". Click on \"Create Server\". The mail server should have 4 GB of RAM and 4 CPU cores. Set the server name to acquiamailX where X is the number of this mail server. Bear in mind that these are to be numbered sequentially. Select \"Saved\" under image type, then choose the parent server you are cloning under \"Parent Server\" and choose the most recent snapshot under \"Name\". Finally click on \"Create Server\" to begin the cloning process. Make note of the root password and IP address of the new server in a local text file on your computer for now. DNS Management Login into dynect and Go to Managed DNS > Click on Manage next to the acquia.com Zone. Under Add a New Node - enter acquiamailX (replace X with the number) and click on add node. Now click on Add a New Record and select (A) - ipv4 Address and enter the IP address of the new mail server. Set the TTL to 5 minutes. Next, scroll down in the list on the right to find the _spf record > Click on the down arrow to expand > Add the IP address of the new mail server. Click on Review and Publish zone notice on the top and publish the changes after reviewing. Configuring the new mail server Either select your newly cloned server from the \"Cloud Servers\" dashboard or if the \"Server Details\" is visible, click on \"Add Record...\" next to Reverse DNS. Now add the PTR record for both ipv4 and ipv6 one by one Set the hostname to acquiamailX.acquia.com where X is the number of new mail server Login into the new mail server using your bastion username and ssh key: ssh $USER@acquiamailX.acquia.com Switch to root user and in your favourite text editor open /etc/mysql/my.cnf. Edit line 90, server-id to the number of your new mail server (XX) and update report-host on line number 91 to hostname of new mail server and save the file. Restart mysql: service mysql stop; service mysql start . Login into acquiamail.acquia.com and issue the following command to get the current MASTER_LOG_FILE (binlog.NUMBER) and MASTER_LOG_POS (NUMBERS): root@acquiamail:~# mysql -BNe 'show master status' -p binlog.XXXXX YYYYYYY Note: The root password of mysql can be found under /root/.my.cnf file on the new server (as this is a clone of existing mail server image). Now login into the new created mail server acquiamailX.acquia.com and login into mysql: root@acquiamailX:~# mysql -u root -p mysql> stop slave; Query OK, 0 rows affected, 1 warning (0.00 sec) mysql> reset slave; Query OK, 0 rows affected (0.00 sec) mysql> CHANGE MASTER TO MASTER_HOST='67.23.31.6', MASTER_USER='FIND ME IN THE MYSQL', MASTER_PASSWORD='HISTORY OF ANOTHER ACQUIAMAIL SERVER', MASTER_LOG_FILE='binlog.XXXXX', MASTER_LOG_POS=YYYYYYY; Query OK, 0 rows affected (0.00 sec) mysql> start slave; Query OK, 0 rows affected (0.00 sec) mysql> show slave status \\G; Note: The MASTER_USER and MASTER_PASSWORD can be found under /root/.mysql_history file on the new server. 1. Now exit out of the mysql shell and open /etc/exim4/exim4.conf in a text editor. Add disable_ipv6 = true at the beginning in the file. Edit line 30, MAIN_LOCAL_INTERFACES=$IP and line 56 DCsmarthost=$IP and replace $IP with the IP of the new server. On line 43, update ETC_MAILNAME with hostname of new mail server (acquiamailX.acquia.com). Restart the exim4 service using service exim4 restart command to reflect changes. Verify the ipv6 is disabled by using the following command: root@acquiamailtest:/etc/exim4# exim -bP disable_ipv6 disable_ipv6 Testing the new mail server In order to test the new mail server, login into any employee site's server and edit /etc/exim4/exim4.conf and replace the IP under DCsmarthost around line number 58 to IP of the new mail server. Run this command to send an email to your email account: echo \"This email is from new mail server.\" | mail -s 'AcquiamailX' $USER@acquia.com Check your mailbox and verify that it doesn't ends up in spam folder. If it lands in spam, check on mxtoolbox.com if new IP is listed anywhere. Replacing mail server with new server Please note that replacing the mail server in a realm requires a hosting release/hotfix. Thus you will need to get it done by the cloud team. In the event of emergency, you would need Ops manager's approval for cloud escalation. Update the list of mail servers in confluence and runbook and update the notes with relevant info. Adding the mail server to monitoring Create a pull request in ops-mon-2 repo to add the new server in monitoring. Update the objects/intranet.cfg file and add the following entries in appropriate locations: define host { host_name acquiamailX.acquia.com ; alias mail relay X ; address X.X.X.X ; use intranet-server ; } .... .... members acquiamail.acquia.com,acquiamail3.acquia.com,acquiamail4.acquia.com,acquiamail5.acquia.com,acquiamail7.acquia.com, acquiamail9.acquia.com,acquiamail10.acquia.com,acquiamailX.acquia.com } .... .... host_name acquiamail.acquia.com,acquiamail3.acquia.com,acquiamail4.acquia.com,acquiamail5.acquia.com,acquiamail7.acquia.com, acquiamail9.acquia.com,acquiamail10.acquia.com,acquiamailX.acquia.com; .... .... define service { service_description Mail Blacklist host_name acquiamailX.acquia.com use fields-service check_interval 30 check_command check_blacklist!acquiamailX.acquia.com } Once the PR is ready, get at least 2 Ops approval before merging the changes to master. Adding the mail server in mxtoolbox for blacklist monitoring Login to mxtoolbox using Ops shared credentials > click on Add Monitoring > Blacklist > Enter hostname of new mail server (recommended to easy identification).","title":"Provisioning a mail server for Acquia Hosting Platform"},{"location":"kanban_tickets/provisioning_mail_server/#provisioning-a-mail-server-for-acquia-hosting-platform","text":"This runbook documents the process of spinning up a new mail server in the event of outages/blacklists which may take long time to resolve.","title":"Provisioning a mail server for Acquia Hosting Platform"},{"location":"kanban_tickets/provisioning_mail_server/#cloning-an-existing-mail-server","text":"Log into Rackspace with the shared creds that can be located under Ops infrastructure credentials file in google drive. From the menu in the top left, choose \"Rackspace Cloud\". From the Servers menu item, choose \"Cloud Servers\". Click on \"Create Server\". The mail server should have 4 GB of RAM and 4 CPU cores. Set the server name to acquiamailX where X is the number of this mail server. Bear in mind that these are to be numbered sequentially. Select \"Saved\" under image type, then choose the parent server you are cloning under \"Parent Server\" and choose the most recent snapshot under \"Name\". Finally click on \"Create Server\" to begin the cloning process. Make note of the root password and IP address of the new server in a local text file on your computer for now.","title":"Cloning an existing mail server"},{"location":"kanban_tickets/provisioning_mail_server/#dns-management","text":"Login into dynect and Go to Managed DNS > Click on Manage next to the acquia.com Zone. Under Add a New Node - enter acquiamailX (replace X with the number) and click on add node. Now click on Add a New Record and select (A) - ipv4 Address and enter the IP address of the new mail server. Set the TTL to 5 minutes. Next, scroll down in the list on the right to find the _spf record > Click on the down arrow to expand > Add the IP address of the new mail server. Click on Review and Publish zone notice on the top and publish the changes after reviewing.","title":"DNS Management"},{"location":"kanban_tickets/provisioning_mail_server/#configuring-the-new-mail-server","text":"Either select your newly cloned server from the \"Cloud Servers\" dashboard or if the \"Server Details\" is visible, click on \"Add Record...\" next to Reverse DNS. Now add the PTR record for both ipv4 and ipv6 one by one Set the hostname to acquiamailX.acquia.com where X is the number of new mail server Login into the new mail server using your bastion username and ssh key: ssh $USER@acquiamailX.acquia.com Switch to root user and in your favourite text editor open /etc/mysql/my.cnf. Edit line 90, server-id to the number of your new mail server (XX) and update report-host on line number 91 to hostname of new mail server and save the file. Restart mysql: service mysql stop; service mysql start . Login into acquiamail.acquia.com and issue the following command to get the current MASTER_LOG_FILE (binlog.NUMBER) and MASTER_LOG_POS (NUMBERS): root@acquiamail:~# mysql -BNe 'show master status' -p binlog.XXXXX YYYYYYY Note: The root password of mysql can be found under /root/.my.cnf file on the new server (as this is a clone of existing mail server image). Now login into the new created mail server acquiamailX.acquia.com and login into mysql: root@acquiamailX:~# mysql -u root -p mysql> stop slave; Query OK, 0 rows affected, 1 warning (0.00 sec) mysql> reset slave; Query OK, 0 rows affected (0.00 sec) mysql> CHANGE MASTER TO MASTER_HOST='67.23.31.6', MASTER_USER='FIND ME IN THE MYSQL', MASTER_PASSWORD='HISTORY OF ANOTHER ACQUIAMAIL SERVER', MASTER_LOG_FILE='binlog.XXXXX', MASTER_LOG_POS=YYYYYYY; Query OK, 0 rows affected (0.00 sec) mysql> start slave; Query OK, 0 rows affected (0.00 sec) mysql> show slave status \\G; Note: The MASTER_USER and MASTER_PASSWORD can be found under /root/.mysql_history file on the new server. 1. Now exit out of the mysql shell and open /etc/exim4/exim4.conf in a text editor. Add disable_ipv6 = true at the beginning in the file. Edit line 30, MAIN_LOCAL_INTERFACES=$IP and line 56 DCsmarthost=$IP and replace $IP with the IP of the new server. On line 43, update ETC_MAILNAME with hostname of new mail server (acquiamailX.acquia.com). Restart the exim4 service using service exim4 restart command to reflect changes. Verify the ipv6 is disabled by using the following command: root@acquiamailtest:/etc/exim4# exim -bP disable_ipv6 disable_ipv6","title":"Configuring the new mail server"},{"location":"kanban_tickets/provisioning_mail_server/#testing-the-new-mail-server","text":"In order to test the new mail server, login into any employee site's server and edit /etc/exim4/exim4.conf and replace the IP under DCsmarthost around line number 58 to IP of the new mail server. Run this command to send an email to your email account: echo \"This email is from new mail server.\" | mail -s 'AcquiamailX' $USER@acquia.com Check your mailbox and verify that it doesn't ends up in spam folder. If it lands in spam, check on mxtoolbox.com if new IP is listed anywhere.","title":"Testing the new mail server"},{"location":"kanban_tickets/provisioning_mail_server/#replacing-mail-server-with-new-server","text":"Please note that replacing the mail server in a realm requires a hosting release/hotfix. Thus you will need to get it done by the cloud team. In the event of emergency, you would need Ops manager's approval for cloud escalation. Update the list of mail servers in confluence and runbook and update the notes with relevant info.","title":"Replacing mail server with new server"},{"location":"kanban_tickets/provisioning_mail_server/#adding-the-mail-server-to-monitoring","text":"Create a pull request in ops-mon-2 repo to add the new server in monitoring. Update the objects/intranet.cfg file and add the following entries in appropriate locations: define host { host_name acquiamailX.acquia.com ; alias mail relay X ; address X.X.X.X ; use intranet-server ; } .... .... members acquiamail.acquia.com,acquiamail3.acquia.com,acquiamail4.acquia.com,acquiamail5.acquia.com,acquiamail7.acquia.com, acquiamail9.acquia.com,acquiamail10.acquia.com,acquiamailX.acquia.com } .... .... host_name acquiamail.acquia.com,acquiamail3.acquia.com,acquiamail4.acquia.com,acquiamail5.acquia.com,acquiamail7.acquia.com, acquiamail9.acquia.com,acquiamail10.acquia.com,acquiamailX.acquia.com; .... .... define service { service_description Mail Blacklist host_name acquiamailX.acquia.com use fields-service check_interval 30 check_command check_blacklist!acquiamailX.acquia.com } Once the PR is ready, get at least 2 Ops approval before merging the changes to master.","title":"Adding the mail server to monitoring"},{"location":"kanban_tickets/provisioning_mail_server/#adding-the-mail-server-in-mxtoolbox-for-blacklist-monitoring","text":"Login to mxtoolbox using Ops shared credentials > click on Add Monitoring > Blacklist > Enter hostname of new mail server (recommended to easy identification).","title":"Adding the mail server in mxtoolbox for blacklist monitoring"},{"location":"kanban_tickets/puppet_master/","text":"Generating and updating the root CA cert for puppet master The process is that we are creating a new root ca cert based on the old one which has already signed the puppetmaster cert. This means that all client certs will also be validly signed against the new root ca as well, as the puppetmaster cert is the intermediary cert. All commands should be run on master unless told otherwise. Change directory to ssl path cd /var/lib/puppet/ssl Setup steps Remove old newcert.pem from last time rm /var/lib/puppet/ssl/newcert.pem Check config Create/Set file \"index.txt\" > index.txt Create/Set file \"serial\" echo 00 >serial Create/Set file \"openssl.cnf\" cat << EOF > openssl.cnf [ca] default_ca = CA_default # The default ca section [CA_default] database = ./index.txt # index file. new_certs_dir = ./newcerts # new certs dir certificate = ./ca/ca_crt.pem serial = ./serial default_md = sha256 # md to use policy = CA_policy # default policy email_in_dn = no # Don't add the email name_opt = ca_default # SubjectName display option cert_opt = ca_default # Certificate display option x509_extensions = CA_extensions [CA_policy] countryName = optional stateOrProvinceName = optional organizationName = optional organizationalUnitName = optional commonName = supplied emailAddress = optional [CA_extensions] nsComment = \"Puppet Cert: manual.\" basicConstraints = CA:TRUE subjectKeyIdentifier = hash keyUsage = keyCertSign, cRLSign EOF Create directory \"newcerts\" if it does not exist mkdir newcerts Generate csr and cert Get CA password cat ca/private/ca.pass Generate csr openssl x509 -x509toreq -in certs/ca.pem -signkey ca/ca_key.pem -out certreq.csr This will prompt for a password. Enter the one from ca.pass. Generate pem openssl ca -in certreq.csr -keyfile ca/ca_key.pem -days 3650 -out newcert.pem \\ -config ./openssl.cnf This will prompt for a password. Enter the one from ca.pass. Check newcert.pem looks normal relative to ca.pem openssl x509 -text -noout -in newcert.pem openssl x509 -text -noout -in certs/ca.pem Verify the new cert Choose a server to verify Does not have to be but a bal makes the choices easier. ah-server list bal% -w status=0 eip_id=nil | head -n1 openssl verify -CAfile ./newcert.pem ca/signed/$CERT_FILE example of $CERT_FILE: bal-%.gardens.hosting.acquia.com.pem. Use server the one you chose above At this point, make a backup of the current cert cp ca/ca_crt.pem ca/ca_crt.bak cp newcert.pem ca/ca_crt.pem mv certs/ca.pem certs/ca.bak Reload Apache /etc/init.d/apache2 reload Test that puppet runs on the master and the new CA is cached puppet agent -t --noop Test that puppet runs on an arbitrary server Choose a server to test (does not have to be but a bal makes the choices easier) ah-server list bal% -w status=0 eip_id=nil | head -n1 THIS IS RUN ON THE SERVER YOU CHOSE ABOVE you@bal-x $ sudo mv /var/lib/puppet/ssl/certs/ca.pem{,.bak} you@bal-x $ sudo puppet agent -t Now we need to move the current ca on all clients in the stage This is so that puppet will cache the new CA on next run THIS IS RUN ON THE BASTION you@bastion $ fpdsh -t % -p 200 -c 'sudo mv /var/lib/puppet/ssl/certs/ca.pem{,.bak}'","title":"Generating and updating the root CA cert for puppet master"},{"location":"kanban_tickets/puppet_master/#generating-and-updating-the-root-ca-cert-for-puppet-master","text":"The process is that we are creating a new root ca cert based on the old one which has already signed the puppetmaster cert. This means that all client certs will also be validly signed against the new root ca as well, as the puppetmaster cert is the intermediary cert. All commands should be run on master unless told otherwise.","title":"Generating and updating the root CA cert for puppet master"},{"location":"kanban_tickets/puppet_master/#change-directory-to-ssl-path","text":"cd /var/lib/puppet/ssl","title":"Change directory to ssl path"},{"location":"kanban_tickets/puppet_master/#setup-steps","text":"","title":"Setup steps"},{"location":"kanban_tickets/puppet_master/#remove-old-newcertpem-from-last-time","text":"rm /var/lib/puppet/ssl/newcert.pem","title":"Remove old newcert.pem from last time"},{"location":"kanban_tickets/puppet_master/#check-config","text":"","title":"Check config"},{"location":"kanban_tickets/puppet_master/#createset-file-indextxt","text":"> index.txt","title":"Create/Set file \"index.txt\""},{"location":"kanban_tickets/puppet_master/#createset-file-serial","text":"echo 00 >serial","title":"Create/Set file \"serial\""},{"location":"kanban_tickets/puppet_master/#createset-file-opensslcnf","text":"cat << EOF > openssl.cnf [ca] default_ca = CA_default # The default ca section [CA_default] database = ./index.txt # index file. new_certs_dir = ./newcerts # new certs dir certificate = ./ca/ca_crt.pem serial = ./serial default_md = sha256 # md to use policy = CA_policy # default policy email_in_dn = no # Don't add the email name_opt = ca_default # SubjectName display option cert_opt = ca_default # Certificate display option x509_extensions = CA_extensions [CA_policy] countryName = optional stateOrProvinceName = optional organizationName = optional organizationalUnitName = optional commonName = supplied emailAddress = optional [CA_extensions] nsComment = \"Puppet Cert: manual.\" basicConstraints = CA:TRUE subjectKeyIdentifier = hash keyUsage = keyCertSign, cRLSign EOF","title":"Create/Set file \"openssl.cnf\""},{"location":"kanban_tickets/puppet_master/#create-directory-newcerts-if-it-does-not-exist","text":"mkdir newcerts","title":"Create directory \"newcerts\" if it does not exist"},{"location":"kanban_tickets/puppet_master/#generate-csr-and-cert","text":"","title":"Generate csr and cert"},{"location":"kanban_tickets/puppet_master/#get-ca-password","text":"cat ca/private/ca.pass","title":"Get CA password"},{"location":"kanban_tickets/puppet_master/#generate-csr","text":"openssl x509 -x509toreq -in certs/ca.pem -signkey ca/ca_key.pem -out certreq.csr This will prompt for a password. Enter the one from ca.pass.","title":"Generate csr"},{"location":"kanban_tickets/puppet_master/#generate-pem","text":"openssl ca -in certreq.csr -keyfile ca/ca_key.pem -days 3650 -out newcert.pem \\ -config ./openssl.cnf This will prompt for a password. Enter the one from ca.pass.","title":"Generate pem"},{"location":"kanban_tickets/puppet_master/#check-newcertpem-looks-normal-relative-to-capem","text":"openssl x509 -text -noout -in newcert.pem openssl x509 -text -noout -in certs/ca.pem","title":"Check newcert.pem looks normal relative to ca.pem"},{"location":"kanban_tickets/puppet_master/#verify-the-new-cert","text":"","title":"Verify the new cert"},{"location":"kanban_tickets/puppet_master/#choose-a-server-to-verify","text":"Does not have to be but a bal makes the choices easier. ah-server list bal% -w status=0 eip_id=nil | head -n1 openssl verify -CAfile ./newcert.pem ca/signed/$CERT_FILE example of $CERT_FILE: bal-%.gardens.hosting.acquia.com.pem. Use server the one you chose above","title":"Choose a server to verify"},{"location":"kanban_tickets/puppet_master/#at-this-point-make-a-backup-of-the-current-cert","text":"cp ca/ca_crt.pem ca/ca_crt.bak cp newcert.pem ca/ca_crt.pem mv certs/ca.pem certs/ca.bak","title":"At this point, make a backup of the current cert"},{"location":"kanban_tickets/puppet_master/#reload-apache","text":"/etc/init.d/apache2 reload","title":"Reload Apache"},{"location":"kanban_tickets/puppet_master/#test-that-puppet-runs-on-the-master-and-the-new-ca-is-cached","text":"puppet agent -t --noop","title":"Test that puppet runs on the master and the new CA is cached"},{"location":"kanban_tickets/puppet_master/#test-that-puppet-runs-on-an-arbitrary-server","text":"","title":"Test that puppet runs on an arbitrary server"},{"location":"kanban_tickets/puppet_master/#choose-a-server-to-test","text":"(does not have to be but a bal makes the choices easier) ah-server list bal% -w status=0 eip_id=nil | head -n1 THIS IS RUN ON THE SERVER YOU CHOSE ABOVE you@bal-x $ sudo mv /var/lib/puppet/ssl/certs/ca.pem{,.bak} you@bal-x $ sudo puppet agent -t","title":"Choose a server to test"},{"location":"kanban_tickets/puppet_master/#now-we-need-to-move-the-current-ca-on-all-clients-in-the-stage","text":"This is so that puppet will cache the new CA on next run THIS IS RUN ON THE BASTION you@bastion $ fpdsh -t % -p 200 -c 'sudo mv /var/lib/puppet/ssl/certs/ca.pem{,.bak}'","title":"Now we need to move the current ca on all clients in the stage"},{"location":"kanban_tickets/regenerate_netrcs/","text":"Regenerating netrc Credentials Summary A bastion user may find that their netrc credentials are not working or need to be rolled due to a security incident. The admin-regneratecreds script does this for you. WARNINGS This script requires sudo access on the bastion. This process will roll ALL applicable netrc creds for a given username and place them into a new directory. The directory created MUST be moved to the user's home directory and chown ed correctly. Procedure Ahops Ahops creds are reset using admin-regeneratecreds. REALMS is a comma-separated list of realms to reset. JIRA= DATE=$(date +%Y%m%d-%H_%M_%S) USERNAME= REALMS= USER_HOMEDIR=\"/vol/ebs1/home/${USERNAME}/\" TEMP_DIR=\"${HOME}/${JIRA}-${USERNAME}-admin-regeneratecreds-${DATE}\" admin-regeneratecreds ${USERNAME} ${TEMP_DIR} ${REALMS} sudo mv ${TEMP_DIR} ${USER_HOMEDIR}; sudo chown -R ${USERNAME}:${USERNAME} \\ ${USER_HOMEDIR}/${JIRA}-${USERNAME}-admin-regeneratecreds-${DATE} Ahsupport Ahsupport creds are reset using ahsupport-rpc-creds-reset. REALMS is an array of realms to reset. REALMS=() # Populate 'USERNAME' with the user that you want to reset creds for USERNAME= for realm in ${REALMS[@]}; do ahsupport-rpc-creds-reset ${USERNAME} ${realm} done","title":"Regenerating netrc Credentials"},{"location":"kanban_tickets/regenerate_netrcs/#regenerating-netrc-credentials","text":"","title":"Regenerating netrc Credentials"},{"location":"kanban_tickets/regenerate_netrcs/#summary","text":"A bastion user may find that their netrc credentials are not working or need to be rolled due to a security incident. The admin-regneratecreds script does this for you.","title":"Summary"},{"location":"kanban_tickets/regenerate_netrcs/#warnings","text":"This script requires sudo access on the bastion. This process will roll ALL applicable netrc creds for a given username and place them into a new directory. The directory created MUST be moved to the user's home directory and chown ed correctly.","title":"WARNINGS"},{"location":"kanban_tickets/regenerate_netrcs/#procedure","text":"","title":"Procedure"},{"location":"kanban_tickets/regenerate_netrcs/#ahops","text":"Ahops creds are reset using admin-regeneratecreds. REALMS is a comma-separated list of realms to reset. JIRA= DATE=$(date +%Y%m%d-%H_%M_%S) USERNAME= REALMS= USER_HOMEDIR=\"/vol/ebs1/home/${USERNAME}/\" TEMP_DIR=\"${HOME}/${JIRA}-${USERNAME}-admin-regeneratecreds-${DATE}\" admin-regeneratecreds ${USERNAME} ${TEMP_DIR} ${REALMS} sudo mv ${TEMP_DIR} ${USER_HOMEDIR}; sudo chown -R ${USERNAME}:${USERNAME} \\ ${USER_HOMEDIR}/${JIRA}-${USERNAME}-admin-regeneratecreds-${DATE}","title":"Ahops"},{"location":"kanban_tickets/regenerate_netrcs/#ahsupport","text":"Ahsupport creds are reset using ahsupport-rpc-creds-reset. REALMS is an array of realms to reset. REALMS=() # Populate 'USERNAME' with the user that you want to reset creds for USERNAME= for realm in ${REALMS[@]}; do ahsupport-rpc-creds-reset ${USERNAME} ${realm} done","title":"Ahsupport"},{"location":"kanban_tickets/releasing_domains/","text":"Site Domains Management Usage Checking domains for old site SITE= ah-site list domain:${SITE} Removing domain from old site ah-site domain2 remove --env-uuid=$(ah-site list ${SITE} -c uuid --no-name) --name=somewebsite.com Adding domain to new site ah-site domain2 add --env-uuid=$(ah-site list ${SITE} -c uuid --no-name) --name=somewebsite.com Real-life Example Removing a domain may be necessary when restoring an accidentally deleted site. ie. OP-248840 Customer can't add the domain vgpvet.com.au that they were using previously. I tried and was unable to use cloudapi to delete the domain on the deactivated docroot. I have a theory the domain is stuck in our system somewhere and it cannot be added in two places, causing the error customer is seeing. DOMAIN=vgpvet.com.au SITENAME=$(ah-site list domain:${DOMAIN}); echo $SITENAME vgpautjgjhbeb2q ah-site domain2 remove --env-uuid=$(ah-site list ${SITENAME} -c uuid --no-name) --name=$DOMAIN","title":"Site Domains Management"},{"location":"kanban_tickets/releasing_domains/#site-domains-management","text":"","title":"Site Domains Management"},{"location":"kanban_tickets/releasing_domains/#usage","text":"","title":"Usage"},{"location":"kanban_tickets/releasing_domains/#checking-domains-for-old-site","text":"SITE= ah-site list domain:${SITE}","title":"Checking domains for old site"},{"location":"kanban_tickets/releasing_domains/#removing-domain-from-old-site","text":"ah-site domain2 remove --env-uuid=$(ah-site list ${SITE} -c uuid --no-name) --name=somewebsite.com","title":"Removing domain from old site"},{"location":"kanban_tickets/releasing_domains/#adding-domain-to-new-site","text":"ah-site domain2 add --env-uuid=$(ah-site list ${SITE} -c uuid --no-name) --name=somewebsite.com","title":"Adding domain to new site"},{"location":"kanban_tickets/releasing_domains/#real-life-example","text":"Removing a domain may be necessary when restoring an accidentally deleted site. ie. OP-248840 Customer can't add the domain vgpvet.com.au that they were using previously. I tried and was unable to use cloudapi to delete the domain on the deactivated docroot. I have a theory the domain is stuck in our system somewhere and it cannot be added in two places, causing the error customer is seeing. DOMAIN=vgpvet.com.au SITENAME=$(ah-site list domain:${DOMAIN}); echo $SITENAME vgpautjgjhbeb2q ah-site domain2 remove --env-uuid=$(ah-site list ${SITENAME} -c uuid --no-name) --name=$DOMAIN","title":"Real-life Example"},{"location":"kanban_tickets/remove_user/","text":"Deprovision User Access Ops receives tickets for deprovisioning access for employees that are leaving. Here is a list of access to deprovision, and how to deprovision it. This runbook is intended for engineers who have sudo on bastion. Bastion access We deprovision bastion access by disabling the account and making a tarball of their home directory. Validate username USERNAME= admin-list ${USERNAME} Remove user from all stages admin-disable ${USERNAME} Kill any open ssh connections for that user after taking sudo login ps aux | grep [u]sername pkill -u ${USERNAME} Move their home directory to the archive after taking sudo login cd /vol/ebs1/home/ && tar -czvf ${USERNAME}.tar.gz ./${USERNAME}/ && rm -r ${USERNAME} Delete the public key from the bastion: rm /vol/ebs1/keys/authorized_keys/${USERNAME} Ops-Puppet There are two changes to make to ops-puppet. Against the production branch, remove their ssh key from hiera/modules/acquia.yaml, and add their username to the section of former employees. Example: Master example Against the LEGACY_2015-02-17 branch, add their username to modules/user/manifests/blacklist.pp and remove their ssh key from modules/user/manifests/ops.pp. Example: Legacy example Fields Check the sudoers file in fields and remove their username if it is there. Make sure you check the master branch. [cloudservicesprod|hosting-prod:prod] ~/fields/master$ git grep bbuckner puppet/versions/devel/modules/bastion/files/sudoers:bbuckner ALL=NOPASSWD: ALL AWS If the user is in engineering, they also need their AWS creds removed. Escalate the ticket to ops management for that portion.","title":"Deprovision User Access"},{"location":"kanban_tickets/remove_user/#deprovision-user-access","text":"Ops receives tickets for deprovisioning access for employees that are leaving. Here is a list of access to deprovision, and how to deprovision it. This runbook is intended for engineers who have sudo on bastion.","title":"Deprovision User Access"},{"location":"kanban_tickets/remove_user/#bastion-access","text":"We deprovision bastion access by disabling the account and making a tarball of their home directory. Validate username USERNAME= admin-list ${USERNAME} Remove user from all stages admin-disable ${USERNAME} Kill any open ssh connections for that user after taking sudo login ps aux | grep [u]sername pkill -u ${USERNAME} Move their home directory to the archive after taking sudo login cd /vol/ebs1/home/ && tar -czvf ${USERNAME}.tar.gz ./${USERNAME}/ && rm -r ${USERNAME} Delete the public key from the bastion: rm /vol/ebs1/keys/authorized_keys/${USERNAME}","title":"Bastion access"},{"location":"kanban_tickets/remove_user/#ops-puppet","text":"There are two changes to make to ops-puppet. Against the production branch, remove their ssh key from hiera/modules/acquia.yaml, and add their username to the section of former employees. Example: Master example Against the LEGACY_2015-02-17 branch, add their username to modules/user/manifests/blacklist.pp and remove their ssh key from modules/user/manifests/ops.pp. Example: Legacy example","title":"Ops-Puppet"},{"location":"kanban_tickets/remove_user/#fields","text":"Check the sudoers file in fields and remove their username if it is there. Make sure you check the master branch. [cloudservicesprod|hosting-prod:prod] ~/fields/master$ git grep bbuckner puppet/versions/devel/modules/bastion/files/sudoers:bbuckner ALL=NOPASSWD: ALL","title":"Fields"},{"location":"kanban_tickets/remove_user/#aws","text":"If the user is in engineering, they also need their AWS creds removed. Escalate the ticket to ops management for that portion.","title":"AWS"},{"location":"kanban_tickets/renewing_certificates/","text":"Renewing SSL Certificates Preface Renewing an SSL certificate, with the exception of Acquia-controlled UCCs such as ssl_ucc* , must be communicated and approved by the Account Manager(s) for the customer(s) that are affected by the renewal. Important Note Our DigiCert account is upgraded recently where the new platform is called as CertCentral, hence please refer below Digicert Central UI confluence page for updated instructions: https://confluence.acquia.com/display/OE/DigiCert+-+CertCentral+UI Procedure Log into the DigiCert UI. Find the order for the certificate that is set to expire. Click \"Renew\". Ensure 1 year is selected under \"Validity Period\", click \"Continue\". Follow the prompts and enter the information requested in the next form. Choose Account credit as the payment method. Once renewal is complete, please see the instructions under Deploy Certificate . An email will be sent to ops@acquia.com with a receipt attached as a PDF file. Forward this to acctspay@acquia.com .","title":"Renewing SSL Certificates"},{"location":"kanban_tickets/renewing_certificates/#renewing-ssl-certificates","text":"","title":"Renewing SSL Certificates"},{"location":"kanban_tickets/renewing_certificates/#preface","text":"Renewing an SSL certificate, with the exception of Acquia-controlled UCCs such as ssl_ucc* , must be communicated and approved by the Account Manager(s) for the customer(s) that are affected by the renewal.","title":"Preface"},{"location":"kanban_tickets/renewing_certificates/#important-note","text":"Our DigiCert account is upgraded recently where the new platform is called as CertCentral, hence please refer below Digicert Central UI confluence page for updated instructions: https://confluence.acquia.com/display/OE/DigiCert+-+CertCentral+UI","title":"Important Note"},{"location":"kanban_tickets/renewing_certificates/#procedure","text":"Log into the DigiCert UI. Find the order for the certificate that is set to expire. Click \"Renew\". Ensure 1 year is selected under \"Validity Period\", click \"Continue\". Follow the prompts and enter the information requested in the next form. Choose Account credit as the payment method. Once renewal is complete, please see the instructions under Deploy Certificate . An email will be sent to ops@acquia.com with a receipt attached as a PDF file. Forward this to acctspay@acquia.com .","title":"Procedure"},{"location":"kanban_tickets/renewing_puppet_master_cert/","text":"Renewing SSL cert for puppet master This runbook comes into action when SSL certificate on the master is expiring. You will notice the following error while running puppet agent on the client nodes: Warning: Certificate 'master.i.devcloud.f.e2a.us' will expire on 2018-11-11T16:13:12UTC Steps to renew puppet master SSL cert Verify the SSL cert needs to be renewed by running puppet agent -t OR in Masterless Puppet mode sudo run-puppet on both master and client. Clean up old SSL cert on puppet master by running the following command: puppet cert clean $(hostname) Generate new SSL cert by executing the following command on master: puppet cert generate $(hostname) --dns_alt_names=$(hostname),$(hostname \\ | sed -e 's/master\\.i\\./master\\.e\\./') Restart apache on puppet master to make sure new cert is loaded by puppet. We would need to kill existing puppet processes: pkill -u puppet && /etc/init.d/apache2 restart Run puppet agent -t OR in Masterless Puppet mode sudo run-puppet on both master and client to verify that cert has been renewed. Also verify the expiry date using openssl command on both master and client: echo |openssl s_client -connect master.i.devcloud.f.e2a.us:8140 -showcerts |& openssl x509 -noout -enddate","title":"Renewing SSL cert for puppet master"},{"location":"kanban_tickets/renewing_puppet_master_cert/#renewing-ssl-cert-for-puppet-master","text":"This runbook comes into action when SSL certificate on the master is expiring. You will notice the following error while running puppet agent on the client nodes: Warning: Certificate 'master.i.devcloud.f.e2a.us' will expire on 2018-11-11T16:13:12UTC","title":"Renewing SSL cert for puppet master"},{"location":"kanban_tickets/renewing_puppet_master_cert/#steps-to-renew-puppet-master-ssl-cert","text":"Verify the SSL cert needs to be renewed by running puppet agent -t OR in Masterless Puppet mode sudo run-puppet on both master and client. Clean up old SSL cert on puppet master by running the following command: puppet cert clean $(hostname) Generate new SSL cert by executing the following command on master: puppet cert generate $(hostname) --dns_alt_names=$(hostname),$(hostname \\ | sed -e 's/master\\.i\\./master\\.e\\./') Restart apache on puppet master to make sure new cert is loaded by puppet. We would need to kill existing puppet processes: pkill -u puppet && /etc/init.d/apache2 restart Run puppet agent -t OR in Masterless Puppet mode sudo run-puppet on both master and client to verify that cert has been renewed. Also verify the expiry date using openssl command on both master and client: echo |openssl s_client -connect master.i.devcloud.f.e2a.us:8140 -showcerts |& openssl x509 -noout -enddate","title":"Steps to renew puppet master SSL cert"},{"location":"kanban_tickets/resize_volumes_bastion/","text":"Modify volumes on bastions manually Modifying EBS volumes for bastions has unique concerns that go above and beyond other server types. If you are modifying volumes on a server type other than a bastion, please refer to the page on Resizing volumes manually . EBS volumes can be resized to any of the supported sizes , provided the data fits. The supported sizes are a business restriction, not a technical restriction. The sizes of ephemeral volumes ('/dev/xvda' and '/dev/xvdb') are tied to the ami_type and can not be changed. EBS volumes can not be resized directly. Instead, we create new EBS volumes, copy the data, and exchange the volumes. Creating the volumes and copying the data is done in two phases with a prep phase and a maintenance window phase. Copying the data is typically done with rsync. Exchanging the volumes requires a maintenance window. During this window, services are stopped and an incremental copy is made before volumes are exchanged. Preparatory steps To be completed before the maintenance window opens. If downsizing, make sure the space currently used is less than 95% of the new volume size. SERVER= SIZE= TYPE=gp3 INSTANCE=$(ah-server list $SERVER --no-name -c ec2_id) REGION=$(ah-server list $SERVER --no-name -c ec2_region) AZ=$(ah-server list $SERVER --no-name -c ec2_availability_zone) OLD_VOL=$(ah-server list $SERVER --no-name -c ebs_id) KMS=$(aws ec2 describe-volumes --region ${REGION} --volume-ids ${OLD_VOL} --query 'Volumes[].KmsKeyId' --output text) Gather volume information and create a backup snapshot Gather volume information and put it in the ticket. sv-vollist $SERVER Create a snapshot of the current volume - this can be used to restore the volume in case of issues with the rsync aws ec2 create-snapshot --volume-id $OLD_VOL --description \"CL-XXXXX User\" Creating and attaching the volume Create a new volume of the new size. As a reminder, database volumes need to stay the same type unless specifically requested and approved. For a MySQL volume, do this: aws ec2 create-volume \\ --encrypted \\ --kms-key-id $KMS \\ --region $REGION \\ --availability-zone $AZ \\ --size $SIZE \\ --volume-type $TYPE Ensure that the volume was created. The describe-volumes will show the new volume if the request succeeded. If this create volume request fails, ensure your kms key is correct. aws ec2 describe-volumes --region $REGION --volume-ids <<NEW VOL ID>> Set variables for the old and new volumes. OLD_VOL= NEW_VOL= View the tags from the current volume. aws ec2 describe-volumes \\ --region $REGION \\ --volume-ids $OLD_VOL \\ --output text Set the DEVICE and TMP_DEVICE variables. TMP_DEVICE is the new temporary attach point for the volume, such as /dev/xvdz . DEVICE=$(ah-server get $SERVER | grep device | awk -F: '{print $2}' | xargs) TMP_DEVICE=/dev/xvdz Tag the new volume. The launching user is you, not the original person. aws ec2 create-tags \\ --region $REGION \\ --resources $NEW_VOL \\ --tags Key=ah_stage,Value=$FIELDS_STAGE \\ Key=ah_server_name,Value=$SERVER \\ Key=ah_attach_to_device,Value=$DEVICE \\ Key=ah_launching_user,Value=$USER Attach the volume at the temporary device. aws ec2 attach-volume \\ --region $REGION \\ --volume-id $NEW_VOL \\ --instance-id $INSTANCE \\ --device $TMP_DEVICE Formatting the file system On the server, export variables so they are usable from a Screen session. export NEW_DEV=xvdz export OLD_DEV=xvdm export NEW_MOUNTPOINT=/vol/ebs2 export OLD_MOUNTPOINT=/vol/ebs1 Create the filesystem. mkfs.xfs /dev/$NEW_DEV Create the mountpoint. This may exist from a previous resize. As long as nothing is mounted, that is fine. mkdir -p $NEW_MOUNTPOINT Mount. mount /dev/$NEW_DEV $NEW_MOUNTPOINT Confirm the directory was formatted properly xfs_info /dev/$NEW_DEV Should have output like meta-data=/dev/xvdz isize=512 agcount=4, agsize=32768000 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=1 spinodes=0 data = bsize=4096 blocks=131072000, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=1 log =internal bsize=4096 blocks=64000, version=2 = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 Copy data: rsync method Start screen. screen -S rsync-$NEW_DEV Run rsync. Ensure there are trailing slashes on these paths. (date; rsync -avP ${OLD_MOUNTPOINT}/ ${NEW_MOUNTPOINT}/; date) \\ | tee -a /mnt/tmp/vol-resize-${NEW_DEV}-rsync-0.log ;sh Detach from Screen Ctrl + ad Reattach to Screen screen -r rsync-$NEW_DEV Maintenance window steps These steps must be completed during the assigned maintenance window. Set these variables on the bastion. SERVER= INSTANCE=$(ah-server list $SERVER --no-name -c ec2_id) REGION=$(ah-server list $SERVER --no-name -c ec2_region) AZ=$(ah-server list $SERVER --no-name -c ec2_availability_zone) OLD_VOL= NEW_VOL= DEV=xvdm Set these variables on the server. JIRA_TICKET= DEV= MOUNTPOINT= Disable monitoring to prevent alerts since puppet will be disabled sv-mondisable ${SERVER} Disable Puppet and stop cron. puppet agent --disable \"$JIRA_TICKET - $USER - /dev/$DEV resize.\" service cron stop Confirm puppet is stopped cat $(puppet agent --configprint agent_disabled_lockfile) Verify nothing is using the volume. meh or other services may need to be stopped. lsof | grep $MOUNTPOINT User sessions in the bastion homedirs may also need to be killed. To list user sessions: who -u To courteously kill specific user sessions with a warning: USERNAME= PTYNAME= echo \"Your session will terminate in 30 seconds\" | write $USERNAME $PTYNAME && sleep 30 && killall -u $USERNAME -HUP Swap the volumes once the data transfer is complete Unmount the current and replacement volumes. umount /vol/ebs1 umount /vol/ebs2 Detach both volumes. aws ec2 detach-volume --region $REGION --volume-id $OLD_VOL aws ec2 detach-volume --region $REGION --volume-id $NEW_VOL Attach the new volume, no longer at the temporary location. aws ec2 attach-volume \\ --region $REGION \\ --volume-id $NEW_VOL \\ --instance-id $INSTANCE \\ --device /dev/$DEV Mount the new volume, no longer at the temporary mount point. mount /dev/xvdm /vol/ebs1 Attach the old volume at the temporary location. The old volume should be left attached to the bastion at a temporary mountpoint for a brief transition time, in case Ops needs it. aws ec2 attach-volume \\ --region $REGION \\ --volume-id $OLD_VOL \\ --instance-id $INSTANCE \\ --device $TMP_DEVICE Mount the old volume as read-only mount -o ro /dev/xvdz /vol/ebs2 Create a follow-up JIRA ticket to unmount and detach the old volume in a week or so Enable and run Puppet to start any services stopped earlier. puppet agent --enable; puppet agent --test service cron start Turn monitoring back on sv-monenable ${SERVER} Update the volume id in the fields record. Note : When you modify a volume with ah-server , a brand new volume ID is created. You must run sv-vollist again if you need to know the new volume id. ah-server edit $SERVER -s ebs_id=$NEW_VOL When the old volume is detached and ready to be reaped, tag it as having been replaced. (Remove some unused tags to make room.) aws ec2 delete-tags \\ --region $REGION \\ --resources $OLD_VOL \\ --tags Key=title Key=active aws ec2 create-tags \\ --region $REGION \\ --resources $OLD_VOL \\ --tags Key=ops_replaced_in,Value=$JIRA_TICKET \\ Key=ah_resize_info,Value=${OLD_VOL}/$(date +%Y%m%d%H%M -d \"+7 days\") The replaced volume will be deleted in 1 week by the cronjob on the master","title":"Modify volumes on bastions manually"},{"location":"kanban_tickets/resize_volumes_bastion/#modify-volumes-on-bastions-manually","text":"Modifying EBS volumes for bastions has unique concerns that go above and beyond other server types. If you are modifying volumes on a server type other than a bastion, please refer to the page on Resizing volumes manually . EBS volumes can be resized to any of the supported sizes , provided the data fits. The supported sizes are a business restriction, not a technical restriction. The sizes of ephemeral volumes ('/dev/xvda' and '/dev/xvdb') are tied to the ami_type and can not be changed. EBS volumes can not be resized directly. Instead, we create new EBS volumes, copy the data, and exchange the volumes. Creating the volumes and copying the data is done in two phases with a prep phase and a maintenance window phase. Copying the data is typically done with rsync. Exchanging the volumes requires a maintenance window. During this window, services are stopped and an incremental copy is made before volumes are exchanged.","title":"Modify volumes on bastions manually"},{"location":"kanban_tickets/resize_volumes_bastion/#preparatory-steps","text":"To be completed before the maintenance window opens. If downsizing, make sure the space currently used is less than 95% of the new volume size. SERVER= SIZE= TYPE=gp3 INSTANCE=$(ah-server list $SERVER --no-name -c ec2_id) REGION=$(ah-server list $SERVER --no-name -c ec2_region) AZ=$(ah-server list $SERVER --no-name -c ec2_availability_zone) OLD_VOL=$(ah-server list $SERVER --no-name -c ebs_id) KMS=$(aws ec2 describe-volumes --region ${REGION} --volume-ids ${OLD_VOL} --query 'Volumes[].KmsKeyId' --output text)","title":"Preparatory steps"},{"location":"kanban_tickets/resize_volumes_bastion/#gather-volume-information-and-create-a-backup-snapshot","text":"Gather volume information and put it in the ticket. sv-vollist $SERVER Create a snapshot of the current volume - this can be used to restore the volume in case of issues with the rsync aws ec2 create-snapshot --volume-id $OLD_VOL --description \"CL-XXXXX User\"","title":"Gather volume information and create a backup snapshot"},{"location":"kanban_tickets/resize_volumes_bastion/#creating-and-attaching-the-volume","text":"Create a new volume of the new size. As a reminder, database volumes need to stay the same type unless specifically requested and approved. For a MySQL volume, do this: aws ec2 create-volume \\ --encrypted \\ --kms-key-id $KMS \\ --region $REGION \\ --availability-zone $AZ \\ --size $SIZE \\ --volume-type $TYPE Ensure that the volume was created. The describe-volumes will show the new volume if the request succeeded. If this create volume request fails, ensure your kms key is correct. aws ec2 describe-volumes --region $REGION --volume-ids <<NEW VOL ID>> Set variables for the old and new volumes. OLD_VOL= NEW_VOL= View the tags from the current volume. aws ec2 describe-volumes \\ --region $REGION \\ --volume-ids $OLD_VOL \\ --output text Set the DEVICE and TMP_DEVICE variables. TMP_DEVICE is the new temporary attach point for the volume, such as /dev/xvdz . DEVICE=$(ah-server get $SERVER | grep device | awk -F: '{print $2}' | xargs) TMP_DEVICE=/dev/xvdz Tag the new volume. The launching user is you, not the original person. aws ec2 create-tags \\ --region $REGION \\ --resources $NEW_VOL \\ --tags Key=ah_stage,Value=$FIELDS_STAGE \\ Key=ah_server_name,Value=$SERVER \\ Key=ah_attach_to_device,Value=$DEVICE \\ Key=ah_launching_user,Value=$USER Attach the volume at the temporary device. aws ec2 attach-volume \\ --region $REGION \\ --volume-id $NEW_VOL \\ --instance-id $INSTANCE \\ --device $TMP_DEVICE","title":"Creating and attaching the volume"},{"location":"kanban_tickets/resize_volumes_bastion/#formatting-the-file-system","text":"On the server, export variables so they are usable from a Screen session. export NEW_DEV=xvdz export OLD_DEV=xvdm export NEW_MOUNTPOINT=/vol/ebs2 export OLD_MOUNTPOINT=/vol/ebs1 Create the filesystem. mkfs.xfs /dev/$NEW_DEV Create the mountpoint. This may exist from a previous resize. As long as nothing is mounted, that is fine. mkdir -p $NEW_MOUNTPOINT Mount. mount /dev/$NEW_DEV $NEW_MOUNTPOINT Confirm the directory was formatted properly xfs_info /dev/$NEW_DEV Should have output like meta-data=/dev/xvdz isize=512 agcount=4, agsize=32768000 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=1 spinodes=0 data = bsize=4096 blocks=131072000, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=1 log =internal bsize=4096 blocks=64000, version=2 = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0","title":"Formatting the file system"},{"location":"kanban_tickets/resize_volumes_bastion/#copy-data-rsync-method","text":"Start screen. screen -S rsync-$NEW_DEV Run rsync. Ensure there are trailing slashes on these paths. (date; rsync -avP ${OLD_MOUNTPOINT}/ ${NEW_MOUNTPOINT}/; date) \\ | tee -a /mnt/tmp/vol-resize-${NEW_DEV}-rsync-0.log ;sh Detach from Screen Ctrl + ad Reattach to Screen screen -r rsync-$NEW_DEV","title":"Copy data: rsync method"},{"location":"kanban_tickets/resize_volumes_bastion/#maintenance-window-steps","text":"These steps must be completed during the assigned maintenance window. Set these variables on the bastion. SERVER= INSTANCE=$(ah-server list $SERVER --no-name -c ec2_id) REGION=$(ah-server list $SERVER --no-name -c ec2_region) AZ=$(ah-server list $SERVER --no-name -c ec2_availability_zone) OLD_VOL= NEW_VOL= DEV=xvdm Set these variables on the server. JIRA_TICKET= DEV= MOUNTPOINT= Disable monitoring to prevent alerts since puppet will be disabled sv-mondisable ${SERVER} Disable Puppet and stop cron. puppet agent --disable \"$JIRA_TICKET - $USER - /dev/$DEV resize.\" service cron stop Confirm puppet is stopped cat $(puppet agent --configprint agent_disabled_lockfile) Verify nothing is using the volume. meh or other services may need to be stopped. lsof | grep $MOUNTPOINT User sessions in the bastion homedirs may also need to be killed. To list user sessions: who -u To courteously kill specific user sessions with a warning: USERNAME= PTYNAME= echo \"Your session will terminate in 30 seconds\" | write $USERNAME $PTYNAME && sleep 30 && killall -u $USERNAME -HUP","title":"Maintenance window steps"},{"location":"kanban_tickets/resize_volumes_bastion/#swap-the-volumes-once-the-data-transfer-is-complete","text":"Unmount the current and replacement volumes. umount /vol/ebs1 umount /vol/ebs2 Detach both volumes. aws ec2 detach-volume --region $REGION --volume-id $OLD_VOL aws ec2 detach-volume --region $REGION --volume-id $NEW_VOL Attach the new volume, no longer at the temporary location. aws ec2 attach-volume \\ --region $REGION \\ --volume-id $NEW_VOL \\ --instance-id $INSTANCE \\ --device /dev/$DEV Mount the new volume, no longer at the temporary mount point. mount /dev/xvdm /vol/ebs1 Attach the old volume at the temporary location. The old volume should be left attached to the bastion at a temporary mountpoint for a brief transition time, in case Ops needs it. aws ec2 attach-volume \\ --region $REGION \\ --volume-id $OLD_VOL \\ --instance-id $INSTANCE \\ --device $TMP_DEVICE Mount the old volume as read-only mount -o ro /dev/xvdz /vol/ebs2 Create a follow-up JIRA ticket to unmount and detach the old volume in a week or so Enable and run Puppet to start any services stopped earlier. puppet agent --enable; puppet agent --test service cron start Turn monitoring back on sv-monenable ${SERVER} Update the volume id in the fields record. Note : When you modify a volume with ah-server , a brand new volume ID is created. You must run sv-vollist again if you need to know the new volume id. ah-server edit $SERVER -s ebs_id=$NEW_VOL When the old volume is detached and ready to be reaped, tag it as having been replaced. (Remove some unused tags to make room.) aws ec2 delete-tags \\ --region $REGION \\ --resources $OLD_VOL \\ --tags Key=title Key=active aws ec2 create-tags \\ --region $REGION \\ --resources $OLD_VOL \\ --tags Key=ops_replaced_in,Value=$JIRA_TICKET \\ Key=ah_resize_info,Value=${OLD_VOL}/$(date +%Y%m%d%H%M -d \"+7 days\") The replaced volume will be deleted in 1 week by the cronjob on the master","title":"Swap the volumes once the data transfer is complete"},{"location":"kanban_tickets/restore_snapshot_on_new_hardware/","text":"Restore Snapshots on New Hardware (ACE) This runbook deals with the procedure of restoring snapshots to newly provisioned hardware for existing sites in case a site move requires particular snapshots to be restored. It is assumed that site is already moved using the site-move workflow before proceeding with the steps below. Restore DB from backup Restoring DB backups from the DB snapshots would require help from a DBA. Rather, we can restore the full DB backup from the site's gluster brick. The steps are given below to perform this: Identify the ID of the backup you want to restore on the new hardware using ah-backup list-runs $SERVER Mount the backup on the primary fsdb/ded/db server using the following command on any backup server: backup-mount --for-run xxxx --server $SERVER or incase you need to mount two different backups, backup-mount --for-run xxxx --server $SERVER --mountpoint /mnt/xxxx --device /dev/xxx Identify the DB backup (gz file) file under /mnt/$RESTORE/brickxxxx/brick/$SITE/backups . Restore the DB backup file in gz format as follows (do not move your terminal while performing the DB restore, or it may cancel): zcat $FILE | pv | mysql $DBNAME Restore files from backup If the restore needs to be done from same snapshot, simply run the following command (specify exact path): rsync --delete -avuP --exclude 'backups' --exclude '.ssh' \\ /mnt/$RESTORE/brickxxxx/brick/$SITE /mnt/brickxxxx/brick/$SITE Verify that all files have been moved completely and permissions are correct. Perform site checks to verify everything is in the right place. site-check $SITE site-checkwebs $SITE site-checkgluster $SITE Unmount the snapshot volumes after restoring everything Unmount the snapshots after performing the above steps using the following command on any backup server: backup-unmount --server $SERVER","title":"Restore Snapshots on New Hardware (ACE)"},{"location":"kanban_tickets/restore_snapshot_on_new_hardware/#restore-snapshots-on-new-hardware-ace","text":"This runbook deals with the procedure of restoring snapshots to newly provisioned hardware for existing sites in case a site move requires particular snapshots to be restored. It is assumed that site is already moved using the site-move workflow before proceeding with the steps below.","title":"Restore Snapshots on New Hardware (ACE)"},{"location":"kanban_tickets/restore_snapshot_on_new_hardware/#restore-db-from-backup","text":"Restoring DB backups from the DB snapshots would require help from a DBA. Rather, we can restore the full DB backup from the site's gluster brick. The steps are given below to perform this: Identify the ID of the backup you want to restore on the new hardware using ah-backup list-runs $SERVER Mount the backup on the primary fsdb/ded/db server using the following command on any backup server: backup-mount --for-run xxxx --server $SERVER or incase you need to mount two different backups, backup-mount --for-run xxxx --server $SERVER --mountpoint /mnt/xxxx --device /dev/xxx Identify the DB backup (gz file) file under /mnt/$RESTORE/brickxxxx/brick/$SITE/backups . Restore the DB backup file in gz format as follows (do not move your terminal while performing the DB restore, or it may cancel): zcat $FILE | pv | mysql $DBNAME","title":"Restore DB from backup"},{"location":"kanban_tickets/restore_snapshot_on_new_hardware/#restore-files-from-backup","text":"If the restore needs to be done from same snapshot, simply run the following command (specify exact path): rsync --delete -avuP --exclude 'backups' --exclude '.ssh' \\ /mnt/$RESTORE/brickxxxx/brick/$SITE /mnt/brickxxxx/brick/$SITE Verify that all files have been moved completely and permissions are correct. Perform site checks to verify everything is in the right place. site-check $SITE site-checkwebs $SITE site-checkgluster $SITE","title":"Restore files from backup"},{"location":"kanban_tickets/restore_snapshot_on_new_hardware/#unmount-the-snapshot-volumes-after-restoring-everything","text":"Unmount the snapshots after performing the above steps using the following command on any backup server: backup-unmount --server $SERVER","title":"Unmount the snapshot volumes after restoring everything"},{"location":"kanban_tickets/restore_volumes/","text":"Restore Volume Backups Note: if you are looking to restore snapshots to new hardware in ACE, use this runbook instead. Procedure Set the Variables SOURCE_SERVER= JIRA_TICKET= SOURCE_SERVER is the server whose data needs to be restored from backups Find the backup to be used for restore Find the Run ID corresponding to the date for the recovery request is received. Find the same or nearest matching date and choose Run ID for backup run. Date for the Run ID should be the same date or closest prior to the requested date. Consult with support to determine the backup to be used for restore when backup from the exact date is not found. Choose the backup run closest to the time you want to restore from. The first section is for the fs-cluster (sdo volumes) and the second is for the db-cluster (sdm volumes) ah-backup list-runs ${SOURCE_SERVER} task, id: 4, cluster_type: fs-cluster, cluster_id: 3, frequency: 3600 run, id: 71836300, status: retained_monthly, created_at: 2015-07-01T00 run, id: 75622654, status: retained_monthly, created_at: 2015-08-01T03 [...] task, id: 59, cluster_type: db-cluster, cluster_id: 20, frequency: 3600 run, id: 71832911, status: retained_monthly, created_at: 2015-06-30T23 run, id: 75621516, status: retained_monthly, created_at: 2015-08-01T02 [...] Mounting (Not ACSF DB) Run backup-mount on any backup server and mount it on the customer's lowest numbered web server, which could be a ded or web . RUN_ID= # WEB_RESTORE is the customer's 1st web WEB_RESTORE= BACKUP=$(ah-server list backup% -w status=0 | head -n1) fssh ${BACKUP} \"sudo backup-mount --for-run ${RUN_ID} --server ${WEB_RESTORE}\" Mounting ACSF DB Allocate and launch a new staging server and configure it for the cluster you're restoring, which is $SOURCE_SERVER AMI_TYPE=$(ah-server list ${SOURCE_SERVER} -c ami_type --no-name) REGION=$(ah-server list ${SOURCE_SERVER} -c ec2_region --no-name) AZ=$(ah-server list ${SOURCE_SERVER} -c ec2_availability_zone --no-name) VPC_ID=$(ah-server list ${SOURCE_SERVER} -c vpc_id --no-name) if [[ $VPC_ID -ne \"nil\" ]];then \\ VPC=\"$(ah-vpc list % -w id=$VPC_ID)\" fi DB_RESTORE=$(ah-provision stack staging \\ -i $AMI_TYPE -r $REGION -z $AZ -d 10 -g 10 -n $(date +%s) -V $VPC) echo $DB_RESTORE ah-server tag add $DB_RESTORE --tags dbrestore monitor_suppress sv-taskrelaunch server $DB_RESTORE Mount the backup to restore server fssh ${DB_RESTORE} \"sudo mysql -e 'show databases;' > /dev/null \\ && echo 'mysql working'\" fssh ${BACKUP} \"sudo backup-mount --for-run ${RUN_ID} --server ${DB_RESTORE}\" fssh ${DB_RESTORE} \"sudo su -c 'puppet agent --disable ${USER} - ${JIRA_TICKET} && service mysql stop && unlink /var/lib/mysql && ln -s /mnt/restores/restore0/mysql /var/lib/mysql'\" fssh ${SOURCE_SERVER} sudo cat /root/.my.cnf \\ | fssh ${DB_RESTORE} \"sudo su -c 'cat - > /root/.my.cnf'\" fssh ${DB_RESTORE} \"sudo service mysql start\" sv-resetdebian ${SOURCE_SERVER},${DB_RESTORE} Communication Update the ticket with the server name on which you mounted the volume you restored from backup and the mountpoint and put the ticket in 'waiting for feedback' Cleanup (Not ACSF DB) Run backup-unmount (sudo required) after feedback is submitted and restore is finished RESTORE_WEB= fssh ${BACKUP} \"sudo backup-unmount --server ${WEB_RESTORE}\" Cleanup (ACSF DB) Run backup-unmount and suspend the dbrestore server after feedback is submitted and restore is finished DB_RESTORE= BACKUP=$(ah-server list backup% -w status=0 | head -n1) fssh ${DB_RESTORE} \"sudo service mysql stop && sudo unlink /var/lib/mysql\" fssh ${BACKUP} \"sudo backup-unmount --server ${DB_RESTORE}\" ah-server suspend ${DB_RESTORE} ah-server terminate ${DB_RESTORE} Restore Repo Restoring a customer's repo is similar to a normal volume restore, but instead you are restoring an svn server's backup volume. Identify the site's svn server and list its backup runs: SITE= SVN=$(ah-server list site:${SITE} -w type=svn status=0) ah-backup list-runs ${SVN} -a -s Provide the list of svn volume backups to Support and coordinate with them to determine the most appropriate snapshot to restore. Once a backup has been identified, mount it to the svn server: RUN_ID= BACKUP=$(ah-server list backup% -w status=0 | head -n1) fssh ${BACKUP} \"sudo backup-mount --for-run ${RUN_ID} --server ${SVN}\" SSH into the svn server and verify the location of the customer's repo on the backup volume. The path should be something like /mnt/restores/restore0/${SITE}/${SITE}.git/ . Once you've found their repo, make a tarball of it in /mnt/tmp : OP= SITE= mkdir /mnt/tmp/${OP} cd /mnt/restores/restore0 tar -czvf /mnt/tmp/${OP}/${SITE}.tar.gz ${SITE} Inform Support of the location of the tarball so that they can restore the customer's repo appropriately. Unmount the backup volume: fssh ${BACKUP} \"sudo backup-unmount --server ${SVN}\" If Support has everything they need, you're done.","title":"Restore Volume Backups"},{"location":"kanban_tickets/restore_volumes/#restore-volume-backups","text":"Note: if you are looking to restore snapshots to new hardware in ACE, use this runbook instead.","title":"Restore Volume Backups"},{"location":"kanban_tickets/restore_volumes/#procedure","text":"","title":"Procedure"},{"location":"kanban_tickets/restore_volumes/#set-the-variables","text":"SOURCE_SERVER= JIRA_TICKET= SOURCE_SERVER is the server whose data needs to be restored from backups","title":"Set the Variables"},{"location":"kanban_tickets/restore_volumes/#find-the-backup-to-be-used-for-restore","text":"Find the Run ID corresponding to the date for the recovery request is received. Find the same or nearest matching date and choose Run ID for backup run. Date for the Run ID should be the same date or closest prior to the requested date. Consult with support to determine the backup to be used for restore when backup from the exact date is not found. Choose the backup run closest to the time you want to restore from. The first section is for the fs-cluster (sdo volumes) and the second is for the db-cluster (sdm volumes) ah-backup list-runs ${SOURCE_SERVER} task, id: 4, cluster_type: fs-cluster, cluster_id: 3, frequency: 3600 run, id: 71836300, status: retained_monthly, created_at: 2015-07-01T00 run, id: 75622654, status: retained_monthly, created_at: 2015-08-01T03 [...] task, id: 59, cluster_type: db-cluster, cluster_id: 20, frequency: 3600 run, id: 71832911, status: retained_monthly, created_at: 2015-06-30T23 run, id: 75621516, status: retained_monthly, created_at: 2015-08-01T02 [...]","title":"Find the backup to be used for restore"},{"location":"kanban_tickets/restore_volumes/#mounting-not-acsf-db","text":"Run backup-mount on any backup server and mount it on the customer's lowest numbered web server, which could be a ded or web . RUN_ID= # WEB_RESTORE is the customer's 1st web WEB_RESTORE= BACKUP=$(ah-server list backup% -w status=0 | head -n1) fssh ${BACKUP} \"sudo backup-mount --for-run ${RUN_ID} --server ${WEB_RESTORE}\"","title":"Mounting (Not ACSF DB)"},{"location":"kanban_tickets/restore_volumes/#mounting-acsf-db","text":"Allocate and launch a new staging server and configure it for the cluster you're restoring, which is $SOURCE_SERVER AMI_TYPE=$(ah-server list ${SOURCE_SERVER} -c ami_type --no-name) REGION=$(ah-server list ${SOURCE_SERVER} -c ec2_region --no-name) AZ=$(ah-server list ${SOURCE_SERVER} -c ec2_availability_zone --no-name) VPC_ID=$(ah-server list ${SOURCE_SERVER} -c vpc_id --no-name) if [[ $VPC_ID -ne \"nil\" ]];then \\ VPC=\"$(ah-vpc list % -w id=$VPC_ID)\" fi DB_RESTORE=$(ah-provision stack staging \\ -i $AMI_TYPE -r $REGION -z $AZ -d 10 -g 10 -n $(date +%s) -V $VPC) echo $DB_RESTORE ah-server tag add $DB_RESTORE --tags dbrestore monitor_suppress sv-taskrelaunch server $DB_RESTORE Mount the backup to restore server fssh ${DB_RESTORE} \"sudo mysql -e 'show databases;' > /dev/null \\ && echo 'mysql working'\" fssh ${BACKUP} \"sudo backup-mount --for-run ${RUN_ID} --server ${DB_RESTORE}\" fssh ${DB_RESTORE} \"sudo su -c 'puppet agent --disable ${USER} - ${JIRA_TICKET} && service mysql stop && unlink /var/lib/mysql && ln -s /mnt/restores/restore0/mysql /var/lib/mysql'\" fssh ${SOURCE_SERVER} sudo cat /root/.my.cnf \\ | fssh ${DB_RESTORE} \"sudo su -c 'cat - > /root/.my.cnf'\" fssh ${DB_RESTORE} \"sudo service mysql start\" sv-resetdebian ${SOURCE_SERVER},${DB_RESTORE}","title":"Mounting ACSF DB"},{"location":"kanban_tickets/restore_volumes/#communication","text":"Update the ticket with the server name on which you mounted the volume you restored from backup and the mountpoint and put the ticket in 'waiting for feedback'","title":"Communication"},{"location":"kanban_tickets/restore_volumes/#cleanup-not-acsf-db","text":"Run backup-unmount (sudo required) after feedback is submitted and restore is finished RESTORE_WEB= fssh ${BACKUP} \"sudo backup-unmount --server ${WEB_RESTORE}\"","title":"Cleanup (Not ACSF DB)"},{"location":"kanban_tickets/restore_volumes/#cleanup-acsf-db","text":"Run backup-unmount and suspend the dbrestore server after feedback is submitted and restore is finished DB_RESTORE= BACKUP=$(ah-server list backup% -w status=0 | head -n1) fssh ${DB_RESTORE} \"sudo service mysql stop && sudo unlink /var/lib/mysql\" fssh ${BACKUP} \"sudo backup-unmount --server ${DB_RESTORE}\" ah-server suspend ${DB_RESTORE} ah-server terminate ${DB_RESTORE}","title":"Cleanup (ACSF DB)"},{"location":"kanban_tickets/restore_volumes/#restore-repo","text":"Restoring a customer's repo is similar to a normal volume restore, but instead you are restoring an svn server's backup volume. Identify the site's svn server and list its backup runs: SITE= SVN=$(ah-server list site:${SITE} -w type=svn status=0) ah-backup list-runs ${SVN} -a -s Provide the list of svn volume backups to Support and coordinate with them to determine the most appropriate snapshot to restore. Once a backup has been identified, mount it to the svn server: RUN_ID= BACKUP=$(ah-server list backup% -w status=0 | head -n1) fssh ${BACKUP} \"sudo backup-mount --for-run ${RUN_ID} --server ${SVN}\" SSH into the svn server and verify the location of the customer's repo on the backup volume. The path should be something like /mnt/restores/restore0/${SITE}/${SITE}.git/ . Once you've found their repo, make a tarball of it in /mnt/tmp : OP= SITE= mkdir /mnt/tmp/${OP} cd /mnt/restores/restore0 tar -czvf /mnt/tmp/${OP}/${SITE}.tar.gz ${SITE} Inform Support of the location of the tarball so that they can restore the customer's repo appropriately. Unmount the backup volume: fssh ${BACKUP} \"sudo backup-unmount --server ${SVN}\" If Support has everything they need, you're done.","title":"Restore Repo"},{"location":"kanban_tickets/revert_ssl/","text":"Restoring an Acquia-Managed SSL Cert If something goes wrong with an SSL deployment for any reason, Ops will often need to (quickly) restore a previously working version of the customer's SSL to restore their site. The procedure below should work in most situations where a given SSL tag has a valid certificate registered in hosting-api. There could be other difficulties: ...where any balancer found has more than one SSL tag. ...where not all balancers with the SSL tag have a valid backup cert/key available. ...where not all balancers with the SSL tag have the same backup cert/key. If you encounter any of these problems, you should verify that the SSL tag is correct (generally of the form ssl_<sitegroup> ) and that all servers with that tag are tagged appropriately. After these checks you will be able to know what you should do, you will know if you should use the default Acquia certificate for a given balancers/clusters or override the default certificatre with a custom one. How to revert certificates for LEGACY BALANCERS Identify the SSL tag for the cert that you need to revert and verify that it points to the balancers you expect it to. SSL tags are of the form ssl_* . TAG= ah-server list tag:${TAG} -w status=0 type=bal If the tag is good and there are no surprises in the server list, revert the cert. If you need to restore the Acquia's default certificate or the realm's default certificate follow the procedure Remove a certificate override (Legacy balancer) . If you want to revert to a custom certificate use the procedure Deploy a certificate override (Legacy balancer) . Done! How to revert certificates for EDGE CLUSTERS Since the certificate is configured for all sites within an Edge Cluster: If you need to restore Acquia's default certificate or the realm's default certificate follow the procedure Remove a certificate override (Edge cluster) . In case you need to revert to a custom certificate, use the procedure Deploy a certificate override (Edge cluster) . Done!","title":"Restoring an Acquia-Managed SSL Cert"},{"location":"kanban_tickets/revert_ssl/#restoring-an-acquia-managed-ssl-cert","text":"If something goes wrong with an SSL deployment for any reason, Ops will often need to (quickly) restore a previously working version of the customer's SSL to restore their site. The procedure below should work in most situations where a given SSL tag has a valid certificate registered in hosting-api. There could be other difficulties: ...where any balancer found has more than one SSL tag. ...where not all balancers with the SSL tag have a valid backup cert/key available. ...where not all balancers with the SSL tag have the same backup cert/key. If you encounter any of these problems, you should verify that the SSL tag is correct (generally of the form ssl_<sitegroup> ) and that all servers with that tag are tagged appropriately. After these checks you will be able to know what you should do, you will know if you should use the default Acquia certificate for a given balancers/clusters or override the default certificatre with a custom one.","title":"Restoring an Acquia-Managed SSL Cert"},{"location":"kanban_tickets/revert_ssl/#how-to-revert-certificates-for-legacy-balancers","text":"Identify the SSL tag for the cert that you need to revert and verify that it points to the balancers you expect it to. SSL tags are of the form ssl_* . TAG= ah-server list tag:${TAG} -w status=0 type=bal If the tag is good and there are no surprises in the server list, revert the cert. If you need to restore the Acquia's default certificate or the realm's default certificate follow the procedure Remove a certificate override (Legacy balancer) . If you want to revert to a custom certificate use the procedure Deploy a certificate override (Legacy balancer) . Done!","title":"How to revert certificates for LEGACY BALANCERS"},{"location":"kanban_tickets/revert_ssl/#how-to-revert-certificates-for-edge-clusters","text":"Since the certificate is configured for all sites within an Edge Cluster: If you need to restore Acquia's default certificate or the realm's default certificate follow the procedure Remove a certificate override (Edge cluster) . In case you need to revert to a custom certificate, use the procedure Deploy a certificate override (Edge cluster) . Done!","title":"How to revert certificates for EDGE CLUSTERS"},{"location":"kanban_tickets/root_cause_analysis/","text":"Root Cause Analysis Process Ops occasionally receives RCA requests from our stakeholders, to review an incident step-by-step and come up with a plan for the future to prevent this from happening again. These analyses are blameless , so make sure to keep a neutral voice and focus on process and technology, not people. Copy the Template The template for RCAs exists at This Confluence Page . Navigate to the template and open the extended menu Click 'Copy' Make your intial edits to the document, and click \"Publish\" at the bottom of the page to create it. Perform the RCA Gather as much information as you can about the incident, including related tickets, even if they were not mentioned in the RCA request. The main sections are: Impact: What was the impact of this outage? Timeline of Events: All times are in UTC. Make a detailed timeline of events, including actions taken, start and end of outage, and handoffs. Retrospective: What went right with the outage? What went wrong, and what was lucky? Resolution: A list of action items, including things that can be completed immediately, and in the short term and long term, to keep this from reoccurring. Request Feedback/Approval Once you are done making changes, mark the ticket as \"Feedback Submitted\" and unassign it from yourself. Once a few ops people have approved it, escalate the ticket to ops management to get final approval.","title":"Root Cause Analysis Process"},{"location":"kanban_tickets/root_cause_analysis/#root-cause-analysis-process","text":"Ops occasionally receives RCA requests from our stakeholders, to review an incident step-by-step and come up with a plan for the future to prevent this from happening again. These analyses are blameless , so make sure to keep a neutral voice and focus on process and technology, not people.","title":"Root Cause Analysis Process"},{"location":"kanban_tickets/root_cause_analysis/#copy-the-template","text":"The template for RCAs exists at This Confluence Page . Navigate to the template and open the extended menu Click 'Copy' Make your intial edits to the document, and click \"Publish\" at the bottom of the page to create it.","title":"Copy the Template"},{"location":"kanban_tickets/root_cause_analysis/#perform-the-rca","text":"Gather as much information as you can about the incident, including related tickets, even if they were not mentioned in the RCA request. The main sections are: Impact: What was the impact of this outage? Timeline of Events: All times are in UTC. Make a detailed timeline of events, including actions taken, start and end of outage, and handoffs. Retrospective: What went right with the outage? What went wrong, and what was lucky? Resolution: A list of action items, including things that can be completed immediately, and in the short term and long term, to keep this from reoccurring.","title":"Perform the RCA"},{"location":"kanban_tickets/root_cause_analysis/#request-feedbackapproval","text":"Once you are done making changes, mark the ticket as \"Feedback Submitted\" and unassign it from yourself. Once a few ops people have approved it, escalate the ticket to ops management to get final approval.","title":"Request Feedback/Approval"},{"location":"kanban_tickets/search_audit/","text":"Shared Search Audit On a weekly basis, we generally do weekly audits on the amount of cores per farm. The threshold that is currently established is each shared farm can hold about 425 cores, but over utilization can sometimes cause a farm to go down. There are a few ways to keep drilling down. Assuming you have already installed the search audit tool locally here to do your weekly audits, you can also use the tool to check the current size of all shared farms. If a customer is over utilizing their limits in the shared farms, they should be moved to dedicated. To find that out, we need to use flypaper to drill down to the appropriate farm. Note that not all the newly provisioned farms work in flypaper. When going through flypaper, we should pay attention to the top 10 users by usage which you can also go into CCI to check what they are currently paying for vs what they are using To get the top 10 users https://flypaper.acquia.com/search/errors Find the colony you want to use Click on the farm you want to audit Wait for the page to load (this can take a while), and you should be able to see the top 10 cores in each farm by use Usually we can audit any farm is it's giving hotseat a lot of issues on hotseat, so if any particular farm is alerting, we can go ahead and use the above steps. After you identify the top 10 cores, you can go into CCI and search for that core. It should show what the customer is contracted for and how many queries and the amount they are allowed to have per year. Usually if we see them over-utilizing their limits, chances are we need to move them to dedicated search, but always make sure you submit an AM ticket along with it. This is not limited to shared as dedicated search tier can also go over what they pay for in wh ich we also need to submit an AM ticket to get them to pay for the next tier up where you can see here . Properly auditing and rebalancing/resizing/migrating to dedicated will ensure we get less alerts for hotseat and less chance for them to OOM Audit Step by Step Use Search Audit Tool to determine if a farm is overloaded with cores, if so, create a ticket to move cores to another farm in the same colony, and also make sure the overloaded farm isn't the default farm where you can change the settings in governor Check flypaper periodically to check the farms are mostly green, if there are mostly red, drill down to the farm and see what their usage is and use that information in CCI to see if they are going over If they are going over, and is already in dedicated \u2192 submit AM ticket to get them upsized to the next available tier, if they are shared, move them over to dedicated If they are shared farm, and is still well below the usual threshold of 400 cores but is draining resources (maybe due to more queries than normal), we should upsize the farm into the next tier. Normally we want to keep the shared farms the same size since it's easier to audit but in special cases we should upsize the shared farms if certain cores are causing an issue. No need to submit an AM ticket but we should also create a new default farm and start migrating cores off of it onto the new one after the upsize","title":"Shared Search Audit"},{"location":"kanban_tickets/search_audit/#shared-search-audit","text":"On a weekly basis, we generally do weekly audits on the amount of cores per farm. The threshold that is currently established is each shared farm can hold about 425 cores, but over utilization can sometimes cause a farm to go down. There are a few ways to keep drilling down. Assuming you have already installed the search audit tool locally here to do your weekly audits, you can also use the tool to check the current size of all shared farms. If a customer is over utilizing their limits in the shared farms, they should be moved to dedicated. To find that out, we need to use flypaper to drill down to the appropriate farm. Note that not all the newly provisioned farms work in flypaper. When going through flypaper, we should pay attention to the top 10 users by usage which you can also go into CCI to check what they are currently paying for vs what they are using","title":"Shared Search Audit"},{"location":"kanban_tickets/search_audit/#to-get-the-top-10-users","text":"https://flypaper.acquia.com/search/errors Find the colony you want to use Click on the farm you want to audit Wait for the page to load (this can take a while), and you should be able to see the top 10 cores in each farm by use Usually we can audit any farm is it's giving hotseat a lot of issues on hotseat, so if any particular farm is alerting, we can go ahead and use the above steps. After you identify the top 10 cores, you can go into CCI and search for that core. It should show what the customer is contracted for and how many queries and the amount they are allowed to have per year. Usually if we see them over-utilizing their limits, chances are we need to move them to dedicated search, but always make sure you submit an AM ticket along with it. This is not limited to shared as dedicated search tier can also go over what they pay for in wh ich we also need to submit an AM ticket to get them to pay for the next tier up where you can see here . Properly auditing and rebalancing/resizing/migrating to dedicated will ensure we get less alerts for hotseat and less chance for them to OOM","title":"To get the top 10 users"},{"location":"kanban_tickets/search_audit/#audit-step-by-step","text":"Use Search Audit Tool to determine if a farm is overloaded with cores, if so, create a ticket to move cores to another farm in the same colony, and also make sure the overloaded farm isn't the default farm where you can change the settings in governor Check flypaper periodically to check the farms are mostly green, if there are mostly red, drill down to the farm and see what their usage is and use that information in CCI to see if they are going over If they are going over, and is already in dedicated \u2192 submit AM ticket to get them upsized to the next available tier, if they are shared, move them over to dedicated If they are shared farm, and is still well below the usual threshold of 400 cores but is draining resources (maybe due to more queries than normal), we should upsize the farm into the next tier. Normally we want to keep the shared farms the same size since it's easier to audit but in special cases we should upsize the shared farms if certain cores are causing an issue. No need to submit an AM ticket but we should also create a new default farm and start migrating cores off of it onto the new one after the upsize","title":"Audit Step by Step"},{"location":"kanban_tickets/search_cert_update/","text":"Renewal ACM Certificates In Search Realm ELBs Note: To login Search jumpboxes, follow these instructions CAUTION :Make sure before proceeding above commands that you are in correct realm. As this will deploy the SSL Certificate on all the ELBs from a single realm. Download SSL certificate(single pem) from Digicert and save it in your home directory. Ops can get the private key from KeePassx(choose private key from ssl>*.acquia-search.com) Uploading new certificate/key pair for Search Realm Using a new certificate/key pair is a two step process. First, we have to upload the certificate/key pair. Then, deploy the uploaded SSL to the ELBs. Uploading a cert/key pair for ACM in Search Realm. CERT_NAME=[star_acquia-search.comyyyymmdd] CERT=[PATH To CERTIFICATE] KEY=[PATH To PRIVATE KEY] CA=[PATH To CERTIFICATION AUTHORITY] The certificate stored at `$CERT` should include the server certificate, key and CA certificates which are used to upload. Below command will upload the new certificate pair. aws iam upload-server-certificate --server-certificate-name $CERT_NAME --certificate-body file:///$CERT --private-key file:///$KEY --certificate-chain file:///$CA ###eg:aws iam upload-server-certificate --server-certificate-name star_acquia-search.com20200722 --certificate-body file:///vol/ebs1/home/chandankumar/OP-272024/cert.pem --private-key file:///vol/ebs1/home/chandankumar/OP-272024/key --certificate-chain file:///vol/ebs1/home/chandankumar/OP-272024/chain.pem Listing Destination ELBs, Copy and Paste the output in the ticket. Below command will list all the Destination Search realm's ELBs. REGIONS are us-east-1,us-west-2,ap-southeast-1,ap-southeast-2,eu-west-1. REGION=[us-east-1|us-west-2|ap-southeast-1|ap-southeast-2|eu-west-1] (select one region at a time) aws elb describe-load-balancers --region ${REGION} | grep 'LoadBalancerName' | grep -v log | awk {'print $2'} | sed 's/[\",]//g' Verify the SSL certificate before the deployment. ELB_FQDN=$(aws elb describe-load-balancers --region ${REGION} --query 'LoadBalancerDescriptions[*].[DNSName]' --output text|awk -F= '{print $1}'|head -n1) echo -n | openssl s_client -showcerts -connect $ELB_FQDN:443| openssl x509 -text 2> /dev/null | egrep 'Before|After' SSL Deployment Below command will deploy the new SSL certificate to all the realm ELBs. Repeat SSL Deployment step for each region mentioned above. CERT_ARN=[You can get it from the SSL cert upload output] eg. CERT_ARN=arn:aws:iam::209496442179:server-certificate/star_acquia-search.com20200722 for ELB in $(aws elb describe-load-balancers --region ${REGION} | grep 'LoadBalancerName' | grep -v log | awk {'print $2'} | sed 's/[\",]//g'); do aws elb set-load-balancer-listener-ssl-certificate --region $REGION --load-balancer-name $ELB --load-balancer-port 443 --ssl-certificate-id $CERT_ARN; done Verify the SSL Certificate after the deployment. ELB_FQDN=$(aws elb describe-load-balancers --region ${REGION} --query 'LoadBalancerDescriptions[*].[DNSName]' --output text|awk -F= '{print $1}'|head -n1) echo -n | openssl s_client -showcerts -connect $ELB_FQDN:443| openssl x509 -text 2> /dev/null | egrep 'Before|After' Renewal ACM Certificates In guvannuh's ELB CAUTION : Make sure that you are working in Network realm for guvannuh ELB cert update. Uploading new certificate/key pair in Network Realm for guvannuh ELB Using a new certificate/key pair is a two step process. First, we have to upload the certificate/key pair.Then, deploy the uploaded SSL to the ELBs.Ops can get the private key from KeePassx. Uploading a cert/key pair for ACM in Search Realm. The certificate stored at $CERT should include the server certificate, key and CA certificates which are used to upload. Below command will upload the new certificate pair. CERT_NAME=[star_acquia-search.comyyyymmdd] CERT=[PATH To CERTIFICATE] KEY=[PATH To PRIVATE KEY] CA=[PATH To CERTIFICATION AUTHORITY] aws iam upload-server-certificate --server-certificate-name $CERT_NAME --certificate-body file:///$CERT --private-key file:///$KEY --certificate-chain file:///$CA ###eg:aws iam upload-server-certificate --server-certificate-name star_acquia-search.com20200722 --certificate-body file:///vol/ebs1/home/chandankumar/OP-272024/cert.pem --private-key file:///vol/ebs1/home/chandankumar/OP-272024/key --certificate-chain file:///vol/ebs1/home/chandankumar/OP-272024/chain.pem Listing Destination ELB, Copy and Paste the output in the ticket. Below command will list the guvannuh ELB. REGION is us-east-1. REGION=us-east-1 GUVANNUH_ELB=$(aws elb describe-load-balancers --region ${REGION} --query 'LoadBalancerDescriptions[*].[DNSName,HealthCheck.Target]' --output text|awk -F= '{print $1,$2}'|awk '{print $1,$3}'|awk -F\\& '{print $1}'|grep guvannuh.pr od) Verify the SSL certificate before deployment. ELB_FQDN=$(aws elb describe-load-balancers --region ${REGION} --query 'LoadBalancerDescriptions[*].[DNSName,HealthCheck.Target]' --output text|awk -F= '{print $1,$2}'|awk '{print $1,$3}'|grep guvannuh|awk {'print $1'}) echo -n | openssl s_client -showcerts -connect $ELB_FQDN:443| openssl x509 -text 2> /dev/null | egrep 'Before|After' SSL Deployment Below command will deploy the new SSL certificate to guvannuh ELB. CERT_ARN=[You can get it from the SSL cert upload output] eg. CERT_ARN=arn:aws:iam::209496442179:server-certificate/star_acquia-search.com20200722 ELB_NAME=$(aws elb describe-load-balancers --region ${REGION} --query 'LoadBalancerDescriptions[*].[DNSName,HealthCheck.Target]' --output text|awk -F= '{print $1,$2}'|grep guvannuh|awk {'print $1'}|cut -c '1-6') aws elb set-load-balancer-listener-ssl-certificate --region $REGION --load-balancer-name $ELB_NAME --load-balancer-port 443 --ssl-certificate-id $CERT_ARN Verify the SSL Certificate after deployment. ELB_FQDN=$(aws elb describe-load-balancers --region ${REGION} --query 'LoadBalancerDescriptions[*].[DNSName,HealthCheck.Target]' --output text|awk -F= '{print $1,$2}'|awk '{print $1,$3}'|grep guvannuh|awk {'print $1'}) echo -n | openssl s_client -showcerts -connect $ELB_FQDN:443| openssl x509 -text 2> /dev/null | egrep 'Before|After'","title":"Renewal ACM Certificates In Search Realm ELBs"},{"location":"kanban_tickets/search_cert_update/#renewal-acm-certificates-in-search-realm-elbs","text":"Note: To login Search jumpboxes, follow these instructions CAUTION :Make sure before proceeding above commands that you are in correct realm. As this will deploy the SSL Certificate on all the ELBs from a single realm. Download SSL certificate(single pem) from Digicert and save it in your home directory. Ops can get the private key from KeePassx(choose private key from ssl>*.acquia-search.com)","title":"Renewal ACM Certificates In Search Realm ELBs"},{"location":"kanban_tickets/search_cert_update/#uploading-new-certificatekey-pair-for-search-realm","text":"Using a new certificate/key pair is a two step process. First, we have to upload the certificate/key pair. Then, deploy the uploaded SSL to the ELBs. Uploading a cert/key pair for ACM in Search Realm. CERT_NAME=[star_acquia-search.comyyyymmdd] CERT=[PATH To CERTIFICATE] KEY=[PATH To PRIVATE KEY] CA=[PATH To CERTIFICATION AUTHORITY] The certificate stored at `$CERT` should include the server certificate, key and CA certificates which are used to upload. Below command will upload the new certificate pair. aws iam upload-server-certificate --server-certificate-name $CERT_NAME --certificate-body file:///$CERT --private-key file:///$KEY --certificate-chain file:///$CA ###eg:aws iam upload-server-certificate --server-certificate-name star_acquia-search.com20200722 --certificate-body file:///vol/ebs1/home/chandankumar/OP-272024/cert.pem --private-key file:///vol/ebs1/home/chandankumar/OP-272024/key --certificate-chain file:///vol/ebs1/home/chandankumar/OP-272024/chain.pem Listing Destination ELBs, Copy and Paste the output in the ticket. Below command will list all the Destination Search realm's ELBs. REGIONS are us-east-1,us-west-2,ap-southeast-1,ap-southeast-2,eu-west-1. REGION=[us-east-1|us-west-2|ap-southeast-1|ap-southeast-2|eu-west-1] (select one region at a time) aws elb describe-load-balancers --region ${REGION} | grep 'LoadBalancerName' | grep -v log | awk {'print $2'} | sed 's/[\",]//g' Verify the SSL certificate before the deployment. ELB_FQDN=$(aws elb describe-load-balancers --region ${REGION} --query 'LoadBalancerDescriptions[*].[DNSName]' --output text|awk -F= '{print $1}'|head -n1) echo -n | openssl s_client -showcerts -connect $ELB_FQDN:443| openssl x509 -text 2> /dev/null | egrep 'Before|After' SSL Deployment Below command will deploy the new SSL certificate to all the realm ELBs. Repeat SSL Deployment step for each region mentioned above. CERT_ARN=[You can get it from the SSL cert upload output] eg. CERT_ARN=arn:aws:iam::209496442179:server-certificate/star_acquia-search.com20200722 for ELB in $(aws elb describe-load-balancers --region ${REGION} | grep 'LoadBalancerName' | grep -v log | awk {'print $2'} | sed 's/[\",]//g'); do aws elb set-load-balancer-listener-ssl-certificate --region $REGION --load-balancer-name $ELB --load-balancer-port 443 --ssl-certificate-id $CERT_ARN; done Verify the SSL Certificate after the deployment. ELB_FQDN=$(aws elb describe-load-balancers --region ${REGION} --query 'LoadBalancerDescriptions[*].[DNSName]' --output text|awk -F= '{print $1}'|head -n1) echo -n | openssl s_client -showcerts -connect $ELB_FQDN:443| openssl x509 -text 2> /dev/null | egrep 'Before|After'","title":"Uploading new certificate/key pair for Search Realm"},{"location":"kanban_tickets/search_cert_update/#renewal-acm-certificates-in-guvannuhs-elb","text":"CAUTION : Make sure that you are working in Network realm for guvannuh ELB cert update.","title":"Renewal ACM Certificates In guvannuh's ELB"},{"location":"kanban_tickets/search_cert_update/#uploading-new-certificatekey-pair-in-network-realm-for-guvannuh-elb","text":"Using a new certificate/key pair is a two step process. First, we have to upload the certificate/key pair.Then, deploy the uploaded SSL to the ELBs.Ops can get the private key from KeePassx. Uploading a cert/key pair for ACM in Search Realm. The certificate stored at $CERT should include the server certificate, key and CA certificates which are used to upload. Below command will upload the new certificate pair. CERT_NAME=[star_acquia-search.comyyyymmdd] CERT=[PATH To CERTIFICATE] KEY=[PATH To PRIVATE KEY] CA=[PATH To CERTIFICATION AUTHORITY] aws iam upload-server-certificate --server-certificate-name $CERT_NAME --certificate-body file:///$CERT --private-key file:///$KEY --certificate-chain file:///$CA ###eg:aws iam upload-server-certificate --server-certificate-name star_acquia-search.com20200722 --certificate-body file:///vol/ebs1/home/chandankumar/OP-272024/cert.pem --private-key file:///vol/ebs1/home/chandankumar/OP-272024/key --certificate-chain file:///vol/ebs1/home/chandankumar/OP-272024/chain.pem Listing Destination ELB, Copy and Paste the output in the ticket. Below command will list the guvannuh ELB. REGION is us-east-1. REGION=us-east-1 GUVANNUH_ELB=$(aws elb describe-load-balancers --region ${REGION} --query 'LoadBalancerDescriptions[*].[DNSName,HealthCheck.Target]' --output text|awk -F= '{print $1,$2}'|awk '{print $1,$3}'|awk -F\\& '{print $1}'|grep guvannuh.pr od) Verify the SSL certificate before deployment. ELB_FQDN=$(aws elb describe-load-balancers --region ${REGION} --query 'LoadBalancerDescriptions[*].[DNSName,HealthCheck.Target]' --output text|awk -F= '{print $1,$2}'|awk '{print $1,$3}'|grep guvannuh|awk {'print $1'}) echo -n | openssl s_client -showcerts -connect $ELB_FQDN:443| openssl x509 -text 2> /dev/null | egrep 'Before|After' SSL Deployment Below command will deploy the new SSL certificate to guvannuh ELB. CERT_ARN=[You can get it from the SSL cert upload output] eg. CERT_ARN=arn:aws:iam::209496442179:server-certificate/star_acquia-search.com20200722 ELB_NAME=$(aws elb describe-load-balancers --region ${REGION} --query 'LoadBalancerDescriptions[*].[DNSName,HealthCheck.Target]' --output text|awk -F= '{print $1,$2}'|grep guvannuh|awk {'print $1'}|cut -c '1-6') aws elb set-load-balancer-listener-ssl-certificate --region $REGION --load-balancer-name $ELB_NAME --load-balancer-port 443 --ssl-certificate-id $CERT_ARN Verify the SSL Certificate after deployment. ELB_FQDN=$(aws elb describe-load-balancers --region ${REGION} --query 'LoadBalancerDescriptions[*].[DNSName,HealthCheck.Target]' --output text|awk -F= '{print $1,$2}'|awk '{print $1,$3}'|grep guvannuh|awk {'print $1'}) echo -n | openssl s_client -showcerts -connect $ELB_FQDN:443| openssl x509 -text 2> /dev/null | egrep 'Before|After'","title":"Uploading new certificate/key pair in Network Realm for guvannuh ELB"},{"location":"kanban_tickets/search_index_migration/","text":"Search Index Migration Note: To login Search jumpboxes, follow these instructions Gathering information Answer the following questions first to determine the correct course of action. What index is being moved (Examples: BMRW-91821 or BMRW-91821.qa.csnma)? What farm is this index currently on. INDEX= ah-search core $INDEX What farm is the index being migrated to? If a new farm is requested, refer to Provisioning a Search Farm . What colony is the index being migrated to? If a new colony is requested, refer to Provisioning a Search Colony . Count the number of document associated with the core and document in the ticket: FARM= ls -l /mnt/gfs/${FARM}/files/indexes/${INDEX} | grep -v ^total | wc -l Also, calculate and document the size of core directories in the ticket: du -s /mnt/gfs/${FARM}/files/indexes/${INDEX} NOTE It is strongly advised not to work on a core index migration ticket if it is not a Maintenance Request. All provisioning of new Farms and Colonies should always be done in prep work or normal OP before the actual maintenance. Risks and Customer Notification The length of downtime/unavailability of the search index varies: Moving an index within the same colony does not incur downtime as the ELB endpoint does not change (only internal routing of requests). Moving an index to a different colony will incur downtime as the ELB endpoint will change and will require changes to the customer's site to route requests to the new endpoint. We can do the switch in two parts. First part is the internal move. Second part is the external move and we do need clients involvement for the second part. There will be downtime for indexing for as long as the move lasts during the internal move. This is no longer than five minutes per index. Migrate the indexes WITH data by default if index move type has not been specified in the ticket. Once the other ELB has been activated the customer will need to refresh their subscription so the new URL is pulled in to their website automatically. They can wait for cron to run and have some downtime or do this manually. If there is any public facing downtime, this needs to be communicated with the customer and this communication should confirmed in the Ops ticket by the person requesting the move. Procedures Same colony Different colony, same region Different colony, different region Same Colony Log in to Governor server. anetwork fssh ded-178 Become the Governor user. sudo ah-site-exec guvannuh.prod bash Change directory to the scripts directory. cd /var/www/html/guvannuh.prod/scripts Migrate the index. FROM= TO= CORE= ./guv_migrate_core.sh -f $FROM -t $TO -s $CORE [Optional] In case the above command times out after 10 minutes, check the underlying task that is still running in the background. TASK_ID= drush @guvannuh.prod qr-cts $TASK_ID Different Colony, Same Region As mentioned above, the customer will notice downtime as this is a 2-step process. Verify that the downtime has been scheduled with the customer and that the customer has been notified that their hostname will change and their site will require an update. Log in to Governor server. anetwork fssh ded-178 Become the Governor user. sudo ah-site-exec guvannuh.prod bash Change directory to the scripts directory. cd /var/www/html/guvannuh.prod/scripts Migrate the index. FROM= TO= CORE= ./guv_migrate_core.sh -f $FROM -t $TO -s $CORE [Optional] In case the above command times out after 10 minutes, check the underlying task that is still running in the background. TASK_ID= drush @guvannuh.prod qr-cts $TASK_ID Update the Governor to reflect the new colony & farm. Log in to the Acquia Search Governor Search for the subscription by entering the index in the Title contains textbox and clicking Apply . Click on the appropriate result Click the Edit tab. Select the correct colony from the Colony selection box. Confirm the Belongs to Farm value. Save the node. Verify changes by executing the following on bastion. CORE= ah-search core $CORE Support needs to be asked to step-in at this point in the process and update the customer's site. This is achieved by: Support should log in to the website Go to reports/status Click on \"refresh subscription\" The new URL should be visible in the reports/status page Different Colony, Different Region This process will incur downtime for the customer and is often inadvisable. In the majority of cases the customer should be strongly advised to have the index moved to the new region and farm and simply re-index. Verify that the downtime has been scheduled with the customer and that the customer has been notified that their hostname will change and their site will require an update before proceeding. Moving the index WITHOUT the data Log in to the Acquia Search Governor Search for the subscription by entering the index in the Title contains textbox and clicking Apply . Click on the appropriate result Click the Edit tab. Click the Publishing options then uncheck Published . Select the correct colony from Colony selection box. Select the correct farm from the Belongs to Farm selection box. Click Save . Click the Edit tab again. Click the Publishing options then check Published . Verify changes by executing the following on bastion. CORE= ah-search core $CORE Support needs to be asked to step-in at this point in the process and update the customer's site. This is achieved by: Support should log in to the website Go to reports/status Click on \"refresh subscription\" The new URL should be visible in the reports/status page Moving the index WITH the data Gather information, you should already know what farm the index is currently on from the gathering information step above. Get information about source farm. FARM= ah-search farm $FARM Repeat previous step for the destination farm. Set the index to read only: Log in to the Acquia Search Governor Search for the subscription by entering the index in the Title contains textbox and clicking Apply . Click on the appropriate result Click the Edit tab. Click the Read Only checkbox. Click Save . Follow these directions to rsync the index from the source to destination server. On the servers, the indexes can be found at /mnt/gfs/<FARM>m/files/indexes/<INDEX . Log onto the destination javasrv and using the Unix username retrieved above for the destination farm, change ownership of the copied indexes. UNIX_USER= FARM= CORE= sudo chown -R $UNIX_USER:$UNIX_USER /mnt/gfs/${FARM}m/files/indexes/${CORE} Log in to the governor and change the colony and farm for the index. Log in to the Acquia Search Governor Search for the subscription by entering the index in the Title contains textbox and clicking Apply . Click on the appropriate result. Click the Edit tab. Select the correct colony from Colony selection box. Select the correct farm from the Belongs to Farm selection box. Click Save . Verify if everything is correct. The index should get updated in Acquia CCI with a new balancer, it should match the balancer for the new farm. Reload everything in the new farms: JAVASRV= JAVAEPHEM= fssh $JAVASRV UNIX_USER= CORE= sudo su - $UNIX_USER rake update_subscription_data rake client_force_reload client=${CORE} rake cron fssh $JAVAEPHEM UNIX_USER= CORE= sudo su - $UNIX_USER rake update_subscription_data rake client_force_reload client=${CORE} rake cron Support needs to be asked to step-in at this point in the process and update the customer's site. This is achieved by: Support should log in to the website Go to reports/status Click on \"refresh subscription\" The new URL should be visible in the reports/status page Make migrate index read-write. Log in to the Acquia Search Governor Search for the subscription by entering the index in the Title contains textbox and clicking Apply . Click on the appropriate result Click the Edit tab. Uncheck the Read Only checkbox. Click Save .","title":"Search Index Migration"},{"location":"kanban_tickets/search_index_migration/#search-index-migration","text":"Note: To login Search jumpboxes, follow these instructions","title":"Search Index Migration"},{"location":"kanban_tickets/search_index_migration/#gathering-information","text":"Answer the following questions first to determine the correct course of action. What index is being moved (Examples: BMRW-91821 or BMRW-91821.qa.csnma)? What farm is this index currently on. INDEX= ah-search core $INDEX What farm is the index being migrated to? If a new farm is requested, refer to Provisioning a Search Farm . What colony is the index being migrated to? If a new colony is requested, refer to Provisioning a Search Colony . Count the number of document associated with the core and document in the ticket: FARM= ls -l /mnt/gfs/${FARM}/files/indexes/${INDEX} | grep -v ^total | wc -l Also, calculate and document the size of core directories in the ticket: du -s /mnt/gfs/${FARM}/files/indexes/${INDEX} NOTE It is strongly advised not to work on a core index migration ticket if it is not a Maintenance Request. All provisioning of new Farms and Colonies should always be done in prep work or normal OP before the actual maintenance.","title":"Gathering information"},{"location":"kanban_tickets/search_index_migration/#risks-and-customer-notification","text":"The length of downtime/unavailability of the search index varies: Moving an index within the same colony does not incur downtime as the ELB endpoint does not change (only internal routing of requests). Moving an index to a different colony will incur downtime as the ELB endpoint will change and will require changes to the customer's site to route requests to the new endpoint. We can do the switch in two parts. First part is the internal move. Second part is the external move and we do need clients involvement for the second part. There will be downtime for indexing for as long as the move lasts during the internal move. This is no longer than five minutes per index. Migrate the indexes WITH data by default if index move type has not been specified in the ticket. Once the other ELB has been activated the customer will need to refresh their subscription so the new URL is pulled in to their website automatically. They can wait for cron to run and have some downtime or do this manually. If there is any public facing downtime, this needs to be communicated with the customer and this communication should confirmed in the Ops ticket by the person requesting the move.","title":"Risks and Customer Notification"},{"location":"kanban_tickets/search_index_migration/#procedures","text":"Same colony Different colony, same region Different colony, different region","title":"Procedures"},{"location":"kanban_tickets/search_index_migration/#same-colony","text":"Log in to Governor server. anetwork fssh ded-178 Become the Governor user. sudo ah-site-exec guvannuh.prod bash Change directory to the scripts directory. cd /var/www/html/guvannuh.prod/scripts Migrate the index. FROM= TO= CORE= ./guv_migrate_core.sh -f $FROM -t $TO -s $CORE [Optional] In case the above command times out after 10 minutes, check the underlying task that is still running in the background. TASK_ID= drush @guvannuh.prod qr-cts $TASK_ID","title":"Same Colony"},{"location":"kanban_tickets/search_index_migration/#different-colony-same-region","text":"As mentioned above, the customer will notice downtime as this is a 2-step process. Verify that the downtime has been scheduled with the customer and that the customer has been notified that their hostname will change and their site will require an update. Log in to Governor server. anetwork fssh ded-178 Become the Governor user. sudo ah-site-exec guvannuh.prod bash Change directory to the scripts directory. cd /var/www/html/guvannuh.prod/scripts Migrate the index. FROM= TO= CORE= ./guv_migrate_core.sh -f $FROM -t $TO -s $CORE [Optional] In case the above command times out after 10 minutes, check the underlying task that is still running in the background. TASK_ID= drush @guvannuh.prod qr-cts $TASK_ID Update the Governor to reflect the new colony & farm. Log in to the Acquia Search Governor Search for the subscription by entering the index in the Title contains textbox and clicking Apply . Click on the appropriate result Click the Edit tab. Select the correct colony from the Colony selection box. Confirm the Belongs to Farm value. Save the node. Verify changes by executing the following on bastion. CORE= ah-search core $CORE Support needs to be asked to step-in at this point in the process and update the customer's site. This is achieved by: Support should log in to the website Go to reports/status Click on \"refresh subscription\" The new URL should be visible in the reports/status page","title":"Different Colony, Same Region"},{"location":"kanban_tickets/search_index_migration/#different-colony-different-region","text":"This process will incur downtime for the customer and is often inadvisable. In the majority of cases the customer should be strongly advised to have the index moved to the new region and farm and simply re-index. Verify that the downtime has been scheduled with the customer and that the customer has been notified that their hostname will change and their site will require an update before proceeding.","title":"Different Colony, Different Region"},{"location":"kanban_tickets/search_index_migration/#moving-the-index-without-the-data","text":"Log in to the Acquia Search Governor Search for the subscription by entering the index in the Title contains textbox and clicking Apply . Click on the appropriate result Click the Edit tab. Click the Publishing options then uncheck Published . Select the correct colony from Colony selection box. Select the correct farm from the Belongs to Farm selection box. Click Save . Click the Edit tab again. Click the Publishing options then check Published . Verify changes by executing the following on bastion. CORE= ah-search core $CORE Support needs to be asked to step-in at this point in the process and update the customer's site. This is achieved by: Support should log in to the website Go to reports/status Click on \"refresh subscription\" The new URL should be visible in the reports/status page","title":"Moving the index WITHOUT the data"},{"location":"kanban_tickets/search_index_migration/#moving-the-index-with-the-data","text":"Gather information, you should already know what farm the index is currently on from the gathering information step above. Get information about source farm. FARM= ah-search farm $FARM Repeat previous step for the destination farm. Set the index to read only: Log in to the Acquia Search Governor Search for the subscription by entering the index in the Title contains textbox and clicking Apply . Click on the appropriate result Click the Edit tab. Click the Read Only checkbox. Click Save . Follow these directions to rsync the index from the source to destination server. On the servers, the indexes can be found at /mnt/gfs/<FARM>m/files/indexes/<INDEX . Log onto the destination javasrv and using the Unix username retrieved above for the destination farm, change ownership of the copied indexes. UNIX_USER= FARM= CORE= sudo chown -R $UNIX_USER:$UNIX_USER /mnt/gfs/${FARM}m/files/indexes/${CORE} Log in to the governor and change the colony and farm for the index. Log in to the Acquia Search Governor Search for the subscription by entering the index in the Title contains textbox and clicking Apply . Click on the appropriate result. Click the Edit tab. Select the correct colony from Colony selection box. Select the correct farm from the Belongs to Farm selection box. Click Save . Verify if everything is correct. The index should get updated in Acquia CCI with a new balancer, it should match the balancer for the new farm. Reload everything in the new farms: JAVASRV= JAVAEPHEM= fssh $JAVASRV UNIX_USER= CORE= sudo su - $UNIX_USER rake update_subscription_data rake client_force_reload client=${CORE} rake cron fssh $JAVAEPHEM UNIX_USER= CORE= sudo su - $UNIX_USER rake update_subscription_data rake client_force_reload client=${CORE} rake cron Support needs to be asked to step-in at this point in the process and update the customer's site. This is achieved by: Support should log in to the website Go to reports/status Click on \"refresh subscription\" The new URL should be visible in the reports/status page Make migrate index read-write. Log in to the Acquia Search Governor Search for the subscription by entering the index in the Title contains textbox and clicking Apply . Click on the appropriate result Click the Edit tab. Uncheck the Read Only checkbox. Click Save .","title":"Moving the index WITH the data"},{"location":"kanban_tickets/secondary_db_cluster/","text":"Provisioning of single-region secondary database cluster Preparation Set some variables AMI_TYPE= REGION= AZ_1= AZ_2= SDM_SIZE= SDN_SIZE=1 Procedure Determine VPC_ID for the customer esl $SITENAME Set the VPC VPC_ID= Allocate two dbmasters ah-server allocate dbmaster \\ --ami-type $AMI_TYPE --region $REGION --avail-zone $AZ_1 \\ --primary-volume-size $SDM_SIZE --secondary-volume-size $SDN_SIZE \\ -v $VPC_ID ah-server allocate dbmaster \\ --ami-type $AMI_TYPE --region $REGION --avail-zone $AZ_2 \\ --primary-volume-size $SDM_SIZE --secondary-volume-size $SDN_SIZE \\ -v $VPC_ID DBMASTER1= DBMASTER2= Allocate the db cluster ./fields-provision.php --db-cluster-allocate $DBMASTER1,$DBMASTER2 Set the id number from the output above DB_CLUSTER_ID_NUMBER=<XX> Add the db cluster to the corresponding site. For SMB Gardens realm the site is tangle00X SITE= ah-site db-cluster ${SITE} --add=$DB_CLUSTER_ID_NUMBER If SMB Gardens add the cluster to the update site as well ah-site db-cluster ${SITE}_update --add=$DB_CLUSTER_ID_NUMBER and add the db cluster to perf-mon monitoring (via the perf-mon git repo (under ./perf-mon/perf-mon/data) Launch the servers Verification You can verify the cluster was added with the list command ah-site db-cluster ${SITE} --list ah-site db-cluster ${SITE}_update --list #only for SMB Gardens The dbmaster will not show up in esl or sl until a database has been created by the customer","title":"Provisioning of single-region secondary database cluster"},{"location":"kanban_tickets/secondary_db_cluster/#provisioning-of-single-region-secondary-database-cluster","text":"","title":"Provisioning of single-region secondary database cluster"},{"location":"kanban_tickets/secondary_db_cluster/#preparation","text":"Set some variables AMI_TYPE= REGION= AZ_1= AZ_2= SDM_SIZE= SDN_SIZE=1","title":"Preparation"},{"location":"kanban_tickets/secondary_db_cluster/#procedure","text":"Determine VPC_ID for the customer esl $SITENAME Set the VPC VPC_ID= Allocate two dbmasters ah-server allocate dbmaster \\ --ami-type $AMI_TYPE --region $REGION --avail-zone $AZ_1 \\ --primary-volume-size $SDM_SIZE --secondary-volume-size $SDN_SIZE \\ -v $VPC_ID ah-server allocate dbmaster \\ --ami-type $AMI_TYPE --region $REGION --avail-zone $AZ_2 \\ --primary-volume-size $SDM_SIZE --secondary-volume-size $SDN_SIZE \\ -v $VPC_ID DBMASTER1= DBMASTER2= Allocate the db cluster ./fields-provision.php --db-cluster-allocate $DBMASTER1,$DBMASTER2 Set the id number from the output above DB_CLUSTER_ID_NUMBER=<XX> Add the db cluster to the corresponding site. For SMB Gardens realm the site is tangle00X SITE= ah-site db-cluster ${SITE} --add=$DB_CLUSTER_ID_NUMBER If SMB Gardens add the cluster to the update site as well ah-site db-cluster ${SITE}_update --add=$DB_CLUSTER_ID_NUMBER and add the db cluster to perf-mon monitoring (via the perf-mon git repo (under ./perf-mon/perf-mon/data) Launch the servers","title":"Procedure"},{"location":"kanban_tickets/secondary_db_cluster/#verification","text":"You can verify the cluster was added with the list command ah-site db-cluster ${SITE} --list ah-site db-cluster ${SITE}_update --list #only for SMB Gardens The dbmaster will not show up in esl or sl until a database has been created by the customer","title":"Verification"},{"location":"kanban_tickets/self_service_ssl/","text":"Self-service SSL (on ELBs) Acquia offers self-service SSL in ACE and ACP using elastic load balancers (ELBs). Important Note Do not abort workflows! If you are unable to resolve a problem with a workflow, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership Enabling Self-Service SSL We will sometimes be offered to perform the self-service SSL workflow on behalf of a customer. You will need the identity cert and any intermediate certs as well as the private key. Be sure to provide the full path to the files. SITENAME= CERT= CA= KEY= ah-site ssl create-elb $SITENAME --cert $CERT --ca $CA --key $KEY In rare cases you may be specifically asked to provision an Internal ELB (VPC only). Most VPC ELBs are not internal so please double check with the requestor. ah-site ssl create-elb $SITENAME --cert $CERT --ca $CA --key $KEY --scheme internal Location of the CSR, cert, and key The cert can be at the following locations. Support-Specified Certificate Path Support has provided a path to the cert and key on the customers server Pre-Existing Certificates on Bals The customer should have an ssl_$SITENAME tag on the bals and Support should be able to confirm if you can use that cert on the ELB. SITENAME=<SiteName> ah-server list site:${SITENAME} -w type=bal -c tags for FILE in {certs/acquia-sites_com.pem,private/acquia-sites_com.key}; do 2>/dev/null fssh $(ah-server list site:${SITENAME} -w type=bal | head -n1) \\ \"sudo cat /etc/ssl/${FILE}\" > ${OPSTMP}/${SITENAME}.${FILE##*.} done chmod 0400 ${OPSTMP}/${SITENAME}.key The certificate file, ${OPSTMP}/${SITENAME}.pem , will have both server certificate and CA chain. First certificate on the file ${OPSTMP}/${SITENAME}.pem is the server certificate and rest is the CA chain. Separate them out into two files. Pre-Existing Certificate on ELBs The cert and key are in the task log from a previous ELB. The last task should contain the most recent cert and key. Follow the docs on confluence to change the key output to a valid pem file. SITENAME= ah-task list -w site_id=$(ah-site list $SITENAME -c id --no-name) \\ queue=install-ssl -c created queue description The CSR, cert, and key are stored on the site's Gluster mount under /mnt/gfs/${SITENAME}/ssl . It is not possible to get these files back from AWS once they are uploaded. [03:58:06] root@web-2190.prod:/mnt/files/aluinternet/ssl# ls -lha total 48K drwx------ 3 aluinternet aluinternet 74 2013-01-10 03:45 . drwxr-x--- 13 aluinternet www-data 4.0K 2013-01-10 06:02 .. -rw------- 1 aluinternet aluinternet 3.3K 2012-12-13 03:17 ca.crt -rw------- 1 aluinternet aluinternet 1.9K 2012-12-31 15:29 ssl.crt -rw-r--r-- 1 aluinternet aluinternet 1.1K 2013-01-01 16:00 ssl.csr -rw-r--r-- 1 aluinternet aluinternet 1.7K 2013-01-01 16:00 ssl.key If the customer requests a new cert, a new key is generated, and the old files are not kept. They may, however, be retained in a backup snapshot. TODO: We should make a story to keep old files and fix the file permissions If the key is present but the cert is missing, download the cert via HTTPS from the ELB. ELB_FQDN=$(site-elbdescribe $SITENAME | grep 'elb.amazonaws.com') ahops-ssltool pull ${ELB_FQDN} You will need to edit the output to only include the certificate chain. Check the certificate and the key to make sure they are a match. ahops-ssltool verify [PATH_TO_CERT] [PATH_TO_KEY] If they pass verification, you may deploy them to the ELB normally. NOTE : If both the certificate and the key are missing from the above directory and there is no install-ssl task for the site: Support, AM/TAM, or the customer must supply the certificate, CA file, and key Support, AM/TAM, or the customer must specify which Acquia certificate they need deployed to the ELB Debugging SSL on ELBs Read the Amazon documentation regarding ELBs . Make sure the cert matches the key: ahops-ssltool verify [PATH_TO_CERT] [PATH_TO_KEY] Check the AWS console. Adding Certs to ELBs Manually or Updating an Existing ELB Cert Certs can be installed on ELBs via the AWS console. Certificates are handled as properties of ELBs called \"listeners\" on the AWS platform. Find the certs Verify that the private key is RSA formatted. It will begin with -----BEGIN RSA PRIVATE KEY----- instead of -----BEGIN PRIVATE KEY----- . Convert it to pem format with: openssl rsa -in key.key -outform PEM Paste the domain certificate (the first cert in a combined .pem file) separately from the certificate chain (the second and third cert in a combined .pem file). Upload the certificate to the ELB (the create-elb verb also updates existing ELB listeners/certificates): ah-site ssl create-elb $SITENAME --cert=[PATH_TO_CERT] --ca=[PATH_TO_CAFILE] --key=[PATH_TO_KEY] Test SSL connectivity to the ELB: ELB_FQDN=$(site-elbdescribe $SITENAME | grep 'elb.amazonaws.com') ahops-ssltool pull ${ELB_FQDN}","title":"Self-service SSL (on ELBs)"},{"location":"kanban_tickets/self_service_ssl/#self-service-ssl-on-elbs","text":"Acquia offers self-service SSL in ACE and ACP using elastic load balancers (ELBs).","title":"Self-service SSL (on ELBs)"},{"location":"kanban_tickets/self_service_ssl/#important-note","text":"Do not abort workflows! If you are unable to resolve a problem with a workflow, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership","title":"Important Note"},{"location":"kanban_tickets/self_service_ssl/#enabling-self-service-ssl","text":"We will sometimes be offered to perform the self-service SSL workflow on behalf of a customer. You will need the identity cert and any intermediate certs as well as the private key. Be sure to provide the full path to the files. SITENAME= CERT= CA= KEY= ah-site ssl create-elb $SITENAME --cert $CERT --ca $CA --key $KEY In rare cases you may be specifically asked to provision an Internal ELB (VPC only). Most VPC ELBs are not internal so please double check with the requestor. ah-site ssl create-elb $SITENAME --cert $CERT --ca $CA --key $KEY --scheme internal","title":"Enabling Self-Service SSL"},{"location":"kanban_tickets/self_service_ssl/#location-of-the-csr-cert-and-key","text":"The cert can be at the following locations.","title":"Location of the CSR, cert, and key"},{"location":"kanban_tickets/self_service_ssl/#support-specified-certificate-path","text":"Support has provided a path to the cert and key on the customers server","title":"Support-Specified Certificate Path"},{"location":"kanban_tickets/self_service_ssl/#pre-existing-certificates-on-bals","text":"The customer should have an ssl_$SITENAME tag on the bals and Support should be able to confirm if you can use that cert on the ELB. SITENAME=<SiteName> ah-server list site:${SITENAME} -w type=bal -c tags for FILE in {certs/acquia-sites_com.pem,private/acquia-sites_com.key}; do 2>/dev/null fssh $(ah-server list site:${SITENAME} -w type=bal | head -n1) \\ \"sudo cat /etc/ssl/${FILE}\" > ${OPSTMP}/${SITENAME}.${FILE##*.} done chmod 0400 ${OPSTMP}/${SITENAME}.key The certificate file, ${OPSTMP}/${SITENAME}.pem , will have both server certificate and CA chain. First certificate on the file ${OPSTMP}/${SITENAME}.pem is the server certificate and rest is the CA chain. Separate them out into two files.","title":"Pre-Existing Certificates on Bals"},{"location":"kanban_tickets/self_service_ssl/#pre-existing-certificate-on-elbs","text":"The cert and key are in the task log from a previous ELB. The last task should contain the most recent cert and key. Follow the docs on confluence to change the key output to a valid pem file. SITENAME= ah-task list -w site_id=$(ah-site list $SITENAME -c id --no-name) \\ queue=install-ssl -c created queue description The CSR, cert, and key are stored on the site's Gluster mount under /mnt/gfs/${SITENAME}/ssl . It is not possible to get these files back from AWS once they are uploaded. [03:58:06] root@web-2190.prod:/mnt/files/aluinternet/ssl# ls -lha total 48K drwx------ 3 aluinternet aluinternet 74 2013-01-10 03:45 . drwxr-x--- 13 aluinternet www-data 4.0K 2013-01-10 06:02 .. -rw------- 1 aluinternet aluinternet 3.3K 2012-12-13 03:17 ca.crt -rw------- 1 aluinternet aluinternet 1.9K 2012-12-31 15:29 ssl.crt -rw-r--r-- 1 aluinternet aluinternet 1.1K 2013-01-01 16:00 ssl.csr -rw-r--r-- 1 aluinternet aluinternet 1.7K 2013-01-01 16:00 ssl.key If the customer requests a new cert, a new key is generated, and the old files are not kept. They may, however, be retained in a backup snapshot. TODO: We should make a story to keep old files and fix the file permissions If the key is present but the cert is missing, download the cert via HTTPS from the ELB. ELB_FQDN=$(site-elbdescribe $SITENAME | grep 'elb.amazonaws.com') ahops-ssltool pull ${ELB_FQDN} You will need to edit the output to only include the certificate chain. Check the certificate and the key to make sure they are a match. ahops-ssltool verify [PATH_TO_CERT] [PATH_TO_KEY] If they pass verification, you may deploy them to the ELB normally. NOTE : If both the certificate and the key are missing from the above directory and there is no install-ssl task for the site: Support, AM/TAM, or the customer must supply the certificate, CA file, and key Support, AM/TAM, or the customer must specify which Acquia certificate they need deployed to the ELB","title":"Pre-Existing Certificate on ELBs"},{"location":"kanban_tickets/self_service_ssl/#debugging-ssl-on-elbs","text":"Read the Amazon documentation regarding ELBs . Make sure the cert matches the key: ahops-ssltool verify [PATH_TO_CERT] [PATH_TO_KEY] Check the AWS console.","title":"Debugging SSL on ELBs"},{"location":"kanban_tickets/self_service_ssl/#adding-certs-to-elbs-manually-or-updating-an-existing-elb-cert","text":"Certs can be installed on ELBs via the AWS console. Certificates are handled as properties of ELBs called \"listeners\" on the AWS platform. Find the certs Verify that the private key is RSA formatted. It will begin with -----BEGIN RSA PRIVATE KEY----- instead of -----BEGIN PRIVATE KEY----- . Convert it to pem format with: openssl rsa -in key.key -outform PEM Paste the domain certificate (the first cert in a combined .pem file) separately from the certificate chain (the second and third cert in a combined .pem file). Upload the certificate to the ELB (the create-elb verb also updates existing ELB listeners/certificates): ah-site ssl create-elb $SITENAME --cert=[PATH_TO_CERT] --ca=[PATH_TO_CAFILE] --key=[PATH_TO_KEY] Test SSL connectivity to the ELB: ELB_FQDN=$(site-elbdescribe $SITENAME | grep 'elb.amazonaws.com') ahops-ssltool pull ${ELB_FQDN}","title":"Adding Certs to ELBs Manually or Updating an Existing ELB Cert"},{"location":"kanban_tickets/single_tier_to_multi_tier/","text":"Single-tier to Multi-tier Upsize This procedure is for breaking out a customers DED pair in to a multi-tier, Web + FSDB (DED), cluster. We don't ever change the name of a server from DED to FSDB, or visa versa. This can be done as part of an emergency upsize, but due to potential impact it is advised to only perform it during a maintenance window. Traps These traps are the most common issues you will find when resizing a customers stack. The procedure below incorporates the handling of these gotchas. EIPs Multiple sites on a single stack Set Variables Even though for the upsize you are about to perform there may only be one site, still declare the variables below as arrays where needed. This procedure expects there to be arrays. NOTE : We only ever provision servers in pairs for HA and because it makes a lot of other things easier. A customer requesting a single server upsize should be rejected pending Ops manager approval. SITES=() AMI_TYPE= NUM_WEBS= DEDS=($(ah-server list site:${SITES[0]} -w type=ded)) Sites running on same hardware: TOTAL_SITES=($(ah-site list on:${DEDS[0]})) SITES=($(echo ${TOTAL_SITES[@]})) Verify variable assignment. echo \"{noformat:title=Procedure Variables}\" \\ && echo \"SITES=(${SITES[@]})\" \\ && echo \"AMI_TYPE=${AMI_TYPE}\" \\ && echo \"NUM_WEBS=${NUM_WEBS}\" \\ && echo \"DEDS=(${DEDS[@]})\" \\ && echo \"{noformat}\" Existing Webs The single-to-multi workflow will not use existing webs. It will add however many new webs you specify. Gather information Capture the output from these tools, for each of the sites affected, and paste the relevant parts into the Jira ticket. Ra, dev & test sites can be omitted esl ${DEDS[@]} for site in ${SITES[@]}; do echo ${site} site-getwebrotationstatus ${site} done AMI Types and Constrained AZs IMPORTANT : The new webs will be created in the same AZs as the deds, so if you are trying to add gen2 webs to a site that has a ded in us-east-1d, the workflow will fail. The steps to fix it once the workflow pauses are: The webs are currently suspended, change the ec2_availability_zone Resume workflow. If it fails again, resume again. NOTE Try to match the ec2_availability_zone of newly provisioning webs with existing bals AZs. Start the Workflow There are some caveats if the deds have EIPs. For safety, the workflow will stop if the deds have EIPs and there are sites on them that are not passed to the workflow or the number of webs requested were more than 2. This is to keep from disrupting unsuspecting sites that were not intended to go to multi-tier. NOTE Workflow will complete and move the EIP to new webs if there are no other sites on the hardware and number of webs requested is 2. ah-site single-to-multi \\ --deds ${DEDS[@]} \\ --web-instance $AMI_TYPE \\ --num-webs $NUM_WEBS Adding New EIPs IMPORTANT : If new EIPs are required it is vital that the servers stay out of balancer rotation until the customer has confirmed that they have white-listed the new EIPs. Failure to do this means the customers site will fail! To make this possible, the workflow will pause automatically and give the customer a chance to whitelist the new EIPs. The servers will be tagged with \"workflow-###-eip-not-whitelisted\". Put the newly launched webs out of roation until the customer whitelists the IPs of the new webs. for site in ${SITES[@]}; do ./fields-provision.php --site-set-web ${site}:inactive --webs web-3,web-4; done After the customer confirms that the EIPs have been whitelisted, add the webs in rotation. for site in ${SITES[@]}; do ./fields-provision.php --site-set-web ${site}:active --webs web-3,web-4; done Important Note Do not abort workflows! If you are unable to resolve a problem with a workflow, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership After Workflow: Memcache There is currently a bug where memcache settings are not removed from the deds after the new webs are added. To fix this manually: for i in ${DEDS[@]} ; do ah-server edit $i -c memcached.conf:-m= done Account Management Dealsheet If this Single to Multi Tier upsize was a result of an emergency upsize, you must file an AM ticket for a dealsheet by visiting the following link: AM Dealsheet: Emergency Upsize","title":"Single-tier to Multi-tier Upsize"},{"location":"kanban_tickets/single_tier_to_multi_tier/#single-tier-to-multi-tier-upsize","text":"This procedure is for breaking out a customers DED pair in to a multi-tier, Web + FSDB (DED), cluster. We don't ever change the name of a server from DED to FSDB, or visa versa. This can be done as part of an emergency upsize, but due to potential impact it is advised to only perform it during a maintenance window.","title":"Single-tier to Multi-tier Upsize"},{"location":"kanban_tickets/single_tier_to_multi_tier/#traps","text":"These traps are the most common issues you will find when resizing a customers stack. The procedure below incorporates the handling of these gotchas. EIPs Multiple sites on a single stack","title":"Traps"},{"location":"kanban_tickets/single_tier_to_multi_tier/#set-variables","text":"Even though for the upsize you are about to perform there may only be one site, still declare the variables below as arrays where needed. This procedure expects there to be arrays. NOTE : We only ever provision servers in pairs for HA and because it makes a lot of other things easier. A customer requesting a single server upsize should be rejected pending Ops manager approval. SITES=() AMI_TYPE= NUM_WEBS= DEDS=($(ah-server list site:${SITES[0]} -w type=ded)) Sites running on same hardware: TOTAL_SITES=($(ah-site list on:${DEDS[0]})) SITES=($(echo ${TOTAL_SITES[@]})) Verify variable assignment. echo \"{noformat:title=Procedure Variables}\" \\ && echo \"SITES=(${SITES[@]})\" \\ && echo \"AMI_TYPE=${AMI_TYPE}\" \\ && echo \"NUM_WEBS=${NUM_WEBS}\" \\ && echo \"DEDS=(${DEDS[@]})\" \\ && echo \"{noformat}\"","title":"Set Variables"},{"location":"kanban_tickets/single_tier_to_multi_tier/#existing-webs","text":"The single-to-multi workflow will not use existing webs. It will add however many new webs you specify.","title":"Existing Webs"},{"location":"kanban_tickets/single_tier_to_multi_tier/#gather-information","text":"Capture the output from these tools, for each of the sites affected, and paste the relevant parts into the Jira ticket. Ra, dev & test sites can be omitted esl ${DEDS[@]} for site in ${SITES[@]}; do echo ${site} site-getwebrotationstatus ${site} done","title":"Gather information"},{"location":"kanban_tickets/single_tier_to_multi_tier/#ami-types-and-constrained-azs","text":"IMPORTANT : The new webs will be created in the same AZs as the deds, so if you are trying to add gen2 webs to a site that has a ded in us-east-1d, the workflow will fail. The steps to fix it once the workflow pauses are: The webs are currently suspended, change the ec2_availability_zone Resume workflow. If it fails again, resume again. NOTE Try to match the ec2_availability_zone of newly provisioning webs with existing bals AZs.","title":"AMI Types and Constrained AZs"},{"location":"kanban_tickets/single_tier_to_multi_tier/#start-the-workflow","text":"There are some caveats if the deds have EIPs. For safety, the workflow will stop if the deds have EIPs and there are sites on them that are not passed to the workflow or the number of webs requested were more than 2. This is to keep from disrupting unsuspecting sites that were not intended to go to multi-tier. NOTE Workflow will complete and move the EIP to new webs if there are no other sites on the hardware and number of webs requested is 2. ah-site single-to-multi \\ --deds ${DEDS[@]} \\ --web-instance $AMI_TYPE \\ --num-webs $NUM_WEBS","title":"Start the Workflow"},{"location":"kanban_tickets/single_tier_to_multi_tier/#adding-new-eips","text":"IMPORTANT : If new EIPs are required it is vital that the servers stay out of balancer rotation until the customer has confirmed that they have white-listed the new EIPs. Failure to do this means the customers site will fail! To make this possible, the workflow will pause automatically and give the customer a chance to whitelist the new EIPs. The servers will be tagged with \"workflow-###-eip-not-whitelisted\". Put the newly launched webs out of roation until the customer whitelists the IPs of the new webs. for site in ${SITES[@]}; do ./fields-provision.php --site-set-web ${site}:inactive --webs web-3,web-4; done After the customer confirms that the EIPs have been whitelisted, add the webs in rotation. for site in ${SITES[@]}; do ./fields-provision.php --site-set-web ${site}:active --webs web-3,web-4; done","title":"Adding New EIPs"},{"location":"kanban_tickets/single_tier_to_multi_tier/#important-note","text":"Do not abort workflows! If you are unable to resolve a problem with a workflow, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership","title":"Important Note"},{"location":"kanban_tickets/single_tier_to_multi_tier/#after-workflow-memcache","text":"There is currently a bug where memcache settings are not removed from the deds after the new webs are added. To fix this manually: for i in ${DEDS[@]} ; do ah-server edit $i -c memcached.conf:-m= done","title":"After Workflow: Memcache"},{"location":"kanban_tickets/single_tier_to_multi_tier/#account-management-dealsheet","text":"If this Single to Multi Tier upsize was a result of an emergency upsize, you must file an AM ticket for a dealsheet by visiting the following link: AM Dealsheet: Emergency Upsize","title":"Account Management Dealsheet"},{"location":"kanban_tickets/single_tier_to_multi_tier_manual/","text":"Single-tier to Multi-tier Upsize This procedure is for breaking out a customers DED pair in to a multi-tier, Web + FSDB (DED), cluster. We don't ever change the name of a server from DED to FSDB, or visa versa. This can be done as part of an emergency upsize, but due to potential impact it is advised to only perform it during a maintenance window. Traps These traps are the most common issues you will find when resizing a customers stack. The procedure below incorporates the handling of these gotchas. EIPs Multiple sites on a single stack Set Variables Even though for the upsize you are about to perform there may only be one site, still declare the variables below as arrays where needed. This procedure expects there to be arrays. NOTE : We only ever provision servers in pairs for HA and because it makes a lot of other things easier. A customer requesting a single server upsize should be rejected pending Ops manager approval. SITES=() AMI_TYPE= NUM_WEBS= DEDS=($(ah-server list site:${SITES[0]} -w type=ded)) DEDS_CSV=$(echo ${DEDS[@]} | tr ' ' ',') DED_PRIMARY=${DEDS[0]} AZS=($(ah-server list site:${SITES[0]} --no-name -c ec2_availability_zone \\ | sort -ru \\ | head -n2)) REGION=${AZS[0]::-1} VPC_ID=$(ah-server list ${DEDS[0]} -c vpc_id --no-name) Sites running on same hardware: TOTAL_SITES=($(ah-site list on:${DEDS[0]})) SITES=($(echo ${TOTAL_SITES[@]})) Verify variable assignment. echo \"{noformat:title=Procedure Variables}\" \\ && echo \"SITES=(${SITES[@]})\" \\ && echo \"AMI_TYPE=${AMI_TYPE}\" \\ && echo \"NUM_WEBS=${NUM_WEBS}\" \\ && echo \"DEDS=(${DEDS[@]})\" \\ && echo \"DEDS_CSV=${DEDS_CSV}\" \\ && echo \"DED_PRIMARY=${DED_PRIMARY}\" \\ && echo \"AZS=(${AZS[@]})\" \\ && echo \"REGION=${REGION}\" \\ && echo \"VPC_ID=${VPC_ID}\" \\ && echo \"{noformat}\" Existing Webs If the site(s) you are working with already have web servers in the create state, you can skip to verifying server settings . Gather information Capture the output from these tools, for each of the sites affected, and paste the relevant parts into the Jira ticket. Ra, dev & test sites can be omitted esl $DED_PRIMARY $RANDOM for site in ${SITES[@]}; do echo ${site} site-getwebrotationstatus ${site} done Create Provision New Webs Assuming that this command works successfully, you can continue to the next step. If this bombs out for any reason it is vital that you correct the issue immediately and ensure that $WEBS is properly set as a bash array. If the deds are in a VPC ($VPC_ID above is anything but nil), add --vpc-id ${VPC_ID} to the allocate command. for i in $(seq 1 $NUM_WEBS); do ah-server \\ allocate web \\ --ami-type ${AMI_TYPE} \\ --region ${REGION} \\ --avail-zone ${AZS[$(($i % 2))]} done Make more variables WEBS=() WEBS_CSV=$(echo ${WEBS[@]} | tr ' ' ',') Cluster New Webs First check that the Gluster versions match. ah-server list ${DEDS_CSV} -c puppet:gluster_version ah-server list ${WEBS_CSV} -c puppet:gluster_version If they're different update the settings on the webs. For example if the Gluster version was set to 3.4 on the deds: ah-server edit ${WEBS_CSV} -c puppet:gluster_version=3.4 Now add the servers to the same FS cluster as the existing site. ah-server edit ${WEBS_CSV} \\ -s fs_cluster_id=$(ah-server list ${DED_PRIMARY} --no-name -c fs_cluster_id) Add Webs to Site/s for site in ${SITES[@]}; do ./fields-provision.php --site-set-web ${site}:deploy --webs ${WEBS_CSV} done Setting the new webs to deploy means that as soon as they launch, the new webs will be immediately put in to balancer rotation. We don't want this as there are some post launch checks we need to perform before the web is commissioned for service. sv-webdisable ${WEBS_CSV} Verify Server Settings Modify the new servers' settings to match the source. This is important to check on existing webs as while servers are suspended they, more often than not, don't have their settings updated. ah-server get ${DEDS[0]} | grep server_settings ah-server get ${WEBS[0]} | grep server_settings Transfer any settings from the original deds to the new webs. The following settings you can safely ignore: fcgi.conf my.cnf puppet.newrelic% server.total_memory Any others need to be applied to the webs. ah-server edit ${WEBS_CSV} -c file:key=value For example: $ ah-server edit web-14309,web-14310 -c puppet:apache_mpm=worker web-14309 set config puppet:apache_mpm=worker web-14310 set config puppet:apache_mpm=worker Updated 2 servers. Launch New Webs ah-server launch ${WEBS[@]} Post Launch Verify IPTABLES, gluster and code deployment fpdsh -t site:${SITES[0]} -c \"sudo ah-config-iptables\" site-fsremount ${SITES[0]} site-fcw ${SITES[0]} Manage EIPs If the DEDs have EIPs attached, move them to the new webs. If you have provisioned more than two webs then you will need to provision and associate new EIPs. IMPORTANT : If new EIPs are required it is vital that the servers stay out of balancer rotation until the customer has confirmed that they have white-listed the new EIPs. Failure to do this means the customers site will fail! NOTE : When moving an EIP from a DED server there will be a brief period where the server is not reachable and MySQL clients will not be able to connect. Because this procedure should only ever be done during a maintenance window, we can afford this outage, but be vigilant of an auto-failed over DB ah-elastic-ip help allocate ah-elastic-ip help add Put the newly launched webs out of roation until the customer whitelists the IPs of the new webs. for site in ${SITES[@]}; do ./fields-provision.php --site-set-web ${site}:inactive --webs web-3,web-4; done After the customer confirms that the EIPs have been whitelisted, add the webs in rotation. for site in ${SITES[@]}; do ./fields-provision.php --site-set-web ${site}:active --webs web-3,web-4; done Check Replication Both DEDs must have zero seconds of lag before proceeding. fpdsh -t site:${SITES[0]} -n ded -c \"sudo mysql -e 'show slave status\\G'\" \\ | grep Seconds_Behind_Master Move EIP Rotate servers through. Scripting is not easily possible here. sv-webdisable ah-server help migrate-eip sv-webenable For example: $ sv-webdisable ded-596 ded-596 set web_service_status=1 Updated 1 servers. $ ah-server migrate-eip --source-server-name=ded-596 --destination-server-name=web-14309 $ sv-webenable web-14309 web-14309 set web_service_status=2 Updated 1 servers. Verify success by running site-checkloop for each site until you have seen that all webs that should be in rotation are serving traffic. If there is a problem with the new web server, pull it from rotation immediately and investigate. Rinse and repeat until all EIPs are moved. Clean Up We now effectively make the DED servers FSDBs. If you didn't need to move EIPs in the last step make sure the new webs are enabled now. sv-webenable ${WEBS_CSV} Remove the deds from the acquia_fields_rel_site_webnode table using the ah-site tool. The running of fields-config-web.php after ensures that any CRON tasks are removed from the DEDs. site-fcb makes sure the bals know not to send traffic to the deds anymore. We also want to unset memcached.conf:-m . for site in ${SITES[@]}; do ah-site remove-webnode $site ${DEDS[@]} done fpdsh -t site:${SITES[0]} -n ded -c \"sudo fields-config-web.php\" site-fcb ${SITES[0]} ah-server edit ${DEDS_CSV} -c memcached.conf:-m= End Show the new output in your Jira ticket. esl ${WEBS_CSV} ${RANDOM} for site in ${SITES[@]}; do echo ${site} site-getwebrotationstatus ${site} done Account Management Dealsheet If this Single to Multi Tier upsize was a result of an emergency upsize, you must file an AM ticket for a dealsheet by visiting the following link: AM Dealsheet: Emergency Upsize","title":"Single-tier to Multi-tier Upsize"},{"location":"kanban_tickets/single_tier_to_multi_tier_manual/#single-tier-to-multi-tier-upsize","text":"This procedure is for breaking out a customers DED pair in to a multi-tier, Web + FSDB (DED), cluster. We don't ever change the name of a server from DED to FSDB, or visa versa. This can be done as part of an emergency upsize, but due to potential impact it is advised to only perform it during a maintenance window.","title":"Single-tier to Multi-tier Upsize"},{"location":"kanban_tickets/single_tier_to_multi_tier_manual/#traps","text":"These traps are the most common issues you will find when resizing a customers stack. The procedure below incorporates the handling of these gotchas. EIPs Multiple sites on a single stack","title":"Traps"},{"location":"kanban_tickets/single_tier_to_multi_tier_manual/#set-variables","text":"Even though for the upsize you are about to perform there may only be one site, still declare the variables below as arrays where needed. This procedure expects there to be arrays. NOTE : We only ever provision servers in pairs for HA and because it makes a lot of other things easier. A customer requesting a single server upsize should be rejected pending Ops manager approval. SITES=() AMI_TYPE= NUM_WEBS= DEDS=($(ah-server list site:${SITES[0]} -w type=ded)) DEDS_CSV=$(echo ${DEDS[@]} | tr ' ' ',') DED_PRIMARY=${DEDS[0]} AZS=($(ah-server list site:${SITES[0]} --no-name -c ec2_availability_zone \\ | sort -ru \\ | head -n2)) REGION=${AZS[0]::-1} VPC_ID=$(ah-server list ${DEDS[0]} -c vpc_id --no-name) Sites running on same hardware: TOTAL_SITES=($(ah-site list on:${DEDS[0]})) SITES=($(echo ${TOTAL_SITES[@]})) Verify variable assignment. echo \"{noformat:title=Procedure Variables}\" \\ && echo \"SITES=(${SITES[@]})\" \\ && echo \"AMI_TYPE=${AMI_TYPE}\" \\ && echo \"NUM_WEBS=${NUM_WEBS}\" \\ && echo \"DEDS=(${DEDS[@]})\" \\ && echo \"DEDS_CSV=${DEDS_CSV}\" \\ && echo \"DED_PRIMARY=${DED_PRIMARY}\" \\ && echo \"AZS=(${AZS[@]})\" \\ && echo \"REGION=${REGION}\" \\ && echo \"VPC_ID=${VPC_ID}\" \\ && echo \"{noformat}\"","title":"Set Variables"},{"location":"kanban_tickets/single_tier_to_multi_tier_manual/#existing-webs","text":"If the site(s) you are working with already have web servers in the create state, you can skip to verifying server settings .","title":"Existing Webs"},{"location":"kanban_tickets/single_tier_to_multi_tier_manual/#gather-information","text":"Capture the output from these tools, for each of the sites affected, and paste the relevant parts into the Jira ticket. Ra, dev & test sites can be omitted esl $DED_PRIMARY $RANDOM for site in ${SITES[@]}; do echo ${site} site-getwebrotationstatus ${site} done","title":"Gather information"},{"location":"kanban_tickets/single_tier_to_multi_tier_manual/#create","text":"","title":"Create"},{"location":"kanban_tickets/single_tier_to_multi_tier_manual/#provision-new-webs","text":"Assuming that this command works successfully, you can continue to the next step. If this bombs out for any reason it is vital that you correct the issue immediately and ensure that $WEBS is properly set as a bash array. If the deds are in a VPC ($VPC_ID above is anything but nil), add --vpc-id ${VPC_ID} to the allocate command. for i in $(seq 1 $NUM_WEBS); do ah-server \\ allocate web \\ --ami-type ${AMI_TYPE} \\ --region ${REGION} \\ --avail-zone ${AZS[$(($i % 2))]} done Make more variables WEBS=() WEBS_CSV=$(echo ${WEBS[@]} | tr ' ' ',')","title":"Provision New Webs"},{"location":"kanban_tickets/single_tier_to_multi_tier_manual/#cluster-new-webs","text":"First check that the Gluster versions match. ah-server list ${DEDS_CSV} -c puppet:gluster_version ah-server list ${WEBS_CSV} -c puppet:gluster_version If they're different update the settings on the webs. For example if the Gluster version was set to 3.4 on the deds: ah-server edit ${WEBS_CSV} -c puppet:gluster_version=3.4 Now add the servers to the same FS cluster as the existing site. ah-server edit ${WEBS_CSV} \\ -s fs_cluster_id=$(ah-server list ${DED_PRIMARY} --no-name -c fs_cluster_id)","title":"Cluster New Webs"},{"location":"kanban_tickets/single_tier_to_multi_tier_manual/#add-webs-to-sites","text":"for site in ${SITES[@]}; do ./fields-provision.php --site-set-web ${site}:deploy --webs ${WEBS_CSV} done Setting the new webs to deploy means that as soon as they launch, the new webs will be immediately put in to balancer rotation. We don't want this as there are some post launch checks we need to perform before the web is commissioned for service. sv-webdisable ${WEBS_CSV}","title":"Add Webs to Site/s"},{"location":"kanban_tickets/single_tier_to_multi_tier_manual/#verify-server-settings","text":"Modify the new servers' settings to match the source. This is important to check on existing webs as while servers are suspended they, more often than not, don't have their settings updated. ah-server get ${DEDS[0]} | grep server_settings ah-server get ${WEBS[0]} | grep server_settings Transfer any settings from the original deds to the new webs. The following settings you can safely ignore: fcgi.conf my.cnf puppet.newrelic% server.total_memory Any others need to be applied to the webs. ah-server edit ${WEBS_CSV} -c file:key=value For example: $ ah-server edit web-14309,web-14310 -c puppet:apache_mpm=worker web-14309 set config puppet:apache_mpm=worker web-14310 set config puppet:apache_mpm=worker Updated 2 servers.","title":"Verify Server Settings"},{"location":"kanban_tickets/single_tier_to_multi_tier_manual/#launch-new-webs","text":"ah-server launch ${WEBS[@]}","title":"Launch New Webs"},{"location":"kanban_tickets/single_tier_to_multi_tier_manual/#post-launch","text":"Verify IPTABLES, gluster and code deployment fpdsh -t site:${SITES[0]} -c \"sudo ah-config-iptables\" site-fsremount ${SITES[0]} site-fcw ${SITES[0]}","title":"Post Launch"},{"location":"kanban_tickets/single_tier_to_multi_tier_manual/#manage-eips","text":"If the DEDs have EIPs attached, move them to the new webs. If you have provisioned more than two webs then you will need to provision and associate new EIPs. IMPORTANT : If new EIPs are required it is vital that the servers stay out of balancer rotation until the customer has confirmed that they have white-listed the new EIPs. Failure to do this means the customers site will fail! NOTE : When moving an EIP from a DED server there will be a brief period where the server is not reachable and MySQL clients will not be able to connect. Because this procedure should only ever be done during a maintenance window, we can afford this outage, but be vigilant of an auto-failed over DB ah-elastic-ip help allocate ah-elastic-ip help add Put the newly launched webs out of roation until the customer whitelists the IPs of the new webs. for site in ${SITES[@]}; do ./fields-provision.php --site-set-web ${site}:inactive --webs web-3,web-4; done After the customer confirms that the EIPs have been whitelisted, add the webs in rotation. for site in ${SITES[@]}; do ./fields-provision.php --site-set-web ${site}:active --webs web-3,web-4; done","title":"Manage EIPs"},{"location":"kanban_tickets/single_tier_to_multi_tier_manual/#check-replication","text":"Both DEDs must have zero seconds of lag before proceeding. fpdsh -t site:${SITES[0]} -n ded -c \"sudo mysql -e 'show slave status\\G'\" \\ | grep Seconds_Behind_Master","title":"Check Replication"},{"location":"kanban_tickets/single_tier_to_multi_tier_manual/#move-eip","text":"Rotate servers through. Scripting is not easily possible here. sv-webdisable ah-server help migrate-eip sv-webenable For example: $ sv-webdisable ded-596 ded-596 set web_service_status=1 Updated 1 servers. $ ah-server migrate-eip --source-server-name=ded-596 --destination-server-name=web-14309 $ sv-webenable web-14309 web-14309 set web_service_status=2 Updated 1 servers. Verify success by running site-checkloop for each site until you have seen that all webs that should be in rotation are serving traffic. If there is a problem with the new web server, pull it from rotation immediately and investigate. Rinse and repeat until all EIPs are moved.","title":"Move EIP"},{"location":"kanban_tickets/single_tier_to_multi_tier_manual/#clean-up","text":"We now effectively make the DED servers FSDBs. If you didn't need to move EIPs in the last step make sure the new webs are enabled now. sv-webenable ${WEBS_CSV} Remove the deds from the acquia_fields_rel_site_webnode table using the ah-site tool. The running of fields-config-web.php after ensures that any CRON tasks are removed from the DEDs. site-fcb makes sure the bals know not to send traffic to the deds anymore. We also want to unset memcached.conf:-m . for site in ${SITES[@]}; do ah-site remove-webnode $site ${DEDS[@]} done fpdsh -t site:${SITES[0]} -n ded -c \"sudo fields-config-web.php\" site-fcb ${SITES[0]} ah-server edit ${DEDS_CSV} -c memcached.conf:-m=","title":"Clean Up"},{"location":"kanban_tickets/single_tier_to_multi_tier_manual/#end","text":"Show the new output in your Jira ticket. esl ${WEBS_CSV} ${RANDOM} for site in ${SITES[@]}; do echo ${site} site-getwebrotationstatus ${site} done","title":"End"},{"location":"kanban_tickets/single_tier_to_multi_tier_manual/#account-management-dealsheet","text":"If this Single to Multi Tier upsize was a result of an emergency upsize, you must file an AM ticket for a dealsheet by visiting the following link: AM Dealsheet: Emergency Upsize","title":"Account Management Dealsheet"},{"location":"kanban_tickets/site_audit/","text":"Performing a Site Audit There are five different site audits that Account Managers request. Converting to Gen2 Downsizing clusters Upsizing clusters Customer Renewals Additional docroots on existing hardware Converting to Gen2 Get their current hardware configuration with esl2 esl2 $SITENAME Get the Gen2 equivalents of the Gen1 hardware Use the confluence Gen1 to Gen2 page Run site-audittool Scan for any server with cpu_percent_used using more than 70% in the 90th percentile column and check the fpm_procs section for excessive usage. If anything looks highly utilized spend more time investigating and determine if you might need a bigger Gen2 instances than the one recommended in confluence. If you think you need a bigger instance proceed to the upsizing clusters section. site-audittool $SITENAME Run site-audit Check for any warnings that may affect site performance site-audit $SITENAME Check perf-mon for recent downtime in your browser https://perf-mon.acquia.com/site_downtime.php?stage=mc&sitename=$SITENAME Check /mnt/tmp usage on each instance and make sure then Gen2 instance has enough space. Run ops-audit-tools with recommend option to get a recommendation: ops-audit-tools recommend $SITENAME Note: This recommendation will give you an idea and it may not be the exact configuration. Please check other performance factors like php-fpm procs usage, mysql usage and corresponding graphs. You can also use --start -Xday if you want to audit for particular time frame.Here X is number of days. Submit a recommendation to the Account manager Downsizing / Upsizing clusters Run site-audittool Run site-audit Check perf-mon for downtime Run ops-audit-tools recommend Check if servers are ooming Bal Layer Check CPU, Network, and varnish eviction rate. High eviction rate or OOMing may indicate that bals needs more memory. Cache Layer Look at CPU utilization, Memory utilization, and memcache eviction rate and hit rate. Like bals, dedicated memcache webs may show high memory utilization but not need to be upsized. However, if any web is OOMing, it probably needs to be upsized. If memcache hit rate is low, inform Support/Customer about it, since this is an indication that the customer may not have memcache set up properly. If the memcache eviction rate is high, the server likely needs more memory. Web Layer Look at fpm procs and CPU utilization The optimal number of fpm procs is twice as many fpm procs as the 75th percentile of their proc usage DB Layer Look at CPU, Memory, and IO utilization on /vol/ebs1 and /dev/sdb High IO Utilization on /dev/xvdm could indicate they need a machine with more memory High IO utilization on /dev/sdb could indicate queries making huge temp tables High IO utilization on /vol/ebs1 when the volume type is gp3 (SSD) could indicate they need a larger SSD. FS Layer Look at CPU, Memory, and IO utilization on /dev/xvdo High IO utilization could indicate they need a machine with more memory or SSDs Customer Renewals Follow the upsize / downsize section Check volume usage for sdm and sdo Check perf-mon for recent downtime Check graphs for the FPM proc and CPU utilization for the past year in SFX: site-graphs ${SITENAME} Additional Docroots Follow the upsize / downsize section to look for bottlenecks Refer to the PHP Sizing spreadsheet to see how many fpm procs would be available for each instance size and compare it to their current usage. Summary/Recommendations of Audit Make sure to add brief summary/insight of the audit and your recommendations at the end, so that it is easier for customer facing teams togive recommendations to the customer.","title":"Performing a Site Audit"},{"location":"kanban_tickets/site_audit/#performing-a-site-audit","text":"There are five different site audits that Account Managers request. Converting to Gen2 Downsizing clusters Upsizing clusters Customer Renewals Additional docroots on existing hardware","title":"Performing a Site Audit"},{"location":"kanban_tickets/site_audit/#converting-to-gen2","text":"Get their current hardware configuration with esl2 esl2 $SITENAME Get the Gen2 equivalents of the Gen1 hardware Use the confluence Gen1 to Gen2 page Run site-audittool Scan for any server with cpu_percent_used using more than 70% in the 90th percentile column and check the fpm_procs section for excessive usage. If anything looks highly utilized spend more time investigating and determine if you might need a bigger Gen2 instances than the one recommended in confluence. If you think you need a bigger instance proceed to the upsizing clusters section. site-audittool $SITENAME Run site-audit Check for any warnings that may affect site performance site-audit $SITENAME Check perf-mon for recent downtime in your browser https://perf-mon.acquia.com/site_downtime.php?stage=mc&sitename=$SITENAME Check /mnt/tmp usage on each instance and make sure then Gen2 instance has enough space. Run ops-audit-tools with recommend option to get a recommendation: ops-audit-tools recommend $SITENAME Note: This recommendation will give you an idea and it may not be the exact configuration. Please check other performance factors like php-fpm procs usage, mysql usage and corresponding graphs. You can also use --start -Xday if you want to audit for particular time frame.Here X is number of days. Submit a recommendation to the Account manager","title":"Converting to Gen2"},{"location":"kanban_tickets/site_audit/#downsizing-upsizing-clusters","text":"Run site-audittool Run site-audit Check perf-mon for downtime Run ops-audit-tools recommend Check if servers are ooming","title":"Downsizing / Upsizing clusters"},{"location":"kanban_tickets/site_audit/#bal-layer","text":"Check CPU, Network, and varnish eviction rate. High eviction rate or OOMing may indicate that bals needs more memory.","title":"Bal Layer"},{"location":"kanban_tickets/site_audit/#cache-layer","text":"Look at CPU utilization, Memory utilization, and memcache eviction rate and hit rate. Like bals, dedicated memcache webs may show high memory utilization but not need to be upsized. However, if any web is OOMing, it probably needs to be upsized. If memcache hit rate is low, inform Support/Customer about it, since this is an indication that the customer may not have memcache set up properly. If the memcache eviction rate is high, the server likely needs more memory.","title":"Cache Layer"},{"location":"kanban_tickets/site_audit/#web-layer","text":"Look at fpm procs and CPU utilization The optimal number of fpm procs is twice as many fpm procs as the 75th percentile of their proc usage","title":"Web Layer"},{"location":"kanban_tickets/site_audit/#db-layer","text":"Look at CPU, Memory, and IO utilization on /vol/ebs1 and /dev/sdb High IO Utilization on /dev/xvdm could indicate they need a machine with more memory High IO utilization on /dev/sdb could indicate queries making huge temp tables High IO utilization on /vol/ebs1 when the volume type is gp3 (SSD) could indicate they need a larger SSD.","title":"DB Layer"},{"location":"kanban_tickets/site_audit/#fs-layer","text":"Look at CPU, Memory, and IO utilization on /dev/xvdo High IO utilization could indicate they need a machine with more memory or SSDs","title":"FS Layer"},{"location":"kanban_tickets/site_audit/#customer-renewals","text":"Follow the upsize / downsize section Check volume usage for sdm and sdo Check perf-mon for recent downtime Check graphs for the FPM proc and CPU utilization for the past year in SFX: site-graphs ${SITENAME}","title":"Customer Renewals"},{"location":"kanban_tickets/site_audit/#additional-docroots","text":"Follow the upsize / downsize section to look for bottlenecks Refer to the PHP Sizing spreadsheet to see how many fpm procs would be available for each instance size and compare it to their current usage.","title":"Additional Docroots"},{"location":"kanban_tickets/site_audit/#summaryrecommendations-of-audit","text":"Make sure to add brief summary/insight of the audit and your recommendations at the end, so that it is easier for customer facing teams togive recommendations to the customer.","title":"Summary/Recommendations of Audit"},{"location":"kanban_tickets/site_move/","text":"Site Move This procedure guides you through moving a site from one stack of servers to another. VPC When a site is moving to a different VPC, you will need to provision new balancers and an ELB in the destination VPC. ODE/CDE instructions Please reject the ode site moves, because it's not supported by site move tool, and it only works if on_demand value of the site is 0. this confluence page . If you are being asked to move a site then, make sure the on_demand value is 0. And then, inform the requestor about the same. To check on_demand value: SITE= ah-site list $SITE -c on_demand All the ODE sites have unique platform, where you will not see dedicated database instances like [ded-fsdb-dbmaster] because we are using RDS instances. For ODE, the Site-moveduration tool will give an estimate for FS only, and not for DB, as the tool is not designed to connect with RDS instances. The on_demand value for the ODE sites would be 1. To list all the ODE sites, run: ah-site list $SITE1,$SITE2 -w on_demand=1 To set the on_demand value, run: ah-site list $SITE1,$SITE2 -s on_demand=0 Site Factory Site Factory site moves, such as in the enterprise-g1 realm, have some noteworthy differences from site moves in ACE: Site Factory sites are comprised of several sitegroups which cannot be moved independently of one another ELBs in Site Factory have extra requirements Create a DG ticket after the site move is completed. Since it is required to move all sites in a Site Factory, it is helpful to understand the sitegroup/sites on a typical site factory . esl ${CUSTOMERNAME}% Each Site Factory has three sitegroups, ${CUSTOMERNAME} , ${CUSTOMERNAME}sf , and ${CUSTOMERNAME}theme . These sitegroups are often on separate stacks, so spend time tracking down all of the hardware. Within those sitegroups you will see sitenames such as ${CUSTOMERNAME}01live , ${CUSTOMERNAME}01update , ${CUSTOMERNAME}01theme , etc. Note some older site factories may add an underscore, i.e. ${CUSTOMERNAME}_sf . You will also see proxy hosting sites with names like ${CUSTOMERNAME}prod . These proxies do not map to hardware. Identify all sitegroups, sites, and hardware before beginning the site move. Preparation The following prep work should be completed before the site move is executed: Verify that the site and destination servers are in the same region. If the regions differ, then balancers and VCS repos must move to the new region as well. If site is moved to different region, then customer need to update their DNS. Share the IP with customer in advance else site will be down after site move. Note : Here SITE is name of a single sitename not the sitegroup. SITE= DST_FS_SERVER= DST_DB_SERVER= SRC_SRV=$(ah-server list site:${SITE} -w type!=svn| tail -1) ah-server list ${SRC_SRV},${DST_FS_SERVER} -c ec2_region --no-name | paste -s \\ | awk '$1 != $2 { exit 1; }' && echo \"Regions match\" || echo \"WARNING: Regions do not match\" Verify that the destination server has enough disk space to accommodate the new site. This is a hard stop point if this check does not pass. site-movevolusage ${SITE} ${DST_FS_SERVER} ${DST_DB_SERVER} Additionally, if the destination hardware does not exist yet, run the above as follows (with destination sizes): site-movevolusage ${SITE} ${DST_FS_SIZE} [e.g. 10G or 10240M] ${DST_DB_SIZE} [e.g. 10G or 10240M] If the site is moving to servers in a different region and it has an ELB then verify that the key and cert are on the gluster volume at Note : Here SITE is name of a single sitename not the sitegroup. SITE= SITE_ENV=$(ah-site list ${SITE} --no-name -c stage) SITEGROUP=$(ah-site list ${SITE} --no-name -c sitegroup) /home/${SITEGROUP}/${SITE_ENV}/ssl If they are not, assign the ticket to the reporter, set to waiting for Feedback , and ask that the files be provided at that path. EIPs cannot move between regions, so the customer needs to whitelist any new webnode EIPs before the site move can go forward. Please check if suspended or terminated webs are linked with the site or not by running esl2 tool for that particular site: esl2 $SITE If suspended/terminated webs are showing there, then remove the terminated webs from the site prior the site move: ah-site remove-webnode ${SITE} $(ah-server list site:${SITE} -w type=web statusIN1,3 | paste -sd \" \") Verify whether the source hardware has other sites on it or not and in case of shared hardware EIP will be intact with the source hardware. NOTE: For any discrepency reach out to support or ops-coordinator! SRC_WEB=(ded/web/staging) * This is the source hardware from where the sites are moving off ah-site list on:$SRC_WEB If you need to start at a specific time, calculate the UNIX_START_TIME variable: UNIX_START_TIME=$(date -d '2018/03/22 20:00 UTC' +\"%s\") add the following flag to your ah-site move command: --scheduled-time ${UNIX_START_TIME} If you want to resume a workflow task at a specific time, calculate UNIX_START_TIME as above, then schedule it to resume (you must do this after starting the workflow with ah-site move below): WORKFLOW_ID= ah-workflow schedule-resume ${WORKFLOW_ID} \\ --scheduled-time ${UNIX_START_TIME} To check scheduled maintenance information and status, Run scheduled_task=$(ah-workflow get ${WORKFLOW_ID} | grep -w \"scheduled_task_ids.0\"|cut -d: -f2) wf-scheduled or ah-scheduled-task get $scheduled_task To Cancel/Remove the scheduled task in case if your maintenance will be cancelled, Run ah-scheduled-task kill $scheduled_task Beware: Always check the last hrs update in your maintenance ticket for cancellation updates if any. Procedure The procedure varies slightly between moving sites within the same region and moving a site to a new region. NOTE: Same region : Once the site move is done, put the old bals back in rotation and put them out of rotation only once customer has confirmed that they have updated the DNS. We should also create a TSR ticket to remove the old bals (if dedicated) or for moving them out of rotation (if bals are shared). Different region : Share the new bal pair IP with the customer via support before site move to update the DNS else site will be down till the time DNS is updated by customer after site move. Only use one of the sections below. Same Region Different Regions Important Note Do not abort workflows! If you are unable to resolve a problem with a workflow, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership Syncing Data Prior to Downtime The site move workflow can be used in such a way that the majority of a site's data can be rsynced onto the new hardware before the site is actually transferred. This \"pre-rsync\" does not require downtime and can shorten the total required downtime for switching hardware. To do this, simply pause the workflow at the step update_site_location_within_the_hosting_api . --pause-at-step=update_site_location_within_the_hosting_api The step which executes the pre-rsync is called pre_migrate_site_files . Same Region Variables Set variables for the SITE to be moved, the lowest-numbered destination DB server, space-separated lists of destination WEBS and BALS , and the OP ticket. Note : Here SITE is name of a single sitename not the sitegroup. SITE= SITE_ENV=$(ah-site list ${SITE} --no-name -c stage) DST_DB= DST_WEBS=() DST_BALS=() OP= DST_WEBS_CSV=$(array-csv ${DST_WEBS[@]}) DST_BALS_CSV=$(array-csv ${DST_BALS[@]}) Home directory copy commands These commands are generated now but executed later after site-move for moving customer's home directory contents. Copy these to the OP ticket to be run after the site-move is done while true; do SRC=$(ah-server list site:${SITE} -w typeINded,fs,fsdb,fsdbmesh,staging | head -1) DST_FS_CLUSTER_ID=$(ah-server list ${DST_WEBS_CSV} --no-name -c fs_cluster_id | head -1) DST=$(ah-server list % -w typeINded,fs,fsdb,fsdbmesh,staging fs_cluster_id=${DST_FS_CLUSTER_ID} | head -1) SITEGROUP=$(ah-site list ${SITE} --no-name -c sitegroup) SITEGROUP_UID=$(ah-sitegroup list ${SITEGROUP} --no-name -c unix_uid) echo \"{code:title= Move $SITE home directory content from $SRC to $DST}\" echo \"fssh ${DST} 'sudo mkdir -m755 /mnt/gfs/home'\" echo \"sv-rsyncfile -o avPu ${SRC}:/mnt/gfs/home/${SITEGROUP}/ ${DST_WEBS[0]}:/mnt/gfs/home/${SITEGROUP}/\" echo \"fssh ${DST} 'sudo chown -Rh ${SITEGROUP_UID}:${SITEGROUP_UID} /mnt/gfs/home/${SITEGROUP}'\" echo \"{code}\" echo echo 'COPY THE ABOVE OUTPUT TO JIRA TICKET AND EXECUTE THEM LATER AFTER THE SITE MOVE AS LAST STEP' break done Site Move - Same region Until CL-46442 is fixed, disable e2e encryption and re-enable it after the site move SITE=nginxvarnishtest ah-site disable-e2e-encryption --site-names=${SITE} \u2714 Disabled End to End Encryption for nginxvarnishtest If the command reports the following you do not need to do take note and do not enable e2e encryption after the site move SITE=nginxvarnishtest ah-site disable-e2e-encryption --site-names=${SITE} XMLRPCRemoteException: The following site(s) do not have end to end encryption enabled: nginxvarnishtest As seen in case of OP-272857 (For RA Site), OP-247706 (For RA Site) and OP-278069 (For QA Site), site move WF from any kind of source BAL (Legacy or Edge) to Destination Edge Bals can error out with the error: update_site_location_within_the_hosting_api raised error Aq::Hosting::ApiClient::XMLRPCRemoteException ERROR: Caught Aq::Hosting::ApiClient::XMLRPCRemoteException while running workflow: Cannot assign a site to balancers without an elastic IP address. This error occurs because WF expects the destination Bals to have an EIP whereas Edge Bals don\u2019t have EIPs. To avoid this issue we can take the following steps: If the destination servers are in a different VPC, please make sure the memcache service is disabled on all the web/ded instances in the destination VPC. This is required to prevent site outage, the site will experience downtime as the web services on sources web/ded serves fails to connect to the memcache services on destination servers in different VPC. If the Source and Destination Bals are same, no need to specify the Bals in WF command. ah-site move ${SITE} --webs ${DST_WEBS[@]} --db ${DST_DB} --force Check if the Destination Bals are Edge BALs, using esl2 command. esl2 ${SITE} If Destination Bals are Edge Bals , you may initiate the Site move WF without specifying the Bals in the wf command. ah-site move ${SITE} --webs ${DST_WEBS[@]} --db ${DST_DB} --force Check the memcache requirements after the site move. Enable enable memcache service or add memcache servers if required. After the WF is complete, assign the new BAL values to the site manually, get the CLUSTER_UUID from above esl2 command : ah-edge add-environment-to-edge-cluster --environment-name=${SITE} --uuid=${CLUSTER_UUID} If you started the WF anyway with specifying the BALs and the WF did error out with error : \u201cCannot assign a site to balancers without an elastic IP address.\u201d ; then clean up the error WF and its so far executed steps (examples as shown in OP-272857, OP-247706). Start a new WF without specifying the BAL. Please do not try to assign an EIP to the EDGE Bals If the destination servers are in a different VPC, please make sure the memcache service is disabled on all the web/ded instances in the destination VPC. This is required to prevent site outage, the site will experience downtime as the web services on sources web/ded serves fails to connect to the memcache services on destination servers in different VPC. Start the workflow to move the site. Omit any parameters which are not being changed (i.e. if the site is keeping its current balancers): ah-site move ${SITE} --webs ${DST_WEBS[@]} --bals ${DST_BALS[@]} --db ${DST_DB} --force If you want to scheduled the site move workflow then use ah-site move ${SITE} --webs ${DST_WEBS[@]} --bals ${DST_BALS[@]} --db ${DST_DB} --force --scheduled-time ${UNIX_START_TIME} Caution:Always move the site one by one. Calculate the total migration time and then schedule the site move accordingly. Check the memcache requirements after the site move. Enable enable memcache service or add memcache servers if required. If the workflow cannot be made to work, trying manually moving the site Warning - In case of shared infra EIP will be intact with the source hardware hardware. If the old webs or deds have EIPs, move them to the new webs/deds. VPC to CLASSIC will never be supported due to AWS restrictions. ah-server help migrate-eip Usage: ah-server migrate-eip --destination-server-name=DESTINATION_SERVER_NAME --source-server-name=SOURCE_SERVER_NAME # Note. Classic Elastic IPs need to be allocated 24 hours before moving them to vpc which is a hard AWS restriction. # Example : ah-server migrate-eip --source-server-name=ded-123 --destination-server-name=ded-596 Post EIP migration,verify and make sure that the EIPs are moved correctly. In ACE, a site move in the same region allows you to continue to use the same ELB if it exists, but you must ensure that the ELB is configured for the new balancers' AZs: site-elbdescribe ${SITE} If the site has an ELB and it is not configured for the right AZs, update it: ELB=$(ruby -e \"require 'aq'; begin; site_input = '$SITE'; site_id = Aq::Hosting::Site.from_name(site_input).record['id']; site_elb = Aq::Hosting::SiteElb.fromQuery('site_id' => site_id); rescue Aq::Hosting::EntityNotFoundError => e; puts 'nil'; else; puts site_elb['elb_name'].to_s; end\") AZS=($(ah-server list ${DST_BALS_CSV} -c ec2_availability_zone --no-name | paste -sd' ')) aws elb enable-availability-zones-for-load-balancer \\ --region ${REGION} \\ --load-balancer-name ${ELB} \\ --availability-zones ${AZS} If the site is in a Site Factory realm, follow the steps to create an ELB for Site Factory . Deprovision the existing one. If the site previously had e2e enabled, follow the enable e2e runbook to re-enable it. You have to configure mysql only once per server and restart mysql after enabling e2e on the site. Also check and verify the e2e installation as per the steps given in below e2e runbook. Enable e2e after site move As a last step, move the contents of the customer's home directory using the commands we generated above before the site move and copied to JIRA ticket. Note: Create a TSR to remove /mnt/gfs/SITENAME-MOVED-* directory,which should be executed after 7 days. Note: We generally don\u2019t move RA site or environments while moving entire site group. However there are some situations when we also need to move RA environments. For example while moving the entire site into a dedicated VPC or while region moves where RA team has asked for it. Different Regions Variables - Different regions Set variables for the SITE to be moved, the lowest-numbered destination DB server, WEBS , and BALS , as applicable, and the OP ticket. Note : Here SITE is name of a single sitename not the sitegroup SITE= DST_WEBS=() DST_BALS=() DST_DB= OP= DST_WEBS_CSV=$(array-csv ${DST_WEBS[@]}) DST_BALS_CSV=$(array-csv ${DST_BALS[@]}) Home directory copy commands multi-region These commands are generated now but executed later after site-move for moving customer's home directory contents. Copy these to the OP ticket to be run after the site-move is done while true; do SRC=$(ah-server list site:${SITE} -w typeINded,fs,fsdb,fsdbmesh,staging | head -1) DST_FS_CLUSTER_ID=$(ah-server list ${DST_WEBS_CSV} --no-name -c fs_cluster_id | head -1) DST=$(ah-server list % -w typeINded,fs,fsdb,fsdbmesh,staging fs_cluster_id=${DST_FS_CLUSTER_ID} | head -1) SITEGROUP=$(ah-site list ${SITE} --no-name -c sitegroup) SITEGROUP_UID=$(ah-sitegroup list ${SITEGROUP} --no-name -c unix_uid) echo \"{code:title= Move $SITE home directory content from $SRC to $DST}\" echo \"fssh ${DST} 'sudo mkdir -m755 /mnt/gfs/home'\" echo \"sv-rsyncfile -o avPu ${SRC}:/mnt/gfs/home/${SITEGROUP}/ ${DST_WEBS[0]}:/mnt/gfs/home/${SITEGROUP}/\" echo \"fssh ${DST} 'sudo chown -Rh ${SITEGROUP_UID}:${SITEGROUP_UID} /mnt/gfs/home/${SITEGROUP}'\" echo \"{code}\" echo echo 'COPY THE ABOVE OUTPUT TO JIRA TICKET AND EXECUTE THEM LATER AFTER THE SITE MOVE AS LAST STEP' break done Site Move - Different region Use site-taglistactive to determine an available SVN instance in the new region and VPC. REGION= VPC= site-taglistactive svn ${REGION} ${VPC} SVN= Until CL-46442 is fixed, disable e2e encryption and re-enable it after the site move SITE=nginxvarnishtest ah-site disable-e2e-encryption --site-names=${SITE} \u2714 Disabled End to End Encryption for nginxvarnishtest If the command reports the following you do not need to do take note and do not enable e2e encryption after the site move SITE=nginxvarnishtest ah-site disable-e2e-encryption --site-names=${SITE} XMLRPCRemoteException: The following site(s) do not have end to end encryption enabled: nginxvarnishtest As seen in case of OP-272857 (For RA Site), OP-247706 (For RA Site) and OP-278069 (For QA Site), site move WF from any kind of source BAL (Legacy or Edge) to Destination Edge Bals can error out with the error: update_site_location_within_the_hosting_api raised error Aq::Hosting::ApiClient::XMLRPCRemoteException ERROR: Caught Aq::Hosting::ApiClient::XMLRPCRemoteException while running workflow: Cannot assign a site to balancers without an elastic IP address. This error occurs because WF expects the destination Bals to have an EIP whereas Edge Bals don\u2019t have EIPs. To avoid this issue we can take the following steps: Check if the Destination Bals are Edge BALs, using esl2 command. esl2 ${SITE} If the destination servers are in a different VPC, please make sure the memcache service is disabled on all the web/ded instances in the destination VPC. This is required to prevent site outage, the site will experience downtime as the web services on sources web/ded serves fails to connect to the memcache services on destination servers in different VPC. If Destination Bals are Edge Bals , you may initiate the Site move WF without specifying the Bals in the wf command. ah-site move ${SITE} --webs ${DST_WEBS[@]} --db ${DST_DB} --force After the WF is complete, assign the new BAL values to the site manually, get the CLUSTER_UUID from above esl2 command. ah-edge add-environment-to-edge-cluster --environment-name=${SITE} --uuid=${CLUSTER_UUID} If you started the WF anyway with specifying the BALs and the WF did error out with error : \u201cCannot assign a site to balancers without an elastic IP address.\u201d ; then clean up the error WF and its so far executed steps (examples as shown in OP-272857, OP-247706). Start a new WF without specifying the BAL. Check the memcache requirements after the site move. Enable enable memcache service or add memcache servers if required. In case of Site move to different Region, the EIPs ofcourse can not be moved from one region to another. Please do not try to assign an EIP to the EDGE Bals If the destination servers are in a different VPC, please make sure the memcache service is disabled on all the web/ded instances in the destination VPC. This is required to prevent site outage, the site will experience downtime as the web services on sources web/ded serves fails to connect to the memcache services on destination servers in different VPC. Start the workflow to move the site. ah-site move ${SITE} --webs ${DST_WEBS[@]} --bals ${DST_BALS[@]} --db ${DST_DB} --force Note that data can be rsynced to the new hardware prior to downtime by pausing at the step update_site_location_within_the_hosting_api . ah-site move ${SITE} --webs ${DST_WEBS[@]} --bals ${DST_BALS[@]} --db ${DST_DB} --force --pause-at-step=update_site_location_within_the_hosting_api --pause-description=\"$OP | $SITE site move\" If paused, resume the workflow when you are ready to commence downtime. A second rsync pass will occur to transfer any files which were created after the initial pre-rsync was run. If you want to scheduled the site move workflow then use ah-site move ${SITE} --webs ${DST_WEBS[@]} --bals ${DST_BALS[@]} --db ${DST_DB} --force --scheduled-time ${UNIX_START_TIME} Check the memcache requirements after the site move. Enable enable memcache service or add memcache servers if required. If you want to resume a presynced workflow task at a specific time, calculate UNIX_START_TIME as above, then schedule it to resume (you must do this after starting the workflow with ah-site move below): WORKFLOW_ID= ah-workflow schedule-resume ${WORKFLOW_ID} --scheduled-time ${UNIX_START_TIME} Caution: Always move the site one by one. Calculate the total migration time and then schedule the site move accordingly. If the workflow cannot be made to work, trying manually moving the site Migrate the SVN repo SITEGROUP=$(ah-site list ${SITE} --no-name -c sitegroup) ah-sitegroup move-repos ${SITEGROUP} ${SVN} If the site has an ELB, deprovision it site-elbdescribe ${SITE} ah-site ssl deprovision-elb ${SITE} If the customer is using Self-Service SSL, then just notify Support to tell the customer that they will need to reconfigure SSL. Otherwise, provision a new ELB and configure it with the key and certs from the prep work. In the instructions below, CERT refers to a file with only the identity cert and CA refers to a chain with only the intermediate certs. CERT= CA= KEY= ah-site ssl create-elb ${SITE} --ca=$CA --cert=$CERT --key=$KEY If the site move is in Site Factory, follow the specific steps to create an ELB for site factory in the new destination. If the site previously had e2e enabled, follow the enable e2e runbook to re-enable it. You have to configure mysql only once per server and restart mysql after enabling e2e on the site. Also check and verify the e2e installation as per the steps given in below e2e runbook. Enable e2e after site move Provide the ticket requester with the EIP of the new balancers, so the customers can update DNS. As a last step, move the contents of the customer's home directory using the commands we generated above before the site move and copied to JIRA ticket. Note: Create a TSR to remove /mnt/gfs/SITENAME-MOVED-* directory,which should be executed after 7 days. Verification Verify there are no alerts for any of the hardware or sites affected by the site move. All tasks and/or workflows should be done. site-checkwebs ${SITE} site-check ${SITE} If no more sites remain on the source server(s) then verify if they can be deprovisioned and file a TSR ticket to deprovision the instances in seven days. If Site Factory: Create a DG ticket in JIRA and link to the site move ticket. The site move ticket is not done until the DG ticket is done. The ACSF engineering team will perform a cleanup as needed on the new hardware. There are typically some caches that need refreshing on the factory, and some files are not brought over during the regular process. Recovery If the task is any state other than \"done\", then you must determine what went wrong during the site move. There are two major points which the task can fail: migrating data from /vol/ebs1 , or migrating data from /mnt/gfs . Examine the task output to determine which part of the site move failed. Databases: follow the procedure for XFS Dump Restore, and restore the data on the destination DB's. File System: Follow the ssh-between-servers runbook to sync the remaining files. Make sure to run the rsync on screen session. An example is below. WARNING: Always use a trailing slash with rsync paths!! sv-screen screen_name rsync -avPe 'ssh -i /root/.ssh/path_of_key\u2019 /home/${SITEGROUP}/${SITE_ENV}/ ${DST_FS_SERVER}:/home/${SITEGROUP}/${SITE_ENV}/ fssh ${DST_FS_SERVER} \"sudo chown -Rh ${SITEGROUP_UID}:${SITEGROUP_UID} /home/${SITEGROUP}/${SITE_ENV}/\" NOTE: If a site move workflow gets stuck or failed, we should escalate the issue to cloud immediately after getting approval from Ops management. Cleanup Once the site move is complete and verification successful, you need to cleanup the site directory from source web. As part of site move, the site directory on the source web will be appended with a string -MOVED-{workflow|task}-{id} . For example, the directory on /mnt/gfs will look like ${SITE}-MOVED-{workflow|task}-{id} . The site directory has to be manually removed. fssh ${SRC_WEB} \"sudo rm -rf /mnt/gfs/${SITE}-MOVED-{workflow|task}-{id}\" If the new feature flag PersistentDataService.SiteMoveUseEnvFileSymlink is set to true , it will no longer append the string to the site directory on /mnt/gfs . You have to find the site directory on the source web and remove it. You can check the value of feature flag using a CLI command and then remove site directory by ssh'ing to the source web. bin/ah-stage get-config --key=PersistentDataService.SiteMoveUseEnvFileSymlink fssh ${SRC_WEB} \"sudo rm -rf /mnt/gfs/${SITE}\"","title":"Site Move"},{"location":"kanban_tickets/site_move/#site-move","text":"This procedure guides you through moving a site from one stack of servers to another.","title":"Site Move"},{"location":"kanban_tickets/site_move/#vpc","text":"When a site is moving to a different VPC, you will need to provision new balancers and an ELB in the destination VPC.","title":"VPC"},{"location":"kanban_tickets/site_move/#odecde-instructions","text":"Please reject the ode site moves, because it's not supported by site move tool, and it only works if on_demand value of the site is 0. this confluence page . If you are being asked to move a site then, make sure the on_demand value is 0. And then, inform the requestor about the same. To check on_demand value: SITE= ah-site list $SITE -c on_demand All the ODE sites have unique platform, where you will not see dedicated database instances like [ded-fsdb-dbmaster] because we are using RDS instances. For ODE, the Site-moveduration tool will give an estimate for FS only, and not for DB, as the tool is not designed to connect with RDS instances. The on_demand value for the ODE sites would be 1. To list all the ODE sites, run: ah-site list $SITE1,$SITE2 -w on_demand=1 To set the on_demand value, run: ah-site list $SITE1,$SITE2 -s on_demand=0","title":"ODE/CDE instructions"},{"location":"kanban_tickets/site_move/#site-factory","text":"Site Factory site moves, such as in the enterprise-g1 realm, have some noteworthy differences from site moves in ACE: Site Factory sites are comprised of several sitegroups which cannot be moved independently of one another ELBs in Site Factory have extra requirements Create a DG ticket after the site move is completed. Since it is required to move all sites in a Site Factory, it is helpful to understand the sitegroup/sites on a typical site factory . esl ${CUSTOMERNAME}% Each Site Factory has three sitegroups, ${CUSTOMERNAME} , ${CUSTOMERNAME}sf , and ${CUSTOMERNAME}theme . These sitegroups are often on separate stacks, so spend time tracking down all of the hardware. Within those sitegroups you will see sitenames such as ${CUSTOMERNAME}01live , ${CUSTOMERNAME}01update , ${CUSTOMERNAME}01theme , etc. Note some older site factories may add an underscore, i.e. ${CUSTOMERNAME}_sf . You will also see proxy hosting sites with names like ${CUSTOMERNAME}prod . These proxies do not map to hardware. Identify all sitegroups, sites, and hardware before beginning the site move.","title":"Site Factory"},{"location":"kanban_tickets/site_move/#preparation","text":"The following prep work should be completed before the site move is executed: Verify that the site and destination servers are in the same region. If the regions differ, then balancers and VCS repos must move to the new region as well. If site is moved to different region, then customer need to update their DNS. Share the IP with customer in advance else site will be down after site move. Note : Here SITE is name of a single sitename not the sitegroup. SITE= DST_FS_SERVER= DST_DB_SERVER= SRC_SRV=$(ah-server list site:${SITE} -w type!=svn| tail -1) ah-server list ${SRC_SRV},${DST_FS_SERVER} -c ec2_region --no-name | paste -s \\ | awk '$1 != $2 { exit 1; }' && echo \"Regions match\" || echo \"WARNING: Regions do not match\" Verify that the destination server has enough disk space to accommodate the new site. This is a hard stop point if this check does not pass. site-movevolusage ${SITE} ${DST_FS_SERVER} ${DST_DB_SERVER} Additionally, if the destination hardware does not exist yet, run the above as follows (with destination sizes): site-movevolusage ${SITE} ${DST_FS_SIZE} [e.g. 10G or 10240M] ${DST_DB_SIZE} [e.g. 10G or 10240M] If the site is moving to servers in a different region and it has an ELB then verify that the key and cert are on the gluster volume at Note : Here SITE is name of a single sitename not the sitegroup. SITE= SITE_ENV=$(ah-site list ${SITE} --no-name -c stage) SITEGROUP=$(ah-site list ${SITE} --no-name -c sitegroup) /home/${SITEGROUP}/${SITE_ENV}/ssl If they are not, assign the ticket to the reporter, set to waiting for Feedback , and ask that the files be provided at that path. EIPs cannot move between regions, so the customer needs to whitelist any new webnode EIPs before the site move can go forward. Please check if suspended or terminated webs are linked with the site or not by running esl2 tool for that particular site: esl2 $SITE If suspended/terminated webs are showing there, then remove the terminated webs from the site prior the site move: ah-site remove-webnode ${SITE} $(ah-server list site:${SITE} -w type=web statusIN1,3 | paste -sd \" \") Verify whether the source hardware has other sites on it or not and in case of shared hardware EIP will be intact with the source hardware. NOTE: For any discrepency reach out to support or ops-coordinator! SRC_WEB=(ded/web/staging) * This is the source hardware from where the sites are moving off ah-site list on:$SRC_WEB If you need to start at a specific time, calculate the UNIX_START_TIME variable: UNIX_START_TIME=$(date -d '2018/03/22 20:00 UTC' +\"%s\") add the following flag to your ah-site move command: --scheduled-time ${UNIX_START_TIME} If you want to resume a workflow task at a specific time, calculate UNIX_START_TIME as above, then schedule it to resume (you must do this after starting the workflow with ah-site move below): WORKFLOW_ID= ah-workflow schedule-resume ${WORKFLOW_ID} \\ --scheduled-time ${UNIX_START_TIME} To check scheduled maintenance information and status, Run scheduled_task=$(ah-workflow get ${WORKFLOW_ID} | grep -w \"scheduled_task_ids.0\"|cut -d: -f2) wf-scheduled or ah-scheduled-task get $scheduled_task To Cancel/Remove the scheduled task in case if your maintenance will be cancelled, Run ah-scheduled-task kill $scheduled_task Beware: Always check the last hrs update in your maintenance ticket for cancellation updates if any.","title":"Preparation"},{"location":"kanban_tickets/site_move/#procedure","text":"The procedure varies slightly between moving sites within the same region and moving a site to a new region. NOTE: Same region : Once the site move is done, put the old bals back in rotation and put them out of rotation only once customer has confirmed that they have updated the DNS. We should also create a TSR ticket to remove the old bals (if dedicated) or for moving them out of rotation (if bals are shared). Different region : Share the new bal pair IP with the customer via support before site move to update the DNS else site will be down till the time DNS is updated by customer after site move. Only use one of the sections below. Same Region Different Regions","title":"Procedure"},{"location":"kanban_tickets/site_move/#important-note","text":"Do not abort workflows! If you are unable to resolve a problem with a workflow, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership","title":"Important Note"},{"location":"kanban_tickets/site_move/#syncing-data-prior-to-downtime","text":"The site move workflow can be used in such a way that the majority of a site's data can be rsynced onto the new hardware before the site is actually transferred. This \"pre-rsync\" does not require downtime and can shorten the total required downtime for switching hardware. To do this, simply pause the workflow at the step update_site_location_within_the_hosting_api . --pause-at-step=update_site_location_within_the_hosting_api The step which executes the pre-rsync is called pre_migrate_site_files .","title":"Syncing Data Prior to Downtime"},{"location":"kanban_tickets/site_move/#same-region","text":"","title":"Same Region"},{"location":"kanban_tickets/site_move/#variables","text":"Set variables for the SITE to be moved, the lowest-numbered destination DB server, space-separated lists of destination WEBS and BALS , and the OP ticket. Note : Here SITE is name of a single sitename not the sitegroup. SITE= SITE_ENV=$(ah-site list ${SITE} --no-name -c stage) DST_DB= DST_WEBS=() DST_BALS=() OP= DST_WEBS_CSV=$(array-csv ${DST_WEBS[@]}) DST_BALS_CSV=$(array-csv ${DST_BALS[@]})","title":"Variables"},{"location":"kanban_tickets/site_move/#home-directory-copy-commands","text":"These commands are generated now but executed later after site-move for moving customer's home directory contents. Copy these to the OP ticket to be run after the site-move is done while true; do SRC=$(ah-server list site:${SITE} -w typeINded,fs,fsdb,fsdbmesh,staging | head -1) DST_FS_CLUSTER_ID=$(ah-server list ${DST_WEBS_CSV} --no-name -c fs_cluster_id | head -1) DST=$(ah-server list % -w typeINded,fs,fsdb,fsdbmesh,staging fs_cluster_id=${DST_FS_CLUSTER_ID} | head -1) SITEGROUP=$(ah-site list ${SITE} --no-name -c sitegroup) SITEGROUP_UID=$(ah-sitegroup list ${SITEGROUP} --no-name -c unix_uid) echo \"{code:title= Move $SITE home directory content from $SRC to $DST}\" echo \"fssh ${DST} 'sudo mkdir -m755 /mnt/gfs/home'\" echo \"sv-rsyncfile -o avPu ${SRC}:/mnt/gfs/home/${SITEGROUP}/ ${DST_WEBS[0]}:/mnt/gfs/home/${SITEGROUP}/\" echo \"fssh ${DST} 'sudo chown -Rh ${SITEGROUP_UID}:${SITEGROUP_UID} /mnt/gfs/home/${SITEGROUP}'\" echo \"{code}\" echo echo 'COPY THE ABOVE OUTPUT TO JIRA TICKET AND EXECUTE THEM LATER AFTER THE SITE MOVE AS LAST STEP' break done","title":"Home directory copy commands"},{"location":"kanban_tickets/site_move/#site-move-same-region","text":"Until CL-46442 is fixed, disable e2e encryption and re-enable it after the site move SITE=nginxvarnishtest ah-site disable-e2e-encryption --site-names=${SITE} \u2714 Disabled End to End Encryption for nginxvarnishtest If the command reports the following you do not need to do take note and do not enable e2e encryption after the site move SITE=nginxvarnishtest ah-site disable-e2e-encryption --site-names=${SITE} XMLRPCRemoteException: The following site(s) do not have end to end encryption enabled: nginxvarnishtest As seen in case of OP-272857 (For RA Site), OP-247706 (For RA Site) and OP-278069 (For QA Site), site move WF from any kind of source BAL (Legacy or Edge) to Destination Edge Bals can error out with the error: update_site_location_within_the_hosting_api raised error Aq::Hosting::ApiClient::XMLRPCRemoteException ERROR: Caught Aq::Hosting::ApiClient::XMLRPCRemoteException while running workflow: Cannot assign a site to balancers without an elastic IP address. This error occurs because WF expects the destination Bals to have an EIP whereas Edge Bals don\u2019t have EIPs. To avoid this issue we can take the following steps: If the destination servers are in a different VPC, please make sure the memcache service is disabled on all the web/ded instances in the destination VPC. This is required to prevent site outage, the site will experience downtime as the web services on sources web/ded serves fails to connect to the memcache services on destination servers in different VPC. If the Source and Destination Bals are same, no need to specify the Bals in WF command. ah-site move ${SITE} --webs ${DST_WEBS[@]} --db ${DST_DB} --force Check if the Destination Bals are Edge BALs, using esl2 command. esl2 ${SITE} If Destination Bals are Edge Bals , you may initiate the Site move WF without specifying the Bals in the wf command. ah-site move ${SITE} --webs ${DST_WEBS[@]} --db ${DST_DB} --force Check the memcache requirements after the site move. Enable enable memcache service or add memcache servers if required. After the WF is complete, assign the new BAL values to the site manually, get the CLUSTER_UUID from above esl2 command : ah-edge add-environment-to-edge-cluster --environment-name=${SITE} --uuid=${CLUSTER_UUID} If you started the WF anyway with specifying the BALs and the WF did error out with error : \u201cCannot assign a site to balancers without an elastic IP address.\u201d ; then clean up the error WF and its so far executed steps (examples as shown in OP-272857, OP-247706). Start a new WF without specifying the BAL. Please do not try to assign an EIP to the EDGE Bals If the destination servers are in a different VPC, please make sure the memcache service is disabled on all the web/ded instances in the destination VPC. This is required to prevent site outage, the site will experience downtime as the web services on sources web/ded serves fails to connect to the memcache services on destination servers in different VPC. Start the workflow to move the site. Omit any parameters which are not being changed (i.e. if the site is keeping its current balancers): ah-site move ${SITE} --webs ${DST_WEBS[@]} --bals ${DST_BALS[@]} --db ${DST_DB} --force If you want to scheduled the site move workflow then use ah-site move ${SITE} --webs ${DST_WEBS[@]} --bals ${DST_BALS[@]} --db ${DST_DB} --force --scheduled-time ${UNIX_START_TIME} Caution:Always move the site one by one. Calculate the total migration time and then schedule the site move accordingly. Check the memcache requirements after the site move. Enable enable memcache service or add memcache servers if required. If the workflow cannot be made to work, trying manually moving the site Warning - In case of shared infra EIP will be intact with the source hardware hardware. If the old webs or deds have EIPs, move them to the new webs/deds. VPC to CLASSIC will never be supported due to AWS restrictions. ah-server help migrate-eip Usage: ah-server migrate-eip --destination-server-name=DESTINATION_SERVER_NAME --source-server-name=SOURCE_SERVER_NAME # Note. Classic Elastic IPs need to be allocated 24 hours before moving them to vpc which is a hard AWS restriction. # Example : ah-server migrate-eip --source-server-name=ded-123 --destination-server-name=ded-596 Post EIP migration,verify and make sure that the EIPs are moved correctly. In ACE, a site move in the same region allows you to continue to use the same ELB if it exists, but you must ensure that the ELB is configured for the new balancers' AZs: site-elbdescribe ${SITE} If the site has an ELB and it is not configured for the right AZs, update it: ELB=$(ruby -e \"require 'aq'; begin; site_input = '$SITE'; site_id = Aq::Hosting::Site.from_name(site_input).record['id']; site_elb = Aq::Hosting::SiteElb.fromQuery('site_id' => site_id); rescue Aq::Hosting::EntityNotFoundError => e; puts 'nil'; else; puts site_elb['elb_name'].to_s; end\") AZS=($(ah-server list ${DST_BALS_CSV} -c ec2_availability_zone --no-name | paste -sd' ')) aws elb enable-availability-zones-for-load-balancer \\ --region ${REGION} \\ --load-balancer-name ${ELB} \\ --availability-zones ${AZS} If the site is in a Site Factory realm, follow the steps to create an ELB for Site Factory . Deprovision the existing one. If the site previously had e2e enabled, follow the enable e2e runbook to re-enable it. You have to configure mysql only once per server and restart mysql after enabling e2e on the site. Also check and verify the e2e installation as per the steps given in below e2e runbook. Enable e2e after site move As a last step, move the contents of the customer's home directory using the commands we generated above before the site move and copied to JIRA ticket. Note: Create a TSR to remove /mnt/gfs/SITENAME-MOVED-* directory,which should be executed after 7 days. Note: We generally don\u2019t move RA site or environments while moving entire site group. However there are some situations when we also need to move RA environments. For example while moving the entire site into a dedicated VPC or while region moves where RA team has asked for it.","title":"Site Move - Same region"},{"location":"kanban_tickets/site_move/#different-regions","text":"","title":"Different Regions"},{"location":"kanban_tickets/site_move/#variables-different-regions","text":"Set variables for the SITE to be moved, the lowest-numbered destination DB server, WEBS , and BALS , as applicable, and the OP ticket. Note : Here SITE is name of a single sitename not the sitegroup SITE= DST_WEBS=() DST_BALS=() DST_DB= OP= DST_WEBS_CSV=$(array-csv ${DST_WEBS[@]}) DST_BALS_CSV=$(array-csv ${DST_BALS[@]})","title":"Variables - Different regions"},{"location":"kanban_tickets/site_move/#home-directory-copy-commands-multi-region","text":"These commands are generated now but executed later after site-move for moving customer's home directory contents. Copy these to the OP ticket to be run after the site-move is done while true; do SRC=$(ah-server list site:${SITE} -w typeINded,fs,fsdb,fsdbmesh,staging | head -1) DST_FS_CLUSTER_ID=$(ah-server list ${DST_WEBS_CSV} --no-name -c fs_cluster_id | head -1) DST=$(ah-server list % -w typeINded,fs,fsdb,fsdbmesh,staging fs_cluster_id=${DST_FS_CLUSTER_ID} | head -1) SITEGROUP=$(ah-site list ${SITE} --no-name -c sitegroup) SITEGROUP_UID=$(ah-sitegroup list ${SITEGROUP} --no-name -c unix_uid) echo \"{code:title= Move $SITE home directory content from $SRC to $DST}\" echo \"fssh ${DST} 'sudo mkdir -m755 /mnt/gfs/home'\" echo \"sv-rsyncfile -o avPu ${SRC}:/mnt/gfs/home/${SITEGROUP}/ ${DST_WEBS[0]}:/mnt/gfs/home/${SITEGROUP}/\" echo \"fssh ${DST} 'sudo chown -Rh ${SITEGROUP_UID}:${SITEGROUP_UID} /mnt/gfs/home/${SITEGROUP}'\" echo \"{code}\" echo echo 'COPY THE ABOVE OUTPUT TO JIRA TICKET AND EXECUTE THEM LATER AFTER THE SITE MOVE AS LAST STEP' break done","title":"Home directory copy commands multi-region"},{"location":"kanban_tickets/site_move/#site-move-different-region","text":"Use site-taglistactive to determine an available SVN instance in the new region and VPC. REGION= VPC= site-taglistactive svn ${REGION} ${VPC} SVN= Until CL-46442 is fixed, disable e2e encryption and re-enable it after the site move SITE=nginxvarnishtest ah-site disable-e2e-encryption --site-names=${SITE} \u2714 Disabled End to End Encryption for nginxvarnishtest If the command reports the following you do not need to do take note and do not enable e2e encryption after the site move SITE=nginxvarnishtest ah-site disable-e2e-encryption --site-names=${SITE} XMLRPCRemoteException: The following site(s) do not have end to end encryption enabled: nginxvarnishtest As seen in case of OP-272857 (For RA Site), OP-247706 (For RA Site) and OP-278069 (For QA Site), site move WF from any kind of source BAL (Legacy or Edge) to Destination Edge Bals can error out with the error: update_site_location_within_the_hosting_api raised error Aq::Hosting::ApiClient::XMLRPCRemoteException ERROR: Caught Aq::Hosting::ApiClient::XMLRPCRemoteException while running workflow: Cannot assign a site to balancers without an elastic IP address. This error occurs because WF expects the destination Bals to have an EIP whereas Edge Bals don\u2019t have EIPs. To avoid this issue we can take the following steps: Check if the Destination Bals are Edge BALs, using esl2 command. esl2 ${SITE} If the destination servers are in a different VPC, please make sure the memcache service is disabled on all the web/ded instances in the destination VPC. This is required to prevent site outage, the site will experience downtime as the web services on sources web/ded serves fails to connect to the memcache services on destination servers in different VPC. If Destination Bals are Edge Bals , you may initiate the Site move WF without specifying the Bals in the wf command. ah-site move ${SITE} --webs ${DST_WEBS[@]} --db ${DST_DB} --force After the WF is complete, assign the new BAL values to the site manually, get the CLUSTER_UUID from above esl2 command. ah-edge add-environment-to-edge-cluster --environment-name=${SITE} --uuid=${CLUSTER_UUID} If you started the WF anyway with specifying the BALs and the WF did error out with error : \u201cCannot assign a site to balancers without an elastic IP address.\u201d ; then clean up the error WF and its so far executed steps (examples as shown in OP-272857, OP-247706). Start a new WF without specifying the BAL. Check the memcache requirements after the site move. Enable enable memcache service or add memcache servers if required. In case of Site move to different Region, the EIPs ofcourse can not be moved from one region to another. Please do not try to assign an EIP to the EDGE Bals If the destination servers are in a different VPC, please make sure the memcache service is disabled on all the web/ded instances in the destination VPC. This is required to prevent site outage, the site will experience downtime as the web services on sources web/ded serves fails to connect to the memcache services on destination servers in different VPC. Start the workflow to move the site. ah-site move ${SITE} --webs ${DST_WEBS[@]} --bals ${DST_BALS[@]} --db ${DST_DB} --force Note that data can be rsynced to the new hardware prior to downtime by pausing at the step update_site_location_within_the_hosting_api . ah-site move ${SITE} --webs ${DST_WEBS[@]} --bals ${DST_BALS[@]} --db ${DST_DB} --force --pause-at-step=update_site_location_within_the_hosting_api --pause-description=\"$OP | $SITE site move\" If paused, resume the workflow when you are ready to commence downtime. A second rsync pass will occur to transfer any files which were created after the initial pre-rsync was run. If you want to scheduled the site move workflow then use ah-site move ${SITE} --webs ${DST_WEBS[@]} --bals ${DST_BALS[@]} --db ${DST_DB} --force --scheduled-time ${UNIX_START_TIME} Check the memcache requirements after the site move. Enable enable memcache service or add memcache servers if required. If you want to resume a presynced workflow task at a specific time, calculate UNIX_START_TIME as above, then schedule it to resume (you must do this after starting the workflow with ah-site move below): WORKFLOW_ID= ah-workflow schedule-resume ${WORKFLOW_ID} --scheduled-time ${UNIX_START_TIME} Caution: Always move the site one by one. Calculate the total migration time and then schedule the site move accordingly. If the workflow cannot be made to work, trying manually moving the site Migrate the SVN repo SITEGROUP=$(ah-site list ${SITE} --no-name -c sitegroup) ah-sitegroup move-repos ${SITEGROUP} ${SVN} If the site has an ELB, deprovision it site-elbdescribe ${SITE} ah-site ssl deprovision-elb ${SITE} If the customer is using Self-Service SSL, then just notify Support to tell the customer that they will need to reconfigure SSL. Otherwise, provision a new ELB and configure it with the key and certs from the prep work. In the instructions below, CERT refers to a file with only the identity cert and CA refers to a chain with only the intermediate certs. CERT= CA= KEY= ah-site ssl create-elb ${SITE} --ca=$CA --cert=$CERT --key=$KEY If the site move is in Site Factory, follow the specific steps to create an ELB for site factory in the new destination. If the site previously had e2e enabled, follow the enable e2e runbook to re-enable it. You have to configure mysql only once per server and restart mysql after enabling e2e on the site. Also check and verify the e2e installation as per the steps given in below e2e runbook. Enable e2e after site move Provide the ticket requester with the EIP of the new balancers, so the customers can update DNS. As a last step, move the contents of the customer's home directory using the commands we generated above before the site move and copied to JIRA ticket. Note: Create a TSR to remove /mnt/gfs/SITENAME-MOVED-* directory,which should be executed after 7 days.","title":"Site Move - Different region"},{"location":"kanban_tickets/site_move/#verification","text":"Verify there are no alerts for any of the hardware or sites affected by the site move. All tasks and/or workflows should be done. site-checkwebs ${SITE} site-check ${SITE} If no more sites remain on the source server(s) then verify if they can be deprovisioned and file a TSR ticket to deprovision the instances in seven days. If Site Factory: Create a DG ticket in JIRA and link to the site move ticket. The site move ticket is not done until the DG ticket is done. The ACSF engineering team will perform a cleanup as needed on the new hardware. There are typically some caches that need refreshing on the factory, and some files are not brought over during the regular process.","title":"Verification"},{"location":"kanban_tickets/site_move/#recovery","text":"If the task is any state other than \"done\", then you must determine what went wrong during the site move. There are two major points which the task can fail: migrating data from /vol/ebs1 , or migrating data from /mnt/gfs . Examine the task output to determine which part of the site move failed. Databases: follow the procedure for XFS Dump Restore, and restore the data on the destination DB's. File System: Follow the ssh-between-servers runbook to sync the remaining files. Make sure to run the rsync on screen session. An example is below. WARNING: Always use a trailing slash with rsync paths!! sv-screen screen_name rsync -avPe 'ssh -i /root/.ssh/path_of_key\u2019 /home/${SITEGROUP}/${SITE_ENV}/ ${DST_FS_SERVER}:/home/${SITEGROUP}/${SITE_ENV}/ fssh ${DST_FS_SERVER} \"sudo chown -Rh ${SITEGROUP_UID}:${SITEGROUP_UID} /home/${SITEGROUP}/${SITE_ENV}/\" NOTE: If a site move workflow gets stuck or failed, we should escalate the issue to cloud immediately after getting approval from Ops management.","title":"Recovery"},{"location":"kanban_tickets/site_move/#cleanup","text":"Once the site move is complete and verification successful, you need to cleanup the site directory from source web. As part of site move, the site directory on the source web will be appended with a string -MOVED-{workflow|task}-{id} . For example, the directory on /mnt/gfs will look like ${SITE}-MOVED-{workflow|task}-{id} . The site directory has to be manually removed. fssh ${SRC_WEB} \"sudo rm -rf /mnt/gfs/${SITE}-MOVED-{workflow|task}-{id}\" If the new feature flag PersistentDataService.SiteMoveUseEnvFileSymlink is set to true , it will no longer append the string to the site directory on /mnt/gfs . You have to find the site directory on the source web and remove it. You can check the value of feature flag using a CLI command and then remove site directory by ssh'ing to the source web. bin/ah-stage get-config --key=PersistentDataService.SiteMoveUseEnvFileSymlink fssh ${SRC_WEB} \"sudo rm -rf /mnt/gfs/${SITE}\"","title":"Cleanup"},{"location":"kanban_tickets/sni_ssl/","text":"SNI Certificates (deployed to bals) SNI feature in fields was developed for use with ACP, ACE, and ACSF to be used by customer directly from Cloud UI. However, the feature is not available on the cloud UI for ACSF so it has to be deployed/redeployed/un-deployed manually by using CLI tools when requested. This runbook has been created to help with dealing with SNI certificate/key pairs for a site in ACSF since that's the only method available currently but can be used in ACE as well if required for any reasons. We should push back requests to handle ACE/ACP SNI issues to be resolved through Cloud UI. Some SNI concepts (for information purposes - can be skipped) Without a SNI capable web server, a server can only have one SSL certificate deployed per listening port. This means you have to include all the domains you want to cover into a single certificate. SNI makes it possible to deploy multiple SSL certificate/key pairs to a SNI capable web server(eg: nginx) listening on a single port. In acquia cloud, a customer can deploy a SNI certificate per sitegroup stage (environment: eg prod,dev,test) so that same bal pair can have multiple certificates deployed to them targeting different sitegroup environments. SNI features in fields A SNI certificate/key pair is to be deployed per site A site can have more than one SNI key/pair deployed to it An active SNI cert/key pair is actually used by nginx for serving traffic. All inactive cert/key pairs only exist in fields but are not used for serving any SSL traffic. A site could also have all of the SNIs as inactive in which case, SSL will fall back to the default certificate used by nginx (The one we deploy using bal tags eg: ssl_ucc5) This kind of certificates are slowly replacing direct install or server overrides in the platform. So, please prefer this kind of certificate when replacing an expired certificate. Additionally, remember that you may be alerted by an expiring direct install certificate that may be already replaced by a SNI certificate. In this case you just need to remove the certificate override using the instructions: Remove a certificate override (Legacy balancer) Remove a certificate override (Edge cluster) . Uploading new certificate/key pair and activating it for use with SNI Using a new SNI certificate/key pair is a two step process. First, we have to upload the certificate/key pair. Then, the uploaded cert/key pair has to be made active for it be made available for use. Uploading a cert/key pair for SNI SITE= CERT=[PATH To CERTIFICATE] KEY=[PATH To PRIVATE KEY] CA=[PATH To CERTIFICATION AUTHORITY] ah-site ssl setup-sni-certificate $SITE --cert=${CERT} --key=${KEY} --ca=${CA} The certificate stored at $CERT should include the server certificate and any intermediate certificates that are used to sign the server certificate. Above command will generate an output that includes the certificate ID of the just uploaded certificate/key pair. eg: ah-site ssl setup-sni-certificate eembhusaldev --cert=selfsigneddev.crt --key=selfsigneddev.key --ca=certauth.crt Site name Created certificate ID eembhusaldev xxxxx Activate the uploaded SNI cert/key pair Grab the Certificate ID from step 1 and put it into CERT_ID variable CERT_ID= ah-site ssl set-sni-certificates-active $CERT_ID You may need to run site-fcb $SITE if the effect is not yet visible Changing active cert/key pair for a site which has multiple cert/key pairs availabile for SNI As stated in SNI features in fields , a fields site can have more than one certificate/key pair associated with it but only one of them can be active . An active certificate/key pair is the one that's going to be served when there is any SSL traffic to the site. List certificate/key pairs for a site SITE= ah-site ssl show $SITE The above command will show, among other things, list by certificate/key pairs with their ID (first column), eg: ah-site ssl show eembhusaldev No ELB Certificates. -------------------- SNI Certificates. SNI is complete when the Cert+Key are present. Under that condition fields-config-bal.php will deploy this automatically. ID Complete? Status CA present? Created Issuer CN SANs |/ CSR present? ||/ Cert present? |||/ Key present? 24653 true active --++ 10-11-2018 09:59 24655 true inactive --++ 10-11-2018 10:02 Make the required certificate/key pair active CERT_ID= ah-site ssl set-sni-certificates-active $CERT_ID You may need to run site-fcb $SITE if the effect is not yet visible Making an SNI key/pair 'inactive' for disabling SNI NOTE : Once a cert/key is made inactive, a site won't be using SNI unless another cert/key pair is made active. Making a cert/key pair inactive has an effect of disabling SNI until the SNI is enabled again by making any other available cert/key pair active As stated in SNI features in fields , a fields site all the the certificate/key pairs as inactive . This will mean, the site's SSL traffic will be served using the default cert/key pair that's deployed to the bal by default or using fields SSL tags. List certificate/key pairs for a site SITE= ah-site ssl show $SITE The above command will show, among other things, list by certificate/key pairs with their ID (first column), eg: ah-site ssl show eembhusaldev No ELB Certificates. -------------------- SNI Certificates. SNI is complete when the Cert+Key are present. Under that condition fields-config-bal.php will deploy this automatically. ID Complete? Status CA present? Created Issuer CN SANs |/ CSR present? ||/ Cert present? |||/ Key present? 24653 true active --++ 10-11-2018 09:59 24655 true inactive --++ 10-11-2018 10:02 Make any of the active certificate/key pair the list inactive CERT_ID= ah-site ssl set-sni-certificates-inactive $CERT_ID You may need to run site-fcb $SITE if the effect is not yet visible Deleting an SNI key/pair 'inactive' for a site An inactive certificate/key pair is not going to be used by nginx for SSL traffic in any manner. Only the active cert is actually used by nginx in service SSL traffic using SNI. So an inactive cert/key pair won't be causing any site issues since it's not used at all. We still could get requests to delete a cert/key pair from a site. If we get such requests, we can delete a SNI cert/key pair for a site as follows List certificate/key pairs for a site SITE= ah-site ssl show $SITE The above command will show, among other things, list by certificate/key pairs with their ID (first column), eg: ah-site ssl show eembhusaldev No ELB Certificates. -------------------- SNI Certificates. SNI is complete when the Cert+Key are present. Under that condition fields-config-bal.php will deploy this automatically. ID Complete? Status CA present? Created Issuer CN SANs |/ CSR present? ||/ Cert present? |||/ Key present? 24653 true active --++ 10-11-2018 09:59 24655 true inactive --++ 10-11-2018 10:02 If the cert/key pair to be deleted is active , make it inactive first. CERT_ID= ah-site ssl set-sni-certificates-inactive $CERT_ID Delete the required certificate key pair CERT_ID= ah-site ssl remove-sni-certificates $SITE --cert-ids $CERT_ID You may need to run site-fcb $SITE if the effect is not yet visible NOTE : Once a cert/key is made inactive, a site won't be using SNI unless another cert/key pair is made active. Making a cert/key pair inactive has an effect of disabling SNI until the SNI is enabled again by making any other available cert/key pair 'active`","title":"SNI Certificates (deployed to bals)"},{"location":"kanban_tickets/sni_ssl/#sni-certificates-deployed-to-bals","text":"SNI feature in fields was developed for use with ACP, ACE, and ACSF to be used by customer directly from Cloud UI. However, the feature is not available on the cloud UI for ACSF so it has to be deployed/redeployed/un-deployed manually by using CLI tools when requested. This runbook has been created to help with dealing with SNI certificate/key pairs for a site in ACSF since that's the only method available currently but can be used in ACE as well if required for any reasons. We should push back requests to handle ACE/ACP SNI issues to be resolved through Cloud UI.","title":"SNI Certificates (deployed to bals)"},{"location":"kanban_tickets/sni_ssl/#some-sni-concepts-for-information-purposes-can-be-skipped","text":"Without a SNI capable web server, a server can only have one SSL certificate deployed per listening port. This means you have to include all the domains you want to cover into a single certificate. SNI makes it possible to deploy multiple SSL certificate/key pairs to a SNI capable web server(eg: nginx) listening on a single port. In acquia cloud, a customer can deploy a SNI certificate per sitegroup stage (environment: eg prod,dev,test) so that same bal pair can have multiple certificates deployed to them targeting different sitegroup environments.","title":"Some SNI concepts (for information purposes - can be skipped)"},{"location":"kanban_tickets/sni_ssl/#sni-features-in-fields","text":"A SNI certificate/key pair is to be deployed per site A site can have more than one SNI key/pair deployed to it An active SNI cert/key pair is actually used by nginx for serving traffic. All inactive cert/key pairs only exist in fields but are not used for serving any SSL traffic. A site could also have all of the SNIs as inactive in which case, SSL will fall back to the default certificate used by nginx (The one we deploy using bal tags eg: ssl_ucc5) This kind of certificates are slowly replacing direct install or server overrides in the platform. So, please prefer this kind of certificate when replacing an expired certificate. Additionally, remember that you may be alerted by an expiring direct install certificate that may be already replaced by a SNI certificate. In this case you just need to remove the certificate override using the instructions: Remove a certificate override (Legacy balancer) Remove a certificate override (Edge cluster) .","title":"SNI features in fields"},{"location":"kanban_tickets/sni_ssl/#uploading-new-certificatekey-pair-and-activating-it-for-use-with-sni","text":"Using a new SNI certificate/key pair is a two step process. First, we have to upload the certificate/key pair. Then, the uploaded cert/key pair has to be made active for it be made available for use. Uploading a cert/key pair for SNI SITE= CERT=[PATH To CERTIFICATE] KEY=[PATH To PRIVATE KEY] CA=[PATH To CERTIFICATION AUTHORITY] ah-site ssl setup-sni-certificate $SITE --cert=${CERT} --key=${KEY} --ca=${CA} The certificate stored at $CERT should include the server certificate and any intermediate certificates that are used to sign the server certificate. Above command will generate an output that includes the certificate ID of the just uploaded certificate/key pair. eg: ah-site ssl setup-sni-certificate eembhusaldev --cert=selfsigneddev.crt --key=selfsigneddev.key --ca=certauth.crt Site name Created certificate ID eembhusaldev xxxxx Activate the uploaded SNI cert/key pair Grab the Certificate ID from step 1 and put it into CERT_ID variable CERT_ID= ah-site ssl set-sni-certificates-active $CERT_ID You may need to run site-fcb $SITE if the effect is not yet visible","title":"Uploading new certificate/key pair and activating it for use with SNI"},{"location":"kanban_tickets/sni_ssl/#changing-active-certkey-pair-for-a-site-which-has-multiple-certkey-pairs-availabile-for-sni","text":"As stated in SNI features in fields , a fields site can have more than one certificate/key pair associated with it but only one of them can be active . An active certificate/key pair is the one that's going to be served when there is any SSL traffic to the site. List certificate/key pairs for a site SITE= ah-site ssl show $SITE The above command will show, among other things, list by certificate/key pairs with their ID (first column), eg: ah-site ssl show eembhusaldev No ELB Certificates. -------------------- SNI Certificates. SNI is complete when the Cert+Key are present. Under that condition fields-config-bal.php will deploy this automatically. ID Complete? Status CA present? Created Issuer CN SANs |/ CSR present? ||/ Cert present? |||/ Key present? 24653 true active --++ 10-11-2018 09:59 24655 true inactive --++ 10-11-2018 10:02 Make the required certificate/key pair active CERT_ID= ah-site ssl set-sni-certificates-active $CERT_ID You may need to run site-fcb $SITE if the effect is not yet visible","title":"Changing active cert/key pair for a site which has multiple cert/key pairs availabile for SNI"},{"location":"kanban_tickets/sni_ssl/#making-an-sni-keypair-inactive-for-disabling-sni","text":"NOTE : Once a cert/key is made inactive, a site won't be using SNI unless another cert/key pair is made active. Making a cert/key pair inactive has an effect of disabling SNI until the SNI is enabled again by making any other available cert/key pair active As stated in SNI features in fields , a fields site all the the certificate/key pairs as inactive . This will mean, the site's SSL traffic will be served using the default cert/key pair that's deployed to the bal by default or using fields SSL tags. List certificate/key pairs for a site SITE= ah-site ssl show $SITE The above command will show, among other things, list by certificate/key pairs with their ID (first column), eg: ah-site ssl show eembhusaldev No ELB Certificates. -------------------- SNI Certificates. SNI is complete when the Cert+Key are present. Under that condition fields-config-bal.php will deploy this automatically. ID Complete? Status CA present? Created Issuer CN SANs |/ CSR present? ||/ Cert present? |||/ Key present? 24653 true active --++ 10-11-2018 09:59 24655 true inactive --++ 10-11-2018 10:02 Make any of the active certificate/key pair the list inactive CERT_ID= ah-site ssl set-sni-certificates-inactive $CERT_ID You may need to run site-fcb $SITE if the effect is not yet visible","title":"Making an SNI key/pair 'inactive' for disabling SNI"},{"location":"kanban_tickets/sni_ssl/#deleting-an-sni-keypair-inactive-for-a-site","text":"An inactive certificate/key pair is not going to be used by nginx for SSL traffic in any manner. Only the active cert is actually used by nginx in service SSL traffic using SNI. So an inactive cert/key pair won't be causing any site issues since it's not used at all. We still could get requests to delete a cert/key pair from a site. If we get such requests, we can delete a SNI cert/key pair for a site as follows List certificate/key pairs for a site SITE= ah-site ssl show $SITE The above command will show, among other things, list by certificate/key pairs with their ID (first column), eg: ah-site ssl show eembhusaldev No ELB Certificates. -------------------- SNI Certificates. SNI is complete when the Cert+Key are present. Under that condition fields-config-bal.php will deploy this automatically. ID Complete? Status CA present? Created Issuer CN SANs |/ CSR present? ||/ Cert present? |||/ Key present? 24653 true active --++ 10-11-2018 09:59 24655 true inactive --++ 10-11-2018 10:02 If the cert/key pair to be deleted is active , make it inactive first. CERT_ID= ah-site ssl set-sni-certificates-inactive $CERT_ID Delete the required certificate key pair CERT_ID= ah-site ssl remove-sni-certificates $SITE --cert-ids $CERT_ID You may need to run site-fcb $SITE if the effect is not yet visible NOTE : Once a cert/key is made inactive, a site won't be using SNI unless another cert/key pair is made active. Making a cert/key pair inactive has an effect of disabling SNI until the SNI is enabled again by making any other available cert/key pair 'active`","title":"Deleting an SNI key/pair 'inactive' for a site"},{"location":"kanban_tickets/ssl_acm/","text":"AWS Certificate Manager Some of our internal domains in ACSF are secured with certs we manage with the AWS ACM service. Occasionally Site Factory will ask that certain internal acsitefactory.com domains be covered by SSL certificates, which of course means what it means for any other cert management operation: create a new cert that looks like the desired changes applied to the existing cert. Requesting A Certificate Using the CUSTOMER variable as an anchor, we can request SSL coverage for all environments in the customer's provisioned ACSF sitegroup. An example value for the CUSTOMER variable would be veolia , as their Site Factory sitegroup name is veoliasf . CUSTOMER=\"\" SITE=\"${CUSTOMER}sf\" VALIDATION_DOMAIN=\"acsitefactory.com\" PROD_DOMAIN=\"www.${CUSTOMER}.${VALIDATION_DOMAIN}\" REGION=$(ah-server list site:$SITE -c ec2_region --no-name | uniq) NON_PROD_SITES=($(ah-site list % -w sitegroup=${SITE} stage!=prod -c stage --no-name)) SANS=(${PROD_DOMAIN}) for SUB in ${NON_PROD_SITES[@]}; do SANS+=( www.${SUB}-${CUSTOMER}.${VALIDATION_DOMAIN} ); done echo \"Sans: ${SANS[@]}\" ARN=$(aws acm request-certificate --domain-name ${PROD_DOMAIN} \\ --subject-alternative-names ${SANS[@]} \\ --region ${REGION} --validation-method DNS) echo \"Certificate ARN: $ARN\" You will need to set a value for the CNAME on each domain requested on the certificate. The VALUE will end in acm-validations.aws , whereas the NAME will have an aws hash before the domain name. Remove any periods at the end when copy pasting to avoid errors. ARN= aws acm describe-certificate --certificate-arn ${ARN} --region ${REGION} | egrep \"DomainName|Name|Value\" ah-dns set -t CNAME -v $VALUE -h $NAME Deploying an ACM Certificate Proceed with deploying the new cert and deleting the previous one: ELB_FQDN=$(site-elbdescribe $SITE | grep amazonaws.com) ELB=$(echo $ELB_FQDN | sed \"s/-[0-9]*\\.$REGION.*//\") OLD_ARN=$(aws elb describe-load-balancers --region $REGION \\ --load-balancer-names $ELB \\ --query '*[].ListenerDescriptions[].Listener.SSLCertificateId' --output text) aws elb set-load-balancer-listener-ssl-certificate --load-balancer-name \\ ${ELB} --load-balancer-port 443 --ssl-certificate-id ${ARN} \\ --region ${REGION} for san in ${SANS[@]}; do ah-dns set -t CNAME -v ${ELB_FQDN} -h ${san} done aws acm delete-certificate --certificate-arn $OLD_ARN --region ${REGION}","title":"AWS Certificate Manager"},{"location":"kanban_tickets/ssl_acm/#aws-certificate-manager","text":"Some of our internal domains in ACSF are secured with certs we manage with the AWS ACM service. Occasionally Site Factory will ask that certain internal acsitefactory.com domains be covered by SSL certificates, which of course means what it means for any other cert management operation: create a new cert that looks like the desired changes applied to the existing cert.","title":"AWS Certificate Manager"},{"location":"kanban_tickets/ssl_acm/#requesting-a-certificate","text":"Using the CUSTOMER variable as an anchor, we can request SSL coverage for all environments in the customer's provisioned ACSF sitegroup. An example value for the CUSTOMER variable would be veolia , as their Site Factory sitegroup name is veoliasf . CUSTOMER=\"\" SITE=\"${CUSTOMER}sf\" VALIDATION_DOMAIN=\"acsitefactory.com\" PROD_DOMAIN=\"www.${CUSTOMER}.${VALIDATION_DOMAIN}\" REGION=$(ah-server list site:$SITE -c ec2_region --no-name | uniq) NON_PROD_SITES=($(ah-site list % -w sitegroup=${SITE} stage!=prod -c stage --no-name)) SANS=(${PROD_DOMAIN}) for SUB in ${NON_PROD_SITES[@]}; do SANS+=( www.${SUB}-${CUSTOMER}.${VALIDATION_DOMAIN} ); done echo \"Sans: ${SANS[@]}\" ARN=$(aws acm request-certificate --domain-name ${PROD_DOMAIN} \\ --subject-alternative-names ${SANS[@]} \\ --region ${REGION} --validation-method DNS) echo \"Certificate ARN: $ARN\" You will need to set a value for the CNAME on each domain requested on the certificate. The VALUE will end in acm-validations.aws , whereas the NAME will have an aws hash before the domain name. Remove any periods at the end when copy pasting to avoid errors. ARN= aws acm describe-certificate --certificate-arn ${ARN} --region ${REGION} | egrep \"DomainName|Name|Value\" ah-dns set -t CNAME -v $VALUE -h $NAME","title":"Requesting A Certificate"},{"location":"kanban_tickets/ssl_acm/#deploying-an-acm-certificate","text":"Proceed with deploying the new cert and deleting the previous one: ELB_FQDN=$(site-elbdescribe $SITE | grep amazonaws.com) ELB=$(echo $ELB_FQDN | sed \"s/-[0-9]*\\.$REGION.*//\") OLD_ARN=$(aws elb describe-load-balancers --region $REGION \\ --load-balancer-names $ELB \\ --query '*[].ListenerDescriptions[].Listener.SSLCertificateId' --output text) aws elb set-load-balancer-listener-ssl-certificate --load-balancer-name \\ ${ELB} --load-balancer-port 443 --ssl-certificate-id ${ARN} \\ --region ${REGION} for san in ${SANS[@]}; do ah-dns set -t CNAME -v ${ELB_FQDN} -h ${san} done aws acm delete-certificate --certificate-arn $OLD_ARN --region ${REGION}","title":"Deploying an ACM Certificate"},{"location":"kanban_tickets/staging_single_tier_to_multi_tier_manual/","text":"Staging Single Tier to Multi-tier Upsize This procedure is for switching a Single Tier Staging to Multi tier, Staging + Web, cluster. We don't ever change the name of a server from Staging to FSDB/DED, or vice versa. This is done in situations where we sell a Multi tier to a customer that has an existing Single Tier staging server. Traps These traps are the most common issues you will find when resizing a customers stack. The procedure below incorporates the handling of these gotchas. EIPs Multiple sites on a single stack Set Variables Even though for the upsize you are about to perform there may only be one site, still declare the variables below as arrays where needed. This procedure expects there to be arrays. SITES=() AMI_TYPE= NUM_WEBS= STAGING=($(ah-server list site:${SITES[0]} -w type=staging)) AZ=($(ah-server list $STAGING --no-name -c ec2_availability_zone)) REGION=${AZ[0]::-1} VPC_ID=$(ah-server list ${STAGING[0]} -c vpc_id --no-name) Sites running on same hardware: TOTAL_SITES=($(ah-site list on:${STAGING})) SITES=($(echo ${TOTAL_SITES[@]})) Verify variable assignment. echo \"{noformat:title=Procedure Variables}\" \\ && echo \"SITES=(${SITES[@]})\" \\ && echo \"AMI_TYPE=${AMI_TYPE}\" \\ && echo \"NUM_WEBS=${NUM_WEBS}\" \\ && echo \"STAGING=(${STAGING[@]})\" \\ && echo \"AZ=(${AZ[@]})\" \\ && echo \"REGION=${REGION}\" \\ && echo \"VPC_ID=${VPC_ID}\" \\ && echo \"{noformat}\" Existing Webs If the site(s) you are working with already have web servers in the create state, you can skip to verifying server settings . Gather information Capture the output from these tools, for each of the sites affected, and paste the relevant parts into the Jira ticket. esl $STAGING for site in ${SITES[@]}; do echo ${site} site-getwebrotationstatus ${site} done Create Provision New Webs Assuming that this command works successfully, you can continue to the next step. If this bombs out for any reason it is vital that you correct the issue immediately and ensure that $WEBS is properly set as a bash array. If the Staging is in a VPC ($VPC_ID above is anything but nil), add --vpc-id ${VPC_ID} to the allocate command. for i in $(seq 1 $NUM_WEBS); do ah-server \\ allocate web \\ --ami-type ${AMI_TYPE} \\ --region ${REGION} \\ --avail-zone ${AZS} done Make more variables WEBS=() WEBS_CSV=$(echo ${WEBS[@]} | tr ' ' ',') Cluster New Webs First check that the Gluster versions match. ah-server list ${STAGING} -c puppet:gluster_version ah-server list ${WEBS_CSV} -c puppet:gluster_version If they're different update the settings on the webs. For example if the Gluster version was set to 3.4 on the staging: ah-server edit ${WEBS_CSV} -c puppet:gluster_version=3.4 Now add the servers to the same FS cluster as the existing site. ah-server edit ${WEBS_CSV} \\ -s fs_cluster_id=$(ah-server list ${STAGING} --no-name -c fs_cluster_id) Add Webs to Site/s for site in ${SITES[@]}; do ./fields-provision.php --site-set-web ${site}:deploy --webs ${WEBS_CSV} done Setting the new webs to deploy means that as soon as they launch, the new webs will be immediately put in to balancer rotation. We don't want this as there are some post launch checks we need to perform before the web is commissioned for service. sv-webdisable ${WEBS_CSV} Verify Server Settings Modify the new servers' settings to match the source. This is important to check on existing webs as while servers are suspended they, more often than not, don't have their settings updated. ah-server get ${STAGING} | grep server_settings ah-server get ${WEBS[0]} | grep server_settings Transfer any settings from the original deds to the new webs. The following settings you can safely ignore: fcgi.conf my.cnf puppet.newrelic% server.total_memory Any others need to be applied to the webs. ah-server edit ${WEBS_CSV} -c file:key=value For example: $ ah-server edit web-14309,web-14310 -c puppet:apache_mpm=worker web-14309 set config puppet:apache_mpm=worker web-14310 set config puppet:apache_mpm=worker Updated 2 servers. Launch New Webs ah-server launch ${WEBS[@]} Post Launch Verify IPTABLES, gluster and code deployment fpdsh -t site:${SITES[0]} -c \"sudo ah-config-iptables\" site-fsremount ${SITES[0]} site-fcw ${SITES[0]} Manage EIPs If the STAGING has an EIP attached, move it to the new web. If you have provisioned more than one web, then you will need to provision and attach new EIPs. IMPORTANT : If new EIPs are required it is vital that the servers stay out of balancer rotation until the customer has confirmed that they have white-listed the new EIPs. Failure to do this means the customers site will fail! ah-elastic-ip help allocate ah-elastic-ip help add Move EIP Move the staging server's EIP to the new web sv-webdisable $STAGING ah-server migrate-eip --source-server-name=$STAGING --destination-server-name=${WEBS[0]} sv-webenable ${WEBS[0]} Verify success by running site-checkloop for each site until you have seen that all webs that should be in rotation are serving traffic. If there is a problem with the new web server, pull it from rotation immediately and investigate. Clean Up We now effectively make the STAGING server into a single FSDB. If you didn't need to move EIPs in the last step make sure the new webs are enabled now. sv-webenable ${WEBS_CSV} Remove the staging from the acquia_fields_rel_site_webnode table using the ah-site tool. The running of fields-config-web.php after ensures that any CRON tasks are removed from the STAGINGs. site-fcb makes sure the bals know not to send traffic to the staging anymore. We also want to unset memcached.conf:-m . for site in ${SITES[@]}; do ah-site remove-webnode $site ${STAGING} done fpdsh -t site:${SITES[0]} -n ded -c \"sudo fields-config-web.php\" site-fcb ${SITES[0]} ah-server edit ${STAGING} -c memcached.conf:-m= End Show the new output in your Jira ticket. esl ${WEBS_CSV} for site in ${SITES[@]}; do echo ${site} site-getwebrotationstatus ${site} done Account Management Dealsheet If this Single to Multi Tier upsize was a result of an emergency upsize, you must file an AM ticket for a dealsheet by visiting the following link: AM Dealsheet: Emergency Upsize","title":"Staging Single Tier to Multi-tier Upsize"},{"location":"kanban_tickets/staging_single_tier_to_multi_tier_manual/#staging-single-tier-to-multi-tier-upsize","text":"This procedure is for switching a Single Tier Staging to Multi tier, Staging + Web, cluster. We don't ever change the name of a server from Staging to FSDB/DED, or vice versa. This is done in situations where we sell a Multi tier to a customer that has an existing Single Tier staging server.","title":"Staging Single Tier to Multi-tier Upsize"},{"location":"kanban_tickets/staging_single_tier_to_multi_tier_manual/#traps","text":"These traps are the most common issues you will find when resizing a customers stack. The procedure below incorporates the handling of these gotchas. EIPs Multiple sites on a single stack","title":"Traps"},{"location":"kanban_tickets/staging_single_tier_to_multi_tier_manual/#set-variables","text":"Even though for the upsize you are about to perform there may only be one site, still declare the variables below as arrays where needed. This procedure expects there to be arrays. SITES=() AMI_TYPE= NUM_WEBS= STAGING=($(ah-server list site:${SITES[0]} -w type=staging)) AZ=($(ah-server list $STAGING --no-name -c ec2_availability_zone)) REGION=${AZ[0]::-1} VPC_ID=$(ah-server list ${STAGING[0]} -c vpc_id --no-name) Sites running on same hardware: TOTAL_SITES=($(ah-site list on:${STAGING})) SITES=($(echo ${TOTAL_SITES[@]})) Verify variable assignment. echo \"{noformat:title=Procedure Variables}\" \\ && echo \"SITES=(${SITES[@]})\" \\ && echo \"AMI_TYPE=${AMI_TYPE}\" \\ && echo \"NUM_WEBS=${NUM_WEBS}\" \\ && echo \"STAGING=(${STAGING[@]})\" \\ && echo \"AZ=(${AZ[@]})\" \\ && echo \"REGION=${REGION}\" \\ && echo \"VPC_ID=${VPC_ID}\" \\ && echo \"{noformat}\"","title":"Set Variables"},{"location":"kanban_tickets/staging_single_tier_to_multi_tier_manual/#existing-webs","text":"If the site(s) you are working with already have web servers in the create state, you can skip to verifying server settings .","title":"Existing Webs"},{"location":"kanban_tickets/staging_single_tier_to_multi_tier_manual/#gather-information","text":"Capture the output from these tools, for each of the sites affected, and paste the relevant parts into the Jira ticket. esl $STAGING for site in ${SITES[@]}; do echo ${site} site-getwebrotationstatus ${site} done","title":"Gather information"},{"location":"kanban_tickets/staging_single_tier_to_multi_tier_manual/#create","text":"","title":"Create"},{"location":"kanban_tickets/staging_single_tier_to_multi_tier_manual/#provision-new-webs","text":"Assuming that this command works successfully, you can continue to the next step. If this bombs out for any reason it is vital that you correct the issue immediately and ensure that $WEBS is properly set as a bash array. If the Staging is in a VPC ($VPC_ID above is anything but nil), add --vpc-id ${VPC_ID} to the allocate command. for i in $(seq 1 $NUM_WEBS); do ah-server \\ allocate web \\ --ami-type ${AMI_TYPE} \\ --region ${REGION} \\ --avail-zone ${AZS} done Make more variables WEBS=() WEBS_CSV=$(echo ${WEBS[@]} | tr ' ' ',')","title":"Provision New Webs"},{"location":"kanban_tickets/staging_single_tier_to_multi_tier_manual/#cluster-new-webs","text":"First check that the Gluster versions match. ah-server list ${STAGING} -c puppet:gluster_version ah-server list ${WEBS_CSV} -c puppet:gluster_version If they're different update the settings on the webs. For example if the Gluster version was set to 3.4 on the staging: ah-server edit ${WEBS_CSV} -c puppet:gluster_version=3.4 Now add the servers to the same FS cluster as the existing site. ah-server edit ${WEBS_CSV} \\ -s fs_cluster_id=$(ah-server list ${STAGING} --no-name -c fs_cluster_id)","title":"Cluster New Webs"},{"location":"kanban_tickets/staging_single_tier_to_multi_tier_manual/#add-webs-to-sites","text":"for site in ${SITES[@]}; do ./fields-provision.php --site-set-web ${site}:deploy --webs ${WEBS_CSV} done Setting the new webs to deploy means that as soon as they launch, the new webs will be immediately put in to balancer rotation. We don't want this as there are some post launch checks we need to perform before the web is commissioned for service. sv-webdisable ${WEBS_CSV}","title":"Add Webs to Site/s"},{"location":"kanban_tickets/staging_single_tier_to_multi_tier_manual/#verify-server-settings","text":"Modify the new servers' settings to match the source. This is important to check on existing webs as while servers are suspended they, more often than not, don't have their settings updated. ah-server get ${STAGING} | grep server_settings ah-server get ${WEBS[0]} | grep server_settings Transfer any settings from the original deds to the new webs. The following settings you can safely ignore: fcgi.conf my.cnf puppet.newrelic% server.total_memory Any others need to be applied to the webs. ah-server edit ${WEBS_CSV} -c file:key=value For example: $ ah-server edit web-14309,web-14310 -c puppet:apache_mpm=worker web-14309 set config puppet:apache_mpm=worker web-14310 set config puppet:apache_mpm=worker Updated 2 servers.","title":"Verify Server Settings"},{"location":"kanban_tickets/staging_single_tier_to_multi_tier_manual/#launch-new-webs","text":"ah-server launch ${WEBS[@]}","title":"Launch New Webs"},{"location":"kanban_tickets/staging_single_tier_to_multi_tier_manual/#post-launch","text":"Verify IPTABLES, gluster and code deployment fpdsh -t site:${SITES[0]} -c \"sudo ah-config-iptables\" site-fsremount ${SITES[0]} site-fcw ${SITES[0]}","title":"Post Launch"},{"location":"kanban_tickets/staging_single_tier_to_multi_tier_manual/#manage-eips","text":"If the STAGING has an EIP attached, move it to the new web. If you have provisioned more than one web, then you will need to provision and attach new EIPs. IMPORTANT : If new EIPs are required it is vital that the servers stay out of balancer rotation until the customer has confirmed that they have white-listed the new EIPs. Failure to do this means the customers site will fail! ah-elastic-ip help allocate ah-elastic-ip help add","title":"Manage EIPs"},{"location":"kanban_tickets/staging_single_tier_to_multi_tier_manual/#move-eip","text":"Move the staging server's EIP to the new web sv-webdisable $STAGING ah-server migrate-eip --source-server-name=$STAGING --destination-server-name=${WEBS[0]} sv-webenable ${WEBS[0]} Verify success by running site-checkloop for each site until you have seen that all webs that should be in rotation are serving traffic. If there is a problem with the new web server, pull it from rotation immediately and investigate.","title":"Move EIP"},{"location":"kanban_tickets/staging_single_tier_to_multi_tier_manual/#clean-up","text":"We now effectively make the STAGING server into a single FSDB. If you didn't need to move EIPs in the last step make sure the new webs are enabled now. sv-webenable ${WEBS_CSV} Remove the staging from the acquia_fields_rel_site_webnode table using the ah-site tool. The running of fields-config-web.php after ensures that any CRON tasks are removed from the STAGINGs. site-fcb makes sure the bals know not to send traffic to the staging anymore. We also want to unset memcached.conf:-m . for site in ${SITES[@]}; do ah-site remove-webnode $site ${STAGING} done fpdsh -t site:${SITES[0]} -n ded -c \"sudo fields-config-web.php\" site-fcb ${SITES[0]} ah-server edit ${STAGING} -c memcached.conf:-m=","title":"Clean Up"},{"location":"kanban_tickets/staging_single_tier_to_multi_tier_manual/#end","text":"Show the new output in your Jira ticket. esl ${WEBS_CSV} for site in ${SITES[@]}; do echo ${site} site-getwebrotationstatus ${site} done","title":"End"},{"location":"kanban_tickets/staging_single_tier_to_multi_tier_manual/#account-management-dealsheet","text":"If this Single to Multi Tier upsize was a result of an emergency upsize, you must file an AM ticket for a dealsheet by visiting the following link: AM Dealsheet: Emergency Upsize","title":"Account Management Dealsheet"},{"location":"kanban_tickets/svn_server_certificates/","text":"SVN Server Certificates SVN servers use certificates that are specific only to the hosting stage in which they are launched, and the certs are managed by the master at-launch only . Any renewal of these certificates means that the certs must be updated in two places: The SVN servers specifically The hosting stage master SVN servers store their certs in /etc/ssl rather than an EBS volume. The launcher code pulls these files from the master during launch. /etc/ssl/private/svn-server-key.pem /etc/ssl/certs/svn-server-cert.pem /etc/ssl/certs/svn-server-cert-chain.pem You will need to restart apache2 instead of reload when the certificate changes.","title":"SVN Server Certificates"},{"location":"kanban_tickets/svn_server_certificates/#svn-server-certificates","text":"SVN servers use certificates that are specific only to the hosting stage in which they are launched, and the certs are managed by the master at-launch only . Any renewal of these certificates means that the certs must be updated in two places: The SVN servers specifically The hosting stage master SVN servers store their certs in /etc/ssl rather than an EBS volume. The launcher code pulls these files from the master during launch. /etc/ssl/private/svn-server-key.pem /etc/ssl/certs/svn-server-cert.pem /etc/ssl/certs/svn-server-cert-chain.pem You will need to restart apache2 instead of reload when the certificate changes.","title":"SVN Server Certificates"},{"location":"kanban_tickets/toc/","text":"Kanban Tickets Bastion servers are privileged jump hosts from which people can connect to fields infrastructure. Access is restricted with two-factor authentication and the EIPs of all three bastions are white listed in all regions for all accounts. Production Bastions: bastion-21.network.hosting.acquia.com (us-east-1) bastion-22.network.hosting.acquia.com (eu-west-1) bastion-133.network.hosting.acquia.com (ap-southeast-2) Topics Bastion Add A New User Add an RA Bastion user to ahrabot Bastion Access User Changes Regenerating netrc Credentials Deprovisioning User Account Resize Bastion Volumes Troubleshooting Troubleshooting Yubikeys Database AcquiaMail Dump Restore Change Database Password Custom Tungsten Settings Enabling/Disabling MySQL Audit MySQL daily replication fix Point in Time Recovery Provision Secondary Database Cluster Gluster Downgrade Gluster Upgrade Gluster Dedicated Balancers Dedicated to Dedicated Dedicated to Shared Shared to Dedicated Shared to Shared Instance Deprovision Deprovision Mail Server Instance Management CPU Wait Dedicated Hypervisor Masterless Puppet Orphaned Processes Pre-Allocating EIPs for Webs Restore Volumes Restore Snapshot on New Hardware Instance Provision Provision Bastion Provision Dedicated Memcache Provision Log Server Provision Mail Server Ops Procedures Root Cause Analysis (RCAs) Search Search Hosting Release Delete Search Index Deprovision Search Colony Deprovision Search Farm Move Provisioning Pointer Provision Search Colony Provision Search Farm Search Index Migration Update Colony Certificate Verify Extractor Site Deprovision Deprovision ACE & ACP Deprovision ACSF Site Management Releasing Domains Add Custom Proxy Conf Add and Remove Sites From Monitoring Add and Remove Webs From Rotation Arbitrary php.ini Settings Bulk Site Move Bulk Site PHP Editing Change Balancers on Existing Environment Clamav Code Checkout Failures Configuring HSD for Sites Core Dumps Create a Test Balancer Deploy Test VCL Email Blacklist Enabling Mod Proxy Enabling Xdebug Fix Livedev Loadtest Balancers Log Forwarding Manage End to End Encryption Move Customer Repository Site Audit Site Move Unblocking Email Service Unique Multisite Hash Salt Site Provision ACE Provision ACP Provision ACSF Provision Provision Employee Free Sites Provision Site Provisioning Fedramp with acquia shield Provisioning Fedramp without acquia shield Provision Multi Region Multiregion Failover Testing SSL AWS Certificate Manager (ACM) Deploy SSL Certificate Diagnostics Disable TLS Versions Duplicate Certificates Extended Validation Certificates Generating a Certificate Signing Request (CSR) SSL Overview Root CA Cert Management For Puppet Master Renewing Certificates Renewing SSL Cert for Puppet Master Restoring an Acquia-Managed SSL Cert Creating an ELB Self Service SSL (on ELBs) SNI Certificates SVN Server Certificates Wildcard Certificates Tier Conversion Multi-tier to Full Tier Multi-tier to Single Tier Single-tier to Multi-tier Single-tier to Multi-tier Manual Staging Single-tier to Multi-tier VPC Deprovision Network Boundaries Provision VPN Deprovision VPN Management VPN Provision","title":"Kanban Tickets"},{"location":"kanban_tickets/toc/#kanban-tickets","text":"Bastion servers are privileged jump hosts from which people can connect to fields infrastructure. Access is restricted with two-factor authentication and the EIPs of all three bastions are white listed in all regions for all accounts. Production Bastions: bastion-21.network.hosting.acquia.com (us-east-1) bastion-22.network.hosting.acquia.com (eu-west-1) bastion-133.network.hosting.acquia.com (ap-southeast-2)","title":"Kanban Tickets"},{"location":"kanban_tickets/toc/#topics","text":"","title":"Topics"},{"location":"kanban_tickets/toc/#bastion","text":"Add A New User Add an RA Bastion user to ahrabot Bastion Access User Changes Regenerating netrc Credentials Deprovisioning User Account Resize Bastion Volumes Troubleshooting Troubleshooting Yubikeys","title":"Bastion"},{"location":"kanban_tickets/toc/#database","text":"AcquiaMail Dump Restore Change Database Password Custom Tungsten Settings Enabling/Disabling MySQL Audit MySQL daily replication fix Point in Time Recovery Provision Secondary Database Cluster","title":"Database"},{"location":"kanban_tickets/toc/#gluster","text":"Downgrade Gluster Upgrade Gluster","title":"Gluster"},{"location":"kanban_tickets/toc/#dedicated-balancers","text":"Dedicated to Dedicated Dedicated to Shared Shared to Dedicated Shared to Shared","title":"Dedicated Balancers"},{"location":"kanban_tickets/toc/#instance-deprovision","text":"Deprovision Mail Server","title":"Instance Deprovision"},{"location":"kanban_tickets/toc/#instance-management","text":"CPU Wait Dedicated Hypervisor Masterless Puppet Orphaned Processes Pre-Allocating EIPs for Webs Restore Volumes Restore Snapshot on New Hardware","title":"Instance Management"},{"location":"kanban_tickets/toc/#instance-provision","text":"Provision Bastion Provision Dedicated Memcache Provision Log Server Provision Mail Server","title":"Instance Provision"},{"location":"kanban_tickets/toc/#ops-procedures","text":"Root Cause Analysis (RCAs)","title":"Ops Procedures"},{"location":"kanban_tickets/toc/#search","text":"Search Hosting Release Delete Search Index Deprovision Search Colony Deprovision Search Farm Move Provisioning Pointer Provision Search Colony Provision Search Farm Search Index Migration Update Colony Certificate Verify Extractor","title":"Search"},{"location":"kanban_tickets/toc/#site-deprovision","text":"Deprovision ACE & ACP Deprovision ACSF","title":"Site Deprovision"},{"location":"kanban_tickets/toc/#site-management","text":"Releasing Domains Add Custom Proxy Conf Add and Remove Sites From Monitoring Add and Remove Webs From Rotation Arbitrary php.ini Settings Bulk Site Move Bulk Site PHP Editing Change Balancers on Existing Environment Clamav Code Checkout Failures Configuring HSD for Sites Core Dumps Create a Test Balancer Deploy Test VCL Email Blacklist Enabling Mod Proxy Enabling Xdebug Fix Livedev Loadtest Balancers Log Forwarding Manage End to End Encryption Move Customer Repository Site Audit Site Move Unblocking Email Service Unique Multisite Hash Salt","title":"Site Management"},{"location":"kanban_tickets/toc/#site-provision","text":"ACE Provision ACP Provision ACSF Provision Provision Employee Free Sites Provision Site Provisioning Fedramp with acquia shield Provisioning Fedramp without acquia shield Provision Multi Region Multiregion Failover Testing","title":"Site Provision"},{"location":"kanban_tickets/toc/#ssl","text":"AWS Certificate Manager (ACM) Deploy SSL Certificate Diagnostics Disable TLS Versions Duplicate Certificates Extended Validation Certificates Generating a Certificate Signing Request (CSR) SSL Overview Root CA Cert Management For Puppet Master Renewing Certificates Renewing SSL Cert for Puppet Master Restoring an Acquia-Managed SSL Cert Creating an ELB Self Service SSL (on ELBs) SNI Certificates SVN Server Certificates Wildcard Certificates","title":"SSL"},{"location":"kanban_tickets/toc/#tier-conversion","text":"Multi-tier to Full Tier Multi-tier to Single Tier Single-tier to Multi-tier Single-tier to Multi-tier Manual Staging Single-tier to Multi-tier","title":"Tier Conversion"},{"location":"kanban_tickets/toc/#vpc","text":"Deprovision Network Boundaries Provision VPN Deprovision VPN Management VPN Provision","title":"VPC"},{"location":"kanban_tickets/troubleshooting_bastion/","text":"Troubleshooting When a User Just Can't Log In Check /var/log/auth.log (look for incorrect name, bad password, \"id_rsa decrypted\" messages, too many connections) Errors in /var/log/auth.log that say \"too many connections\" means that the number of connections for the user are more than the allowed limit. Sometimes it happens if user loses internet connection or terminal. Check the processes for that users: USERNAME= ps -Fp $(pgrep -u ${USERNAME}) And kill the process: kill $PID or if you want to kill all process for the user pkill -u ${USERNAME} When a User Gets Locked Out after successful previous logins A user can lock themselves out of the bastion host if they do the following: Type the incorrect yubikey pin three times. Fail to authenticate to the bastion host using the yubikeys due to yubikey reset. If this happens, a new attestation certificate would be required. See this","title":"Troubleshooting"},{"location":"kanban_tickets/troubleshooting_bastion/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"kanban_tickets/troubleshooting_bastion/#when-a-user-just-cant-log-in","text":"Check /var/log/auth.log (look for incorrect name, bad password, \"id_rsa decrypted\" messages, too many connections) Errors in /var/log/auth.log that say \"too many connections\" means that the number of connections for the user are more than the allowed limit. Sometimes it happens if user loses internet connection or terminal. Check the processes for that users: USERNAME= ps -Fp $(pgrep -u ${USERNAME}) And kill the process: kill $PID or if you want to kill all process for the user pkill -u ${USERNAME}","title":"When a User Just Can't Log In"},{"location":"kanban_tickets/troubleshooting_bastion/#when-a-user-gets-locked-out-after-successful-previous-logins","text":"A user can lock themselves out of the bastion host if they do the following: Type the incorrect yubikey pin three times. Fail to authenticate to the bastion host using the yubikeys due to yubikey reset. If this happens, a new attestation certificate would be required. See this","title":"When a User Gets Locked Out after successful previous logins"},{"location":"kanban_tickets/troubleshooting_yubikey/","text":"Troubleshooting Yubikey When a User Just Can't Log In with Yubikey Resources on Confluence Yubikey Bastion MFA Yubikey Operations/Admin Installation steps for Yubikey Yubikey Installation steps Download yk_bastion_init tool Click to download yk_bastion_init Change the permissions on this file to make it executable: chmod u+x /usr/local/bin/yk_bastion_init Command to run after installation Command Reference for yk_bastion_init Most users will just use yk_bastion_init without any options to initialize their key. yk_bastion_init provides several additional functions. Usage: ./yk_bastion_init [init|attest|set-pin|reset|help] init - initialize the YubiKey, set the ssh private key, and export the attestation certificate for bastion access. This is the default if no command is given. attest - display the current attestation certificate (if any). This will tell you the file path where the previously generated attestation certificate is stored and print the contents of the certificate. This is what you will need to request access to bastion. set-pin - set the PIN to a new value. This will prompt you for the existing PIN. So, you cannot use this if you have forgotten your PIN. reset - reset the YubiKey for bastion access, including wiping out the private key. (This does not affect the functionality used to authenticate with Google apps - it's just the part of the YubiKey concerned with bastion access.) If you have been locked out of your YubiKey by entering the incorrect PIN too many times, you will need to reset. If you have not submitted your attestation certificate to operations to get bastion access, you can run this command any number of times. If you have had bastion access with the YubiKey, and you reset it, then you will need to re-initialize the YubiKey and submit the new attestation certificate. help - display the help information. When a User Gets Locked Out after Three Attempts If a user attempts three times to enter a pin but enters it incorrectly, the Yubikey will enter \"tamper mode\". In this case, the user must reset the Yubikey: /usr/local/bin/yk_bastion_init reset And generate a new certificate /usr/local/bin/yk_bastion_init init The sudo user can then add the new certificate to the bastions for the user using the tool yk_manage_user with the following command: username= sudo /mnt/apps/ops-misc/master/scripts/bastion-tools/yk_manage_user add $username ~/attest.pem When a User Gets Permission denied (publickey) while connecting bastion Sample Error: username@bastion-21.network.hosting.acquia.com: Permission denied (publickey). detach the yubikey and put it into another available C-type port. After changing the port Yubikey should start blinking and touch metalic part of yubikey which should print some text. Then try again.","title":"Troubleshooting Yubikey"},{"location":"kanban_tickets/troubleshooting_yubikey/#troubleshooting-yubikey","text":"","title":"Troubleshooting Yubikey"},{"location":"kanban_tickets/troubleshooting_yubikey/#when-a-user-just-cant-log-in-with-yubikey","text":"","title":"When a User Just Can't Log In with Yubikey"},{"location":"kanban_tickets/troubleshooting_yubikey/#resources-on-confluence","text":"Yubikey Bastion MFA Yubikey Operations/Admin","title":"Resources on Confluence"},{"location":"kanban_tickets/troubleshooting_yubikey/#installation-steps-for-yubikey","text":"Yubikey Installation steps","title":"Installation steps for Yubikey"},{"location":"kanban_tickets/troubleshooting_yubikey/#download-yk_bastion_init-tool","text":"Click to download yk_bastion_init Change the permissions on this file to make it executable: chmod u+x /usr/local/bin/yk_bastion_init","title":"Download yk_bastion_init tool"},{"location":"kanban_tickets/troubleshooting_yubikey/#command-to-run-after-installation","text":"Command Reference for yk_bastion_init Most users will just use yk_bastion_init without any options to initialize their key. yk_bastion_init provides several additional functions. Usage: ./yk_bastion_init [init|attest|set-pin|reset|help] init - initialize the YubiKey, set the ssh private key, and export the attestation certificate for bastion access. This is the default if no command is given. attest - display the current attestation certificate (if any). This will tell you the file path where the previously generated attestation certificate is stored and print the contents of the certificate. This is what you will need to request access to bastion. set-pin - set the PIN to a new value. This will prompt you for the existing PIN. So, you cannot use this if you have forgotten your PIN. reset - reset the YubiKey for bastion access, including wiping out the private key. (This does not affect the functionality used to authenticate with Google apps - it's just the part of the YubiKey concerned with bastion access.) If you have been locked out of your YubiKey by entering the incorrect PIN too many times, you will need to reset. If you have not submitted your attestation certificate to operations to get bastion access, you can run this command any number of times. If you have had bastion access with the YubiKey, and you reset it, then you will need to re-initialize the YubiKey and submit the new attestation certificate. help - display the help information.","title":"Command to run after installation"},{"location":"kanban_tickets/troubleshooting_yubikey/#when-a-user-gets-locked-out-after-three-attempts","text":"If a user attempts three times to enter a pin but enters it incorrectly, the Yubikey will enter \"tamper mode\". In this case, the user must reset the Yubikey: /usr/local/bin/yk_bastion_init reset And generate a new certificate /usr/local/bin/yk_bastion_init init The sudo user can then add the new certificate to the bastions for the user using the tool yk_manage_user with the following command: username= sudo /mnt/apps/ops-misc/master/scripts/bastion-tools/yk_manage_user add $username ~/attest.pem","title":"When a User Gets Locked Out after Three Attempts"},{"location":"kanban_tickets/troubleshooting_yubikey/#when-a-user-gets-permission-denied-publickey-while-connecting-bastion","text":"Sample Error: username@bastion-21.network.hosting.acquia.com: Permission denied (publickey). detach the yubikey and put it into another available C-type port. After changing the port Yubikey should start blinking and touch metalic part of yubikey which should print some text. Then try again.","title":"When a User Gets Permission denied (publickey) while connecting bastion"},{"location":"kanban_tickets/unblocking_email_service/","text":"Unblock Email Sending for a Customer Customers can occasionally be blocked from sending mail due to outbound messages being regarded as spam. When customer requested to unblock email sending service, it can be unblocked by removing the ip of customer's site from iptables. Investigation File a new CL ticket if not created. A previous incident ticket (in which the email service has been blocked for requested customer) must be linked to this ticket, if not then search JIRA for the incident ticket of blocking email sernding service for requested customer. Find the realm, web servers and site from that previous incident tickets. Once you have found a realm for the requested site, you can also check IP addresses and web servers using below command els2 [site_name] SSH into web server and verify the requested site is unable to connect to Acquia email server. telnet acquiamail[?].acquia.com 25 Check the iptables for blocked IP adresses iptable -L SSH into email server and verify the IP address is blocked. Check the comment from the list of sites's blocked IP addresses to verify. ssh ${USER}@acquiamail[?].acquia.com # list the IP addresses with line numbers using the comment iptables -L --line-number | grep \"[comment]\" # OR iptables -L --line-number Resolution Note down the line numbers from iptables list and delete the IP address rule. Note: Here the line number is being used to delete the rule, so in case of unblocking multiple IP addresses, list the iptables to recheck the next line number before deleting the next IP address rule. iptables -D INPUT [line_number] Verify the IP address has been removed iptables -L --line-number | grep \"[comment]\" # OR iptables -L --line-number SSH into web server and verify that requested site is able to connect to Acquia email server. fssh [server] telnet acquiamail[?].acquia.com 25","title":"Unblock Email Sending for a Customer"},{"location":"kanban_tickets/unblocking_email_service/#unblock-email-sending-for-a-customer","text":"Customers can occasionally be blocked from sending mail due to outbound messages being regarded as spam. When customer requested to unblock email sending service, it can be unblocked by removing the ip of customer's site from iptables.","title":"Unblock Email Sending for a Customer"},{"location":"kanban_tickets/unblocking_email_service/#investigation","text":"File a new CL ticket if not created. A previous incident ticket (in which the email service has been blocked for requested customer) must be linked to this ticket, if not then search JIRA for the incident ticket of blocking email sernding service for requested customer. Find the realm, web servers and site from that previous incident tickets. Once you have found a realm for the requested site, you can also check IP addresses and web servers using below command els2 [site_name] SSH into web server and verify the requested site is unable to connect to Acquia email server. telnet acquiamail[?].acquia.com 25 Check the iptables for blocked IP adresses iptable -L SSH into email server and verify the IP address is blocked. Check the comment from the list of sites's blocked IP addresses to verify. ssh ${USER}@acquiamail[?].acquia.com # list the IP addresses with line numbers using the comment iptables -L --line-number | grep \"[comment]\" # OR iptables -L --line-number","title":"Investigation"},{"location":"kanban_tickets/unblocking_email_service/#resolution","text":"Note down the line numbers from iptables list and delete the IP address rule. Note: Here the line number is being used to delete the rule, so in case of unblocking multiple IP addresses, list the iptables to recheck the next line number before deleting the next IP address rule. iptables -D INPUT [line_number] Verify the IP address has been removed iptables -L --line-number | grep \"[comment]\" # OR iptables -L --line-number SSH into web server and verify that requested site is able to connect to Acquia email server. fssh [server] telnet acquiamail[?].acquia.com 25","title":"Resolution"},{"location":"kanban_tickets/unique_multisite_hash_salt/","text":"Enabling Unique Multisite Hash Salt on a Site Discovered in SL-12241 , there is a bug that may affect multisites: the sites may have issues loading per-site modules, as they are loaded via the APCu prefix, which is based on the hash salt. The solution is to enable the unique_multi_site_hash_salt feature flag for that site, which will change the hash salt to be unique to each multisite. This feature flag is enabled by default on all newly-created sites, but some existing multisites may need it to be enabled for them if they are experiencing this issue. This is noted on docs.acquia.com . Note that the customer may see some impact, as multiple parts of drupal utilize the hash salt, primarily to generate time-limited authorization tokens. Enabling Unique Hash Salt Enable the unique hash salt config by setting the feature flag to true: ah-site edit $SITENAME -c feature_flag:unique_multi_site_hash_salt=true Disabling Unique Hash Salt If for some reason the customer needs the disable the unique hash salt config, do so by deleting the the feature flag config: ah-site edit $SITENAME -c feature_flag:unique_multi_site_hash_salt=","title":"Enabling Unique Multisite Hash Salt on a Site"},{"location":"kanban_tickets/unique_multisite_hash_salt/#enabling-unique-multisite-hash-salt-on-a-site","text":"Discovered in SL-12241 , there is a bug that may affect multisites: the sites may have issues loading per-site modules, as they are loaded via the APCu prefix, which is based on the hash salt. The solution is to enable the unique_multi_site_hash_salt feature flag for that site, which will change the hash salt to be unique to each multisite. This feature flag is enabled by default on all newly-created sites, but some existing multisites may need it to be enabled for them if they are experiencing this issue. This is noted on docs.acquia.com . Note that the customer may see some impact, as multiple parts of drupal utilize the hash salt, primarily to generate time-limited authorization tokens.","title":"Enabling Unique Multisite Hash Salt on a Site"},{"location":"kanban_tickets/unique_multisite_hash_salt/#enabling-unique-hash-salt","text":"Enable the unique hash salt config by setting the feature flag to true: ah-site edit $SITENAME -c feature_flag:unique_multi_site_hash_salt=true","title":"Enabling Unique Hash Salt"},{"location":"kanban_tickets/unique_multisite_hash_salt/#disabling-unique-hash-salt","text":"If for some reason the customer needs the disable the unique hash salt config, do so by deleting the the feature flag config: ah-site edit $SITENAME -c feature_flag:unique_multi_site_hash_salt=","title":"Disabling Unique Hash Salt"},{"location":"kanban_tickets/update_colony_certificate/","text":"Update Search Colony Certificate Note: To login Search jumpboxes, follow these instructions This consists of: Get the current ELB for the colony Get certificate information Deploy the certificate Get ELB for Colony You can get the ELB URL by checking the colony in Search Governor or with governor api (NOTE: colony_id is in format awsregion+'bal'+gitbranch eg. useast1balc68 or euwest1balc46 COLONY_ID= ELB_URL=$(governor colony:info ${COLONY_ID} | awk -F'( |,|\")+' '/colony_url/ {print $4}') echo ${ELB_URL} Get Certificate Info ELB=$(dig +short $ELB_URL CNAME) ELB_ID=$(echo $ELB | cut -d'-' -f1,2,3) Get Certificate ARN REGION= OLD_ARN=$(aws elb describe-load-balancers --load-balancer-name ${ELB_ID} \\ --region ${REGION} \\ --query 'LoadBalancerDescriptions[*].{CERT_ARN:ListenerDescriptions[*].Listener.SSLCertificateId}' \\ --output text | awk '{print $2}') Get ARN of latest/valid IAM cert for *.acquia-search.com aws iam list-server-certificates --output text | grep star_acquia-search NEW_ARN= Deploy cert to ELB aws elb set-load-balancer-listener-ssl-certificate --region ${REGION} \\ --load-balancer-name ${ELB_ID} --load-balancer-port 443 \\ --ssl-certificate-id \"${NEW_ARN}\" Verify deployed certificate echo | openssl s_client -connect ${ELB}:443 2>/dev/null | openssl x509 -noout -subject -dates","title":"Update Search Colony Certificate"},{"location":"kanban_tickets/update_colony_certificate/#update-search-colony-certificate","text":"Note: To login Search jumpboxes, follow these instructions This consists of: Get the current ELB for the colony Get certificate information Deploy the certificate","title":"Update Search Colony Certificate"},{"location":"kanban_tickets/update_colony_certificate/#get-elb-for-colony","text":"You can get the ELB URL by checking the colony in Search Governor or with governor api (NOTE: colony_id is in format awsregion+'bal'+gitbranch eg. useast1balc68 or euwest1balc46 COLONY_ID= ELB_URL=$(governor colony:info ${COLONY_ID} | awk -F'( |,|\")+' '/colony_url/ {print $4}') echo ${ELB_URL}","title":"Get ELB for Colony"},{"location":"kanban_tickets/update_colony_certificate/#get-certificate-info","text":"ELB=$(dig +short $ELB_URL CNAME) ELB_ID=$(echo $ELB | cut -d'-' -f1,2,3) Get Certificate ARN REGION= OLD_ARN=$(aws elb describe-load-balancers --load-balancer-name ${ELB_ID} \\ --region ${REGION} \\ --query 'LoadBalancerDescriptions[*].{CERT_ARN:ListenerDescriptions[*].Listener.SSLCertificateId}' \\ --output text | awk '{print $2}') Get ARN of latest/valid IAM cert for *.acquia-search.com aws iam list-server-certificates --output text | grep star_acquia-search NEW_ARN=","title":"Get Certificate Info"},{"location":"kanban_tickets/update_colony_certificate/#deploy-cert-to-elb","text":"aws elb set-load-balancer-listener-ssl-certificate --region ${REGION} \\ --load-balancer-name ${ELB_ID} --load-balancer-port 443 \\ --ssl-certificate-id \"${NEW_ARN}\" Verify deployed certificate echo | openssl s_client -connect ${ELB}:443 2>/dev/null | openssl x509 -noout -subject -dates","title":"Deploy cert to ELB"},{"location":"kanban_tickets/varnish_gather/","text":"VarnishGather Varnishgather is a simple script designed to gather as much relevant information as possible on a Varnish Cache setup and can be found here . We plan to make varnishgather available on all bals automatically in the long term. Currently varnishgather should be installed on a bal manually atm when the need arises. This could be when varnish process on the bal is not behaving as expected. The tool will then take a snapshot of certain values which as per github readme can change over time. NOTE: The script needs to be executed before EIP failover if the issue is still there. Otherwise, it will not fetch the data that is required to debug the issue as live traffic coming to balancer is required for it. If the issue is already over (varnish recovered itself) - running the script may not be helpful. Installing Download package and install shell script on balancer wget -N https://raw.githubusercontent.com/varnish/varnishgather/master/varnishgather Running varnishgather Run varnishgather command sudo sh ./varnishgather This creates a tar.gz file that is named varnishgather.[bal-name]-[yy]-[mm]-[dd].tar.gz Running the command multiple times will overwrite any other dumps on a given day. Varnishgather Outputs The script automatically gathers data and creates a tar.gz file. The file contains all of the reports as txt files from the commands run by the script, plus one varnishlog file. The only option of interest is -p which will also request that perf information is collected and written to perf.data. (This is binary data and appears to show what is being loaded etc) if you need to look at the contents of the varnish log (This can be carried out where ever varnishlog is installed). Decompress the tar.gz file tar -xvf varnishgather.[bal-name]-[yy]-[mm]-[dd].tar.gz Process the varnish log varnishlog -r varnishlog.raw The tar.gz created should be added to the appropriate OPS/EDGE ticket. Uninstalling Delete the varnishgather shell script rm -fr varnishgather Remove any tar.gz files that have been created rm -fr varnishgather.*.tar.gz Files of interest This does not attempt to be a full reference but more attempts to identify what information is available for people to examine further. Also note these files are suffixed with a number but given that the number can change it has been excluded on purpose. varnishd_-V shows varnish version date shows date time of the varnishgetter run dmesg shows message buffer of the kernel ps_aux_egrep__varnish_vha-agent_vac_vstatd_vcs_apache_mysql_nginx_httpd_stud_hitch_stunnel_api-engine_broadcaster_mongod shows information about following procs varnish|vha-agent|vac|vstatd|vcs|apache|mysql|nginx|httpd|stud|hitch|stunnel|api-engine|broadcaster|mongod uptime shows uptime and average load free_-m, cat__proc_meminfo, vmstat_1_3 and mpstat_-P_ALL_1_3 shows memory usage and processor stats iostat_1_3 show device io information netstat_-s shows network stats for the bal ip_n, ip_a, ip_r, ip_-s_l, ipconfig show network information for the bal df_-h shows disk usage varnishstat_-1 and varnishstat_-j shows statistics from a running varnishd instance as txt and json vcls.tar is a tar ball of all the vcls on a bal (Likely not of interest except incases where we have a custom vcl) systemctl_cat_varnish_service shows the service file for varnishd that is on a bal egrep__broadcaster_varnish_vha-agent_hitch_vac_rc_local___v shows logs in /var/log/messages that mention varnish broadcaster_varnish_vha-agent_hitch_vac_rc_local___var_log_syslog shows logs in /var/log/syslog that mention varnish cat__etc_varnish_ shows the contents of individual vcl files on a given bal (Likely not of interest except incases where we have a custom vcl) varnishadm_--_vcl_list shows the vcls that in use/available varnishadm_-- vcl_show -v_* shows the vcl(s) that were loaded as part of given reload or initial reboot varnishadm_--_param_show shows the current parameters that are set in varnish varnishadm_--_ban_list shows the current bans for the varnish cache varnishadm_--_panic_show shows if varnish is in or has had a panic varnishlog.raw is a binary varnishlog notes on how to get data from it are provided above","title":"VarnishGather"},{"location":"kanban_tickets/varnish_gather/#varnishgather","text":"Varnishgather is a simple script designed to gather as much relevant information as possible on a Varnish Cache setup and can be found here . We plan to make varnishgather available on all bals automatically in the long term. Currently varnishgather should be installed on a bal manually atm when the need arises. This could be when varnish process on the bal is not behaving as expected. The tool will then take a snapshot of certain values which as per github readme can change over time. NOTE: The script needs to be executed before EIP failover if the issue is still there. Otherwise, it will not fetch the data that is required to debug the issue as live traffic coming to balancer is required for it. If the issue is already over (varnish recovered itself) - running the script may not be helpful.","title":"VarnishGather"},{"location":"kanban_tickets/varnish_gather/#installing","text":"Download package and install shell script on balancer wget -N https://raw.githubusercontent.com/varnish/varnishgather/master/varnishgather","title":"Installing"},{"location":"kanban_tickets/varnish_gather/#running-varnishgather","text":"Run varnishgather command sudo sh ./varnishgather This creates a tar.gz file that is named varnishgather.[bal-name]-[yy]-[mm]-[dd].tar.gz Running the command multiple times will overwrite any other dumps on a given day.","title":"Running varnishgather"},{"location":"kanban_tickets/varnish_gather/#varnishgather-outputs","text":"The script automatically gathers data and creates a tar.gz file. The file contains all of the reports as txt files from the commands run by the script, plus one varnishlog file. The only option of interest is -p which will also request that perf information is collected and written to perf.data. (This is binary data and appears to show what is being loaded etc) if you need to look at the contents of the varnish log (This can be carried out where ever varnishlog is installed). Decompress the tar.gz file tar -xvf varnishgather.[bal-name]-[yy]-[mm]-[dd].tar.gz Process the varnish log varnishlog -r varnishlog.raw The tar.gz created should be added to the appropriate OPS/EDGE ticket.","title":"Varnishgather Outputs"},{"location":"kanban_tickets/varnish_gather/#uninstalling","text":"Delete the varnishgather shell script rm -fr varnishgather Remove any tar.gz files that have been created rm -fr varnishgather.*.tar.gz","title":"Uninstalling"},{"location":"kanban_tickets/varnish_gather/#files-of-interest","text":"This does not attempt to be a full reference but more attempts to identify what information is available for people to examine further. Also note these files are suffixed with a number but given that the number can change it has been excluded on purpose. varnishd_-V shows varnish version date shows date time of the varnishgetter run dmesg shows message buffer of the kernel ps_aux_egrep__varnish_vha-agent_vac_vstatd_vcs_apache_mysql_nginx_httpd_stud_hitch_stunnel_api-engine_broadcaster_mongod shows information about following procs varnish|vha-agent|vac|vstatd|vcs|apache|mysql|nginx|httpd|stud|hitch|stunnel|api-engine|broadcaster|mongod uptime shows uptime and average load free_-m, cat__proc_meminfo, vmstat_1_3 and mpstat_-P_ALL_1_3 shows memory usage and processor stats iostat_1_3 show device io information netstat_-s shows network stats for the bal ip_n, ip_a, ip_r, ip_-s_l, ipconfig show network information for the bal df_-h shows disk usage varnishstat_-1 and varnishstat_-j shows statistics from a running varnishd instance as txt and json vcls.tar is a tar ball of all the vcls on a bal (Likely not of interest except incases where we have a custom vcl) systemctl_cat_varnish_service shows the service file for varnishd that is on a bal egrep__broadcaster_varnish_vha-agent_hitch_vac_rc_local___v shows logs in /var/log/messages that mention varnish broadcaster_varnish_vha-agent_hitch_vac_rc_local___var_log_syslog shows logs in /var/log/syslog that mention varnish cat__etc_varnish_ shows the contents of individual vcl files on a given bal (Likely not of interest except incases where we have a custom vcl) varnishadm_--_vcl_list shows the vcls that in use/available varnishadm_-- vcl_show -v_* shows the vcl(s) that were loaded as part of given reload or initial reboot varnishadm_--_param_show shows the current parameters that are set in varnish varnishadm_--_ban_list shows the current bans for the varnish cache varnishadm_--_panic_show shows if varnish is in or has had a panic varnishlog.raw is a binary varnishlog notes on how to get data from it are provided above","title":"Files of interest"},{"location":"kanban_tickets/verify_extractor/","text":"Search Extractor Note: To login Search jumpboxes, follow these instructions The javaephem server type can serve one of two roles: as slave to a javasrv master for READ-HA, or as an extractor. When an extractor is rebooted or relaunched, the following steps will need to be performed to verify that it is configured and operating properly. Determining Whether a javaephem is an Extractor If a javaephem is an extractor, it should have the solrextractor tag, and the site associated with the extractor should end in e (ex. uswest2asc23e ). ah-server list <SERVER> -c tags ah-site list on:<SERVER> If you find an extractor without the solrextractor tag, please correct it and ensure it is not tagged solrslave : ah-server tag add <SERVER> --tags solrextractor ah-server tag remove <SERVER> --tags solrslave Test Procedure Test the ability of the extractor to extract content. There are three commands (see below) that can be used: one for a provided list of extractors, one to test all extractors in a region, and one to test all extractors. The expected output for each server is 200. If it is not, proceed to the remediation section below. test-extractors -l <csv server list> test-extractors -r <region name> test-extractors -a Verify that the extractors are aware of all of the indexes in their respective colonies. Again, there is a command for a list of servers, by region, and all (see below). The expected output is zero or greater than one. If it is one, proceed to the next step. client-list-length -l <csv server list> client-list-length -r <region name> client-list-length -a If the client list length is one, verify that it is an actual index and not the TEST-100 demo index. If the output is the demo index, proceed to the remediation section below. cat-client-list <server> Remediation Perform the following steps to resolve issues you may encounter. If you should experience failures in any the of the below steps, please escalate to search engineering. Perform a fields-config-web.php run. Make sure tomcat6_context_environment.solr/home on the site is set correctly. Good: /mnt/gfs/useast1as.c72extract/files/solr. Bad: /mnt/gfs/useast1ass67/files/solr /mnt/gfs/c72extract/files/solr Verify that the server registered with the governor by checking to make sure that the Rakefile exists in the search user's home directory. It can take a few minutes for the server to register, but if it doesn't register within 10 - 20 minutes it is possible that you are looking at a stuck task in the governor queue or an overloaded queue. Resaving the node in the governor. Run rake rebuild and rake cron .","title":"Search Extractor"},{"location":"kanban_tickets/verify_extractor/#search-extractor","text":"Note: To login Search jumpboxes, follow these instructions The javaephem server type can serve one of two roles: as slave to a javasrv master for READ-HA, or as an extractor. When an extractor is rebooted or relaunched, the following steps will need to be performed to verify that it is configured and operating properly.","title":"Search Extractor"},{"location":"kanban_tickets/verify_extractor/#determining-whether-a-javaephem-is-an-extractor","text":"If a javaephem is an extractor, it should have the solrextractor tag, and the site associated with the extractor should end in e (ex. uswest2asc23e ). ah-server list <SERVER> -c tags ah-site list on:<SERVER> If you find an extractor without the solrextractor tag, please correct it and ensure it is not tagged solrslave : ah-server tag add <SERVER> --tags solrextractor ah-server tag remove <SERVER> --tags solrslave","title":"Determining Whether a javaephem is an Extractor"},{"location":"kanban_tickets/verify_extractor/#test-procedure","text":"Test the ability of the extractor to extract content. There are three commands (see below) that can be used: one for a provided list of extractors, one to test all extractors in a region, and one to test all extractors. The expected output for each server is 200. If it is not, proceed to the remediation section below. test-extractors -l <csv server list> test-extractors -r <region name> test-extractors -a Verify that the extractors are aware of all of the indexes in their respective colonies. Again, there is a command for a list of servers, by region, and all (see below). The expected output is zero or greater than one. If it is one, proceed to the next step. client-list-length -l <csv server list> client-list-length -r <region name> client-list-length -a If the client list length is one, verify that it is an actual index and not the TEST-100 demo index. If the output is the demo index, proceed to the remediation section below. cat-client-list <server>","title":"Test Procedure"},{"location":"kanban_tickets/verify_extractor/#remediation","text":"Perform the following steps to resolve issues you may encounter. If you should experience failures in any the of the below steps, please escalate to search engineering. Perform a fields-config-web.php run. Make sure tomcat6_context_environment.solr/home on the site is set correctly. Good: /mnt/gfs/useast1as.c72extract/files/solr. Bad: /mnt/gfs/useast1ass67/files/solr /mnt/gfs/c72extract/files/solr Verify that the server registered with the governor by checking to make sure that the Rakefile exists in the search user's home directory. It can take a few minutes for the server to register, but if it doesn't register within 10 - 20 minutes it is possible that you are looking at a stuck task in the governor queue or an overloaded queue. Resaving the node in the governor. Run rake rebuild and rake cron .","title":"Remediation"},{"location":"kanban_tickets/vpc_deprovision/","text":"Deprovision a VPC Deprovision a VPC. This should be done after all servers for the VPC have been terminated. Preparation Make sure there are no servers left unterminated that would use this VPC. ah-server list vpc:name=$VPC_NAME -w statusIN0,1 Procedure Delete the VPC. This will return a task id that can be watched for with ah-task wait-for-task , that will take about 5 minutes. ah-vpc delete $VPC_NAME Verification Verify the VPC is not listed in ah-vpc list . ah-vpc list $VPC_NAME","title":"Deprovision a VPC"},{"location":"kanban_tickets/vpc_deprovision/#deprovision-a-vpc","text":"Deprovision a VPC. This should be done after all servers for the VPC have been terminated.","title":"Deprovision a VPC"},{"location":"kanban_tickets/vpc_deprovision/#preparation","text":"Make sure there are no servers left unterminated that would use this VPC. ah-server list vpc:name=$VPC_NAME -w statusIN0,1","title":"Preparation"},{"location":"kanban_tickets/vpc_deprovision/#procedure","text":"Delete the VPC. This will return a task id that can be watched for with ah-task wait-for-task , that will take about 5 minutes. ah-vpc delete $VPC_NAME","title":"Procedure"},{"location":"kanban_tickets/vpc_deprovision/#verification","text":"Verify the VPC is not listed in ah-vpc list . ah-vpc list $VPC_NAME","title":"Verification"},{"location":"kanban_tickets/vpc_network_boundaries/","text":"VPC Network Boundaries A Network Boundary is a construct which allows one or more VPCs to have IP whitelisting rules applied to them for port 22. Each Network Boundary has a defined type: SecureVPN - The boundary is fixed to the defaults and the customer cannot modify them. Shield - The customer will be able to make custom Access Control List (ACL) IP rules through the UI once the entitlement has been granted with the corresponding SubscriptionUUID. Customers that have dedicated VPCs and either Acquia Shield or Secure VPN may need to have a Network Boundary created for them, or have one removed so that another can be created with their existing Subscription UUID. Those instructions are listed here. Notes on Shield behavior The default rule (when freshly provisioned, or if the customer invokes \"resets\" their ACL) is 0.0.0.0/0 which is fully open to the world . The most permissive rule in the ACL \"wins.\" So if a customer adds rules to their ACL, but the default ( 0.0.0.0/0 ) is still present, it will still be fully open to the world . Isolation is enforced at the VPC level, so testing must be performed from outside of the associated VPCs. sshd will continue to listen on external interfaces (0.0.0.0) as it must be able to accept external connections from the whitelist. Provisioning a VPC Network Boundary Network boundaries are associated with a customer's Subscription UUID. If you try to create a second network boundary with the same subscription UUID, it will fail, unless the other network boundary is deregistered or deleted. Preparing to create Information you will need from the ticket creator: A guarantee that Shield has been enabled (in CCI) for the customer. This step can happen independently, but it is still required for this to work. If you are reading this, you probably should not proceed until you have this confirmation. The subscription UUID - There should only be one of these per customer. ~~(you can get this with ah-sitegroup list $sitegroup -c subscription_uuid )~~ ~~(subscription_uuid is deprecated, you should use real_subscription_uuid: ah-sitegroup list $sitegroup -c real_subscription_uuid )~~ (real_subscription_uuid is not reliably populated, you probably ought to ask the TAM to find the CUSTOMER LEVEL SUBSCRIPTION UUID ) The realm in which the customer exists. The list of dedicated VPC IDs as an array . If you are given VPC names instead of IDs, you can look them up in fields: VPC_ID= ah-vpc list % -w vpc_id=${VPC_ID} The type (either 'shield' or 'securevpn', case sensitive) A description for the network boundary, such as customer name. Once you have this info, fill in the following fields: SUB_UUID= VPC_IDS=() TYPE= DESCRIPTION= UUID=$(cat /proc/sys/kernel/random/uuid) Registering the Network Boundary Double that the VPC(s) are, in fact, dedicated. Check that the Subscription UUID is not currently in use: ah-network-boundary get --subscription-uuid=${SUB_UUID} If a network boundary with that sub uuid exists and is in state NORMAL , you will need to deregister it before you can continue. Confirm with the customer that they're not using it, and then follow the instructions to deregister . If there's no active network boundary for that sub uuid, you can create the network boundary: ah-network-boundary register \\ --type=${TYPE} \\ --uuid=${UUID} \\ --subscription-uuid=${SUB_UUID} \\ --description=${DESCRIPTION} \\ --vpc-ids=${VPC_IDS[@]} Get the network boundary and check that the info looks correct and the state is NORMAL (it may take a moment to finish creating): ah-network-boundary get --uuid=${UUID} If you have CCI permissions, check to see that the default rule has been applied, or ask the TAM to confirm. It should look like this: Deregistering a VPC Network Boundary Deregistering a network boundary removes it, allowing you to create a new one with the same subscription UUID if necessary. If a network boundary is erroneously deregistered, it cannot be reactivated, but a a new one can be created with the same information (but a new UUID). If this happens to a Shield network boundary, the customer will have to re-add their custom IP whitelisting rules, so please be careful. Preparing to deregister You can look up network boundaries by UUID, subscription UUID, or the name of a server in one of the VPCs in that network boundary. We need to get the UUID. If you're looking up by subscription UUID: SUB_UUID= ah-network-boundary get --subscription-uuid=${SUB_UUID} If you're looking up by server name: SERVER= ah-network-boundary get --server-name=${SERVER} If you know the UUID or you just found it by either of those lookup methods, set it: UUID= Deregistering the Network Boundary Delete the network boundary: ah-network-boundary deregister --uuid=${UUID} Check that the network boundary is now in state DEREGISTERED (it may take a bit to finish deregistering): ah-network-boundary get --uuid=${UUID} Inspecting existing Network Boundaries Listing all the Network Boundaries in a realm $ ah-network-boundary list \u250c\u2500\u2500 Boundaries \u2502 \u251c\u2500\u2500\u2500 UUID: 149e3eeb-c18d-468a-a6ca-b77d6c996b6c \u2502 \u2502 Type: shield \u2502 Subscription UUID: 01eb4a6d-f2c4-40f6-b45f-f0e0f8c7d0cf \u2502 State: NORMAL \u2502 VPC IDs: 12 \u2502 \u251c\u2500\u2500\u2500 UUID: 1dd2e9be-9e3f-48d2-8e33-2ba8fea01d4d \u2502 \u2502 Type: shield \u2502 Subscription UUID: 163325d8-01af-4482-9324-3a3f7f3682cc \u2502 State: NORMAL \u2502 VPC IDs: 11 \u2502 \u2514\u2500\u2500 Viewing the details of a Network Boundary The cli tooling supports the following references: * --uuid - The UUID of the Network Boundary. * --subscription_uuid - The SubscriptionUUID associated with the Network Boundary. * --server-name - A server name belonging to a VPC contained within a Network Boundary. Examples: ah-network-boundary get --uuid 149e3eeb-c18d-468a-a6ca-b77d6c996b6c ah-network-boundary get --subscription_uuid 11eb4a6d-f2c4-40f6-b45f-f0e0f8c7d0cf ah-network-boundary get --server-name web-12848 \u250c\u2500 Aq::Hosting::Type::GetNetworkBoundaryResponse \u2502 \u2502 type uuid subscription_uuid description state \u2502 shield 149e3eeb-c18d-468a-a6ca-b77d6c996b6c 11eb4a6d-f2c4-40f6-b45f-f0e0f8c7d0cf nasdaqcorp NORMAL \u2502 \u251c\u2500\u2500 acl \u2502 \u2502 uuid description service_name action \u2502 1d29529e-a7dc-4653-b2cd-ec7e1748dc2b Boston Office ssh allow \u2502 153bad53-b848-401f-9c59-d46c16ad3da4 AWS Jumpbox-Test ssh allow \u2502 1ca9d222-b8a7-497a-965b-de7ea6684549 GamesAndTheory ssh allow \u2502 18011ee7-4fdb-4b74-8131-184de771c39f Offshore Dev VPC CIDR Blocks ssh allow \u2502 \u251c\u2500\u2500\u2500 cidrs \u2502 \u2502 10.25.82.0/20 \u2502 \u251c\u2500\u2500\u2500 cidrs \u2502 \u2502 2.209.205.232/32 \u2502 2.209.200.116/32 \u2502 \u251c\u2500\u2500\u2500 cidrs \u2502 \u2502 172.254.199.209/32 \u2502 45.142.252.241/32 \u2502 24.232.99.120/32 \u2502 54.163.246.153/32 \u2502 3.18.142.246/32 \u2502 \u251c\u2500\u2500\u2500 cidrs \u2502 \u2502 10.30.44.0/24 \u2502 10.30.20.64/26 \u2502 \u251c\u2500\u2500 acl_services \u2502 \u2502 ssh \u2502 \u251c\u2500\u2500 vpc_ids \u2502 \u2502 12 \u2502 \u2514\u2500\u2500","title":"VPC Network Boundaries"},{"location":"kanban_tickets/vpc_network_boundaries/#vpc-network-boundaries","text":"A Network Boundary is a construct which allows one or more VPCs to have IP whitelisting rules applied to them for port 22. Each Network Boundary has a defined type: SecureVPN - The boundary is fixed to the defaults and the customer cannot modify them. Shield - The customer will be able to make custom Access Control List (ACL) IP rules through the UI once the entitlement has been granted with the corresponding SubscriptionUUID. Customers that have dedicated VPCs and either Acquia Shield or Secure VPN may need to have a Network Boundary created for them, or have one removed so that another can be created with their existing Subscription UUID. Those instructions are listed here.","title":"VPC Network Boundaries"},{"location":"kanban_tickets/vpc_network_boundaries/#notes-on-shield-behavior","text":"The default rule (when freshly provisioned, or if the customer invokes \"resets\" their ACL) is 0.0.0.0/0 which is fully open to the world . The most permissive rule in the ACL \"wins.\" So if a customer adds rules to their ACL, but the default ( 0.0.0.0/0 ) is still present, it will still be fully open to the world . Isolation is enforced at the VPC level, so testing must be performed from outside of the associated VPCs. sshd will continue to listen on external interfaces (0.0.0.0) as it must be able to accept external connections from the whitelist.","title":"Notes on Shield behavior"},{"location":"kanban_tickets/vpc_network_boundaries/#provisioning-a-vpc-network-boundary","text":"Network boundaries are associated with a customer's Subscription UUID. If you try to create a second network boundary with the same subscription UUID, it will fail, unless the other network boundary is deregistered or deleted.","title":"Provisioning a VPC Network Boundary"},{"location":"kanban_tickets/vpc_network_boundaries/#preparing-to-create","text":"Information you will need from the ticket creator: A guarantee that Shield has been enabled (in CCI) for the customer. This step can happen independently, but it is still required for this to work. If you are reading this, you probably should not proceed until you have this confirmation. The subscription UUID - There should only be one of these per customer. ~~(you can get this with ah-sitegroup list $sitegroup -c subscription_uuid )~~ ~~(subscription_uuid is deprecated, you should use real_subscription_uuid: ah-sitegroup list $sitegroup -c real_subscription_uuid )~~ (real_subscription_uuid is not reliably populated, you probably ought to ask the TAM to find the CUSTOMER LEVEL SUBSCRIPTION UUID ) The realm in which the customer exists. The list of dedicated VPC IDs as an array . If you are given VPC names instead of IDs, you can look them up in fields: VPC_ID= ah-vpc list % -w vpc_id=${VPC_ID} The type (either 'shield' or 'securevpn', case sensitive) A description for the network boundary, such as customer name. Once you have this info, fill in the following fields: SUB_UUID= VPC_IDS=() TYPE= DESCRIPTION= UUID=$(cat /proc/sys/kernel/random/uuid)","title":"Preparing to create"},{"location":"kanban_tickets/vpc_network_boundaries/#registering-the-network-boundary","text":"Double that the VPC(s) are, in fact, dedicated. Check that the Subscription UUID is not currently in use: ah-network-boundary get --subscription-uuid=${SUB_UUID} If a network boundary with that sub uuid exists and is in state NORMAL , you will need to deregister it before you can continue. Confirm with the customer that they're not using it, and then follow the instructions to deregister . If there's no active network boundary for that sub uuid, you can create the network boundary: ah-network-boundary register \\ --type=${TYPE} \\ --uuid=${UUID} \\ --subscription-uuid=${SUB_UUID} \\ --description=${DESCRIPTION} \\ --vpc-ids=${VPC_IDS[@]} Get the network boundary and check that the info looks correct and the state is NORMAL (it may take a moment to finish creating): ah-network-boundary get --uuid=${UUID} If you have CCI permissions, check to see that the default rule has been applied, or ask the TAM to confirm. It should look like this:","title":"Registering the Network Boundary"},{"location":"kanban_tickets/vpc_network_boundaries/#deregistering-a-vpc-network-boundary","text":"Deregistering a network boundary removes it, allowing you to create a new one with the same subscription UUID if necessary. If a network boundary is erroneously deregistered, it cannot be reactivated, but a a new one can be created with the same information (but a new UUID). If this happens to a Shield network boundary, the customer will have to re-add their custom IP whitelisting rules, so please be careful.","title":"Deregistering a VPC Network Boundary"},{"location":"kanban_tickets/vpc_network_boundaries/#preparing-to-deregister","text":"You can look up network boundaries by UUID, subscription UUID, or the name of a server in one of the VPCs in that network boundary. We need to get the UUID. If you're looking up by subscription UUID: SUB_UUID= ah-network-boundary get --subscription-uuid=${SUB_UUID} If you're looking up by server name: SERVER= ah-network-boundary get --server-name=${SERVER} If you know the UUID or you just found it by either of those lookup methods, set it: UUID=","title":"Preparing to deregister"},{"location":"kanban_tickets/vpc_network_boundaries/#deregistering-the-network-boundary","text":"Delete the network boundary: ah-network-boundary deregister --uuid=${UUID} Check that the network boundary is now in state DEREGISTERED (it may take a bit to finish deregistering): ah-network-boundary get --uuid=${UUID}","title":"Deregistering the Network Boundary"},{"location":"kanban_tickets/vpc_network_boundaries/#inspecting-existing-network-boundaries","text":"","title":"Inspecting existing Network Boundaries"},{"location":"kanban_tickets/vpc_network_boundaries/#listing-all-the-network-boundaries-in-a-realm","text":"$ ah-network-boundary list \u250c\u2500\u2500 Boundaries \u2502 \u251c\u2500\u2500\u2500 UUID: 149e3eeb-c18d-468a-a6ca-b77d6c996b6c \u2502 \u2502 Type: shield \u2502 Subscription UUID: 01eb4a6d-f2c4-40f6-b45f-f0e0f8c7d0cf \u2502 State: NORMAL \u2502 VPC IDs: 12 \u2502 \u251c\u2500\u2500\u2500 UUID: 1dd2e9be-9e3f-48d2-8e33-2ba8fea01d4d \u2502 \u2502 Type: shield \u2502 Subscription UUID: 163325d8-01af-4482-9324-3a3f7f3682cc \u2502 State: NORMAL \u2502 VPC IDs: 11 \u2502 \u2514\u2500\u2500","title":"Listing all the Network Boundaries in a realm"},{"location":"kanban_tickets/vpc_network_boundaries/#viewing-the-details-of-a-network-boundary","text":"The cli tooling supports the following references: * --uuid - The UUID of the Network Boundary. * --subscription_uuid - The SubscriptionUUID associated with the Network Boundary. * --server-name - A server name belonging to a VPC contained within a Network Boundary. Examples: ah-network-boundary get --uuid 149e3eeb-c18d-468a-a6ca-b77d6c996b6c ah-network-boundary get --subscription_uuid 11eb4a6d-f2c4-40f6-b45f-f0e0f8c7d0cf ah-network-boundary get --server-name web-12848 \u250c\u2500 Aq::Hosting::Type::GetNetworkBoundaryResponse \u2502 \u2502 type uuid subscription_uuid description state \u2502 shield 149e3eeb-c18d-468a-a6ca-b77d6c996b6c 11eb4a6d-f2c4-40f6-b45f-f0e0f8c7d0cf nasdaqcorp NORMAL \u2502 \u251c\u2500\u2500 acl \u2502 \u2502 uuid description service_name action \u2502 1d29529e-a7dc-4653-b2cd-ec7e1748dc2b Boston Office ssh allow \u2502 153bad53-b848-401f-9c59-d46c16ad3da4 AWS Jumpbox-Test ssh allow \u2502 1ca9d222-b8a7-497a-965b-de7ea6684549 GamesAndTheory ssh allow \u2502 18011ee7-4fdb-4b74-8131-184de771c39f Offshore Dev VPC CIDR Blocks ssh allow \u2502 \u251c\u2500\u2500\u2500 cidrs \u2502 \u2502 10.25.82.0/20 \u2502 \u251c\u2500\u2500\u2500 cidrs \u2502 \u2502 2.209.205.232/32 \u2502 2.209.200.116/32 \u2502 \u251c\u2500\u2500\u2500 cidrs \u2502 \u2502 172.254.199.209/32 \u2502 45.142.252.241/32 \u2502 24.232.99.120/32 \u2502 54.163.246.153/32 \u2502 3.18.142.246/32 \u2502 \u251c\u2500\u2500\u2500 cidrs \u2502 \u2502 10.30.44.0/24 \u2502 10.30.20.64/26 \u2502 \u251c\u2500\u2500 acl_services \u2502 \u2502 ssh \u2502 \u251c\u2500\u2500 vpc_ids \u2502 \u2502 12 \u2502 \u2514\u2500\u2500","title":"Viewing the details of a Network Boundary"},{"location":"kanban_tickets/vpc_provision/","text":"Provision a VPC Customers that buy Acquia Shield have all their servers contained within their own dedicated VPC. Acquia also provides some shared VPCs for customers to meet HIPAA, PCI or PII compliance. Preparation A non-routable /16 or /20 CIDR block. For dedicated VPCs the customer needs to declare what block they want which should have been figured out during pre-sales. For shared VPCs Ops can pick any non-routable /16 or /20 block, 172.16.0.0/16 is a good choice as that is what gets used for bootstrapped control plane VPCs. Some name to call it. Typically customer name but for shared VPCs: Product VPC Name Tags to add Region Default shared-vpc-${REGION} shared HIPAA shared-hipaa-vpc-${REGION} shared hipaa PCI shared-pci-vpc-${REGION} shared pci PII shared-pii-vpc-${REGION} shared pii HIPAA+PCI shared-hipaa-pci-vpc-${REGION} shared hipaa pci VPC names must contain only letters, numbers, dashes and start with an alpha character. Setup variables CIDR= REGION= VPC_NAME= TAGS= Procedure Create the VPC. This will return a task id that can be watched for with ah-task wait-for-task , expect it to run for 10-15 minutes. ah-vpc create $VPC_NAME $CIDR $REGION Tag the VPC with additional tags as needed. ah-vpc tag add $VPC_NAME -t $TAGS Note: Follow the below FedRAMP section only if its required, otherwise we need to skip this section. Contact the AM or Ops coordinators if there is any doubt or if any information is missing over the OP ticket. FedRAMP During step 2 of the procedure section, you were asked to tag the VPC with additional tags as needed. Please note this means the VPC must be tagged with the tag fedramp , just having the word fedramp in the name will not tag the VPC properly. Instead, run the following command: ah-vpc tag add $VPC_NAME -t fedramp You will receive the following message if your tag was successfully applied: Added fedramp to $VPC_NAME Once the VPC is tagged, subsequent launches should automatically be provisioned with FIPS enabled. Importantly, this means that existing resources will not have FIPS enablement applied retroactively. Verification Run ah-vpc show against the VPC to verify \"Hosting Status\" is created. ah-vpc show $VPC_NAME","title":"Provision a VPC"},{"location":"kanban_tickets/vpc_provision/#provision-a-vpc","text":"Customers that buy Acquia Shield have all their servers contained within their own dedicated VPC. Acquia also provides some shared VPCs for customers to meet HIPAA, PCI or PII compliance.","title":"Provision a VPC"},{"location":"kanban_tickets/vpc_provision/#preparation","text":"A non-routable /16 or /20 CIDR block. For dedicated VPCs the customer needs to declare what block they want which should have been figured out during pre-sales. For shared VPCs Ops can pick any non-routable /16 or /20 block, 172.16.0.0/16 is a good choice as that is what gets used for bootstrapped control plane VPCs. Some name to call it. Typically customer name but for shared VPCs: Product VPC Name Tags to add Region Default shared-vpc-${REGION} shared HIPAA shared-hipaa-vpc-${REGION} shared hipaa PCI shared-pci-vpc-${REGION} shared pci PII shared-pii-vpc-${REGION} shared pii HIPAA+PCI shared-hipaa-pci-vpc-${REGION} shared hipaa pci VPC names must contain only letters, numbers, dashes and start with an alpha character. Setup variables CIDR= REGION= VPC_NAME= TAGS=","title":"Preparation"},{"location":"kanban_tickets/vpc_provision/#procedure","text":"Create the VPC. This will return a task id that can be watched for with ah-task wait-for-task , expect it to run for 10-15 minutes. ah-vpc create $VPC_NAME $CIDR $REGION Tag the VPC with additional tags as needed. ah-vpc tag add $VPC_NAME -t $TAGS Note: Follow the below FedRAMP section only if its required, otherwise we need to skip this section. Contact the AM or Ops coordinators if there is any doubt or if any information is missing over the OP ticket.","title":"Procedure"},{"location":"kanban_tickets/vpc_provision/#fedramp","text":"During step 2 of the procedure section, you were asked to tag the VPC with additional tags as needed. Please note this means the VPC must be tagged with the tag fedramp , just having the word fedramp in the name will not tag the VPC properly. Instead, run the following command: ah-vpc tag add $VPC_NAME -t fedramp You will receive the following message if your tag was successfully applied: Added fedramp to $VPC_NAME Once the VPC is tagged, subsequent launches should automatically be provisioned with FIPS enabled. Importantly, this means that existing resources will not have FIPS enablement applied retroactively.","title":"FedRAMP"},{"location":"kanban_tickets/vpc_provision/#verification","text":"Run ah-vpc show against the VPC to verify \"Hosting Status\" is created. ah-vpc show $VPC_NAME","title":"Verification"},{"location":"kanban_tickets/vpc_to_vpc/","text":"VPC to VPC Migration If a customer site is running on shared/dedicated VPC, we can relaunch them into another shared/dedicated VPC directly faster, more reliably, and site will have less downtime in comparision to a site move to new hardware provisioned in new VPC. Site Factory site layout Site Factory migration, such as in the enterprise-g1 realm, have some noteworthy differences from hardware migration in ACE: Since it is required to migrate all the hardware in a Site Factory, it is helpful to understand the sitegroup/sites on a typical site factory: esl ${CUSTOMERNAME}% Each Site Factory has three sitegroups, ${CUSTOMERNAME} , ${CUSTOMERNAME}sf , and ${CUSTOMERNAME}theme . These sitegroups are often on separate stacks, so spend time tracking down all of the hardware. Within those sitegroups you will see sitenames such as ${CUSTOMERNAME}01live , ${CUSTOMERNAME}01update , ${CUSTOMERNAME}01theme , etc. Note some older site factories may add an underscore, i.e. ${CUSTOMERNAME}_sf . Identify all hardwares for all the sites before beginning the relaunch. Setting variables For any VPC to VPC migration maintenance, you will be given a customer sitegroup for hardware migration. (potentially a list of sitegroups if the customer has multiple sitegroups). Find all sites and hardware: SITEGROUP= SITES=( $(ah-site list sitegroup:${SITEGROUP} -w stage!=ra) ) SERVERS=( $(ah-server list $(printf 'site:%s\\n' ${SITES[@]} | \\ paste -sd,) -w type!=svn status=0) ) SERVERS_CSV=$(array-csv ${SERVERS[@]}) Identify any shared hardware by checking tags and other sites: ah-server list ${SERVERS_CSV} -c tags site-list -s ${SERVERS_CSV} If any sites are sharing hardware with a site that is not part of your maintenance, then that site's hardware must be removed from the list. Make note of any sites which currently have an ELB: for site in ${SITES[@]}; do site-elbdescribe ${site} done If they do, we need to provision new ELBs for each site and communicate the new ELB FQDN to the customer for DNS. Launch a new VPC or validate the target VPC: To launch a new VPC, follow VPC provisioning else proceed as follows. The target VPC must match the region of the servers you are migrating. VPC_ID= VPC_NAME=$(ah-vpc list % -w id=${VPC_ID}) ah-vpc get ${VPC_NAME} Launch a new VPN if requested by customer follow VPN provisioning Relaunch Into VPC If there is nothing blocking a safe relaunch, proceed to suspend them. Please note that this will incur hard downtime for the customer, but is a faster and less painful process than site moves. Note: Do not try to relaunch an edge cluster into a new VPC. You will need to provision a new edge cluster in the new VPC, and have the customer update DNS before removing the old one. Remove the ACE prod and ACSF sites from monitoring For ACE: site-mon remove ${SITE} For ACSF: site-mondisable ${CUSTOMERNAME}01live site-mondisable ${CUSTOMERNAME}sf site-mondisable ${CUSTOMERNAME}theme Suspend all servers at the same time: ah-server suspend ${SERVERS_CSV} Update the VPC_ID ah-server edit ${SERVERS_CSV} -s vpc_id=${VPC_ID} Launch them: ah-server launch ${SERVERS[@]} If the site has any ELBs, recreate them. Repeat the following step for each of the ELB/s a site (ACE) or related group of sites (ACSF). SITE=[ SITENAME ] REGION=$(ah-site get ${SITE}|egrep '^region:'|awk '{print $2}') ELB_FQDN=\"$(site-elbdescribe $SITE|egrep elb.amazonaws.com)\" ELB_NAME=$(echo ${ELB_FQDN} | \\ egrep elb.amazonaws.com | \\ awk -F. '{print $1}' | \\ awk -F- 'BEGIN{OFS=\"-\"} {NF--; print}') ELB_CERT_ARN=$(aws elb describe-load-balancers \\ --load-balancer-names ${ELB_NAME} --region ${REGION} --output text \\ --query 'LoadBalancerDescriptions[*].ListenerDescriptions[*].Listener.SSLCertificateId') ELB_CERT_TYPE=$(echo ${ELB_CERT_ARN} | cut -d: -f3) if [ ${ELB_CERT_TYPE} == \"acm\" ] ;then CERT_TYPE=\"ACM Managed Certificate\" elif [ ${ELB_CERT_TYPE} == \"iam\" ] ;then CERT_TYPE=\"IAM Server Certificate\" fi site-elbdescribe ${SITE} echo -e \"{code:title=ELB Details - Before new VPC Migration} Site: $SITE Region: $REGION ELB before migration: $ELB_NAME ELB FQDN before migration: $ELB_FQDN elb_cert_arn: $ELB_CERT_ARN ELB Cert Type: $CERT_TYPE {code}\" If ELB Cert Type from the above output is IAM Server Certificate **Re-creation of ELB after moving hardware to new VPC** VPC=[NAME OF THE NEW VPC] ah-site ssl tech-refresh-vpc-migrate-elb ${SITE} ${VPC} # Make note of 'New ELB Name' from the output of the above # command and set following variable with it's value NEW_ELB_NAME=[New ELB Name] # Set existing certificate for the old elb to the new elb # that was created in the step above aws elb set-load-balancer-listener-ssl-certificate \\ --load-balancer-name ${NEW_ELB_NAME} --ssl-certificate-id \\ ${ELB_CERT_ARN} --load-balancer-port 443 --region ${REGION} **Delete the old ELB in AWS (hapi now already has new ELB in VPC)** aws elb delete-load-balancer \\ --load-balancer-name ${ELB_NAME} --region $REGION If ELB Cert Type from the above output is ACM Managed Certificate (ACM certs are common in ACSF) **Re-creation of ELB after moving hardware to new VPC Manually** VPC=[NAME OF THE NEW VPC] # Delete the old elb ah-site ssl deprovision-elb ${SITE} # Create new ELB with self signed certs KEY=${OPSTMP}/$SITE.key CERT=${OPSTMP}/$SITE.pem DOMAIN=\"www.${SITE}.acsitefactory.com\" openssl req -nodes -sha256 -newkey rsa:2048 -keyout ${KEY} -out ${OPSTMP}/${SITE}.csr \\ -subj \"/C=US/ST=Massachusetts/L=Boston/O=Acquia Inc./OU=Acquia/CN=${DOMAIN}\" openssl x509 -req -days 365 -in ${OPSTMP}/${SITE}.csr -signkey ${KEY} -out ${CERT} ah-site ssl create-elb ${SITE} --ca ${CERT} --cert ${CERT} --key ${KEY} # Make note of 'New ELB Name' from the output of the above # command and set following variable with it's value NEW_ELB_NAME=[New ELB Name] aws elb set-load-balancer-listener-ssl-certificate --load-balancer-name ${NEW_ELB_NAME} \\ --load-balancer-port 443 --ssl-certificate-id ${ELB_CERT_ARN} --region ${REGION} Update all the domains pointing OLD ELB to the NEW ELB # Get the new ELB FQDN after recreating it NEW_ELB_FQDN=\"$(site-elbdescribe $SITE|egrep elb.amazonaws.com)\" # Store all domains which are pointing to old ELB in an array DOMAINS=( $(site-domainshost ${CUSTOMERNAME}% | grep \"is an alias for ${ELB_FQDN}\" | awk '{print $1}') ) # Update all the domains to point to the new ELB for DOMAIN in ${DOMAINS[@]}; do ah-dns set -t CNAME -v ${NEW_ELB_FQDN} -h ${DOMAIN} done Note: Double check to make sure that you have re-pointed all the domains to new ELB that were pointed to old ELB, specifically in case of enterprise-g1 where multiple sites are linked with ELB. Once all the servers are back online proceed with site checks and verify the hardware is in new VPC. If any check fails then investigate and fix the issue and add the prod site/s back into monitoring. For ACE: site-mon add ${SITE} For ACSF: site-monenable ${CUSTOMERNAME}01live site-monenable ${CUSTOMERNAME}sf site-monenable ${CUSTOMERNAME}theme","title":"VPC to VPC  Migration"},{"location":"kanban_tickets/vpc_to_vpc/#vpc-to-vpc-migration","text":"If a customer site is running on shared/dedicated VPC, we can relaunch them into another shared/dedicated VPC directly faster, more reliably, and site will have less downtime in comparision to a site move to new hardware provisioned in new VPC.","title":"VPC to VPC  Migration"},{"location":"kanban_tickets/vpc_to_vpc/#site-factory-site-layout","text":"Site Factory migration, such as in the enterprise-g1 realm, have some noteworthy differences from hardware migration in ACE: Since it is required to migrate all the hardware in a Site Factory, it is helpful to understand the sitegroup/sites on a typical site factory: esl ${CUSTOMERNAME}% Each Site Factory has three sitegroups, ${CUSTOMERNAME} , ${CUSTOMERNAME}sf , and ${CUSTOMERNAME}theme . These sitegroups are often on separate stacks, so spend time tracking down all of the hardware. Within those sitegroups you will see sitenames such as ${CUSTOMERNAME}01live , ${CUSTOMERNAME}01update , ${CUSTOMERNAME}01theme , etc. Note some older site factories may add an underscore, i.e. ${CUSTOMERNAME}_sf . Identify all hardwares for all the sites before beginning the relaunch.","title":"Site Factory site layout"},{"location":"kanban_tickets/vpc_to_vpc/#setting-variables","text":"For any VPC to VPC migration maintenance, you will be given a customer sitegroup for hardware migration. (potentially a list of sitegroups if the customer has multiple sitegroups). Find all sites and hardware: SITEGROUP= SITES=( $(ah-site list sitegroup:${SITEGROUP} -w stage!=ra) ) SERVERS=( $(ah-server list $(printf 'site:%s\\n' ${SITES[@]} | \\ paste -sd,) -w type!=svn status=0) ) SERVERS_CSV=$(array-csv ${SERVERS[@]}) Identify any shared hardware by checking tags and other sites: ah-server list ${SERVERS_CSV} -c tags site-list -s ${SERVERS_CSV} If any sites are sharing hardware with a site that is not part of your maintenance, then that site's hardware must be removed from the list. Make note of any sites which currently have an ELB: for site in ${SITES[@]}; do site-elbdescribe ${site} done If they do, we need to provision new ELBs for each site and communicate the new ELB FQDN to the customer for DNS. Launch a new VPC or validate the target VPC: To launch a new VPC, follow VPC provisioning else proceed as follows. The target VPC must match the region of the servers you are migrating. VPC_ID= VPC_NAME=$(ah-vpc list % -w id=${VPC_ID}) ah-vpc get ${VPC_NAME} Launch a new VPN if requested by customer follow VPN provisioning","title":"Setting variables"},{"location":"kanban_tickets/vpc_to_vpc/#relaunch-into-vpc","text":"If there is nothing blocking a safe relaunch, proceed to suspend them. Please note that this will incur hard downtime for the customer, but is a faster and less painful process than site moves. Note: Do not try to relaunch an edge cluster into a new VPC. You will need to provision a new edge cluster in the new VPC, and have the customer update DNS before removing the old one. Remove the ACE prod and ACSF sites from monitoring For ACE: site-mon remove ${SITE} For ACSF: site-mondisable ${CUSTOMERNAME}01live site-mondisable ${CUSTOMERNAME}sf site-mondisable ${CUSTOMERNAME}theme Suspend all servers at the same time: ah-server suspend ${SERVERS_CSV} Update the VPC_ID ah-server edit ${SERVERS_CSV} -s vpc_id=${VPC_ID} Launch them: ah-server launch ${SERVERS[@]} If the site has any ELBs, recreate them. Repeat the following step for each of the ELB/s a site (ACE) or related group of sites (ACSF). SITE=[ SITENAME ] REGION=$(ah-site get ${SITE}|egrep '^region:'|awk '{print $2}') ELB_FQDN=\"$(site-elbdescribe $SITE|egrep elb.amazonaws.com)\" ELB_NAME=$(echo ${ELB_FQDN} | \\ egrep elb.amazonaws.com | \\ awk -F. '{print $1}' | \\ awk -F- 'BEGIN{OFS=\"-\"} {NF--; print}') ELB_CERT_ARN=$(aws elb describe-load-balancers \\ --load-balancer-names ${ELB_NAME} --region ${REGION} --output text \\ --query 'LoadBalancerDescriptions[*].ListenerDescriptions[*].Listener.SSLCertificateId') ELB_CERT_TYPE=$(echo ${ELB_CERT_ARN} | cut -d: -f3) if [ ${ELB_CERT_TYPE} == \"acm\" ] ;then CERT_TYPE=\"ACM Managed Certificate\" elif [ ${ELB_CERT_TYPE} == \"iam\" ] ;then CERT_TYPE=\"IAM Server Certificate\" fi site-elbdescribe ${SITE} echo -e \"{code:title=ELB Details - Before new VPC Migration} Site: $SITE Region: $REGION ELB before migration: $ELB_NAME ELB FQDN before migration: $ELB_FQDN elb_cert_arn: $ELB_CERT_ARN ELB Cert Type: $CERT_TYPE {code}\" If ELB Cert Type from the above output is IAM Server Certificate **Re-creation of ELB after moving hardware to new VPC** VPC=[NAME OF THE NEW VPC] ah-site ssl tech-refresh-vpc-migrate-elb ${SITE} ${VPC} # Make note of 'New ELB Name' from the output of the above # command and set following variable with it's value NEW_ELB_NAME=[New ELB Name] # Set existing certificate for the old elb to the new elb # that was created in the step above aws elb set-load-balancer-listener-ssl-certificate \\ --load-balancer-name ${NEW_ELB_NAME} --ssl-certificate-id \\ ${ELB_CERT_ARN} --load-balancer-port 443 --region ${REGION} **Delete the old ELB in AWS (hapi now already has new ELB in VPC)** aws elb delete-load-balancer \\ --load-balancer-name ${ELB_NAME} --region $REGION If ELB Cert Type from the above output is ACM Managed Certificate (ACM certs are common in ACSF) **Re-creation of ELB after moving hardware to new VPC Manually** VPC=[NAME OF THE NEW VPC] # Delete the old elb ah-site ssl deprovision-elb ${SITE} # Create new ELB with self signed certs KEY=${OPSTMP}/$SITE.key CERT=${OPSTMP}/$SITE.pem DOMAIN=\"www.${SITE}.acsitefactory.com\" openssl req -nodes -sha256 -newkey rsa:2048 -keyout ${KEY} -out ${OPSTMP}/${SITE}.csr \\ -subj \"/C=US/ST=Massachusetts/L=Boston/O=Acquia Inc./OU=Acquia/CN=${DOMAIN}\" openssl x509 -req -days 365 -in ${OPSTMP}/${SITE}.csr -signkey ${KEY} -out ${CERT} ah-site ssl create-elb ${SITE} --ca ${CERT} --cert ${CERT} --key ${KEY} # Make note of 'New ELB Name' from the output of the above # command and set following variable with it's value NEW_ELB_NAME=[New ELB Name] aws elb set-load-balancer-listener-ssl-certificate --load-balancer-name ${NEW_ELB_NAME} \\ --load-balancer-port 443 --ssl-certificate-id ${ELB_CERT_ARN} --region ${REGION} Update all the domains pointing OLD ELB to the NEW ELB # Get the new ELB FQDN after recreating it NEW_ELB_FQDN=\"$(site-elbdescribe $SITE|egrep elb.amazonaws.com)\" # Store all domains which are pointing to old ELB in an array DOMAINS=( $(site-domainshost ${CUSTOMERNAME}% | grep \"is an alias for ${ELB_FQDN}\" | awk '{print $1}') ) # Update all the domains to point to the new ELB for DOMAIN in ${DOMAINS[@]}; do ah-dns set -t CNAME -v ${NEW_ELB_FQDN} -h ${DOMAIN} done Note: Double check to make sure that you have re-pointed all the domains to new ELB that were pointed to old ELB, specifically in case of enterprise-g1 where multiple sites are linked with ELB. Once all the servers are back online proceed with site checks and verify the hardware is in new VPC. If any check fails then investigate and fix the issue and add the prod site/s back into monitoring. For ACE: site-mon add ${SITE} For ACSF: site-monenable ${CUSTOMERNAME}01live site-monenable ${CUSTOMERNAME}sf site-monenable ${CUSTOMERNAME}theme","title":"Relaunch Into VPC"},{"location":"kanban_tickets/vpc_vpn_deprovision/","text":"Deprovision a Shield VPN Deprovision a customer's Shield VPN. This should only be done after an AM has provided the go ahead to deprovision. Preparation VPC_NAME= VPN_NAME= Procedure Delete the VPN. ah-vpn delete $VPC_NAME $VPN_NAME Verification Look at the VPC's status with ah-vpc show , that VPN should no longer be listed. ah-vpc show $VPC_NAME","title":"Deprovision a Shield VPN"},{"location":"kanban_tickets/vpc_vpn_deprovision/#deprovision-a-shield-vpn","text":"Deprovision a customer's Shield VPN. This should only be done after an AM has provided the go ahead to deprovision.","title":"Deprovision a Shield VPN"},{"location":"kanban_tickets/vpc_vpn_deprovision/#preparation","text":"VPC_NAME= VPN_NAME=","title":"Preparation"},{"location":"kanban_tickets/vpc_vpn_deprovision/#procedure","text":"Delete the VPN. ah-vpn delete $VPC_NAME $VPN_NAME","title":"Procedure"},{"location":"kanban_tickets/vpc_vpn_deprovision/#verification","text":"Look at the VPC's status with ah-vpc show , that VPN should no longer be listed. ah-vpc show $VPC_NAME","title":"Verification"},{"location":"kanban_tickets/vpc_vpn_management/","text":"Updating Shield VPNs The only operations that can take place against Shield VPNs are to add and remove routes, one CIDR block at a time. To initiate a full VPN failover , a customer must have two VPN's. We cannot failover from one tunnel to another within the same VPN, this is the customers' responsibility. Add a route Preparation for route addition VPC_NAME= VPN_NAME= VPN_CIDR= ROUTE= Procedure for route addition Check that there is no overlap between the VPN cidr and the route cidr. Any output here means you cannot proceed. vpn-checkcidr $VPN_CIDR $ROUTE Add the route with ah-vpn add-route . ah-vpn add-route $VPC_NAME $VPN_NAME $ROUTE Verification of route addition Use ah-vpn show to verify the route has been added. ah-vpn show $VPC_NAME $VPN_NAME Remove a route Preparation for route removal VPC_NAME= VPN_NAME= ROUTE= Procedure for route removal Remove the route with ah-vpn remove-route . ah-vpn remove-route $VPC_NAME $VPN_NAME $ROUTE Verification of route removal Use ah-vpn show to verify the route has been removed. ah-vpn show $VPC_NAME $VPN_NAME VPN failover To completely failover a VPN, a customer must have two VPNs (one with routes and the other one without routes) set up in their dedicated shield VPC. The process of failing over involves moving all the routes from the primary VPN to the secondary VPN, so that all the packets will traverse through the secondary VPN rather than the primary. Use site-vpc to grab the current VPC and VPN status and comment in the ticket. site-vpc $SITE -v Follow the remove a route and add a route section to move all routes to the secondary VPN. Repeat the site-vpc command above to confirm all routes were moved over and comment in the ticket. To fail back, simply move all the routes back from the secondary VPN to the primary VPN. For an example of this process, please see OP-262618","title":"Updating Shield VPNs"},{"location":"kanban_tickets/vpc_vpn_management/#updating-shield-vpns","text":"The only operations that can take place against Shield VPNs are to add and remove routes, one CIDR block at a time. To initiate a full VPN failover , a customer must have two VPN's. We cannot failover from one tunnel to another within the same VPN, this is the customers' responsibility.","title":"Updating Shield VPNs"},{"location":"kanban_tickets/vpc_vpn_management/#add-a-route","text":"","title":"Add a route"},{"location":"kanban_tickets/vpc_vpn_management/#preparation-for-route-addition","text":"VPC_NAME= VPN_NAME= VPN_CIDR= ROUTE=","title":"Preparation for route addition"},{"location":"kanban_tickets/vpc_vpn_management/#procedure-for-route-addition","text":"Check that there is no overlap between the VPN cidr and the route cidr. Any output here means you cannot proceed. vpn-checkcidr $VPN_CIDR $ROUTE Add the route with ah-vpn add-route . ah-vpn add-route $VPC_NAME $VPN_NAME $ROUTE","title":"Procedure for route addition"},{"location":"kanban_tickets/vpc_vpn_management/#verification-of-route-addition","text":"Use ah-vpn show to verify the route has been added. ah-vpn show $VPC_NAME $VPN_NAME","title":"Verification of route addition"},{"location":"kanban_tickets/vpc_vpn_management/#remove-a-route","text":"","title":"Remove a route"},{"location":"kanban_tickets/vpc_vpn_management/#preparation-for-route-removal","text":"VPC_NAME= VPN_NAME= ROUTE=","title":"Preparation for route removal"},{"location":"kanban_tickets/vpc_vpn_management/#procedure-for-route-removal","text":"Remove the route with ah-vpn remove-route . ah-vpn remove-route $VPC_NAME $VPN_NAME $ROUTE","title":"Procedure for route removal"},{"location":"kanban_tickets/vpc_vpn_management/#verification-of-route-removal","text":"Use ah-vpn show to verify the route has been removed. ah-vpn show $VPC_NAME $VPN_NAME","title":"Verification of route removal"},{"location":"kanban_tickets/vpc_vpn_management/#vpn-failover","text":"To completely failover a VPN, a customer must have two VPNs (one with routes and the other one without routes) set up in their dedicated shield VPC. The process of failing over involves moving all the routes from the primary VPN to the secondary VPN, so that all the packets will traverse through the secondary VPN rather than the primary. Use site-vpc to grab the current VPC and VPN status and comment in the ticket. site-vpc $SITE -v Follow the remove a route and add a route section to move all routes to the secondary VPN. Repeat the site-vpc command above to confirm all routes were moved over and comment in the ticket. To fail back, simply move all the routes back from the secondary VPN to the primary VPN. For an example of this process, please see OP-262618","title":"VPN failover"},{"location":"kanban_tickets/vpc_vpn_provision/","text":"Provisioning a Shield VPN Customers with dedicated VPCs (only dedicated) can purchase a VPC VPN to establish site-to-site VPN tunnels. Preparation Parameter Description Is provided by customer? $VPC_NAME Name of the VPC the VPN is being provisioned for. No. $VPN_NAME A name for the VPN. Something helpful is best like the location of the datacenter but ${SITEGROUP}A and ${SITEGROUP}B have been used before. No. $GATEWAY_IP The gateway IP address of the customer's VPN device. Provided by customer. $ROUTES A list of customer networks that needs traffic statically routed to them, in CIDR notation (ex, 10.1.0.0/8). Provided by customer. $TUNNEL_1_CIDR (Optional) The inside tunnel CIDR for the first VPN tunnel. Must be a size /30 CIDR block from the 169.254.0.0/16 range. * Optionally provided by customer. Otherwise AWS-provided default value will be used. $TUNNEL_2_CIDR (Optional) The inside tunnel CIDR for the second VPN tunnel. Must be a size /30 CIDR block from the 169.254.0.0/16 range. * Optionally provided by customer. Otherwise AWS-provided default value will be used. * The following CIDR blocks are reserved by AWS and cannot be used: - 169.254.0.0/30 - 169.254.1.0/30 - 169.254.2.0/30 - 169.254.3.0/30 - 169.254.4.0/30 - 169.254.5.0/30 - 169.254.169.252/30 Procedure Create the VPN where $ROUTES is a space delimited list. One is needed but multiple can be provided at the time of provision. More can be added later. ah-vpn create $VPC_NAME $VPN_NAME $GATEWAY_IP --routes=$ROUTES [--tunnel_1_cidr $TUNNEL_1_CIDR --tunnel_2_cidr $TUNNEL_2_CIDR] Gather the information needed for the customer. This should be treated a securely as an SSL private key so don't paste it in a ticket. ah-vpn show-config $VPC_NAME $VPN_NAME Verification Run ah-vpn show against the VPN to verify \"Hosting Status\" is created. ah-vpn show $VPC_NAME $VPN_NAME","title":"Provisioning a Shield VPN"},{"location":"kanban_tickets/vpc_vpn_provision/#provisioning-a-shield-vpn","text":"Customers with dedicated VPCs (only dedicated) can purchase a VPC VPN to establish site-to-site VPN tunnels.","title":"Provisioning a Shield VPN"},{"location":"kanban_tickets/vpc_vpn_provision/#preparation","text":"Parameter Description Is provided by customer? $VPC_NAME Name of the VPC the VPN is being provisioned for. No. $VPN_NAME A name for the VPN. Something helpful is best like the location of the datacenter but ${SITEGROUP}A and ${SITEGROUP}B have been used before. No. $GATEWAY_IP The gateway IP address of the customer's VPN device. Provided by customer. $ROUTES A list of customer networks that needs traffic statically routed to them, in CIDR notation (ex, 10.1.0.0/8). Provided by customer. $TUNNEL_1_CIDR (Optional) The inside tunnel CIDR for the first VPN tunnel. Must be a size /30 CIDR block from the 169.254.0.0/16 range. * Optionally provided by customer. Otherwise AWS-provided default value will be used. $TUNNEL_2_CIDR (Optional) The inside tunnel CIDR for the second VPN tunnel. Must be a size /30 CIDR block from the 169.254.0.0/16 range. * Optionally provided by customer. Otherwise AWS-provided default value will be used. * The following CIDR blocks are reserved by AWS and cannot be used: - 169.254.0.0/30 - 169.254.1.0/30 - 169.254.2.0/30 - 169.254.3.0/30 - 169.254.4.0/30 - 169.254.5.0/30 - 169.254.169.252/30","title":"Preparation"},{"location":"kanban_tickets/vpc_vpn_provision/#procedure","text":"Create the VPN where $ROUTES is a space delimited list. One is needed but multiple can be provided at the time of provision. More can be added later. ah-vpn create $VPC_NAME $VPN_NAME $GATEWAY_IP --routes=$ROUTES [--tunnel_1_cidr $TUNNEL_1_CIDR --tunnel_2_cidr $TUNNEL_2_CIDR] Gather the information needed for the customer. This should be treated a securely as an SSL private key so don't paste it in a ticket. ah-vpn show-config $VPC_NAME $VPN_NAME","title":"Procedure"},{"location":"kanban_tickets/vpc_vpn_provision/#verification","text":"Run ah-vpn show against the VPN to verify \"Hosting Status\" is created. ah-vpn show $VPC_NAME $VPN_NAME","title":"Verification"},{"location":"kanban_tickets/wildcard_certificates/","text":"Wildcard Certificates Wildcard SSL Certificates (covering domains such as *.acquia.com ) are purchased and managed through DigiCert's UI. We manage wildcard certificates for two reasons: Customers request a wildcard certificate (sometimes to create a \"combined certificate\" consisting of a wildcard and a UCC with multiple SANs on it) Acquia requires wildcards to be managed for its hosts and services ( *.acquia.com , SVN server certs such as *.prod.hosting.acquia.com , etc.) Important Note Our DigiCert account is upgraded recently where the new platform is called as CertCentral, hence please refer below Digicert Central UI confluence page for updated instructions: https://confluence.acquia.com/display/OE/DigiCert+-+CertCentral+UI Wildcard Management for Customers Ordering a wildcard certificate uses the same process as standard SSL requests. Verify customer information is present in the ticket as outlined in the Generating CSRs doc Generate the CSR and key pair and store them in KeePassX Proceed with the ordering process. Use account credit as the payment option Once the order has completed and the certificate has been issued, either: Follow the Deploying an SSL / TLS certificate to a balancer cluster doc OR if the ticket calls for a different action please consult Tier 2 Ops. Combining Wildcard Certificates and UCCs Some customers require a UCC to be combined with a Wildcard Certificate, this should be specified in the ticket. This process will allow for multiple UCCs to be combined under a single SSL Certificate. Determine the Wildcard Certificate in use by the customer, this is Order 1. Determine the UCC that needs to be combined with the Wildcard Certificate, this is Order 2. Add a note on each certificate to be combined, with the details listed below. Notes are located on the right side of the order page. Format: Please combine Order 1 with Order 2 as a duplicate of Order 1 and use the CSR from Order 1 Open a live chat with digicert using the note you added to each order as the message. Digicert will confirm the details of the notes and create a duplicate per the request. When obtaining the duplicate it is best to check that the SANs on the UCC show up on the duplicate of the Wildcard Certificate. Each duplicate is numbered in-order. Generally the highest-numbered duplicate is the one you want to deploy: Wildcard Management for Acquia Acquia currently maintains a number of wildcard certificates for internal use. An example list of these domains: *.acquia-search.com *.acquia.com *.cis.acquia.com *.connect.acquia.com *.deb.acquiapipe.net *.devcloud.acquia-sites.com *.devcloud.hosting.acquia.com *.drupalgardens.com *.enterprise-g1.hosting.acquia.com *.fpmg-egardens.hosting.acquia.com *.gardens.hosting.acquia.com *.lift.acquia.com *.mollom.com *.network.hosting.acquia.com *.pfizer.edrupalgardens.com *.prod.acquia-sites.com *.prod.hosting.acquia.com *.search-service.hosting.acquia.com *.umg-egardens.hosting.acquia.com *.umg.edrupalgardens.com *.wmg-egardens.hosting.acquia.com *.wmg-gardens.com How to handle Duplicates on a Wildcard Certificate Currently, *.acquia.com has several duplicates that each have their own distinct CSR and Key pair. This is done for a few reasons: If a service is compromised, only the one CSR + Key pair is compromised (fewer keys to rotate in the event of a breach) Easier to deploy/provide a duplicate and change its details separate from the \"root\" certificate Easier to revoke/manage duplicates under the \"root\" certificate Creating a duplicate under an existing Wildcard Certificate In this example, we're going to use *.acquia.com . Generate a new CSR and Key pair using the Generating CSRs doc and store it in the Ops KeePassX vault . For more detailed information on the best way to store your duplicate's CSR and key pair, please consult Tier 2 Ops. Log in to the DigiCert portal and navigate to the current Active order for the wildcard cert you are creating a duplicate for. Click \"Get A Duplicate\". In the pop-up window, paste in: The CSR you just created Select \"nginx\" for server software Add a note (such as dev.acquia.com (owner: Joe Person) | OP-12345\" ) (Optional) Specify additional subdomains to secure. For wildcards, this generally is not necessary unless you are securing something more than a single layer deep (Example: sub1.sub2.sub3.acquia.com ) Ensure \"Use a SHA-2 signature hashing algorithm\" is selected Click \"Process Duplicate Wildcard Cert\" Once processed, and depending on where the certificate needs to be deployed, either use the Deploying an SSL / TLS certificate to a balancer cluster doc to deploy the certificate to a hosting stage, or provide the duplicate cert and key to the ticket submitter via secured channels. A Note On Transmitting \"Secured\" Information Per Acquia Security guidelines (and infosec best-practices), you should ensure: Keys and certificates are sent to recipient(s) separately : Cert via ticket attachment Key via password-protected .zip file Password for zip via Off-The-Record Instant Message \"Bodies\" or \"payloads\" of said files must not be pasted or provided anywhere in plain-text","title":"Wildcard Certificates"},{"location":"kanban_tickets/wildcard_certificates/#wildcard-certificates","text":"Wildcard SSL Certificates (covering domains such as *.acquia.com ) are purchased and managed through DigiCert's UI. We manage wildcard certificates for two reasons: Customers request a wildcard certificate (sometimes to create a \"combined certificate\" consisting of a wildcard and a UCC with multiple SANs on it) Acquia requires wildcards to be managed for its hosts and services ( *.acquia.com , SVN server certs such as *.prod.hosting.acquia.com , etc.)","title":"Wildcard Certificates"},{"location":"kanban_tickets/wildcard_certificates/#important-note","text":"Our DigiCert account is upgraded recently where the new platform is called as CertCentral, hence please refer below Digicert Central UI confluence page for updated instructions: https://confluence.acquia.com/display/OE/DigiCert+-+CertCentral+UI","title":"Important Note"},{"location":"kanban_tickets/wildcard_certificates/#wildcard-management-for-customers","text":"Ordering a wildcard certificate uses the same process as standard SSL requests. Verify customer information is present in the ticket as outlined in the Generating CSRs doc Generate the CSR and key pair and store them in KeePassX Proceed with the ordering process. Use account credit as the payment option Once the order has completed and the certificate has been issued, either: Follow the Deploying an SSL / TLS certificate to a balancer cluster doc OR if the ticket calls for a different action please consult Tier 2 Ops.","title":"Wildcard Management for Customers"},{"location":"kanban_tickets/wildcard_certificates/#combining-wildcard-certificates-and-uccs","text":"Some customers require a UCC to be combined with a Wildcard Certificate, this should be specified in the ticket. This process will allow for multiple UCCs to be combined under a single SSL Certificate. Determine the Wildcard Certificate in use by the customer, this is Order 1. Determine the UCC that needs to be combined with the Wildcard Certificate, this is Order 2. Add a note on each certificate to be combined, with the details listed below. Notes are located on the right side of the order page. Format: Please combine Order 1 with Order 2 as a duplicate of Order 1 and use the CSR from Order 1 Open a live chat with digicert using the note you added to each order as the message. Digicert will confirm the details of the notes and create a duplicate per the request. When obtaining the duplicate it is best to check that the SANs on the UCC show up on the duplicate of the Wildcard Certificate. Each duplicate is numbered in-order. Generally the highest-numbered duplicate is the one you want to deploy:","title":"Combining Wildcard Certificates and UCCs"},{"location":"kanban_tickets/wildcard_certificates/#wildcard-management-for-acquia","text":"Acquia currently maintains a number of wildcard certificates for internal use. An example list of these domains: *.acquia-search.com *.acquia.com *.cis.acquia.com *.connect.acquia.com *.deb.acquiapipe.net *.devcloud.acquia-sites.com *.devcloud.hosting.acquia.com *.drupalgardens.com *.enterprise-g1.hosting.acquia.com *.fpmg-egardens.hosting.acquia.com *.gardens.hosting.acquia.com *.lift.acquia.com *.mollom.com *.network.hosting.acquia.com *.pfizer.edrupalgardens.com *.prod.acquia-sites.com *.prod.hosting.acquia.com *.search-service.hosting.acquia.com *.umg-egardens.hosting.acquia.com *.umg.edrupalgardens.com *.wmg-egardens.hosting.acquia.com *.wmg-gardens.com","title":"Wildcard Management for Acquia"},{"location":"kanban_tickets/wildcard_certificates/#how-to-handle-duplicates-on-a-wildcard-certificate","text":"Currently, *.acquia.com has several duplicates that each have their own distinct CSR and Key pair. This is done for a few reasons: If a service is compromised, only the one CSR + Key pair is compromised (fewer keys to rotate in the event of a breach) Easier to deploy/provide a duplicate and change its details separate from the \"root\" certificate Easier to revoke/manage duplicates under the \"root\" certificate","title":"How to handle Duplicates on a Wildcard Certificate"},{"location":"kanban_tickets/wildcard_certificates/#creating-a-duplicate-under-an-existing-wildcard-certificate","text":"In this example, we're going to use *.acquia.com . Generate a new CSR and Key pair using the Generating CSRs doc and store it in the Ops KeePassX vault . For more detailed information on the best way to store your duplicate's CSR and key pair, please consult Tier 2 Ops. Log in to the DigiCert portal and navigate to the current Active order for the wildcard cert you are creating a duplicate for. Click \"Get A Duplicate\". In the pop-up window, paste in: The CSR you just created Select \"nginx\" for server software Add a note (such as dev.acquia.com (owner: Joe Person) | OP-12345\" ) (Optional) Specify additional subdomains to secure. For wildcards, this generally is not necessary unless you are securing something more than a single layer deep (Example: sub1.sub2.sub3.acquia.com ) Ensure \"Use a SHA-2 signature hashing algorithm\" is selected Click \"Process Duplicate Wildcard Cert\" Once processed, and depending on where the certificate needs to be deployed, either use the Deploying an SSL / TLS certificate to a balancer cluster doc to deploy the certificate to a hosting stage, or provide the duplicate cert and key to the ticket submitter via secured channels.","title":"Creating a duplicate under an existing Wildcard Certificate"},{"location":"kanban_tickets/wildcard_certificates/#a-note-on-transmitting-secured-information","text":"Per Acquia Security guidelines (and infosec best-practices), you should ensure: Keys and certificates are sent to recipient(s) separately : Cert via ticket attachment Key via password-protected .zip file Password for zip via Off-The-Record Instant Message \"Bodies\" or \"payloads\" of said files must not be pasted or provided anywhere in plain-text","title":"A Note On Transmitting \"Secured\" Information"},{"location":"kanban_tickets/dedicated_bals/dedicated_to_dedicated/","text":"Dedicated To Dedicated Hardware Allocation Use Allocating Hardware to allocate the correct hardware for the customer. Pre-Assignment Check SSL requirements If a new SSL certificate is not provided and the customer does not have SNI set up, you can copy the cert/key from their old bals. To do this: Manually copy the current cert/key in /etc/ssl/{certs/,private/} to the bastion Tag the new balancers with the customer's ssl_ tag Deploy the cert/key with ahops-ssltool push bal <tag> <cert> <key> Do not deploy UCC certs to dedicated balancers. If you find a dedicated balancer that is using a UCC cert, coordinate with the ticket requester or account manager to resolve this with SNI, a customer-provided dedicated cert, or an Ops-provided cert with Digicert (this requires a dealsheet). Check VCL requirements NOTE ONLY FOR PFIZER: If the balancers are being assigned to pfizer sites (usually starts with pf - but confirm with TAM/AM) - make sure to apply pfizer-cloudflare VCL to the balancers before assigning balancers to the sites. ONLY FOR PFIZER ah-server edit $BALS -c puppet:varnish_config=pfizer-cloudflare fpdsh -l $BALS -c \"sudo run-puppet && sudo fields-config-bal.php\" ah-server list $BALS -c puppet:varnish_config Note: Make sure to verify if the existing hardware is in vpc or not before adding/assigning the new bals and proceed accordingly. Assigning Balancers Identify all of the sites that will be moved to the new balancers. Modify SITES as needed and add the bals to them. SITEGROUP= NEW_BALS= SITES=($(ah-site list % -w sitegroup=${SITEGROUP} stage!=ra | paste -sd' ')) for site in ${SITES[@]}; do ah-site bal add ${site} --bals ${NEW_BALS}; done If any of the new balancers are not in an AZ configured for the ELB, you must configure the ELB to use the new AZs. for site in ${SITES[@]}; do ELB=$(ruby -e \"require 'aq'; site = Aq::Hosting::Site.from_query(name: '${site}'); puts \\ Aq::Hosting::SiteElb.fromQuery('site_id' => site['id']).record['elb_name']\") AZS=($(ah-server list site:${site} -w type=bal -c ec2_availability_zone --no-name | paste -sd' ')) aws elb enable-availability-zones-for-load-balancer \\ --region $REGION \\ --load-balancer-name $ELB \\ --availability-zones $AZS done Post-Assignment Communicate to Support that the customer must now change DNS to the EIP of the new balancer pair or ELB (if applicable). for site in ${SITES[@]}; do ah-server list site:${site} -w type=bal eip_id!=nil -c external_ip; done | sort -u Mark ticket \"Waiting For Feedback\" Once Support or the customer confirms that DNS has been changed, remove the old balancers from the site record after checking the domains are pointing to the EIP of the new balancers. for site in ${SITES[@]}; do site-domainshost ${site} done for site in ${SITES[@]}; do ah-site bal remove ${site} --bals ${OLD_BALS} done If there are no remaining sites on the old balancers, inform the ticket requester and follow this runbook section to deprovision them.","title":"Dedicated To Dedicated"},{"location":"kanban_tickets/dedicated_bals/dedicated_to_dedicated/#dedicated-to-dedicated","text":"","title":"Dedicated To Dedicated"},{"location":"kanban_tickets/dedicated_bals/dedicated_to_dedicated/#hardware-allocation","text":"Use Allocating Hardware to allocate the correct hardware for the customer.","title":"Hardware Allocation"},{"location":"kanban_tickets/dedicated_bals/dedicated_to_dedicated/#pre-assignment","text":"Check SSL requirements If a new SSL certificate is not provided and the customer does not have SNI set up, you can copy the cert/key from their old bals. To do this: Manually copy the current cert/key in /etc/ssl/{certs/,private/} to the bastion Tag the new balancers with the customer's ssl_ tag Deploy the cert/key with ahops-ssltool push bal <tag> <cert> <key> Do not deploy UCC certs to dedicated balancers. If you find a dedicated balancer that is using a UCC cert, coordinate with the ticket requester or account manager to resolve this with SNI, a customer-provided dedicated cert, or an Ops-provided cert with Digicert (this requires a dealsheet). Check VCL requirements NOTE ONLY FOR PFIZER: If the balancers are being assigned to pfizer sites (usually starts with pf - but confirm with TAM/AM) - make sure to apply pfizer-cloudflare VCL to the balancers before assigning balancers to the sites. ONLY FOR PFIZER ah-server edit $BALS -c puppet:varnish_config=pfizer-cloudflare fpdsh -l $BALS -c \"sudo run-puppet && sudo fields-config-bal.php\" ah-server list $BALS -c puppet:varnish_config Note: Make sure to verify if the existing hardware is in vpc or not before adding/assigning the new bals and proceed accordingly.","title":"Pre-Assignment"},{"location":"kanban_tickets/dedicated_bals/dedicated_to_dedicated/#assigning-balancers","text":"Identify all of the sites that will be moved to the new balancers. Modify SITES as needed and add the bals to them. SITEGROUP= NEW_BALS= SITES=($(ah-site list % -w sitegroup=${SITEGROUP} stage!=ra | paste -sd' ')) for site in ${SITES[@]}; do ah-site bal add ${site} --bals ${NEW_BALS}; done If any of the new balancers are not in an AZ configured for the ELB, you must configure the ELB to use the new AZs. for site in ${SITES[@]}; do ELB=$(ruby -e \"require 'aq'; site = Aq::Hosting::Site.from_query(name: '${site}'); puts \\ Aq::Hosting::SiteElb.fromQuery('site_id' => site['id']).record['elb_name']\") AZS=($(ah-server list site:${site} -w type=bal -c ec2_availability_zone --no-name | paste -sd' ')) aws elb enable-availability-zones-for-load-balancer \\ --region $REGION \\ --load-balancer-name $ELB \\ --availability-zones $AZS done","title":"Assigning Balancers"},{"location":"kanban_tickets/dedicated_bals/dedicated_to_dedicated/#post-assignment","text":"Communicate to Support that the customer must now change DNS to the EIP of the new balancer pair or ELB (if applicable). for site in ${SITES[@]}; do ah-server list site:${site} -w type=bal eip_id!=nil -c external_ip; done | sort -u Mark ticket \"Waiting For Feedback\" Once Support or the customer confirms that DNS has been changed, remove the old balancers from the site record after checking the domains are pointing to the EIP of the new balancers. for site in ${SITES[@]}; do site-domainshost ${site} done for site in ${SITES[@]}; do ah-site bal remove ${site} --bals ${OLD_BALS} done If there are no remaining sites on the old balancers, inform the ticket requester and follow this runbook section to deprovision them.","title":"Post-Assignment"},{"location":"kanban_tickets/dedicated_bals/dedicated_to_shared/","text":"Dedicated to Shared Pre-work Customers looking to move to shared balancers require special care as they may have custom VCLs or specific SSL certificates deployed to their dedicated balancers. Check the customer's VPC status and placement by using the VPC Placement steps. Check VCL requirements Custom VCLs cannot be deployed to shared balancers. Do not migrate the customer to the shared balancers until the ticket requester or account manager verifies that the customer is ok with losing the custom VCL. Check SSL requirements If SSL termination is required on the new shared bal and the customer does not have SNI set, then you need to add the customer's domains to the UCC cert on the destination balancer by following the SSL UCCs runbook. A dealsheet must always be provided for adding domains to a UCC. If the shared balancer is not already tagged to use a UCC cert, then you will need to find an appropriate UCC cert with a sufficient number of slots available to add to the balancer. If the customer has SNI set up but is missing domains, verify its validity with the ticket requester or account manager. Note: Make sure to verify if the existing hardware is in vpc or not before adding/assigning the new bals and proceed accordingly. Assign Balancers Find a shared balancer using site-taglistactive . If the customer is in a VPC, ensure that you select the correct VPC when looking for available shared balancers. site-taglistactive bal ${REGION} ${VPC} ${STAGE} Identify all of the sites that will be moved to the new balancers. Modify SITES as needed and add the bals to them. For prod balancers: SITEGROUP= NEW_BALS_PROD= SITE=$(ah-site list tag:prod -w sitegroup=${SITEGROUP}) ah-site bal add ${SITE} --bals ${NEW_BALS_PROD} For test, stg, and dev balancers: SITEGROUP= NEW_BALS_STG= PROD=$(ah-site list tag:prod | paste -s -d',') SITES=($(ah-site list % -w sitegroup=${SITEGROUP} ra=0 \"name NOT IN $PROD\")) for site in ${SITES[@]}; do ah-site bal add ${site} --bals ${NEW_BALS_STG} done If any of the new balancers are not in an AZ configured for the ELB, you must configure the ELB to use the new AZs. for site in ${SITES[@]}; do ELB=$(ruby -e \"require 'aq'; site = Aq::Hosting::Site.from_query(name: '${site}'); puts \\ Aq::Hosting::SiteElb.fromQuery('site_id' => site['id']).record['elb_name']\") AZS=($(ah-server list site:${site} -w type=bal -c ec2_availability_zone --no-name | paste -sd' ')) aws elb enable-availability-zones-for-load-balancer \\ --region $REGION \\ --load-balancer-name $ELB \\ --availability-zones $AZS done Post-Assignment Communicate to Support that the customer must now change DNS to the EIP of the new balancer pair. for site in ${SITES[@]}; do ah-server list site:${site} -w type=bal eip_id!=nil -c external_ip; done | sort -u Mark ticket \"Waiting For Feedback\" Once Support or the customer confirms that DNS has been changed, remove the old balancers from the site record after checking the domains are pointing to the EIP of the new balancers. for site in ${SITES[@]}; do site-domainshost ${site} done for site in ${SITES[@]}; do ah-site bal remove ${site} --bals ${OLD_BALS} done If there are no remaining sites on the old balancers, inform the ticket requester and follow this runbook section to deprovision them.","title":"Dedicated to Shared"},{"location":"kanban_tickets/dedicated_bals/dedicated_to_shared/#dedicated-to-shared","text":"","title":"Dedicated to Shared"},{"location":"kanban_tickets/dedicated_bals/dedicated_to_shared/#pre-work","text":"Customers looking to move to shared balancers require special care as they may have custom VCLs or specific SSL certificates deployed to their dedicated balancers. Check the customer's VPC status and placement by using the VPC Placement steps. Check VCL requirements Custom VCLs cannot be deployed to shared balancers. Do not migrate the customer to the shared balancers until the ticket requester or account manager verifies that the customer is ok with losing the custom VCL. Check SSL requirements If SSL termination is required on the new shared bal and the customer does not have SNI set, then you need to add the customer's domains to the UCC cert on the destination balancer by following the SSL UCCs runbook. A dealsheet must always be provided for adding domains to a UCC. If the shared balancer is not already tagged to use a UCC cert, then you will need to find an appropriate UCC cert with a sufficient number of slots available to add to the balancer. If the customer has SNI set up but is missing domains, verify its validity with the ticket requester or account manager. Note: Make sure to verify if the existing hardware is in vpc or not before adding/assigning the new bals and proceed accordingly.","title":"Pre-work"},{"location":"kanban_tickets/dedicated_bals/dedicated_to_shared/#assign-balancers","text":"Find a shared balancer using site-taglistactive . If the customer is in a VPC, ensure that you select the correct VPC when looking for available shared balancers. site-taglistactive bal ${REGION} ${VPC} ${STAGE} Identify all of the sites that will be moved to the new balancers. Modify SITES as needed and add the bals to them. For prod balancers: SITEGROUP= NEW_BALS_PROD= SITE=$(ah-site list tag:prod -w sitegroup=${SITEGROUP}) ah-site bal add ${SITE} --bals ${NEW_BALS_PROD} For test, stg, and dev balancers: SITEGROUP= NEW_BALS_STG= PROD=$(ah-site list tag:prod | paste -s -d',') SITES=($(ah-site list % -w sitegroup=${SITEGROUP} ra=0 \"name NOT IN $PROD\")) for site in ${SITES[@]}; do ah-site bal add ${site} --bals ${NEW_BALS_STG} done If any of the new balancers are not in an AZ configured for the ELB, you must configure the ELB to use the new AZs. for site in ${SITES[@]}; do ELB=$(ruby -e \"require 'aq'; site = Aq::Hosting::Site.from_query(name: '${site}'); puts \\ Aq::Hosting::SiteElb.fromQuery('site_id' => site['id']).record['elb_name']\") AZS=($(ah-server list site:${site} -w type=bal -c ec2_availability_zone --no-name | paste -sd' ')) aws elb enable-availability-zones-for-load-balancer \\ --region $REGION \\ --load-balancer-name $ELB \\ --availability-zones $AZS done","title":"Assign Balancers"},{"location":"kanban_tickets/dedicated_bals/dedicated_to_shared/#post-assignment","text":"Communicate to Support that the customer must now change DNS to the EIP of the new balancer pair. for site in ${SITES[@]}; do ah-server list site:${site} -w type=bal eip_id!=nil -c external_ip; done | sort -u Mark ticket \"Waiting For Feedback\" Once Support or the customer confirms that DNS has been changed, remove the old balancers from the site record after checking the domains are pointing to the EIP of the new balancers. for site in ${SITES[@]}; do site-domainshost ${site} done for site in ${SITES[@]}; do ah-site bal remove ${site} --bals ${OLD_BALS} done If there are no remaining sites on the old balancers, inform the ticket requester and follow this runbook section to deprovision them.","title":"Post-Assignment"},{"location":"kanban_tickets/dedicated_bals/shared_to_dedicated/","text":"Shared to Dedicated If Edge balancers are requested in ticket, please refer this runbook . Hardware Allocation Make sure you match the AZs of newly provisioning bals with AZs of existing web/ded/staging servers. ah-server list site:${site} -w typeIN'web,ded,staging' -c ec2_availability_zone --no-name |sort -u REGION= AZ1= AZ2= NOTE ONLY FOR PFIZER: If the balancers are being assigned to pfizer sites (usually starts with pf - but confirm with TAM/AM) - make sure to apply pfizer-cloudflare VCL to the balancers before assigning balancers to the sites. ONLY FOR PFIZER ah-server edit $BALS -c puppet:varnish_config=pfizer-cloudflare fpdsh -l $BALS -c \"sudo run-puppet && sudo fields-config-bal.php\" ah-server list $BALS -c puppet:varnish_config Use Allocating Hardware to allocate the correct hardware for the customer. Pre-Assignment Check SSL requirements Do not deploy UCC certs to dedicated balancers. If SSL termination is required on the dedicated bals, the customer will need to set up SNI or provide us with a dedicated SSL certificate. A dealsheet is required if we are ordering the certificate through Digicert on behalf of the customer. Note: Make sure to verify if the existing hardware is in vpc or not before adding/assigning the new bals and proceed accordingly. Assigning Balancers Identify all of the sites that will be moved to the new balancers. Modify SITES as needed and add the bals to them. SITEGROUP= NEW_BALS= SITES=($(ah-site list % -w sitegroup=${SITEGROUP} stage'NOT IN'ra -c stage | sed '/ode[0-9]/d' | cut -f1 -d ',' | paste -sd ' ')) for site in ${SITES[@]}; do ah-site bal add ${site} --bals ${NEW_BALS}; done If any of the new balancers are not in an AZ configured for the ELB, you must configure the ELB to use the new AZs. for site in ${SITES[@]}; do ELB=$(ruby -e \"require 'aq'; site = Aq::Hosting::Site.from_query(name: '${site}'); puts \\ Aq::Hosting::SiteElb.fromQuery('site_id' => site['id']).record['elb_name']\") AZS=($(ah-server list site:${site} -w type=bal -c ec2_availability_zone --no-name | paste -sd' ')) aws elb enable-availability-zones-for-load-balancer \\ --region $REGION \\ --load-balancer-name $ELB \\ --availability-zones $AZS done Post-Assignment Communicate to Support that the customer must now change DNS to the EIP of the new balancer pair. for site in ${SITES[@]}; do ah-server list site:${site} -w type=bal eip_id!=nil -c external_ip done | sort | uniq Mark ticket \"Waiting For Feedback\" Once Support or the customer confirms that DNS has been changed, remove the old balancers from the site record after checking the domains are pointing to the EIP of the new balancers. for site in ${SITES[@]}; do site-domainshost ${site} done OLD_BALS= for site in ${SITES[@]}; do ah-site bal remove ${site} --bals ${OLD_BALS} done","title":"Shared to Dedicated"},{"location":"kanban_tickets/dedicated_bals/shared_to_dedicated/#shared-to-dedicated","text":"If Edge balancers are requested in ticket, please refer this runbook .","title":"Shared to Dedicated"},{"location":"kanban_tickets/dedicated_bals/shared_to_dedicated/#hardware-allocation","text":"Make sure you match the AZs of newly provisioning bals with AZs of existing web/ded/staging servers. ah-server list site:${site} -w typeIN'web,ded,staging' -c ec2_availability_zone --no-name |sort -u REGION= AZ1= AZ2= NOTE ONLY FOR PFIZER: If the balancers are being assigned to pfizer sites (usually starts with pf - but confirm with TAM/AM) - make sure to apply pfizer-cloudflare VCL to the balancers before assigning balancers to the sites. ONLY FOR PFIZER ah-server edit $BALS -c puppet:varnish_config=pfizer-cloudflare fpdsh -l $BALS -c \"sudo run-puppet && sudo fields-config-bal.php\" ah-server list $BALS -c puppet:varnish_config Use Allocating Hardware to allocate the correct hardware for the customer.","title":"Hardware Allocation"},{"location":"kanban_tickets/dedicated_bals/shared_to_dedicated/#pre-assignment","text":"Check SSL requirements Do not deploy UCC certs to dedicated balancers. If SSL termination is required on the dedicated bals, the customer will need to set up SNI or provide us with a dedicated SSL certificate. A dealsheet is required if we are ordering the certificate through Digicert on behalf of the customer. Note: Make sure to verify if the existing hardware is in vpc or not before adding/assigning the new bals and proceed accordingly.","title":"Pre-Assignment"},{"location":"kanban_tickets/dedicated_bals/shared_to_dedicated/#assigning-balancers","text":"Identify all of the sites that will be moved to the new balancers. Modify SITES as needed and add the bals to them. SITEGROUP= NEW_BALS= SITES=($(ah-site list % -w sitegroup=${SITEGROUP} stage'NOT IN'ra -c stage | sed '/ode[0-9]/d' | cut -f1 -d ',' | paste -sd ' ')) for site in ${SITES[@]}; do ah-site bal add ${site} --bals ${NEW_BALS}; done If any of the new balancers are not in an AZ configured for the ELB, you must configure the ELB to use the new AZs. for site in ${SITES[@]}; do ELB=$(ruby -e \"require 'aq'; site = Aq::Hosting::Site.from_query(name: '${site}'); puts \\ Aq::Hosting::SiteElb.fromQuery('site_id' => site['id']).record['elb_name']\") AZS=($(ah-server list site:${site} -w type=bal -c ec2_availability_zone --no-name | paste -sd' ')) aws elb enable-availability-zones-for-load-balancer \\ --region $REGION \\ --load-balancer-name $ELB \\ --availability-zones $AZS done","title":"Assigning Balancers"},{"location":"kanban_tickets/dedicated_bals/shared_to_dedicated/#post-assignment","text":"Communicate to Support that the customer must now change DNS to the EIP of the new balancer pair. for site in ${SITES[@]}; do ah-server list site:${site} -w type=bal eip_id!=nil -c external_ip done | sort | uniq Mark ticket \"Waiting For Feedback\" Once Support or the customer confirms that DNS has been changed, remove the old balancers from the site record after checking the domains are pointing to the EIP of the new balancers. for site in ${SITES[@]}; do site-domainshost ${site} done OLD_BALS= for site in ${SITES[@]}; do ah-site bal remove ${site} --bals ${OLD_BALS} done","title":"Post-Assignment"},{"location":"kanban_tickets/dedicated_bals/shared_to_shared/","text":"Shared to Shared Pre-work Customers looking to move to shared balancers require special care as they may have custom VCLs or specific SSL certificates deployed to their dedicated balancers. Check SSL requirements If SSL termination is required on the new shared bal and the customer does not have SNI set, then you should identify a shared balancer which is using the same certificate as their current balancers (instructions below). If no such shared balancer exists, then you need to add the customer's domains to the UCC cert on the destination balancer by following the SSL UCCs runbook. A dealsheet must always be provided for adding domains to a UCC. If the shared balancer is not already tagged to use a UCC cert, then you will need to find an appropriate UCC cert with a sufficient number of slots available to add to the balancer. If the customer has SNI set up but is missing domains, verify its validity with the ticket requester or account manager. Note: Make sure to verify if the existing hardware is in vpc or not before adding/assigning the new bals and proceed accordingly. Assigning Balancers Set some variables. SITE= REGION= OLD_BALS=($(ah-server list site:${SITE} -w type=bal | paste -sd' ')) SSL_TAG=$(ah-server tag list ${OLD_BALS[@]} | grep 'ssl_' | awk {'print $2'} | uniq) If this site is behind an ELB, you must ensure that the new balancers are in an AZ associated to that ELB. site-elbdescribe ${SITE} Find a shared balancer cluster using the same SSL tag. ah-server list tag:${SSL_TAG} -w status=0 ec2_region=${REGION} -c tags | grep shared Assign the balancers to the site. ah-site bal add ${SITE} --bals ${NEW_BALS} Identify all of the sites that will be moved to the new balancers. Modify SITES as needed and add the bals to them. SITEGROUP= NEW_BALS= SITES=($(ah-site list % -w sitegroup=${SITEGROUP} stage!=ra | paste -sd' ')) for site in ${SITES[@]}; do ah-site bal add ${site} --bals ${NEW_BALS}; done If any of the new balancers are not in an AZ configured for the ELB, you must configure the ELB to use the new AZs. for site in ${SITES[@]}; do ELB=$(ruby -e \"require 'aq'; site = Aq::Hosting::Site.from_query(name: '${site}'); puts \\ Aq::Hosting::SiteElb.fromQuery('site_id' => site['id']).record['elb_name']\") AZS=($(ah-server list site:${site} -w type=bal -c ec2_availability_zone --no-name | paste -sd' ')) aws elb enable-availability-zones-for-load-balancer \\ --region $REGION \\ --load-balancer-name $ELB \\ --availability-zones $AZS done Post-Assignment Communicate to Support that the customer must now change DNS to the EIP of the new balancer pair. ah-server list site:${SITE} -w type=bal eip_id!=nil -c external_ip Mark ticket \"Waiting For Feedback\" Once Support or the customer confirms that DNS has been changed, remove the old balancers from the site record after checking the domains are pointing to the EIP of the new balancers. for site in ${SITES[@]}; do site-domainshost ${site} done ah-site bal remove ${SITE} --bals ${OLD_BALS}","title":"Shared to Shared"},{"location":"kanban_tickets/dedicated_bals/shared_to_shared/#shared-to-shared","text":"","title":"Shared to Shared"},{"location":"kanban_tickets/dedicated_bals/shared_to_shared/#pre-work","text":"Customers looking to move to shared balancers require special care as they may have custom VCLs or specific SSL certificates deployed to their dedicated balancers. Check SSL requirements If SSL termination is required on the new shared bal and the customer does not have SNI set, then you should identify a shared balancer which is using the same certificate as their current balancers (instructions below). If no such shared balancer exists, then you need to add the customer's domains to the UCC cert on the destination balancer by following the SSL UCCs runbook. A dealsheet must always be provided for adding domains to a UCC. If the shared balancer is not already tagged to use a UCC cert, then you will need to find an appropriate UCC cert with a sufficient number of slots available to add to the balancer. If the customer has SNI set up but is missing domains, verify its validity with the ticket requester or account manager. Note: Make sure to verify if the existing hardware is in vpc or not before adding/assigning the new bals and proceed accordingly.","title":"Pre-work"},{"location":"kanban_tickets/dedicated_bals/shared_to_shared/#assigning-balancers","text":"Set some variables. SITE= REGION= OLD_BALS=($(ah-server list site:${SITE} -w type=bal | paste -sd' ')) SSL_TAG=$(ah-server tag list ${OLD_BALS[@]} | grep 'ssl_' | awk {'print $2'} | uniq) If this site is behind an ELB, you must ensure that the new balancers are in an AZ associated to that ELB. site-elbdescribe ${SITE} Find a shared balancer cluster using the same SSL tag. ah-server list tag:${SSL_TAG} -w status=0 ec2_region=${REGION} -c tags | grep shared Assign the balancers to the site. ah-site bal add ${SITE} --bals ${NEW_BALS} Identify all of the sites that will be moved to the new balancers. Modify SITES as needed and add the bals to them. SITEGROUP= NEW_BALS= SITES=($(ah-site list % -w sitegroup=${SITEGROUP} stage!=ra | paste -sd' ')) for site in ${SITES[@]}; do ah-site bal add ${site} --bals ${NEW_BALS}; done If any of the new balancers are not in an AZ configured for the ELB, you must configure the ELB to use the new AZs. for site in ${SITES[@]}; do ELB=$(ruby -e \"require 'aq'; site = Aq::Hosting::Site.from_query(name: '${site}'); puts \\ Aq::Hosting::SiteElb.fromQuery('site_id' => site['id']).record['elb_name']\") AZS=($(ah-server list site:${site} -w type=bal -c ec2_availability_zone --no-name | paste -sd' ')) aws elb enable-availability-zones-for-load-balancer \\ --region $REGION \\ --load-balancer-name $ELB \\ --availability-zones $AZS done","title":"Assigning Balancers"},{"location":"kanban_tickets/dedicated_bals/shared_to_shared/#post-assignment","text":"Communicate to Support that the customer must now change DNS to the EIP of the new balancer pair. ah-server list site:${SITE} -w type=bal eip_id!=nil -c external_ip Mark ticket \"Waiting For Feedback\" Once Support or the customer confirms that DNS has been changed, remove the old balancers from the site record after checking the domains are pointing to the EIP of the new balancers. for site in ${SITES[@]}; do site-domainshost ${site} done ah-site bal remove ${SITE} --bals ${OLD_BALS}","title":"Post-Assignment"},{"location":"kanban_tickets/test_vcl/automated/","text":"Test VCL Deployment - Automated NOTE: Be sure to provide the IP address of the test bal from the output of the below commands. Review the VCL PR Please make sure that the PR given in the OP ticket has passed all the tests or is approved by the Cloud team or support leadership before provisioning a test balancer for the customer. CREATE a VCL test bal from an initial request SITEGROUP= STAGES_CSV= JIRA_TICKET= GITHUB_USER= BRANCH= VCL_PATH= VARNISH_VERSION= ahops-vcltestbal -a create \\ -s $SITEGROUP \\ -e $STAGES_CSV \\ -t $JIRA_TICKET \\ -g $GITHUB_USER \\ -b $BRANCH \\ -v $VCL_PATH \\ -V $VARNISH_VERSION After creating a new test balancer, make sure the test balancer is not in ELB rotation for each site, since this can cause a site outage: TESTBAL= for site in $(ah-site list on:${TESTBAL}); do site-elbdescribe ${site} done If it is in rotation, manually remove it with: ELB= TESTBAL_INSTANCE=$(ah-server list ${TESTBAL} -c ec2_id --no-name) aws elb deregister-instances-from-load-balancer --region ${REGION} \\ --load-balancer-name ${ELB} --instances ${TESTBAL_INSTANCE} UPDATE a test VCL on an existing VCL test balancer Set the varnish_vcl:preserve_custom_vcl_on_bal on the server in question. This will prevent fields-config-bal from overwriting the cVcl when it is run. ah-server edit $TESTBAL -c varnish_vcl:preserve_custom_vcl_on_bal='true' SITEGROUP= STAGES_CSV= JIRA_TICKET= GITHUB_USER= BRANCH= VCL_PATH= VARNISH_VERSION= ahops-vcltestbal -a update \\ -s $SITEGROUP \\ -e $STAGES_CSV \\ -t $JIRA_TICKET \\ -g $GITHUB_USER \\ -b $BRANCH \\ -v $VCL_PATH \\ -V $VARNISH_VERSION DESTROY a test VCL balancer Remove the varnish_vcl:preserve_custom_vcl_on_bal on the server in question ah-server edit $TESTBAL -c varnish_vcl:preserve_custom_vcl_on_bal='false' Then destroy the balancer SITEGROUP= ahops-vcltestbal -a destroy \\ -s $SITEGROUP","title":"Test VCL Deployment - Automated"},{"location":"kanban_tickets/test_vcl/automated/#test-vcl-deployment-automated","text":"NOTE: Be sure to provide the IP address of the test bal from the output of the below commands.","title":"Test VCL Deployment - Automated"},{"location":"kanban_tickets/test_vcl/automated/#review-the-vcl-pr","text":"Please make sure that the PR given in the OP ticket has passed all the tests or is approved by the Cloud team or support leadership before provisioning a test balancer for the customer.","title":"Review the VCL PR"},{"location":"kanban_tickets/test_vcl/automated/#create-a-vcl-test-bal-from-an-initial-request","text":"SITEGROUP= STAGES_CSV= JIRA_TICKET= GITHUB_USER= BRANCH= VCL_PATH= VARNISH_VERSION= ahops-vcltestbal -a create \\ -s $SITEGROUP \\ -e $STAGES_CSV \\ -t $JIRA_TICKET \\ -g $GITHUB_USER \\ -b $BRANCH \\ -v $VCL_PATH \\ -V $VARNISH_VERSION After creating a new test balancer, make sure the test balancer is not in ELB rotation for each site, since this can cause a site outage: TESTBAL= for site in $(ah-site list on:${TESTBAL}); do site-elbdescribe ${site} done If it is in rotation, manually remove it with: ELB= TESTBAL_INSTANCE=$(ah-server list ${TESTBAL} -c ec2_id --no-name) aws elb deregister-instances-from-load-balancer --region ${REGION} \\ --load-balancer-name ${ELB} --instances ${TESTBAL_INSTANCE}","title":"CREATE a VCL test bal from an initial request"},{"location":"kanban_tickets/test_vcl/automated/#update-a-test-vcl-on-an-existing-vcl-test-balancer","text":"Set the varnish_vcl:preserve_custom_vcl_on_bal on the server in question. This will prevent fields-config-bal from overwriting the cVcl when it is run. ah-server edit $TESTBAL -c varnish_vcl:preserve_custom_vcl_on_bal='true' SITEGROUP= STAGES_CSV= JIRA_TICKET= GITHUB_USER= BRANCH= VCL_PATH= VARNISH_VERSION= ahops-vcltestbal -a update \\ -s $SITEGROUP \\ -e $STAGES_CSV \\ -t $JIRA_TICKET \\ -g $GITHUB_USER \\ -b $BRANCH \\ -v $VCL_PATH \\ -V $VARNISH_VERSION","title":"UPDATE a test VCL on an existing VCL test balancer"},{"location":"kanban_tickets/test_vcl/automated/#destroy-a-test-vcl-balancer","text":"Remove the varnish_vcl:preserve_custom_vcl_on_bal on the server in question ah-server edit $TESTBAL -c varnish_vcl:preserve_custom_vcl_on_bal='false' Then destroy the balancer SITEGROUP= ahops-vcltestbal -a destroy \\ -s $SITEGROUP","title":"DESTROY a test VCL balancer"},{"location":"kanban_tickets/test_vcl/manual/","text":"Test VCL Deployment - MANUAL Review the VCL PR Please make sure that the PR given in the OP ticket has passed all the tests or is approved by the Cloud team or support leadership before provisioning a test balancer for the customer. Set Up Some Variables SITEGROUP= JIRA= SITES=$(ah-site list % -w sitegroup=${SITEGROUP} ra=0 status=2001 | paste -sd' ') SITES_CSV=$(echo ${SITES[@]} | tr ' ' ',') PROD_SITE=$(ah-site list tag:prod -w sitegroup=${SITEGROUP}) PROD_BALS=$(ah-server list site:${PROD_SITE} -w type=bal status=0 | paste -sd,) AZ=($(ah-server list site:${PROD_SITE} --no-name -w type=bal -c ec2_availability_zone)) REGION=${AZ[0]%?} PROD_BAL_TAGS=($(ah-server list ${PROD_BALS} -c tags --no-name | sed 's/+/ /g')) SHARED_VALUE=$(if contains shared ${PROD_BAL_TAGS[@]}; then echo \"True\"; else echo \"False\"; fi) FIRST_BAL=$(ah-server list site:${PROD_SITE} -w type=bal status=0 | head -n1) Provision a Test Balancer Find an available VCL test balancer in status 1 with 0 sites on it. Find an available VCL test balancer in the same AZ as the customer's existing VPC balancers ah-server list tag:vcltestbal \\ -w type=bal status=1 ec2_region=${REGION} ec2_availability_zoneIN$(array-csv ${AZ[@]}) \\ -c site-count ami_type TESTBAL= Change the ami_type to t2.small if the existing ami_type is different ah-server edit $TESTBAL -s ami_type=t2.small If there are no available VCL test balancers in the region, provision one. Allocate VCL testbal TESTBAL=$(ah-provision stack bal -c 1 -i t2.small -r ${REGION} -z ${AZ}) EIP_ID=$(ah-server list ${TESTBAL} --no-name -c eip_id) EIP=$(ruby -e \"require 'aq'; puts Aq::Hosting::ElasticIp.from_id(${EIP_ID})['ip']\") VPC_ID=$(ah-server list site:${PROD_SITE} --no-name -w type=bal -c vpc_id | head -n1) ah-server edit ${TESTBAL} -s vpc_id=${VPC_ID} Then add tags and remove any EIP that the balancer may have come with ah-server tag add ${TESTBAL} --tags vcltestbal ah-server edit ${TESTBAL} -c puppet:skip_vcl_deployment=on ah-elastic-ip remove ${EIP} ${TESTBAL} ah-elastic-ip release ${EIP} Remove any lingering ssl tags. for TAG in $(ah-server list ${TESTBAL} -c tags --no-name | tr '+' ' '); do [[ ${TAG} == ssl_* ]] && ah-server tag remove ${TESTBAL} -t ${TAG} done Check if the production balancers have GeoIP enabled. ah-server list site:${PROD_SITE} -w type=bal -c puppet:varnish_geoip \\ puppet:varnish_geoip_licensekey puppet:varnish_geoip_user If they do, enable GeoIP on the test balancer. GEOIP_USER= GEOIP_KEY= ah-server edit ${TESTBAL} -c puppet:varnish_geoip=enabled \\ puppet:varnish_geoip_user=${GEOIP_USER} puppet:varnish_geoip_licensekey=${GEOIP_KEY} If applicable, this would be a good time to set any other special configurations for the server, such varnish version. Verify that the varnish version on VCL test bal is set to 5. ah-server edit $TESTBAL -c puppet:varnish_major_version=5 Launch the test balancer sv-taskrelaunch server ${TESTBAL} Set up the Test Balancer Add sites to the test balancer. if [ \"${SHARED_VALUE}\" = \"True\" ]; then ALL_SITES=${SITES_CSV} ah-site bal add ${ALL_SITES} --bals ${TESTBAL}; elif [ \"${SHARED_VALUE}\" = \"False\" ]; then ALL_SITES=$(ah-site list on:${FIRST_BAL} -w status=2001 | paste -sd,); ah-site bal add ${ALL_SITES} --bals ${TESTBAL}; else echo \"ERROR: Tags are not valid.\" fi Check if any of the sites have ELBs. SITES=$(echo ${ALL_SITES} | tr ',' ' ') for SITE in ${SITES}; do echo ${SITE} dig +short ${SITE}.${FIELDS_STAGE}.acquia-sites.com done Remove the test balancer from each ELB. With AWS CLI. ELB is the ELB name, such as \"mc-1234\". ELB= TESTBAL_INSTANCE=$(ah-server list ${TESTBAL} -c ec2_id --no-name) aws elb deregister-instances-from-load-balancer --region ${REGION} \\ --load-balancer-name ${ELB} --instances ${TESTBAL_INSTANCE} With fields (1.86+) ( Broken. ) SITE= ah-site elb-remove-server-oob ${SITE} ${TESTBAL} Add a runbook entry on the test bal. fssh ${TESTBAL} sudo ah-runbook \"${JIRA} - ${USER} - VCL test\" Deploy the Test VCL to the Test Balancer Set the varnish_vcl:preserve_custom_vcl_on_bal on the server in question. This will prevent fields-config-bal from overwriting the cVcl when it is run. ah-server edit $TESTBAL -c varnish_vcl:preserve_custom_vcl_on_bal='true' Choose a method: Download it directly into place on the test balancer from GitHub . In the pull request, open the \"files changed\" tag, \"view\" the file, then switch to the \"raw\" view. Copy the URL. Download it to the balancer. Remove the \"token\" part of the URL when pasting commands and output into the ticket. URL= cd /etc/varnish/ wget -O default-real.vcl --no-check-certificate ${URL} scp from your computer to a bastion, then fscp from the bastion to your home directory on the test balancer, then move it into place as '/etc/varnish/default-real.vcl'. Check that the VCL compiles. Proper compilation will return only '0'. Note : 'default.vcl' is compiled, not 'default-real.vcl', but 'default.vcl' includes 'default-real.vcl'. 'default-real.vcl' will not compile by itself. VARNISH_VERSION=$((varnishd -V) 2>&1 | awk {'print $2'} | sed 's/[\\(\\)]//g' | cut -d'c' -f1) if [[ \"$VARNISH_VERSION\" == \"varnish-3.0.7\" ]] && \\ [[ -e \"/etc/varnish/varnish-addon-geoip.vcl\" ]]; then varnishd -C -f /etc/varnish/default.vcl \\ -p cc_command=\"/usr/bin/compile.sh %s %o\" &> /dev/null; echo $? else varnishd -C -f /etc/varnish/default.vcl &> /dev/null; echo $? fi Reload Varnish. service varnish reload Copy custom TLS cert and private key from the production bal if present. for TAG in $(ah-server list site:${PROD_SITE} -w type=bal status=0 -c tags --no-name | tr '+' ' '); do [[ ${TAG} == ssl_* ]] && SSL=${TAG} && break done if [[ ${SSL-} ]]; then mkdir ${OPSTMP}/${JIRA} fssh ${FIRST_BAL} \"sudo -s bash -c 'cp /etc/ssl/private/acquia-sites_com.key . && chown ${USER} \\ acquia-sites_com.key'\" fscp ${FIRST_BAL}:~/acquia-sites_com.key ${OPSTMP}/${JIRA}/key fssh ${FIRST_BAL} \"sudo -s bash -c 'cp /etc/ssl/certs/acquia-sites_com.pem . && chown ${USER} \\ acquia-sites_com.pem'\" fscp ${FIRST_BAL}:~/acquia-sites_com.pem ${OPSTMP}/${JIRA}/cert ah-server tag add ${TESTBAL} -t ${SSL} ahops-ssltool push bal ${SSL} ${OPSTMP}/${JIRA}/cert ${OPSTMP}/${JIRA}/key fssh ${FIRST_BAL} \"sudo rm -rf *.key\" rm -vf ${OPSTMP}/${JIRA}/cert ${OPSTMP}/${JIRA}/key fi Provide the IP address of the test balancer to the ticket requester and mark the ticket as waiting for the customer.","title":"Test VCL Deployment - MANUAL"},{"location":"kanban_tickets/test_vcl/manual/#test-vcl-deployment-manual","text":"","title":"Test VCL Deployment - MANUAL"},{"location":"kanban_tickets/test_vcl/manual/#review-the-vcl-pr","text":"Please make sure that the PR given in the OP ticket has passed all the tests or is approved by the Cloud team or support leadership before provisioning a test balancer for the customer.","title":"Review the VCL PR"},{"location":"kanban_tickets/test_vcl/manual/#set-up-some-variables","text":"SITEGROUP= JIRA= SITES=$(ah-site list % -w sitegroup=${SITEGROUP} ra=0 status=2001 | paste -sd' ') SITES_CSV=$(echo ${SITES[@]} | tr ' ' ',') PROD_SITE=$(ah-site list tag:prod -w sitegroup=${SITEGROUP}) PROD_BALS=$(ah-server list site:${PROD_SITE} -w type=bal status=0 | paste -sd,) AZ=($(ah-server list site:${PROD_SITE} --no-name -w type=bal -c ec2_availability_zone)) REGION=${AZ[0]%?} PROD_BAL_TAGS=($(ah-server list ${PROD_BALS} -c tags --no-name | sed 's/+/ /g')) SHARED_VALUE=$(if contains shared ${PROD_BAL_TAGS[@]}; then echo \"True\"; else echo \"False\"; fi) FIRST_BAL=$(ah-server list site:${PROD_SITE} -w type=bal status=0 | head -n1)","title":"Set Up Some Variables"},{"location":"kanban_tickets/test_vcl/manual/#provision-a-test-balancer","text":"Find an available VCL test balancer in status 1 with 0 sites on it. Find an available VCL test balancer in the same AZ as the customer's existing VPC balancers ah-server list tag:vcltestbal \\ -w type=bal status=1 ec2_region=${REGION} ec2_availability_zoneIN$(array-csv ${AZ[@]}) \\ -c site-count ami_type TESTBAL= Change the ami_type to t2.small if the existing ami_type is different ah-server edit $TESTBAL -s ami_type=t2.small If there are no available VCL test balancers in the region, provision one. Allocate VCL testbal TESTBAL=$(ah-provision stack bal -c 1 -i t2.small -r ${REGION} -z ${AZ}) EIP_ID=$(ah-server list ${TESTBAL} --no-name -c eip_id) EIP=$(ruby -e \"require 'aq'; puts Aq::Hosting::ElasticIp.from_id(${EIP_ID})['ip']\") VPC_ID=$(ah-server list site:${PROD_SITE} --no-name -w type=bal -c vpc_id | head -n1) ah-server edit ${TESTBAL} -s vpc_id=${VPC_ID} Then add tags and remove any EIP that the balancer may have come with ah-server tag add ${TESTBAL} --tags vcltestbal ah-server edit ${TESTBAL} -c puppet:skip_vcl_deployment=on ah-elastic-ip remove ${EIP} ${TESTBAL} ah-elastic-ip release ${EIP} Remove any lingering ssl tags. for TAG in $(ah-server list ${TESTBAL} -c tags --no-name | tr '+' ' '); do [[ ${TAG} == ssl_* ]] && ah-server tag remove ${TESTBAL} -t ${TAG} done Check if the production balancers have GeoIP enabled. ah-server list site:${PROD_SITE} -w type=bal -c puppet:varnish_geoip \\ puppet:varnish_geoip_licensekey puppet:varnish_geoip_user If they do, enable GeoIP on the test balancer. GEOIP_USER= GEOIP_KEY= ah-server edit ${TESTBAL} -c puppet:varnish_geoip=enabled \\ puppet:varnish_geoip_user=${GEOIP_USER} puppet:varnish_geoip_licensekey=${GEOIP_KEY} If applicable, this would be a good time to set any other special configurations for the server, such varnish version. Verify that the varnish version on VCL test bal is set to 5. ah-server edit $TESTBAL -c puppet:varnish_major_version=5 Launch the test balancer sv-taskrelaunch server ${TESTBAL}","title":"Provision a Test Balancer"},{"location":"kanban_tickets/test_vcl/manual/#set-up-the-test-balancer","text":"Add sites to the test balancer. if [ \"${SHARED_VALUE}\" = \"True\" ]; then ALL_SITES=${SITES_CSV} ah-site bal add ${ALL_SITES} --bals ${TESTBAL}; elif [ \"${SHARED_VALUE}\" = \"False\" ]; then ALL_SITES=$(ah-site list on:${FIRST_BAL} -w status=2001 | paste -sd,); ah-site bal add ${ALL_SITES} --bals ${TESTBAL}; else echo \"ERROR: Tags are not valid.\" fi Check if any of the sites have ELBs. SITES=$(echo ${ALL_SITES} | tr ',' ' ') for SITE in ${SITES}; do echo ${SITE} dig +short ${SITE}.${FIELDS_STAGE}.acquia-sites.com done Remove the test balancer from each ELB. With AWS CLI. ELB is the ELB name, such as \"mc-1234\". ELB= TESTBAL_INSTANCE=$(ah-server list ${TESTBAL} -c ec2_id --no-name) aws elb deregister-instances-from-load-balancer --region ${REGION} \\ --load-balancer-name ${ELB} --instances ${TESTBAL_INSTANCE} With fields (1.86+) ( Broken. ) SITE= ah-site elb-remove-server-oob ${SITE} ${TESTBAL} Add a runbook entry on the test bal. fssh ${TESTBAL} sudo ah-runbook \"${JIRA} - ${USER} - VCL test\"","title":"Set up the Test Balancer"},{"location":"kanban_tickets/test_vcl/manual/#deploy-the-test-vcl-to-the-test-balancer","text":"Set the varnish_vcl:preserve_custom_vcl_on_bal on the server in question. This will prevent fields-config-bal from overwriting the cVcl when it is run. ah-server edit $TESTBAL -c varnish_vcl:preserve_custom_vcl_on_bal='true' Choose a method: Download it directly into place on the test balancer from GitHub . In the pull request, open the \"files changed\" tag, \"view\" the file, then switch to the \"raw\" view. Copy the URL. Download it to the balancer. Remove the \"token\" part of the URL when pasting commands and output into the ticket. URL= cd /etc/varnish/ wget -O default-real.vcl --no-check-certificate ${URL} scp from your computer to a bastion, then fscp from the bastion to your home directory on the test balancer, then move it into place as '/etc/varnish/default-real.vcl'. Check that the VCL compiles. Proper compilation will return only '0'. Note : 'default.vcl' is compiled, not 'default-real.vcl', but 'default.vcl' includes 'default-real.vcl'. 'default-real.vcl' will not compile by itself. VARNISH_VERSION=$((varnishd -V) 2>&1 | awk {'print $2'} | sed 's/[\\(\\)]//g' | cut -d'c' -f1) if [[ \"$VARNISH_VERSION\" == \"varnish-3.0.7\" ]] && \\ [[ -e \"/etc/varnish/varnish-addon-geoip.vcl\" ]]; then varnishd -C -f /etc/varnish/default.vcl \\ -p cc_command=\"/usr/bin/compile.sh %s %o\" &> /dev/null; echo $? else varnishd -C -f /etc/varnish/default.vcl &> /dev/null; echo $? fi Reload Varnish. service varnish reload Copy custom TLS cert and private key from the production bal if present. for TAG in $(ah-server list site:${PROD_SITE} -w type=bal status=0 -c tags --no-name | tr '+' ' '); do [[ ${TAG} == ssl_* ]] && SSL=${TAG} && break done if [[ ${SSL-} ]]; then mkdir ${OPSTMP}/${JIRA} fssh ${FIRST_BAL} \"sudo -s bash -c 'cp /etc/ssl/private/acquia-sites_com.key . && chown ${USER} \\ acquia-sites_com.key'\" fscp ${FIRST_BAL}:~/acquia-sites_com.key ${OPSTMP}/${JIRA}/key fssh ${FIRST_BAL} \"sudo -s bash -c 'cp /etc/ssl/certs/acquia-sites_com.pem . && chown ${USER} \\ acquia-sites_com.pem'\" fscp ${FIRST_BAL}:~/acquia-sites_com.pem ${OPSTMP}/${JIRA}/cert ah-server tag add ${TESTBAL} -t ${SSL} ahops-ssltool push bal ${SSL} ${OPSTMP}/${JIRA}/cert ${OPSTMP}/${JIRA}/key fssh ${FIRST_BAL} \"sudo rm -rf *.key\" rm -vf ${OPSTMP}/${JIRA}/cert ${OPSTMP}/${JIRA}/key fi Provide the IP address of the test balancer to the ticket requester and mark the ticket as waiting for the customer.","title":"Deploy the Test VCL to the Test Balancer"},{"location":"ops_infrastructure/","text":"Ops Infrastructure Alerts relay server ( alerts.ops.acquia.com ) Alerts relay server ( alerts.ops.acquia.com ) Overview of Services Relaunching Preparation Relaunch Oneoffs General Information About One-Off Servers Access Relaunching One-Offs Preparation Relaunch OPS-Gordon OPS-Gordon Deployment Building ops-gordon Test the Deploy OPS-Gordon Issues OPS-Gordon Production Troubleshooting Alert-Function Timed Out Alert-Function Error Rate Perfmon perf-mon.ops.acquia.com Overview of Services Relaunching Preparation Relaunch","title":"Ops Infrastructure"},{"location":"ops_infrastructure/#ops-infrastructure","text":"","title":"Ops Infrastructure"},{"location":"ops_infrastructure/#alerts-relay-server-alertsopsacquiacom","text":"Alerts relay server ( alerts.ops.acquia.com ) Overview of Services Relaunching Preparation Relaunch","title":"Alerts relay server (alerts.ops.acquia.com)"},{"location":"ops_infrastructure/#oneoffs","text":"General Information About One-Off Servers Access Relaunching One-Offs Preparation Relaunch","title":"Oneoffs"},{"location":"ops_infrastructure/#ops-gordon","text":"OPS-Gordon Deployment Building ops-gordon Test the Deploy","title":"OPS-Gordon"},{"location":"ops_infrastructure/#ops-gordon-issues","text":"OPS-Gordon Production Troubleshooting Alert-Function Timed Out Alert-Function Error Rate","title":"OPS-Gordon Issues"},{"location":"ops_infrastructure/#perfmon","text":"perf-mon.ops.acquia.com Overview of Services Relaunching Preparation Relaunch","title":"Perfmon"},{"location":"ops_infrastructure/alerts/","text":"alerts.ops.acquia.com Overview of Services alerts.ops.acquia.com is a SPOF one-off server which collects Nagios alerts from ops-mon-2 and mon servers in all realms. It filters out unactionable alerts with procmail and uses postfix to forward the rest to PagerDuty which creates the incidents you know and love. Additional information can be found in Confluence . This server is managed by the production branch of ops-puppet . Additionally, this is an EBS-backed instance (not instance-backed like everything we run in Fields), so services on it should be able to start automatically after a relaunch. This confluence page has a useful overview of the 'Ops-Mon-2 Stack'. Relaunching The procedure in this runbook contains steps that are specific to alerts.ops.acquia.com , and should be followed in parallel with the general one-off relaunching runbook . Preparation Before starting, do the general one-off preparation . This signalfx detector monitors postfix message latency. It's not perfect, but it should give you a sense of the instance's current status. While the alerts server is down, new alerts cannot be sent to PagerDuty. Notify hotseat and coordinate a good time to begin the relaunch; they will need to keep a close eye on Nagstamon, ops-mon-2, and SignalFX to identify potential problems in the realms while alerts.ops.acquia.com is down. Make sure that /etc/puppet/puppet.conf is using the production branch of ops-puppet. Relaunch Follow the general one-off relaunch steps . One the instance has relaunched sucessfully, log into the server and verify that postfix is running by watching /var/log/mail.log : ssh alerts.ops.acquia.com 'sudo tail -f /var/log/mail.log' Also, verify that puppet is running correctly. In some cases, particularly for reboots, puppet may break if /var/run/procmail_nosetuid.lock doesn't exist. You may need to manually touch the file to fix this until we fix ops-puppet . If a PagerDuty incident was created for alerts.ops.acquia.com it should auto-resolve when services are back up on the instance. If it doesn't auto-resolve, verify that new PagerDuty incidents are being created properly before resolving it. If anything goes wrong, escalate to a senior Ops engineer.","title":"alerts.ops.acquia.com"},{"location":"ops_infrastructure/alerts/#alertsopsacquiacom","text":"","title":"alerts.ops.acquia.com"},{"location":"ops_infrastructure/alerts/#overview-of-services","text":"alerts.ops.acquia.com is a SPOF one-off server which collects Nagios alerts from ops-mon-2 and mon servers in all realms. It filters out unactionable alerts with procmail and uses postfix to forward the rest to PagerDuty which creates the incidents you know and love. Additional information can be found in Confluence . This server is managed by the production branch of ops-puppet . Additionally, this is an EBS-backed instance (not instance-backed like everything we run in Fields), so services on it should be able to start automatically after a relaunch. This confluence page has a useful overview of the 'Ops-Mon-2 Stack'.","title":"Overview of Services"},{"location":"ops_infrastructure/alerts/#relaunching","text":"The procedure in this runbook contains steps that are specific to alerts.ops.acquia.com , and should be followed in parallel with the general one-off relaunching runbook .","title":"Relaunching"},{"location":"ops_infrastructure/alerts/#preparation","text":"Before starting, do the general one-off preparation . This signalfx detector monitors postfix message latency. It's not perfect, but it should give you a sense of the instance's current status. While the alerts server is down, new alerts cannot be sent to PagerDuty. Notify hotseat and coordinate a good time to begin the relaunch; they will need to keep a close eye on Nagstamon, ops-mon-2, and SignalFX to identify potential problems in the realms while alerts.ops.acquia.com is down. Make sure that /etc/puppet/puppet.conf is using the production branch of ops-puppet.","title":"Preparation"},{"location":"ops_infrastructure/alerts/#relaunch","text":"Follow the general one-off relaunch steps . One the instance has relaunched sucessfully, log into the server and verify that postfix is running by watching /var/log/mail.log : ssh alerts.ops.acquia.com 'sudo tail -f /var/log/mail.log' Also, verify that puppet is running correctly. In some cases, particularly for reboots, puppet may break if /var/run/procmail_nosetuid.lock doesn't exist. You may need to manually touch the file to fix this until we fix ops-puppet . If a PagerDuty incident was created for alerts.ops.acquia.com it should auto-resolve when services are back up on the instance. If it doesn't auto-resolve, verify that new PagerDuty incidents are being created properly before resolving it. If anything goes wrong, escalate to a senior Ops engineer.","title":"Relaunch"},{"location":"ops_infrastructure/compiling_ah_check_http/","text":"Compiling nagios plugin check_http for mon2 To compile the nagios plugin on servers other than mon2 - you may need certain development packages installed - like gcc, libssl etc. If something is not found - the configure option will return some errors complaining about missing those packages. Download the latest nagios-plugins from here URL= wget $URL tar -xf nagios-plugins-x.y.z.tar.gz Run ./configure to compile the plugins. export CFLAGS=\" -Os \" ./configure --prefix==/usr/local/ Edit the file check_http.c in plugins directory and change the result option in block else if (http_status >= 400) from WARNING to critical. result = max_state_alt(STATE_CRITICAL, result); If any other change needs to be introduced in the plugin, edit the same file check_http.c before proceeding further. Run make and make install to complete the compilation: make && make install This should compile the plugin and will create the binary files under $PREFIX/libexec. Now to bundle it with ops-mon-2 repo - just rename check_http to ah_check_http and move it over to the ops-mon-2 branch from where you want to raise a PR.","title":"Compiling nagios plugin check_http for mon2"},{"location":"ops_infrastructure/compiling_ah_check_http/#compiling-nagios-plugin-check_http-for-mon2","text":"To compile the nagios plugin on servers other than mon2 - you may need certain development packages installed - like gcc, libssl etc. If something is not found - the configure option will return some errors complaining about missing those packages. Download the latest nagios-plugins from here URL= wget $URL tar -xf nagios-plugins-x.y.z.tar.gz Run ./configure to compile the plugins. export CFLAGS=\" -Os \" ./configure --prefix==/usr/local/ Edit the file check_http.c in plugins directory and change the result option in block else if (http_status >= 400) from WARNING to critical. result = max_state_alt(STATE_CRITICAL, result); If any other change needs to be introduced in the plugin, edit the same file check_http.c before proceeding further. Run make and make install to complete the compilation: make && make install This should compile the plugin and will create the binary files under $PREFIX/libexec. Now to bundle it with ops-mon-2 repo - just rename check_http to ah_check_http and move it over to the ops-mon-2 branch from where you want to raise a PR.","title":"Compiling nagios plugin check_http for mon2"},{"location":"ops_infrastructure/gordon_deploy/","text":"OPS-Gordon Deployment This runbook assumes that you have your virtualenv confirgured for the build and deploy process. If that is not the case please refer to OPS-Gordon Development Setup Building ops-gordon The build process is fairly straight forward: Activate our virtualenv and move into the repo: PATH_TO_VENV= PATH_TO_GORDON_REPO source $PATH_TO_VENV/bin/activate cd $PATH_TO_GORDON_REPO Run the gordon build tool: gordon build There should be no output if the command was successful. If there are any errors in the build output you should not attempt to deploy, you will need to investigate the errors and fix them before you can move on. ONLY once you have a succesfull build should you deploy to production. Deploy to production using gordon apply gordon apply There should be no output if the command was successful. If there were any errors you will need to track down why, a great place to start is the AWS accounts cloudformation service from the AWS console. While the logs are sparse it will often help you track down where the deploy failed. Test the Deploy Once you have deployed to AWS lambda you should always test that the function can run. You can test directly from the command line as well. OPS-Gordon will display the lambdas ARN once it has succesfully been deployed, you can use this to manually run the function and check for any errors. $ aws lambda invoke \\ --function-name $ARN \\ --log-type Tail \\ --payload '{\"key1\":\"value1\", \"key2\":\"value2\", \"key3\":\"value3\"}' \\ output.txt \\ | jq -r .LogResult | base64 --decode","title":"OPS-Gordon Deployment"},{"location":"ops_infrastructure/gordon_deploy/#ops-gordon-deployment","text":"This runbook assumes that you have your virtualenv confirgured for the build and deploy process. If that is not the case please refer to OPS-Gordon Development Setup","title":"OPS-Gordon Deployment"},{"location":"ops_infrastructure/gordon_deploy/#building-ops-gordon","text":"The build process is fairly straight forward: Activate our virtualenv and move into the repo: PATH_TO_VENV= PATH_TO_GORDON_REPO source $PATH_TO_VENV/bin/activate cd $PATH_TO_GORDON_REPO Run the gordon build tool: gordon build There should be no output if the command was successful. If there are any errors in the build output you should not attempt to deploy, you will need to investigate the errors and fix them before you can move on. ONLY once you have a succesfull build should you deploy to production. Deploy to production using gordon apply gordon apply There should be no output if the command was successful. If there were any errors you will need to track down why, a great place to start is the AWS accounts cloudformation service from the AWS console. While the logs are sparse it will often help you track down where the deploy failed.","title":"Building ops-gordon"},{"location":"ops_infrastructure/gordon_deploy/#test-the-deploy","text":"Once you have deployed to AWS lambda you should always test that the function can run. You can test directly from the command line as well. OPS-Gordon will display the lambdas ARN once it has succesfully been deployed, you can use this to manually run the function and check for any errors. $ aws lambda invoke \\ --function-name $ARN \\ --log-type Tail \\ --payload '{\"key1\":\"value1\", \"key2\":\"value2\", \"key3\":\"value3\"}' \\ output.txt \\ | jq -r .LogResult | base64 --decode","title":"Test the Deploy"},{"location":"ops_infrastructure/gordon_prod_issues/","text":"OPS-Gordon Production Troubleshooting For ops-gordon there are 2 active checks that we run: Did the function take too long ? Did the function error? In both cases an investigation will be required to determine what the root cause is. Alert-Function Timed Out AWS Lambda functions have a MAXIMUM run time of 300sec so we alert on functions that hit that limit. This could imply that the function is relying on an external service that is having issues or that the function is simply taking too long, either way we must check the cloudwatch logs to see what is going on. Logs can be found HERE If the function is held up by an external service that is within our control we should investigate that source(eg. Jira is down). The cloudwatch logs will have some information that you can use to track down the reason the function is timing out. If the function is new and it is not held up on an external resource any triggers should be disabled and the creator contacted to debug the issue. If a change was recently made to a production function that is now impacting its availability you should revert the code and redeploy so that the function availability can return to normal. The changes should then be further tested before allowing them to be merged and deployed once again. OPS-Gordon Deploy Alert-Function Error Rate AWS Lambdas will do their best but if there is a bug in the code it can error on invocation. Once again you will need to investigate by looking at the cloudwatch logs to track down what the issue is. Logs can be found HERE If the function is held up by an external service that is within our control we should investigate that source(eg. Jira is down). The cloudwatch logs will have some information that you can use to track down the reason the function erroring. If a change was recently made to a production function that is now impacting its availability you should revert the code and redeploy so that the function availability can return to normal. The changes should then be further tested before allowing them to be merged and deployed once again. OPS-Gordon Deploy","title":"OPS-Gordon Production Troubleshooting"},{"location":"ops_infrastructure/gordon_prod_issues/#ops-gordon-production-troubleshooting","text":"For ops-gordon there are 2 active checks that we run: Did the function take too long ? Did the function error? In both cases an investigation will be required to determine what the root cause is.","title":"OPS-Gordon Production Troubleshooting"},{"location":"ops_infrastructure/gordon_prod_issues/#alert-function-timed-out","text":"AWS Lambda functions have a MAXIMUM run time of 300sec so we alert on functions that hit that limit. This could imply that the function is relying on an external service that is having issues or that the function is simply taking too long, either way we must check the cloudwatch logs to see what is going on. Logs can be found HERE If the function is held up by an external service that is within our control we should investigate that source(eg. Jira is down). The cloudwatch logs will have some information that you can use to track down the reason the function is timing out. If the function is new and it is not held up on an external resource any triggers should be disabled and the creator contacted to debug the issue. If a change was recently made to a production function that is now impacting its availability you should revert the code and redeploy so that the function availability can return to normal. The changes should then be further tested before allowing them to be merged and deployed once again. OPS-Gordon Deploy","title":"Alert-Function Timed Out"},{"location":"ops_infrastructure/gordon_prod_issues/#alert-function-error-rate","text":"AWS Lambdas will do their best but if there is a bug in the code it can error on invocation. Once again you will need to investigate by looking at the cloudwatch logs to track down what the issue is. Logs can be found HERE If the function is held up by an external service that is within our control we should investigate that source(eg. Jira is down). The cloudwatch logs will have some information that you can use to track down the reason the function erroring. If a change was recently made to a production function that is now impacting its availability you should revert the code and redeploy so that the function availability can return to normal. The changes should then be further tested before allowing them to be merged and deployed once again. OPS-Gordon Deploy","title":"Alert-Function Error Rate"},{"location":"ops_infrastructure/oneoffs/","text":"General Information About One-Off Servers Access Most of our One-Off servers live on the Acquia Consolidated account in AWS. To do maintenance on any instance in the external account, you need: AWS Ops External credentials The AWS Ops launcher SSH key (ask a manager or senior Ops/SRE if you don't have this) Your SSH key in ops-puppet Note: The Ops External AWS account is a Wild West of snowflakes and forgotten servers and should be treated with caution. Not all instances are consistently maintained and some of them are SPOFs for critical services. If in doubt, ask a senior Ops or SRE for assistance. Relaunching One-Offs Preparation Before relaunching any one-off server, we should collect data on its current status. Most one-off instances live in us-east-1 . OP= REGION= EC2_ID= HOSTNAME= aws ec2 describe-instances --region ${REGION} --filters \"Name=tag:Name,Values=${HOSTNAME}\" aws ec2 describe-volumes --region ${REGION} --output text --filters Name=attachment.instance-id,Values=${EC2_ID} Record the instance's EIP ID, if it has one. We need to reattach it to the instance after relaunching. If the instance does not have an EIP, you should consider giving it one. aws ec2 describe-addresses --region ${REGION} --filters --public-ips $(dig +short ${HOSTNAME}) EIP= If the EIP is in a VPC, record its allocation ID. Otherwise, for EC2 Classic EIPs, record the IP. For example: [cloudservicesprod|external:external] ~$ aws ec2 describe-addresses --region ${REGION} \\ > --filters --public-ips $(dig +short ops.acquia.com) ADDRESSES standard i-77f4db14 23.23.220.86 EIP=23.23.220.86 [cloudservicesprod|external:external] ~$ aws ec2 describe-addresses --region ${REGION} \\ > --filters --public-ips $(dig +short cron.ops.acquia.com) ADDRESSES eipalloc-3b2b6604 eipassoc-c14e96ff vpc i-06961a306e82aaa2c eni-d3af9722 831208250803 10.0.0.202 52.55.100.107 EIP=eipalloc-3b2b6604 Make a list of all the volumes listed by the describe-volumes command and create snapshots of them. VOLS=() aws ec2 describe-snapshots --region ${REGION} --output text --filters Name=volume-id,Values=\"$(array-csv ${VOLS[@]})\" for v in ${VOLS[@]}; do echo \"Snapshotting ${v}\"; aws ec2 create-snapshot --volume-id ${vol} --description \"${OP}\"; done Relaunch Once the snapshots are complete, stop the instance and verify that its status is stopped in AWS: aws ec2 stop-instances --region ${REGION} --instance-ids ${EC2_ID} aws ec2 describe-instances --region ${REGION} --output text --instance-ids ${EC2_ID} If we need to resize the instance, give it an EIP, or make other such changes, this is the time to do it. Once necessary changes are made, launch the instance: aws ec2 start-instances --instance-ids ${EC2_ID} aws ec2 describe-instances --region ${REGION} --output text --instance-ids ${EC2_ID} If the instance had an EIP, reattach it: VPC: aws ec2 associate-address --instance-id ${EC2_ID} --allocation-id ${EIP} EC2 Classic: aws ec2 associate-address --instance-id ${EC2_ID} --public-ip ${EIP} If the instance did not have an EIP, you need to manually update all the services that are looking for the instance's old IP, especially DNS. Verify that the instance launched successfully and has mounted all its volumes appropriately. Also check that all relevant services on the instance are running correctly. If anything goes wrong with the relaunch you may be able to get more information by getting its console output: aws ec2 get-console-output --region ${REGION} --instance-id ${EC2_ID} Rebooting the instance may resolve some problems encountered during relaunch. Otherwise, escalate to a senior Ops Engineer. Post relaunch step for ops-mon-2 Ruby on ops-mon-2 lives on an ephemeral volume and would not be available post the relaunch. Therefore, you will need to compile it again. Please refer this runbook for instructions on installing ruby. NOTE: This will going to be automated through puppet/ansible once the work in this ticket is complete. This runbook will also be updated once the change has been made. Other mon servers (mon1, mon2 and mon3) do not have any dependencies on ruby so we do not need to worry about them. Other packages required for functioning are installed and managed through puppet.","title":"General Information About One-Off Servers"},{"location":"ops_infrastructure/oneoffs/#general-information-about-one-off-servers","text":"","title":"General Information About One-Off Servers"},{"location":"ops_infrastructure/oneoffs/#access","text":"Most of our One-Off servers live on the Acquia Consolidated account in AWS. To do maintenance on any instance in the external account, you need: AWS Ops External credentials The AWS Ops launcher SSH key (ask a manager or senior Ops/SRE if you don't have this) Your SSH key in ops-puppet Note: The Ops External AWS account is a Wild West of snowflakes and forgotten servers and should be treated with caution. Not all instances are consistently maintained and some of them are SPOFs for critical services. If in doubt, ask a senior Ops or SRE for assistance.","title":"Access"},{"location":"ops_infrastructure/oneoffs/#relaunching-one-offs","text":"","title":"Relaunching One-Offs"},{"location":"ops_infrastructure/oneoffs/#preparation","text":"Before relaunching any one-off server, we should collect data on its current status. Most one-off instances live in us-east-1 . OP= REGION= EC2_ID= HOSTNAME= aws ec2 describe-instances --region ${REGION} --filters \"Name=tag:Name,Values=${HOSTNAME}\" aws ec2 describe-volumes --region ${REGION} --output text --filters Name=attachment.instance-id,Values=${EC2_ID} Record the instance's EIP ID, if it has one. We need to reattach it to the instance after relaunching. If the instance does not have an EIP, you should consider giving it one. aws ec2 describe-addresses --region ${REGION} --filters --public-ips $(dig +short ${HOSTNAME}) EIP= If the EIP is in a VPC, record its allocation ID. Otherwise, for EC2 Classic EIPs, record the IP. For example: [cloudservicesprod|external:external] ~$ aws ec2 describe-addresses --region ${REGION} \\ > --filters --public-ips $(dig +short ops.acquia.com) ADDRESSES standard i-77f4db14 23.23.220.86 EIP=23.23.220.86 [cloudservicesprod|external:external] ~$ aws ec2 describe-addresses --region ${REGION} \\ > --filters --public-ips $(dig +short cron.ops.acquia.com) ADDRESSES eipalloc-3b2b6604 eipassoc-c14e96ff vpc i-06961a306e82aaa2c eni-d3af9722 831208250803 10.0.0.202 52.55.100.107 EIP=eipalloc-3b2b6604 Make a list of all the volumes listed by the describe-volumes command and create snapshots of them. VOLS=() aws ec2 describe-snapshots --region ${REGION} --output text --filters Name=volume-id,Values=\"$(array-csv ${VOLS[@]})\" for v in ${VOLS[@]}; do echo \"Snapshotting ${v}\"; aws ec2 create-snapshot --volume-id ${vol} --description \"${OP}\"; done","title":"Preparation"},{"location":"ops_infrastructure/oneoffs/#relaunch","text":"Once the snapshots are complete, stop the instance and verify that its status is stopped in AWS: aws ec2 stop-instances --region ${REGION} --instance-ids ${EC2_ID} aws ec2 describe-instances --region ${REGION} --output text --instance-ids ${EC2_ID} If we need to resize the instance, give it an EIP, or make other such changes, this is the time to do it. Once necessary changes are made, launch the instance: aws ec2 start-instances --instance-ids ${EC2_ID} aws ec2 describe-instances --region ${REGION} --output text --instance-ids ${EC2_ID} If the instance had an EIP, reattach it: VPC: aws ec2 associate-address --instance-id ${EC2_ID} --allocation-id ${EIP} EC2 Classic: aws ec2 associate-address --instance-id ${EC2_ID} --public-ip ${EIP} If the instance did not have an EIP, you need to manually update all the services that are looking for the instance's old IP, especially DNS. Verify that the instance launched successfully and has mounted all its volumes appropriately. Also check that all relevant services on the instance are running correctly. If anything goes wrong with the relaunch you may be able to get more information by getting its console output: aws ec2 get-console-output --region ${REGION} --instance-id ${EC2_ID} Rebooting the instance may resolve some problems encountered during relaunch. Otherwise, escalate to a senior Ops Engineer.","title":"Relaunch"},{"location":"ops_infrastructure/oneoffs/#post-relaunch-step-for-ops-mon-2","text":"Ruby on ops-mon-2 lives on an ephemeral volume and would not be available post the relaunch. Therefore, you will need to compile it again. Please refer this runbook for instructions on installing ruby. NOTE: This will going to be automated through puppet/ansible once the work in this ticket is complete. This runbook will also be updated once the change has been made. Other mon servers (mon1, mon2 and mon3) do not have any dependencies on ruby so we do not need to worry about them. Other packages required for functioning are installed and managed through puppet.","title":"Post relaunch step for ops-mon-2"},{"location":"ops_infrastructure/perfmon/","text":"perf-mon.ops.acquia.com Overview of Services perf-mon.acquia.com monitors the availability of all of our customer sites and keeps records of site down-time for SLA compliance calculations. This server is managed by the LEGACY_2015-02-17 branch of ops-puppet . Additionally, this is an EBS-backed instance (not instance-backed like everything we run in Fields), so services on it should be able to start automatically after a relaunch. This confluence page has a useful overview of the 'Ops-Mon-2 Stack'. Relaunching The procedure in this runbook contains steps that are specific to perf-mon.acquia.com , and should be followed in parallel with the general one-off relaunching runbook . Try not to relaunch perf-mon.acquia.com while any customer site is down, since doing so may affect the SLA calculations for that customer. Coordinate with hotseat to find a good time to begin. Preparation Before starting, do the general one-off preparation . Note: perf-mon has a 1000 GB for its MySQL database and take a Very Long Time to create a snapshot for. If you are short on time or the instance is already down, skip taking the snapshot. Relaunch Before relaunching perf-mon log into it and manually stop MySQL to ensure it is shut down cleanly. service mysql stop Then, follow the general one-off relaunch steps . Once the perf-mon has relaunched, log into it and: Verify that sites are getting checked . Open a page served by perf-mon to verify that both Apache and MySQL are running. (Don't forget that you need to be on the Acquia VPN to access perf-mon.) Verify that puppet is running correctly by running puppet agent -t OR in Masterless Puppet mode sudo run-puppet . NRPE uses an IP address whitelist that is maintained by host definitions in the ops-mon-2 repo . This needs to be fixed one day but until then you need to make a branch and update objects/oneoff/hosts/perf-mon_acquia_com.cfg with the new internal IP then submit a PR so the change can be verified. If anything goes wrong, escalate to a senior Ops engineer.","title":"perf-mon.ops.acquia.com"},{"location":"ops_infrastructure/perfmon/#perf-monopsacquiacom","text":"","title":"perf-mon.ops.acquia.com"},{"location":"ops_infrastructure/perfmon/#overview-of-services","text":"perf-mon.acquia.com monitors the availability of all of our customer sites and keeps records of site down-time for SLA compliance calculations. This server is managed by the LEGACY_2015-02-17 branch of ops-puppet . Additionally, this is an EBS-backed instance (not instance-backed like everything we run in Fields), so services on it should be able to start automatically after a relaunch. This confluence page has a useful overview of the 'Ops-Mon-2 Stack'.","title":"Overview of Services"},{"location":"ops_infrastructure/perfmon/#relaunching","text":"The procedure in this runbook contains steps that are specific to perf-mon.acquia.com , and should be followed in parallel with the general one-off relaunching runbook . Try not to relaunch perf-mon.acquia.com while any customer site is down, since doing so may affect the SLA calculations for that customer. Coordinate with hotseat to find a good time to begin.","title":"Relaunching"},{"location":"ops_infrastructure/perfmon/#preparation","text":"Before starting, do the general one-off preparation . Note: perf-mon has a 1000 GB for its MySQL database and take a Very Long Time to create a snapshot for. If you are short on time or the instance is already down, skip taking the snapshot.","title":"Preparation"},{"location":"ops_infrastructure/perfmon/#relaunch","text":"Before relaunching perf-mon log into it and manually stop MySQL to ensure it is shut down cleanly. service mysql stop Then, follow the general one-off relaunch steps . Once the perf-mon has relaunched, log into it and: Verify that sites are getting checked . Open a page served by perf-mon to verify that both Apache and MySQL are running. (Don't forget that you need to be on the Acquia VPN to access perf-mon.) Verify that puppet is running correctly by running puppet agent -t OR in Masterless Puppet mode sudo run-puppet . NRPE uses an IP address whitelist that is maintained by host definitions in the ops-mon-2 repo . This needs to be fixed one day but until then you need to make a branch and update objects/oneoff/hosts/perf-mon_acquia_com.cfg with the new internal IP then submit a PR so the change can be verified. If anything goes wrong, escalate to a senior Ops engineer.","title":"Relaunch"},{"location":"ops_reference/","text":"Ops Reference General Reference Deploying secrets with Masterless Puppet Deploying secrets with Masterless Puppet Keys SCP How to use Training Services Overview Overview of Common Services A Note About Log Analysis System Logs Primary Services Varnish Nginx Apache PHP-FPM Memcached MySQL Gluster Tungsten Secondary Services ah-socketd collectd cron exim4 Nagios ossec pt-heartbeat SSH Between Servers SSHing Between Servers sv-rsyncfile Key Forwarding Temporary SSH Key Strace Using strace Basic strace Usage Interpreting strace Output","title":"Ops Reference"},{"location":"ops_reference/#ops-reference","text":"","title":"Ops Reference"},{"location":"ops_reference/#general-reference","text":"","title":"General Reference"},{"location":"ops_reference/#deploying-secrets-with-masterless-puppet","text":"Deploying secrets with Masterless Puppet Keys","title":"Deploying secrets with Masterless Puppet"},{"location":"ops_reference/#scp","text":"How to use","title":"SCP"},{"location":"ops_reference/#training","text":"","title":"Training"},{"location":"ops_reference/#services-overview","text":"Overview of Common Services A Note About Log Analysis System Logs Primary Services Varnish Nginx Apache PHP-FPM Memcached MySQL Gluster Tungsten Secondary Services ah-socketd collectd cron exim4 Nagios ossec pt-heartbeat","title":"Services Overview"},{"location":"ops_reference/#ssh-between-servers","text":"SSHing Between Servers sv-rsyncfile Key Forwarding Temporary SSH Key","title":"SSH Between Servers"},{"location":"ops_reference/#strace","text":"Using strace Basic strace Usage Interpreting strace Output","title":"Strace"},{"location":"ops_reference/deploy_secrets_masterless/","text":"Deploying secrets with Masterless Puppet Original blog post Masterless Puppet exists as a CDS package that allows us to deprecate storing credentials on the Master server. This new setup gives us the opportunity to remove hard coded credentials and keys from the codebase. Instead, the sensitive data will be migrated into puppet classification by securely storing secret keys in Hosting API using the ConfigurationService. Each secret key will be stored under the corresponding service in the Hosting API. For example, TaskServerSSHKey key will be located under TaskSystem service. For security's sake, secret keys will be stored encrypted. For this purpose, we have created a new config type: SecretKey . It is a simple key-value pair with encrypted value by Hosting API. Please do take advantage of this new type. Hosting API has a service called PuppetENC which is responsible for generating the puppet classification. PuppetENC service has parameter domain which holds all parameters of the classifier. These parameters will be generated based on the requested server type. For example, AcquiaSitesComPrivateKey class is a puppet parameter which holds a private key content in configuration service, moreover, it will be injected to the classifier only if the server type is balancer . This pattern helps us to collect only necessary secret keys in puppet classifier. To store a secret key pair in Hosting API, you will need to find the correct SecretKey config under related service in the table below. Read more about configuration service blog post . Then use the following command to set the config (using the GPG Key as an example): If you have a value instead of a file: SECRET_CONTENT= bin/ah-stage set-config --key HardwareService.AcquiaEngGPGPubKey --value \"$SECRET_CONTENT\" If you have a file instead of a value: SECRET_FILE_PATH= bin/ah-stage set-config-from-file --key HardwareService.AcquiaEngGPGPubKey --file $SECRET_FILE_PATH Keys Location Key Service.ConfigKey Server Type puppet/versions/devel/modules/web_node/files/cloudapi.acquia.com.pem cloud_api_acquia_com_certificate CloudService.CloudAPIAcquiaComCertificate WEB puppet/versions/devel/modules/installer_packages/files/acquia-eng-gpg-pubkey acquia_eng_gpg_public_key HardwareService.AcquiaEngGPGPubKey ALL puppet/versions/devel/modules/balancer/files/acquia-sites_com.pem acquia_sites_com_certificate EdgeService.AcquiaSitesComCertificate BAL puppet/versions/devel/modules/balancer/files/acquia-sites_com.key acquia_sites_com_private_key EdgeService.AcquiaSitesComPrivateKey BAL puppet/versions/devel/modules/puppetmaster/files/hosting_vcl_files_git_key hosting_vcl_files_private_key EdgeService.HostingVCLFilesPrivateKey BAL puppet/versions/devel/modules/stunnel/files/stunnel.pem stunnel_certificate PersistentDataService.StunnelCertificate FS_DB_MESH, DB_MESH TBD: PORT TO MASTERLESS PUPPET task_server_ssh_key TaskSystem.TaskServerSSHKey TASK, BACKUP","title":"Deploying secrets with Masterless Puppet"},{"location":"ops_reference/deploy_secrets_masterless/#deploying-secrets-with-masterless-puppet","text":"Original blog post Masterless Puppet exists as a CDS package that allows us to deprecate storing credentials on the Master server. This new setup gives us the opportunity to remove hard coded credentials and keys from the codebase. Instead, the sensitive data will be migrated into puppet classification by securely storing secret keys in Hosting API using the ConfigurationService. Each secret key will be stored under the corresponding service in the Hosting API. For example, TaskServerSSHKey key will be located under TaskSystem service. For security's sake, secret keys will be stored encrypted. For this purpose, we have created a new config type: SecretKey . It is a simple key-value pair with encrypted value by Hosting API. Please do take advantage of this new type. Hosting API has a service called PuppetENC which is responsible for generating the puppet classification. PuppetENC service has parameter domain which holds all parameters of the classifier. These parameters will be generated based on the requested server type. For example, AcquiaSitesComPrivateKey class is a puppet parameter which holds a private key content in configuration service, moreover, it will be injected to the classifier only if the server type is balancer . This pattern helps us to collect only necessary secret keys in puppet classifier. To store a secret key pair in Hosting API, you will need to find the correct SecretKey config under related service in the table below. Read more about configuration service blog post . Then use the following command to set the config (using the GPG Key as an example): If you have a value instead of a file: SECRET_CONTENT= bin/ah-stage set-config --key HardwareService.AcquiaEngGPGPubKey --value \"$SECRET_CONTENT\" If you have a file instead of a value: SECRET_FILE_PATH= bin/ah-stage set-config-from-file --key HardwareService.AcquiaEngGPGPubKey --file $SECRET_FILE_PATH","title":"Deploying secrets with Masterless Puppet"},{"location":"ops_reference/deploy_secrets_masterless/#keys","text":"Location Key Service.ConfigKey Server Type puppet/versions/devel/modules/web_node/files/cloudapi.acquia.com.pem cloud_api_acquia_com_certificate CloudService.CloudAPIAcquiaComCertificate WEB puppet/versions/devel/modules/installer_packages/files/acquia-eng-gpg-pubkey acquia_eng_gpg_public_key HardwareService.AcquiaEngGPGPubKey ALL puppet/versions/devel/modules/balancer/files/acquia-sites_com.pem acquia_sites_com_certificate EdgeService.AcquiaSitesComCertificate BAL puppet/versions/devel/modules/balancer/files/acquia-sites_com.key acquia_sites_com_private_key EdgeService.AcquiaSitesComPrivateKey BAL puppet/versions/devel/modules/puppetmaster/files/hosting_vcl_files_git_key hosting_vcl_files_private_key EdgeService.HostingVCLFilesPrivateKey BAL puppet/versions/devel/modules/stunnel/files/stunnel.pem stunnel_certificate PersistentDataService.StunnelCertificate FS_DB_MESH, DB_MESH TBD: PORT TO MASTERLESS PUPPET task_server_ssh_key TaskSystem.TaskServerSSHKey TASK, BACKUP","title":"Keys"},{"location":"ops_reference/scp/","text":"SCP A common step in audits will be to scp a file to your local machine,attach to Jira ticket,delete from local machine and bastion. There is no mandate to use SCP, it is only a unix command which is a common way to get files off the bastion. How to use From your local machine, scp a file to your local machine REPORT_PATH= scp bastion21:${REPORT_PATH} LOCAL_DIRECTORY Attach files to Jira ticket from the JIRA GUI, the attach files menu pick is found in More pulldown. The attach files will bring a dialog called Open files where you can select the files from the local directory. Delete files from local machine and bastion. In this example, bastion21 could be what you named HOST:bastion21 in file /home/$USER/.ssh/config on your local machine. If HOST:bastion is your particular .ssh/config entry and you want to copy a file to current directory on local machine, then the command would resemble below. REPORT_PATH=/mnt/ahops/tmp/$USER_BASTION/OP-194106/UserAccessReviewReport-2019-03-01.csv scp bastion:${REPORT_PATH} . Requested to enter your yubikey bastion password. Example file on bastion: /mnt/ahops/tmp/jamesmoran/OP-194106/UserAccessReviewReport-2019-03-01.csv REPORT_PATH is the path on the bastion and should be an absolute as it is remote, therefore not ~/directory/filename.","title":"SCP"},{"location":"ops_reference/scp/#scp","text":"A common step in audits will be to scp a file to your local machine,attach to Jira ticket,delete from local machine and bastion. There is no mandate to use SCP, it is only a unix command which is a common way to get files off the bastion.","title":"SCP"},{"location":"ops_reference/scp/#how-to-use","text":"From your local machine, scp a file to your local machine REPORT_PATH= scp bastion21:${REPORT_PATH} LOCAL_DIRECTORY Attach files to Jira ticket from the JIRA GUI, the attach files menu pick is found in More pulldown. The attach files will bring a dialog called Open files where you can select the files from the local directory. Delete files from local machine and bastion. In this example, bastion21 could be what you named HOST:bastion21 in file /home/$USER/.ssh/config on your local machine. If HOST:bastion is your particular .ssh/config entry and you want to copy a file to current directory on local machine, then the command would resemble below. REPORT_PATH=/mnt/ahops/tmp/$USER_BASTION/OP-194106/UserAccessReviewReport-2019-03-01.csv scp bastion:${REPORT_PATH} . Requested to enter your yubikey bastion password. Example file on bastion: /mnt/ahops/tmp/jamesmoran/OP-194106/UserAccessReviewReport-2019-03-01.csv REPORT_PATH is the path on the bastion and should be an absolute as it is remote, therefore not ~/directory/filename.","title":"How to use"},{"location":"ops_reference/services_overview/","text":"Overview of Common Services Table of Contents: Varnish Nginx Apache PHP-FPM Memcached MySQL Gluster Tungsten A Note About Log Analysis Many of the commands in this runbook are written with simplicity in mind, and will process the entire log file given, which may not provide accurate data for recent or time-specific traffic trends. They can also run very slowly for large files, which are common on high-traffic balancers. One quick and dirty way around this is to modify these commands to tail some number of lines from the log: tail -n10000 ${LOG} | #COMMAND# Alternatively, the following sed commands will restrict the input to the past hour or a specified time range, respectively. Be aware, however, that this will produce bad output if the timestamps are not found in the file. sed -n \"/$(date -d '-1 hours' '+%d\\/%b\\/%Y:%H:%M')/,\\$ p\" ${LOG} | #COMMAND# SDATE=#Ex: \"2018-07-09 00:00\" EDATE=#Ex: \"2018-07-09 01:00\" sed -n \"/$(date -d \"${SDATE}\" '+%d\\/%b\\/%Y:%H:%M')/,/$(date -d \"${EDATE}\" '+%d\\/%b\\/%Y:%H:%M')/ p\" ${LOG} | #COMMAND# System Logs Most services write their own logs for things relevant to their domain, but not all. Various system-level services are available to help diagnose problems on a server. Useful system diagnostic tools: systemctl status ${SERVICE_UNIT} : Check the status of specific service. journalctl -xe -u ${SERVICE_UNIT} : Check the systemd journal for a specific service. dmesg -T | less : Check kernel-level messages (ring buffer). Useful system logs: /var/log/daemon.log : Log for various daemon services. /var/log/kern.log : Log for messages from the kernel, such as OOMing or disk errors. /var/log/syslog : Default log for most system services. All sorts of goodies to be found here. Check the Ubuntu help docs for more . Note: td-agent is the service responsible for writing to these system logs. If something happens to it, logs might not get written! Primary Services Varnish First-line service for non-SSL HTTP requests to customer sites. Sends cache misses to Nginx for back-end processing. Runs On: bal , nxephem Logs: Varnish logs all HTTP requests that it processes. Balancer logs do not get forwarded to Sumologic, so Ops must manually analyze these logs when needed. Varnish does not maintain a dedicated error log. For more information about the Varnish logs, check out the fields architecture documentation . Useful log parsing commands: LOG=/var/log/varnish/varnishncsa.log Top IPs: awk '{print $1}' ${LOG} | sort | uniq -c | sort -hr | head -n10 Top UAs: awk -F\\\" '{print $6}' ${LOG} | sort | uniq -c | sort -hr | head -n10 Top Requests: awk -F\\\" '{print $2}' ${LOG} | sort | uniq -c | sort -hr | head -n10 Forwarded IPs : grep -oP '(?<=forwarded_for=\").+(?=\")' ${LOG} | sort | uniq -c | sort -hr | head -n10 Notable Behaviors: We configure Varnish to use about 60% of available memory on our balancers. A balancer should never OOM! If it does, investigate the bal's history in Jira and SFX to determine if it needs to be upsized. Varnish logs are among the largest log files we deal with since most normal site traffic should be served by the Varnish cache. If/When/How to Restart It: Do not restart Varnish except in emergencies for known issues! If you don't know why you want to restart Varnish, follow our procedure for escalating incidents to Cloud . Restarting varnish will impact site performance by wiping the site cache and forcing all requests to be routed to the backend, potentially causing an outage. EIP failovers produce similar results. Nginx First-line service for SSL HTTPS requests, which may or may not route traffic through Varnish. Load balances requests to the back-end via round-robin. Read the fields arch docs for more information Runs on: bal , nxephem Logs: Nginx logs all HTTP requests that it processes. Balancer logs do not get forwarded to Sumologic, so Ops must manually analyze these logs when needed. Additionally, Nginx utilizes an error log where it tracks problems it encounters. /var/log/nginx/access.log /var/log/nginx/ssl-access.log /var/log/nginx/error.log Useful log parsing commands: LOG=/var/log/nginx/access.log or LOG=/var/log/nginx/ssl-access.log Top IPs: awk '{print $1}' ${LOG} | sort | uniq -c | sort -hr | head -n10 Top UAs: awk -F\\\" '{print $6}' ${LOG} | sort | uniq -c | sort -hr | head -n10 Top Requests: awk -F\\\" '{print $2}' ${LOG} | sort | uniq -c | sort -hr | head -n10 Top Hosting Sites: grep -oP '(?<=hosting_site=)[^ ]+' ${LOG} | sort | uniq -c | sort -hr | head -n10 This will identify the busiest customers on shared balancers. Notable Behaviors: Nginx may break up large resources, such as videos and images, into several pieces and return HTTP code 206 (Partial Response). When it does this, Nginx may cache the file to disk, which can be problematic for Gen1 balancers with magnetic ephemeral volumes. You can identify this behavior by checking for CPU wait and/or high disk I/O on the balancer. If the balancer is shared, the following command will identify the most served partial responses, in bytes, and the sitegroup the resource belongs to. grep -E 'status=206' ${LOG} \\ | awk -F\\\" \\ 'match($0, /hosting_site=([^ ]+)/, s) && match($3, /[0-9]+ *([0-9]+)/, b) {bsum[s[1]\" \"$2]+=b[1]}; END {for (i in bsum) {print bsum[i], i}}' \\ | sort -n | tail -n10 If/When/How to Restart It: You shouldn't ever need to restart Nginx directly. If you suspect something is misconfigured, you can try running site-fcb ${SITE} from the bastion or fields-config-bal.php on the balancer in question which has logic to determine if Nginx needs to be restarted/reloaded. Apache Routes traffic for all sites on a web server to their associated PHP-FPM process. Runs on: web , staging , ded Logs: Apache logs all HTTP requests that a web server gets. These logs are forwarded to Sumologic, so you should use that instead of manually analyzing the access logs if you can. The error log may sometimes be useful for identifying a bad site configuration or other wrongness with a web. /var/log/apache2/access.log /var/log/apache2/error.log If you ever need to analyze the Apache logs, they are formatted nearly identically to the Nginx logs so many of those commands will work for Apache as well. Notable Behaviors: Apache holds at least 3 file descriptors open for every site on a web server. This is important to know for shared servers with many sites, since too many sites (~300) will lead to Apache throwing errors mentioning FD_SETSIZE . If this happens, move sites off the server and ensure any associated active tag (I.e. activestagingra ) is moved to an appropriate alternative server. See also: Provisioning Infrastructure . If/When/How to Restart It: You shouldn't generally need to restart Apache2 manually. If a web server is not responding appropriately, investigate why and, if appropriate, run site-fcw ${SITE} or sv-fcwkick ${SERVER} from the bastion or fields-config-web.php on the web which will ensure customer site code is updated and PHP, Apache, and many other services are running correctly. PHP-FPM Primary service responsible for serving web requests for each site we host. This is where Drupal and customer site code lives. Runs on: web , staging , ded See Also: Debugging PHP Runbook Fields Custom PHP Docs Logs: Each hosting site on every web server has a directory for their logs, located at /var/log/sites/${SITENAME}/logs/$(hostname -s)/ . This directory contains various logs relevant to the customer's site, which are all accessible to the customer. Many of these logs are rotated by our automation but not all, particularly those which are created and managed by the customer. Notable Behaviors: This service is something of a single-point-of-failure for a customer's site. If it dies or becomes stuck waiting on some resource, the customer's site can go down. Check out the runbook on debugging PHP for more information. If/When/How to Restart It: You should always debug PHP before restarting it blindly. However, because PHP-FPM is so sensitive to customer code, resource limitations, and cosmic rays, there are many situations where restarting this service is reasonable. If you don't know why PHP-FPM is misbehaving, restart it with site-restartfpmwithstrace ${SITE} . Otherwise, you can use site-restartfpm ${SITE} . To ensure customer site code is up to date and that various necessary services are running as well, use site-fcw ${site} . Memcached Key-Value caching layer accessed by PHP-FPM. Runs on: web , staging , ded See Also: Support's Memcached Documentation (RECOMMENDED READING!) Memcached Troubleshooting Cache Evictions Fields Memcached Arch Docs Logs: Memcached does not keep any logs. Notable Behaviors: A web server will only serve memcache if memcached.conf:-m is set to a valid value and memcache_service_status is enabled. esl / esl2 will display a 2 or a green checkmark if memcache_service_status is enabled, 1 or a red X if it is disabled. Some servers, including ODE webs (tagged with ode ), run per-site memcached, where each site has its own memcached instance, secured with SASL. These will appear to PagerDuty alerts and service checks with a name resembling ah-site-memcached@site.name.service and will run on a port other than 11211 . Ops is not responsible for per-site memcached! Any issues involving per-site memcached should be escalated to Cloud against the \"Drupal Hosting\" component via Ops Portal . If/When/How to Restart It: If there is a problem with per-site memcached (see above), escalate to Cloud. If server memcached is not currently running you can use site-fcm ${SITE} on the bastion or fields-config-memcached.php on the server to start it. Ops should not need to restart memcached manually. MySQL Database storage for persistant, relational data. Runs on: staging , ded , fsdb , dbmaster , fsdbmesh , dbmesh See Also: Ops Database Runbooks Fields MySQL Architecture Docs: DNS Audit Logs Memory Allocation Logs: MySQL keeps all its logs in /var/lib/mysql , which should be symlinked to /vol/ebs1/mysql : /var/lib/mysql/$(hostname).err : MySQL error logs, particularly useful when MySQL fails to start. /var/lib/mysql/$(hostname -s)-slow.log : MySQL slow query logs, tracks long-running database queries which may be indicative of performance issues as a result of high traffic or inefficient database queries. Binlogs: logs kept by the master database in a HA pair to describe database changes to be sent to the slave DB for replication. Viewable with: mysqlbinlog ${BINLOG} --base64-output=DECODE-ROWS | less (Often Spammy!) Relaylogs: logs kept by the slave database in a HA pair to track updates it has received from the master, but not yet written to disk. Viewable with: mysqlbinlog ${BINLOG} --base64-output=DECODE-ROWS | less (Often Spammy!) Notable Behaviors: MySQL is protected from being targeted by the OOM-killer. There is a known issue, PF-281 , regarding MySQL memory allocation which may cause MySQL to use more memory than configured. This can lead to OOMing or block hosting releases on affected servers. Some database usage patterns and/or Drupal modules can lead to performance issues via slow queries or bloated cache tables, particularly when hit by a traffic spike. MySQL in ACSF realms does not keep separate databases/tables in individual files! Instead, everything is stored in /var/lib/mysql/ibdata1 . If/When/How to Restart It: Avoid restarting MySQL , as doing so will wipe MySQL cache and can be error prone, potentially causing problems with replication or even data loss if done incorrectly. If you must restart MySQL (I.e. to address memory constraints when no alternatives are available), make sure you follow appropriate failover procedures to reduce impact to site performance. Gluster Distributed filesystem service. Known to cause many headaches and split brains. Runs on: staging , ded , fsdb , fsdbmesh , fs See Also: Ops Gluster Runbooks Support Gluster Docs Fields Filesystem Architecture Docs Logs: All Gluster logs can be found in the /var/log/glusterfs/ directory. Both versions of Gluster write to the following logs: mnt-gfs.log : Logs I nformation, W arnings, and E rrors pertaining to specific inodes on the volume. Errors are often an indication of corrupted, missing, or split-brained files. etc-glusterfs-glusterfsd.vol.log : Logs client/peer connections to the volume, etc. In addition to the above, Gluster 3.4 maintains various other logs which might be useful when diagnosing a problem. Notable Behaviors: Gluster often behaves poorly in response to customers using visual filesystem browsers such as Midnight Commander; which has been known to cause file split-brains and/or corruption. Gluster generally tries to track files by their path, but is known to exhibit unusual behavior if any inode has multiple hard-links to it in the filesystem! When statting such files (I.e. via ls , stat , etc.)... Gluster 3.0 may duplicate the file to a new inode. The stat'd hardlink will point to the new inode, all other hardlinks will point to the old inode. Gluster 3.4 may make a new inode and delete the old one. The stat'd hardlink will point to the updated inode, all other hardlinks will point to a non-existent inode and produce errors when stat'd. Gluster often experiences performance issues when a customer has a large number of files (I.e. 10,000+) in any single directory, particularly if they are using magnetic volumes or SSD volumes smaller than 100GB. If/When/How to Restart It: Restart Gluster any time you have to reboot/relaunch one of the FS servers, or if Gluster is exhibiting problematic behavior. (I.e. site-checkgluster returns errors or an abnormally long gluster time , connection errors in any of the Gluster logs, etc.) It is usually sufficient to run site-fsremount ${SITE} and make sure that every server eventually returns success; any process accessing the filesystem will block a remount. Be Aware: A Gluster 3.4 server may sometimes falsely return success ( 0 ) to the remount command. If symptoms continue to present themselves after a remount, it may be necessary to manually stop and/or kill all Gluster processes on the server before running ah-config-gluster . Tungsten Data replication service which we use for multi-region MySQL clusters. Runs on: fsdbmesh , dbmesh See Also: General Tungsten Administration Custom Tungsten Settings Runbook Tungsten Troubleshooting Fields Tungsten Architecture Docs Logs: Tungsten keeps a service log, /usr/local/tungsten-replicator/tungsten/tungsten-replicator/log/trepsvc.log , which can be helpful when encountering problems with replication or Tungsten not starting properly. Check the Ops Tungsten Runbooks for more information. Secondary Services ah-socketd Performs socket activation for Unix domain socket daemons for Acquia Cloud-specific needs. This will eventually be replaced by systemd . Occasionally needs to be restarted when PHP misbehaves. Best way to do this is to let puppet agent -t OR in Masterless Puppet mode sudo run-puppet do it or, if the service needs to be manually restarted, service ah-socketd restart . collectd Collects server statistics and sends them to SignalFX. cron Cron job service. We disable this service when we need to make sure Puppet doesn't run on a server for any reason. exim4 Routes e-mails generated by customer sites for web-forms, user account validation, etc. and routes them to the acquiamail servers in Rackspace. Nagios Monitoring service which detects various problems and relays them through our alerting stack for incident response. If a mon server alerts that Nagios is not running, run fields-config-mon.php . If any other server type is reporting Nagios is not running: MON= fssh ${MON} \"sudo sh -c 'service nagios restart && service nagios-nrpe-server restart'\" ossec Detects issues with system security and intrusion detection. pt-heartbeat Detects disparities in MySQL database replication. If pt-heartbeat is not running: Restart the pt-heartbeat service: service pt-heartbeat restart Check /var/log/syslog for errors. If MySQL errors are reported, run reset-debian-password.sh , then restart pt-heartbeat again.","title":"Overview of Common Services"},{"location":"ops_reference/services_overview/#overview-of-common-services","text":"Table of Contents: Varnish Nginx Apache PHP-FPM Memcached MySQL Gluster Tungsten","title":"Overview of Common Services"},{"location":"ops_reference/services_overview/#a-note-about-log-analysis","text":"Many of the commands in this runbook are written with simplicity in mind, and will process the entire log file given, which may not provide accurate data for recent or time-specific traffic trends. They can also run very slowly for large files, which are common on high-traffic balancers. One quick and dirty way around this is to modify these commands to tail some number of lines from the log: tail -n10000 ${LOG} | #COMMAND# Alternatively, the following sed commands will restrict the input to the past hour or a specified time range, respectively. Be aware, however, that this will produce bad output if the timestamps are not found in the file. sed -n \"/$(date -d '-1 hours' '+%d\\/%b\\/%Y:%H:%M')/,\\$ p\" ${LOG} | #COMMAND# SDATE=#Ex: \"2018-07-09 00:00\" EDATE=#Ex: \"2018-07-09 01:00\" sed -n \"/$(date -d \"${SDATE}\" '+%d\\/%b\\/%Y:%H:%M')/,/$(date -d \"${EDATE}\" '+%d\\/%b\\/%Y:%H:%M')/ p\" ${LOG} | #COMMAND#","title":"A Note About Log Analysis"},{"location":"ops_reference/services_overview/#system-logs","text":"Most services write their own logs for things relevant to their domain, but not all. Various system-level services are available to help diagnose problems on a server. Useful system diagnostic tools: systemctl status ${SERVICE_UNIT} : Check the status of specific service. journalctl -xe -u ${SERVICE_UNIT} : Check the systemd journal for a specific service. dmesg -T | less : Check kernel-level messages (ring buffer). Useful system logs: /var/log/daemon.log : Log for various daemon services. /var/log/kern.log : Log for messages from the kernel, such as OOMing or disk errors. /var/log/syslog : Default log for most system services. All sorts of goodies to be found here. Check the Ubuntu help docs for more . Note: td-agent is the service responsible for writing to these system logs. If something happens to it, logs might not get written!","title":"System Logs"},{"location":"ops_reference/services_overview/#primary-services","text":"","title":"Primary Services"},{"location":"ops_reference/services_overview/#varnish","text":"First-line service for non-SSL HTTP requests to customer sites. Sends cache misses to Nginx for back-end processing. Runs On: bal , nxephem Logs: Varnish logs all HTTP requests that it processes. Balancer logs do not get forwarded to Sumologic, so Ops must manually analyze these logs when needed. Varnish does not maintain a dedicated error log. For more information about the Varnish logs, check out the fields architecture documentation . Useful log parsing commands: LOG=/var/log/varnish/varnishncsa.log Top IPs: awk '{print $1}' ${LOG} | sort | uniq -c | sort -hr | head -n10 Top UAs: awk -F\\\" '{print $6}' ${LOG} | sort | uniq -c | sort -hr | head -n10 Top Requests: awk -F\\\" '{print $2}' ${LOG} | sort | uniq -c | sort -hr | head -n10 Forwarded IPs : grep -oP '(?<=forwarded_for=\").+(?=\")' ${LOG} | sort | uniq -c | sort -hr | head -n10 Notable Behaviors: We configure Varnish to use about 60% of available memory on our balancers. A balancer should never OOM! If it does, investigate the bal's history in Jira and SFX to determine if it needs to be upsized. Varnish logs are among the largest log files we deal with since most normal site traffic should be served by the Varnish cache. If/When/How to Restart It: Do not restart Varnish except in emergencies for known issues! If you don't know why you want to restart Varnish, follow our procedure for escalating incidents to Cloud . Restarting varnish will impact site performance by wiping the site cache and forcing all requests to be routed to the backend, potentially causing an outage. EIP failovers produce similar results.","title":"Varnish"},{"location":"ops_reference/services_overview/#nginx","text":"First-line service for SSL HTTPS requests, which may or may not route traffic through Varnish. Load balances requests to the back-end via round-robin. Read the fields arch docs for more information Runs on: bal , nxephem Logs: Nginx logs all HTTP requests that it processes. Balancer logs do not get forwarded to Sumologic, so Ops must manually analyze these logs when needed. Additionally, Nginx utilizes an error log where it tracks problems it encounters. /var/log/nginx/access.log /var/log/nginx/ssl-access.log /var/log/nginx/error.log Useful log parsing commands: LOG=/var/log/nginx/access.log or LOG=/var/log/nginx/ssl-access.log Top IPs: awk '{print $1}' ${LOG} | sort | uniq -c | sort -hr | head -n10 Top UAs: awk -F\\\" '{print $6}' ${LOG} | sort | uniq -c | sort -hr | head -n10 Top Requests: awk -F\\\" '{print $2}' ${LOG} | sort | uniq -c | sort -hr | head -n10 Top Hosting Sites: grep -oP '(?<=hosting_site=)[^ ]+' ${LOG} | sort | uniq -c | sort -hr | head -n10 This will identify the busiest customers on shared balancers. Notable Behaviors: Nginx may break up large resources, such as videos and images, into several pieces and return HTTP code 206 (Partial Response). When it does this, Nginx may cache the file to disk, which can be problematic for Gen1 balancers with magnetic ephemeral volumes. You can identify this behavior by checking for CPU wait and/or high disk I/O on the balancer. If the balancer is shared, the following command will identify the most served partial responses, in bytes, and the sitegroup the resource belongs to. grep -E 'status=206' ${LOG} \\ | awk -F\\\" \\ 'match($0, /hosting_site=([^ ]+)/, s) && match($3, /[0-9]+ *([0-9]+)/, b) {bsum[s[1]\" \"$2]+=b[1]}; END {for (i in bsum) {print bsum[i], i}}' \\ | sort -n | tail -n10 If/When/How to Restart It: You shouldn't ever need to restart Nginx directly. If you suspect something is misconfigured, you can try running site-fcb ${SITE} from the bastion or fields-config-bal.php on the balancer in question which has logic to determine if Nginx needs to be restarted/reloaded.","title":"Nginx"},{"location":"ops_reference/services_overview/#apache","text":"Routes traffic for all sites on a web server to their associated PHP-FPM process. Runs on: web , staging , ded Logs: Apache logs all HTTP requests that a web server gets. These logs are forwarded to Sumologic, so you should use that instead of manually analyzing the access logs if you can. The error log may sometimes be useful for identifying a bad site configuration or other wrongness with a web. /var/log/apache2/access.log /var/log/apache2/error.log If you ever need to analyze the Apache logs, they are formatted nearly identically to the Nginx logs so many of those commands will work for Apache as well. Notable Behaviors: Apache holds at least 3 file descriptors open for every site on a web server. This is important to know for shared servers with many sites, since too many sites (~300) will lead to Apache throwing errors mentioning FD_SETSIZE . If this happens, move sites off the server and ensure any associated active tag (I.e. activestagingra ) is moved to an appropriate alternative server. See also: Provisioning Infrastructure . If/When/How to Restart It: You shouldn't generally need to restart Apache2 manually. If a web server is not responding appropriately, investigate why and, if appropriate, run site-fcw ${SITE} or sv-fcwkick ${SERVER} from the bastion or fields-config-web.php on the web which will ensure customer site code is updated and PHP, Apache, and many other services are running correctly.","title":"Apache"},{"location":"ops_reference/services_overview/#php-fpm","text":"Primary service responsible for serving web requests for each site we host. This is where Drupal and customer site code lives. Runs on: web , staging , ded See Also: Debugging PHP Runbook Fields Custom PHP Docs Logs: Each hosting site on every web server has a directory for their logs, located at /var/log/sites/${SITENAME}/logs/$(hostname -s)/ . This directory contains various logs relevant to the customer's site, which are all accessible to the customer. Many of these logs are rotated by our automation but not all, particularly those which are created and managed by the customer. Notable Behaviors: This service is something of a single-point-of-failure for a customer's site. If it dies or becomes stuck waiting on some resource, the customer's site can go down. Check out the runbook on debugging PHP for more information. If/When/How to Restart It: You should always debug PHP before restarting it blindly. However, because PHP-FPM is so sensitive to customer code, resource limitations, and cosmic rays, there are many situations where restarting this service is reasonable. If you don't know why PHP-FPM is misbehaving, restart it with site-restartfpmwithstrace ${SITE} . Otherwise, you can use site-restartfpm ${SITE} . To ensure customer site code is up to date and that various necessary services are running as well, use site-fcw ${site} .","title":"PHP-FPM"},{"location":"ops_reference/services_overview/#memcached","text":"Key-Value caching layer accessed by PHP-FPM. Runs on: web , staging , ded See Also: Support's Memcached Documentation (RECOMMENDED READING!) Memcached Troubleshooting Cache Evictions Fields Memcached Arch Docs Logs: Memcached does not keep any logs. Notable Behaviors: A web server will only serve memcache if memcached.conf:-m is set to a valid value and memcache_service_status is enabled. esl / esl2 will display a 2 or a green checkmark if memcache_service_status is enabled, 1 or a red X if it is disabled. Some servers, including ODE webs (tagged with ode ), run per-site memcached, where each site has its own memcached instance, secured with SASL. These will appear to PagerDuty alerts and service checks with a name resembling ah-site-memcached@site.name.service and will run on a port other than 11211 . Ops is not responsible for per-site memcached! Any issues involving per-site memcached should be escalated to Cloud against the \"Drupal Hosting\" component via Ops Portal . If/When/How to Restart It: If there is a problem with per-site memcached (see above), escalate to Cloud. If server memcached is not currently running you can use site-fcm ${SITE} on the bastion or fields-config-memcached.php on the server to start it. Ops should not need to restart memcached manually.","title":"Memcached"},{"location":"ops_reference/services_overview/#mysql","text":"Database storage for persistant, relational data. Runs on: staging , ded , fsdb , dbmaster , fsdbmesh , dbmesh See Also: Ops Database Runbooks Fields MySQL Architecture Docs: DNS Audit Logs Memory Allocation Logs: MySQL keeps all its logs in /var/lib/mysql , which should be symlinked to /vol/ebs1/mysql : /var/lib/mysql/$(hostname).err : MySQL error logs, particularly useful when MySQL fails to start. /var/lib/mysql/$(hostname -s)-slow.log : MySQL slow query logs, tracks long-running database queries which may be indicative of performance issues as a result of high traffic or inefficient database queries. Binlogs: logs kept by the master database in a HA pair to describe database changes to be sent to the slave DB for replication. Viewable with: mysqlbinlog ${BINLOG} --base64-output=DECODE-ROWS | less (Often Spammy!) Relaylogs: logs kept by the slave database in a HA pair to track updates it has received from the master, but not yet written to disk. Viewable with: mysqlbinlog ${BINLOG} --base64-output=DECODE-ROWS | less (Often Spammy!) Notable Behaviors: MySQL is protected from being targeted by the OOM-killer. There is a known issue, PF-281 , regarding MySQL memory allocation which may cause MySQL to use more memory than configured. This can lead to OOMing or block hosting releases on affected servers. Some database usage patterns and/or Drupal modules can lead to performance issues via slow queries or bloated cache tables, particularly when hit by a traffic spike. MySQL in ACSF realms does not keep separate databases/tables in individual files! Instead, everything is stored in /var/lib/mysql/ibdata1 . If/When/How to Restart It: Avoid restarting MySQL , as doing so will wipe MySQL cache and can be error prone, potentially causing problems with replication or even data loss if done incorrectly. If you must restart MySQL (I.e. to address memory constraints when no alternatives are available), make sure you follow appropriate failover procedures to reduce impact to site performance.","title":"MySQL"},{"location":"ops_reference/services_overview/#gluster","text":"Distributed filesystem service. Known to cause many headaches and split brains. Runs on: staging , ded , fsdb , fsdbmesh , fs See Also: Ops Gluster Runbooks Support Gluster Docs Fields Filesystem Architecture Docs Logs: All Gluster logs can be found in the /var/log/glusterfs/ directory. Both versions of Gluster write to the following logs: mnt-gfs.log : Logs I nformation, W arnings, and E rrors pertaining to specific inodes on the volume. Errors are often an indication of corrupted, missing, or split-brained files. etc-glusterfs-glusterfsd.vol.log : Logs client/peer connections to the volume, etc. In addition to the above, Gluster 3.4 maintains various other logs which might be useful when diagnosing a problem. Notable Behaviors: Gluster often behaves poorly in response to customers using visual filesystem browsers such as Midnight Commander; which has been known to cause file split-brains and/or corruption. Gluster generally tries to track files by their path, but is known to exhibit unusual behavior if any inode has multiple hard-links to it in the filesystem! When statting such files (I.e. via ls , stat , etc.)... Gluster 3.0 may duplicate the file to a new inode. The stat'd hardlink will point to the new inode, all other hardlinks will point to the old inode. Gluster 3.4 may make a new inode and delete the old one. The stat'd hardlink will point to the updated inode, all other hardlinks will point to a non-existent inode and produce errors when stat'd. Gluster often experiences performance issues when a customer has a large number of files (I.e. 10,000+) in any single directory, particularly if they are using magnetic volumes or SSD volumes smaller than 100GB. If/When/How to Restart It: Restart Gluster any time you have to reboot/relaunch one of the FS servers, or if Gluster is exhibiting problematic behavior. (I.e. site-checkgluster returns errors or an abnormally long gluster time , connection errors in any of the Gluster logs, etc.) It is usually sufficient to run site-fsremount ${SITE} and make sure that every server eventually returns success; any process accessing the filesystem will block a remount. Be Aware: A Gluster 3.4 server may sometimes falsely return success ( 0 ) to the remount command. If symptoms continue to present themselves after a remount, it may be necessary to manually stop and/or kill all Gluster processes on the server before running ah-config-gluster .","title":"Gluster"},{"location":"ops_reference/services_overview/#tungsten","text":"Data replication service which we use for multi-region MySQL clusters. Runs on: fsdbmesh , dbmesh See Also: General Tungsten Administration Custom Tungsten Settings Runbook Tungsten Troubleshooting Fields Tungsten Architecture Docs Logs: Tungsten keeps a service log, /usr/local/tungsten-replicator/tungsten/tungsten-replicator/log/trepsvc.log , which can be helpful when encountering problems with replication or Tungsten not starting properly. Check the Ops Tungsten Runbooks for more information.","title":"Tungsten"},{"location":"ops_reference/services_overview/#secondary-services","text":"","title":"Secondary Services"},{"location":"ops_reference/services_overview/#ah-socketd","text":"Performs socket activation for Unix domain socket daemons for Acquia Cloud-specific needs. This will eventually be replaced by systemd . Occasionally needs to be restarted when PHP misbehaves. Best way to do this is to let puppet agent -t OR in Masterless Puppet mode sudo run-puppet do it or, if the service needs to be manually restarted, service ah-socketd restart .","title":"ah-socketd"},{"location":"ops_reference/services_overview/#collectd","text":"Collects server statistics and sends them to SignalFX.","title":"collectd"},{"location":"ops_reference/services_overview/#cron","text":"Cron job service. We disable this service when we need to make sure Puppet doesn't run on a server for any reason.","title":"cron"},{"location":"ops_reference/services_overview/#exim4","text":"Routes e-mails generated by customer sites for web-forms, user account validation, etc. and routes them to the acquiamail servers in Rackspace.","title":"exim4"},{"location":"ops_reference/services_overview/#nagios","text":"Monitoring service which detects various problems and relays them through our alerting stack for incident response. If a mon server alerts that Nagios is not running, run fields-config-mon.php . If any other server type is reporting Nagios is not running: MON= fssh ${MON} \"sudo sh -c 'service nagios restart && service nagios-nrpe-server restart'\"","title":"Nagios"},{"location":"ops_reference/services_overview/#ossec","text":"Detects issues with system security and intrusion detection.","title":"ossec"},{"location":"ops_reference/services_overview/#pt-heartbeat","text":"Detects disparities in MySQL database replication. If pt-heartbeat is not running: Restart the pt-heartbeat service: service pt-heartbeat restart Check /var/log/syslog for errors. If MySQL errors are reported, run reset-debian-password.sh , then restart pt-heartbeat again.","title":"pt-heartbeat"},{"location":"ops_reference/ssh_between_servers/","text":"SSHing Between Servers We sometimes need to copy files between servers. There are a few methods of doing this: Recommended: sv-rsyncfile Deprecated: Key forwarding Temporary SSH key sv-rsyncfile This is the easiest method for copying files and does not require modification of iptables. SOURCE is the source server and DEST is the destination server. RSYNC_OPTIONS=\"avP\" # You may specify other options for rsync here as appropriate. sv-rsyncfile -o ${RSYNC_OPTIONS} SOURCE:/path/to/file-or-dir DEST:/path/to/dir Key Forwarding This method copies files from one server to another in the same region without any key generation, but keep in mind you are copying data as your user account on TCP:40506. Connect to the source server and view the OUTPUT iptables rules. Note the lack of - or -l when sudo-ing. This is very important for SSH key forwarding. Read man su for more details. sudo su iptables -vnL OUTPUT --line-numbers Surgically remove the rule that is blocking outbound TCP connections to port 40506. RULE_NUM= iptables -D OUTPUT ${RULE_NUM} Copy files with scp or rsync at will. scp -P 40506 /path/to/src ${USER}@dst-server:/path/to/dst/ or rsync -avPe 'ssh -p 40506' --rsync-path=\"/usr/bin/sudo \\ /usr/bin/rsync\" /path/to/src/ ${USER}@dst-server:/path/to/dst/ Add -u to the rsync options if you want to skip files that are newer on the receiver. Fix iptables after you have finished sudo ah-config-iptables Temporary SSH Key Creating a temporary ssh key is preferable for tasks that will take a long time, require multiple people to action a ticket or for where there are multiple steps you would like to happen in a screen session. Creating a temp ssh key also means you don't have to work around the TCP:40506 restriction and you can also move data between regions - TCP:40506 is locked down to single regions. On the source server create a temporary ssh key. 2048 bits is sufficient and we assume that the work you are about to do is being tracked in an OP. sudo su - ssh-keygen -b 2048 -f /root/.ssh/OP-1234 cat ~/.ssh/OP-1234.pub Surgically insert the public key, CAREFULLY, in to the authorized keys file on the destination server as the root user. NOTE: if you mess this up, you may need to re-launch the host. fssh $DEST_SERVER sudo su - vim /root/.ssh/authorized_keys2 Paste in the contents of the pub key inclusive of \"ssh-rsa\" and the server hostname. Including the server hostname makes it obvious to other Ops people that the key was a temporary one. scp or rsync at will scp /path/to/src dst-server:/path/to/dst/ or rsync -avPe 'ssh -i /root/.ssh/OP-1234' \\ /path/to/src/ dst-server:/path/to/dst/ Add -u to the rsync options if you want to skip files that are newer on the receiver. Clean up your by removing the pub key from /root/.ssh/authorized_keys2 on the destination server.","title":"SSHing Between Servers"},{"location":"ops_reference/ssh_between_servers/#sshing-between-servers","text":"We sometimes need to copy files between servers. There are a few methods of doing this: Recommended: sv-rsyncfile Deprecated: Key forwarding Temporary SSH key","title":"SSHing Between Servers"},{"location":"ops_reference/ssh_between_servers/#sv-rsyncfile","text":"This is the easiest method for copying files and does not require modification of iptables. SOURCE is the source server and DEST is the destination server. RSYNC_OPTIONS=\"avP\" # You may specify other options for rsync here as appropriate. sv-rsyncfile -o ${RSYNC_OPTIONS} SOURCE:/path/to/file-or-dir DEST:/path/to/dir","title":"sv-rsyncfile"},{"location":"ops_reference/ssh_between_servers/#key-forwarding","text":"This method copies files from one server to another in the same region without any key generation, but keep in mind you are copying data as your user account on TCP:40506. Connect to the source server and view the OUTPUT iptables rules. Note the lack of - or -l when sudo-ing. This is very important for SSH key forwarding. Read man su for more details. sudo su iptables -vnL OUTPUT --line-numbers Surgically remove the rule that is blocking outbound TCP connections to port 40506. RULE_NUM= iptables -D OUTPUT ${RULE_NUM} Copy files with scp or rsync at will. scp -P 40506 /path/to/src ${USER}@dst-server:/path/to/dst/ or rsync -avPe 'ssh -p 40506' --rsync-path=\"/usr/bin/sudo \\ /usr/bin/rsync\" /path/to/src/ ${USER}@dst-server:/path/to/dst/ Add -u to the rsync options if you want to skip files that are newer on the receiver. Fix iptables after you have finished sudo ah-config-iptables","title":"Key Forwarding"},{"location":"ops_reference/ssh_between_servers/#temporary-ssh-key","text":"Creating a temporary ssh key is preferable for tasks that will take a long time, require multiple people to action a ticket or for where there are multiple steps you would like to happen in a screen session. Creating a temp ssh key also means you don't have to work around the TCP:40506 restriction and you can also move data between regions - TCP:40506 is locked down to single regions. On the source server create a temporary ssh key. 2048 bits is sufficient and we assume that the work you are about to do is being tracked in an OP. sudo su - ssh-keygen -b 2048 -f /root/.ssh/OP-1234 cat ~/.ssh/OP-1234.pub Surgically insert the public key, CAREFULLY, in to the authorized keys file on the destination server as the root user. NOTE: if you mess this up, you may need to re-launch the host. fssh $DEST_SERVER sudo su - vim /root/.ssh/authorized_keys2 Paste in the contents of the pub key inclusive of \"ssh-rsa\" and the server hostname. Including the server hostname makes it obvious to other Ops people that the key was a temporary one. scp or rsync at will scp /path/to/src dst-server:/path/to/dst/ or rsync -avPe 'ssh -i /root/.ssh/OP-1234' \\ /path/to/src/ dst-server:/path/to/dst/ Add -u to the rsync options if you want to skip files that are newer on the receiver. Clean up your by removing the pub key from /root/.ssh/authorized_keys2 on the destination server.","title":"Temporary SSH Key"},{"location":"ops_reference/ssh_search_jumpbox/","text":"Search Jumpboxes Usage Log into an Acquia bastion(bastion-21, bastion-22 or bastion-133). If you haven't already added your search-service credentials to the Search jumpbox, follow these instructions to do so. Set your preferred Search jumpbox name: SEARCH_JUMPBOX=custom-xxxx #use custom-1037 or custom-1048 Elevate your permission into search-service and log into the Search jumpbox. asearch fssh $SEARCH_JUMPBOX In Search jumpbox, again elevate permission into search-service . asearch Note: After syncing credentials - login to the jumpbox server and do asearch to elevate permissions. After asearch the prompt will change into green background instead of the red background in Acquia bastions, so the operator can distinguish between jumpbox and bastion. Now, you can use the Legacy Search related tooling and services inside the jumpbox as usual. 'ops incidents generate' and 'ticket crit' tools wouldn't work under Jumpbox, you can run these tools on other realms under bastion servers (without Jumpbox). Credentials Synchronization Note: Need to do the credentials synchronisation for all jumbox servers. This step has to be done by everyone who wishes to use the jumpbox server as a Search bastion . At the very first login, you will be asked to enter your email address. Please enter the acquia email address. This is just a one time requirement. Log into either bastion-21, bastion-22 or bastion-133 and go to $SECURE/ec2 directory. ssh bastion cd $SECURE\\ec2 Create a zip file of the subdirectory search-service there. zip -r search-service.zip search-service SCP this file into the jumpbox server. SEARCH_JUMPBOX=<eg: custom-xxxx> #use custom-1037 or custom-1048 scp -P 40506 -i $SECURE/ec2/search-service/ssh/default search-service.zip \\ $USER@$SEARCH_JUMPBOX.search-service.hosting.acquia.com:~ Now, log into the jumpbox server and extract the search-service.zip into $SECURE/ec2 directory of that server. asearch fssh $SEARCH_JUMPBOX unzip search-service.zip -d $SECURE/ec2 rm -f search-service.zip Change permissions of the extracted content for security reasons. chmod 700 $SECURE/ec2/search-service","title":"Search Jumpboxes"},{"location":"ops_reference/ssh_search_jumpbox/#search-jumpboxes","text":"","title":"Search Jumpboxes"},{"location":"ops_reference/ssh_search_jumpbox/#usage","text":"Log into an Acquia bastion(bastion-21, bastion-22 or bastion-133). If you haven't already added your search-service credentials to the Search jumpbox, follow these instructions to do so. Set your preferred Search jumpbox name: SEARCH_JUMPBOX=custom-xxxx #use custom-1037 or custom-1048 Elevate your permission into search-service and log into the Search jumpbox. asearch fssh $SEARCH_JUMPBOX In Search jumpbox, again elevate permission into search-service . asearch Note: After syncing credentials - login to the jumpbox server and do asearch to elevate permissions. After asearch the prompt will change into green background instead of the red background in Acquia bastions, so the operator can distinguish between jumpbox and bastion. Now, you can use the Legacy Search related tooling and services inside the jumpbox as usual. 'ops incidents generate' and 'ticket crit' tools wouldn't work under Jumpbox, you can run these tools on other realms under bastion servers (without Jumpbox).","title":"Usage"},{"location":"ops_reference/ssh_search_jumpbox/#credentials-synchronization","text":"Note: Need to do the credentials synchronisation for all jumbox servers. This step has to be done by everyone who wishes to use the jumpbox server as a Search bastion . At the very first login, you will be asked to enter your email address. Please enter the acquia email address. This is just a one time requirement. Log into either bastion-21, bastion-22 or bastion-133 and go to $SECURE/ec2 directory. ssh bastion cd $SECURE\\ec2 Create a zip file of the subdirectory search-service there. zip -r search-service.zip search-service SCP this file into the jumpbox server. SEARCH_JUMPBOX=<eg: custom-xxxx> #use custom-1037 or custom-1048 scp -P 40506 -i $SECURE/ec2/search-service/ssh/default search-service.zip \\ $USER@$SEARCH_JUMPBOX.search-service.hosting.acquia.com:~ Now, log into the jumpbox server and extract the search-service.zip into $SECURE/ec2 directory of that server. asearch fssh $SEARCH_JUMPBOX unzip search-service.zip -d $SECURE/ec2 rm -f search-service.zip Change permissions of the extracted content for security reasons. chmod 700 $SECURE/ec2/search-service","title":"Credentials Synchronization"},{"location":"ops_reference/strace/","text":"Using strace Basic strace Usage strace displays all system calls and signals made by a running process. By recognizing patterns in the output of strace we can get a sense of what the process is doing internally (and why it might be stuck). strace 's default output is very spammy and difficult to lurk through. You can modify its output by ignoring certain types of system calls that are not relevant to problems, such as gettimeofday and clock_gettime . strace can also provide a useful summary of all the system calls made while the process was being traced. For example: strace -e trace='!gettimeofday,clock_gettime' -C -tt -T -p <pid> Use CTRL-C to stop tracing. Sample output: [21:41:07] root@web-13634.prod:~# strace -e trace='!gettimeofday,clock_gettime' -C -tt -T -p 14871 strace: Process 14871 attached 21:41:33.827578 recvfrom(3, \"n/docroot/core/lib/Drupal/Core/P\"..., 9198, 0, NULL, NULL) = 9198 <0.008434> 21:41:33.836293 write(1, \"ocroot/core/lib/Drupal/Core/Even\"..., 4096) = 4096 <0.000069> ... thousands of lines of system calls ... 21:41:37.542466 write(1, \"ernal function]: _drupal_error_h\"..., 12288) = 12288 <0.000056> 21:41:37.542666 recvfrom(3, \"\\3455\\0c\\01040394426\\0010\\3phpE%type: @mess\"..., 16384, 0, NULL, NULL) = 5904 <0.000053> 21:41:37.542805 recvfrom(3, ^Cstrace: Process 14871 detached <detached ...> % time seconds usecs/call calls errors syscall ------ ----------- ----------- --------- --------- ---------------- 100.00 0.004053 4 1015 recvfrom 0.00 0.000000 0 1098 write ------ ----------- ----------- --------- --------- ---------------- 100.00 0.004053 2113 total Note that you can use strace on any running process. If you need to save the output, use -o <filename> and attach the file to the Jira ticket with an explanation of what the output is telling you. You are strongly encouraged to review man strace to see all available options. Particularly using -p to trace multiple processes. You may also use -f to trace a site's master php-fpm process and all children forked from the traced process; you may need to allow the trace to run for a minute or two to capture the output of forked processes. Interpreting strace Output Certain types of system calls are more relevant to diagnosing problems than others. For example, we suggest ignoring gettimeofday and clock_gettime because these are never the root cause of problems in PHP. Most PHP-FPM problems arise from I/O system calls. read , write : Read/write data to a local file. poll , select : wait for some event on a file (usually waiting for a file to be ready for I/O) stat : Check for the existence or status of a local file. recv , recvfrom , recvmsg : Receive a message from a socket. send , sendto , sendmsg : Send a message on a socket. PHP may use this when it's sending a query to MySQL or data to an external resource wait4 : Wait for another process to change state. This means PHP is waiting for another running process to finish execution. This can cause problems if the other process is also stuck or causing heavy load on a resource. If you find a system call not listed here that you are not familiar with, you can get more information about it by referencing section 2 of the man pages, which covers system calls. For example, man 2 poll . If this doesn't return the right page, search for the system call with apropos -s 2 <sys_call_name> . Various strace usage during training exercise ref OP-290328","title":"Using `strace`"},{"location":"ops_reference/strace/#using-strace","text":"","title":"Using strace"},{"location":"ops_reference/strace/#basic-strace-usage","text":"strace displays all system calls and signals made by a running process. By recognizing patterns in the output of strace we can get a sense of what the process is doing internally (and why it might be stuck). strace 's default output is very spammy and difficult to lurk through. You can modify its output by ignoring certain types of system calls that are not relevant to problems, such as gettimeofday and clock_gettime . strace can also provide a useful summary of all the system calls made while the process was being traced. For example: strace -e trace='!gettimeofday,clock_gettime' -C -tt -T -p <pid> Use CTRL-C to stop tracing. Sample output: [21:41:07] root@web-13634.prod:~# strace -e trace='!gettimeofday,clock_gettime' -C -tt -T -p 14871 strace: Process 14871 attached 21:41:33.827578 recvfrom(3, \"n/docroot/core/lib/Drupal/Core/P\"..., 9198, 0, NULL, NULL) = 9198 <0.008434> 21:41:33.836293 write(1, \"ocroot/core/lib/Drupal/Core/Even\"..., 4096) = 4096 <0.000069> ... thousands of lines of system calls ... 21:41:37.542466 write(1, \"ernal function]: _drupal_error_h\"..., 12288) = 12288 <0.000056> 21:41:37.542666 recvfrom(3, \"\\3455\\0c\\01040394426\\0010\\3phpE%type: @mess\"..., 16384, 0, NULL, NULL) = 5904 <0.000053> 21:41:37.542805 recvfrom(3, ^Cstrace: Process 14871 detached <detached ...> % time seconds usecs/call calls errors syscall ------ ----------- ----------- --------- --------- ---------------- 100.00 0.004053 4 1015 recvfrom 0.00 0.000000 0 1098 write ------ ----------- ----------- --------- --------- ---------------- 100.00 0.004053 2113 total Note that you can use strace on any running process. If you need to save the output, use -o <filename> and attach the file to the Jira ticket with an explanation of what the output is telling you. You are strongly encouraged to review man strace to see all available options. Particularly using -p to trace multiple processes. You may also use -f to trace a site's master php-fpm process and all children forked from the traced process; you may need to allow the trace to run for a minute or two to capture the output of forked processes.","title":"Basic strace Usage"},{"location":"ops_reference/strace/#interpreting-strace-output","text":"Certain types of system calls are more relevant to diagnosing problems than others. For example, we suggest ignoring gettimeofday and clock_gettime because these are never the root cause of problems in PHP. Most PHP-FPM problems arise from I/O system calls. read , write : Read/write data to a local file. poll , select : wait for some event on a file (usually waiting for a file to be ready for I/O) stat : Check for the existence or status of a local file. recv , recvfrom , recvmsg : Receive a message from a socket. send , sendto , sendmsg : Send a message on a socket. PHP may use this when it's sending a query to MySQL or data to an external resource wait4 : Wait for another process to change state. This means PHP is waiting for another running process to finish execution. This can cause problems if the other process is also stuck or causing heavy load on a resource. If you find a system call not listed here that you are not familiar with, you can get more information about it by referencing section 2 of the man pages, which covers system calls. For example, man 2 poll . If this doesn't return the right page, search for the system call with apropos -s 2 <sys_call_name> .","title":"Interpreting strace Output"},{"location":"ops_reference/strace/#various-strace-usage-during-training-exercise-ref-op-290328","text":"","title":"Various strace usage during training exercise ref OP-290328"},{"location":"realm_management/","text":"Realm Management Audit Data Backup Audit Data Backup Log Set filename variable Create Server List Data Backup Logs Clock SCP Audit IPtables Security Groups Audit IPtables Security Groups Set filename variable Create Server List NGINX IPTABLES Security Groups SCP Audit Services Protocols Ports Audit Services Protocols Ports Set filename variable Create Server List NETSTAT Systemctl SCP Audit Sudoers Audit Sudoers Set filename variable Create Server List SUDOERS SCP Audit User Access User Access Audit Set filename variable Tooling to generate the report: admin-userreport Bastion YubiKey Access List MNTFS Volume Reaping Reaping of Unused /mnt EBS Volumes Step 1: Switch to required stage in Bastion Step 2: Create directory to store interim files used for reaping Step 3: Find volumes that are tagged with ah_terminated Step 4: List the volumes that are tagged with ah_terminated Step 5: Reap the /mnt mounting unsued volumes that are tagged with ah_terminated Mysql Restarts MySQL Restart Mass Process Servers with no replication One-off Procedure Servers with replication Preparation Procedure Cleanup Patching Mass patching Preparation Ensure hosts have enough free inodes on root filesystem Patching search Restart services if OpenSSL was updated Verification Backup Servers Reboot Backup Servers Prerequisites Procedure Balancer Balancer Mass Reboots / Relaunches General Information Procedure Important Notes Preparation Reboot / Relaunch Balancers Standard Balancers Singleton Balancers Non-Standard Balancers Control Plane Control Plane Non-Customer-Impacting Hosts: dns , ossec , stats , log Rebooting or Relaunching DNS ( dns ) Rebooting or Relaunching OSSEC ( ossec ) Rebooting or Relaunching STATS ( stats ) Rebooting or Relaunching LOG ( log ) Rebooting or Relaunching Monitoring Hosts ( mon , monui , sitemon ) Customer-Impacting Hosts: svn Rebooting or Relaunching SVN Hosts ( svn ) Custom Servers Custom servers ( custom ) Databases Database Mass Reboot/Relaunch General Information Procedure Important Notes Preparation Reboot or Relaunch Database Clusters Cleanup Workflow Errors Databases (Manual) Databases (dbmaster, ded, fsdb) Summary Filesystem Servers Filesystem Server Mass Reboot/Relaunch Preparation Important Note Ensure Gluster Mounts Reboot/Relaunch FS Servers Cleanup Workflow errors Filesystem Servers (Manual) Filesystem Server Mass Reboot/Relaunch - Manual Preparation Ensure Gluster Mounts Reboot/Relaunch FS Servers Cleanup Non-HA Servers Customer Non-HA Servers ( free , srv , staging , api ) Task Servers Task Servers Prerequisites Procedure Tungsten Multiregion Database Mass Reboot/Relaunch Overview Procedure Important Notes Preparation Reboot Secondary Multiregion Databases Failover to Secondary Multiregion Databases Reboot Primary Multiregion Databases Failover to Primary Multiregion Databases Cleanup webs Webs ( web ) Important Note Reboots using AWS Method Workflow Errors Dealing with Workflow errors Retry Workflow Aborting a workflow Important Note Some Specific Workflow Fixes SSH Disconnect Gluster Failed Workflow Launch Task Times Out Workflow Hit Ruby Threading Bug Workflow Hit Invalid VCS Path Provision New Region Provision New Region Init Preparation Procedure Import the public key into the new region Create the shared vpc Launch a mon Launch a dns Launch a log cluster Launch a ossec Launch a svn Launch a shared production bal pair and a shared non-production bal pair - ACE only Launch a shared staging server - ACE only Reboot Balancers Reboot Bals Using Workflow Variable setup Reboot bals Reboot Master Reboot a Master Find the master Rebooting Post Reboot Reboot Search Mass Rebooting Search Servers Prequisites Patching Rebooting All Servers Rebooting All Servers By Region Rebooting a Subset of Servers Rebooting the Master Troubleshooting Disabling monitoring failed Squelching of index checks failed Server patching fails Server reboot failed Server fails to register with the Governor Rake rebuild fails Index unsquelch fails Re-enabling monitoring fails Reboot command errors out Rebooting & Relaunching Mass Rebooting and Relaunching Procedure Overview Table of Contents IMPORTANT NOTES The bulk-reboot Workflow Monitoring Tasks and Workflows Important Note Credentials Scheduling maintenance for AMI type Change OS Upgrades Preparation Rebooting or Relaunching CPLANE ( dns , ossec , stats , log , svn ) Customer Non-HA Servers ( free , srv , staging , api ) Balancers ( bal ) Databases ( ded , fsdb , dbmaster ) Filesystem-only servers ( fs ) Tungsten Multiregion servers ( fsdbmesh , dbmesh ) Webs ( managed , web ) Custom servers ( custom ) Search Servers ( nxephem , javasrv , javaephem ) Dealing with Workflow errors Auditing TODO: Check version of kernel and important packages updated. Relaunch Instances Relaunch Instances Pre-Relaunch Steps Web Class (ded,managed,staging,web) FS Class (ded,fs,fsdb,fsdbmesh,staging) DB Class (ded,fsdb,fsdbmesh,dbmaster) Relaunching Procedures Relaunching Failed Instances Normal Relaunch Task Relaunch Local Relaunch Forced Relaunch Post checks after successful relaunch(Mandatory) Relaunch Backup Backup Server Relaunch Bugs Backup Credentials Rogue EBS Volumes Relaunch Balancers Relaunch Bals Using Workflow Variable setup Relaunch bals Relaunch Master Relaunch a Master Setting up the variables Prepare for relaunch Relaunch Post relaunch Terminating the old master Rollback relaunch and switch back to previous master Relaunch Master (manual) Relaunch a Master (manual process) Find the master Relaunch During Relaunch Post Relaunch Relaunch Search Mass Relaunching Search Servers Relaunching All Servers by Region Relaunching a Subset of Servers Notes Site Config Changes Bulk config settings changes Procedure Verification Volume Relaunch_fix Volume Relaunch Fix Applicable Situations Diagnosing the condition Workaround Cleanup Webs (manual) Manual Reboot or Relaunch Webs( api , web ) Procedure - Web","title":"Realm Management"},{"location":"realm_management/#realm-management","text":"","title":"Realm Management"},{"location":"realm_management/#audit-data-backup","text":"Audit Data Backup Log Set filename variable Create Server List Data Backup Logs Clock SCP","title":"Audit Data Backup"},{"location":"realm_management/#audit-iptables-security-groups","text":"Audit IPtables Security Groups Set filename variable Create Server List NGINX IPTABLES Security Groups SCP","title":"Audit IPtables Security Groups"},{"location":"realm_management/#audit-services-protocols-ports","text":"Audit Services Protocols Ports Set filename variable Create Server List NETSTAT Systemctl SCP","title":"Audit Services Protocols Ports"},{"location":"realm_management/#audit-sudoers","text":"Audit Sudoers Set filename variable Create Server List SUDOERS SCP","title":"Audit Sudoers"},{"location":"realm_management/#audit-user-access","text":"User Access Audit Set filename variable Tooling to generate the report: admin-userreport Bastion YubiKey Access List","title":"Audit User Access"},{"location":"realm_management/#mntfs-volume-reaping","text":"Reaping of Unused /mnt EBS Volumes Step 1: Switch to required stage in Bastion Step 2: Create directory to store interim files used for reaping Step 3: Find volumes that are tagged with ah_terminated Step 4: List the volumes that are tagged with ah_terminated Step 5: Reap the /mnt mounting unsued volumes that are tagged with ah_terminated","title":"MNTFS Volume Reaping"},{"location":"realm_management/#mysql-restarts","text":"MySQL Restart Mass Process Servers with no replication One-off Procedure Servers with replication Preparation Procedure Cleanup","title":"Mysql Restarts"},{"location":"realm_management/#patching","text":"Mass patching Preparation Ensure hosts have enough free inodes on root filesystem Patching search Restart services if OpenSSL was updated Verification","title":"Patching"},{"location":"realm_management/#backup-servers","text":"Reboot Backup Servers Prerequisites Procedure","title":"Backup Servers"},{"location":"realm_management/#balancer","text":"Balancer Mass Reboots / Relaunches General Information Procedure Important Notes Preparation Reboot / Relaunch Balancers Standard Balancers Singleton Balancers Non-Standard Balancers","title":"Balancer"},{"location":"realm_management/#control-plane","text":"Control Plane Non-Customer-Impacting Hosts: dns , ossec , stats , log Rebooting or Relaunching DNS ( dns ) Rebooting or Relaunching OSSEC ( ossec ) Rebooting or Relaunching STATS ( stats ) Rebooting or Relaunching LOG ( log ) Rebooting or Relaunching Monitoring Hosts ( mon , monui , sitemon ) Customer-Impacting Hosts: svn Rebooting or Relaunching SVN Hosts ( svn )","title":"Control Plane"},{"location":"realm_management/#custom-servers","text":"Custom servers ( custom )","title":"Custom Servers"},{"location":"realm_management/#databases","text":"Database Mass Reboot/Relaunch General Information Procedure Important Notes Preparation Reboot or Relaunch Database Clusters Cleanup Workflow Errors","title":"Databases"},{"location":"realm_management/#databases-manual","text":"Databases (dbmaster, ded, fsdb) Summary","title":"Databases (Manual)"},{"location":"realm_management/#filesystem-servers","text":"Filesystem Server Mass Reboot/Relaunch Preparation Important Note Ensure Gluster Mounts Reboot/Relaunch FS Servers Cleanup Workflow errors","title":"Filesystem Servers"},{"location":"realm_management/#filesystem-servers-manual","text":"Filesystem Server Mass Reboot/Relaunch - Manual Preparation Ensure Gluster Mounts Reboot/Relaunch FS Servers Cleanup","title":"Filesystem Servers (Manual)"},{"location":"realm_management/#non-ha-servers","text":"Customer Non-HA Servers ( free , srv , staging , api )","title":"Non-HA Servers"},{"location":"realm_management/#task-servers","text":"Task Servers Prerequisites Procedure","title":"Task Servers"},{"location":"realm_management/#tungsten","text":"Multiregion Database Mass Reboot/Relaunch Overview Procedure Important Notes Preparation Reboot Secondary Multiregion Databases Failover to Secondary Multiregion Databases Reboot Primary Multiregion Databases Failover to Primary Multiregion Databases Cleanup","title":"Tungsten"},{"location":"realm_management/#webs","text":"Webs ( web ) Important Note","title":"webs"},{"location":"realm_management/#reboots-using-aws-method","text":"","title":"Reboots using AWS Method"},{"location":"realm_management/#workflow-errors","text":"Dealing with Workflow errors Retry Workflow Aborting a workflow Important Note Some Specific Workflow Fixes SSH Disconnect Gluster Failed Workflow Launch Task Times Out Workflow Hit Ruby Threading Bug Workflow Hit Invalid VCS Path","title":"Workflow Errors"},{"location":"realm_management/#provision-new-region","text":"Provision New Region Init Preparation Procedure Import the public key into the new region Create the shared vpc Launch a mon Launch a dns Launch a log cluster Launch a ossec Launch a svn Launch a shared production bal pair and a shared non-production bal pair - ACE only Launch a shared staging server - ACE only","title":"Provision New Region"},{"location":"realm_management/#reboot-balancers","text":"Reboot Bals Using Workflow Variable setup Reboot bals","title":"Reboot Balancers"},{"location":"realm_management/#reboot-master","text":"Reboot a Master Find the master Rebooting Post Reboot","title":"Reboot Master"},{"location":"realm_management/#reboot-search","text":"Mass Rebooting Search Servers Prequisites Patching Rebooting All Servers Rebooting All Servers By Region Rebooting a Subset of Servers Rebooting the Master Troubleshooting Disabling monitoring failed Squelching of index checks failed Server patching fails Server reboot failed Server fails to register with the Governor Rake rebuild fails Index unsquelch fails Re-enabling monitoring fails Reboot command errors out","title":"Reboot Search"},{"location":"realm_management/#rebooting-relaunching","text":"Mass Rebooting and Relaunching Procedure Overview Table of Contents IMPORTANT NOTES The bulk-reboot Workflow Monitoring Tasks and Workflows Important Note Credentials Scheduling maintenance for AMI type Change OS Upgrades Preparation Rebooting or Relaunching CPLANE ( dns , ossec , stats , log , svn ) Customer Non-HA Servers ( free , srv , staging , api ) Balancers ( bal ) Databases ( ded , fsdb , dbmaster ) Filesystem-only servers ( fs ) Tungsten Multiregion servers ( fsdbmesh , dbmesh ) Webs ( managed , web ) Custom servers ( custom ) Search Servers ( nxephem , javasrv , javaephem ) Dealing with Workflow errors Auditing TODO: Check version of kernel and important packages updated.","title":"Rebooting &amp; Relaunching"},{"location":"realm_management/#relaunch-instances","text":"Relaunch Instances Pre-Relaunch Steps Web Class (ded,managed,staging,web) FS Class (ded,fs,fsdb,fsdbmesh,staging) DB Class (ded,fsdb,fsdbmesh,dbmaster) Relaunching Procedures Relaunching Failed Instances Normal Relaunch Task Relaunch Local Relaunch Forced Relaunch Post checks after successful relaunch(Mandatory)","title":"Relaunch Instances"},{"location":"realm_management/#relaunch-backup","text":"Backup Server Relaunch Bugs Backup Credentials Rogue EBS Volumes","title":"Relaunch Backup"},{"location":"realm_management/#relaunch-balancers","text":"Relaunch Bals Using Workflow Variable setup Relaunch bals","title":"Relaunch Balancers"},{"location":"realm_management/#relaunch-master","text":"Relaunch a Master Setting up the variables Prepare for relaunch Relaunch Post relaunch Terminating the old master Rollback relaunch and switch back to previous master","title":"Relaunch Master"},{"location":"realm_management/#relaunch-master-manual","text":"Relaunch a Master (manual process) Find the master Relaunch During Relaunch Post Relaunch","title":"Relaunch Master (manual)"},{"location":"realm_management/#relaunch-search","text":"Mass Relaunching Search Servers Relaunching All Servers by Region Relaunching a Subset of Servers Notes","title":"Relaunch Search"},{"location":"realm_management/#site-config-changes","text":"Bulk config settings changes Procedure Verification","title":"Site Config Changes"},{"location":"realm_management/#volume-relaunch_fix","text":"Volume Relaunch Fix Applicable Situations Diagnosing the condition Workaround Cleanup","title":"Volume Relaunch_fix"},{"location":"realm_management/#webs-manual","text":"Manual Reboot or Relaunch Webs( api , web ) Procedure - Web","title":"Webs (manual)"},{"location":"realm_management/audit_data_backup/","text":"Audit Data Backup Log InfoSec group will request lists that Operations group provides. The Jira ticket is typically titled \"Audit Request - Example Data Backup Log\". Generate the files containing the lists. The titles for files are typically ACE_Data_Backup_Log.txt ACSF_Data_Backup_Log.txt and the request could be for other realms as well. A common step will be to scp a file to your local machine,attach to Jira ticket,delete from local machine and bastion. Set filename variable if [ \"$FIELDS_STAGE\" == 'prod' ] ; then STAGE=ACE; \\ elif [ \"$FIELDS_STAGE\" == 'enterprise-g1' ] ; then STAGE=ACSF; \\ else STAGE=$(echo ${FIELDS_STAGE} | sed -e 's/-//g'); fi JIRA= mkdir /mnt/ahops/tmp/${USER}/${JIRA}/ Create Server List The ticket will always provide a reasonable short list of servers. Put a list of them into variables. declare -a SERVERS=(ded-12316 ded-12317 ded-12341 ded-12342) SERVERS_CSV=$(array-csv ${SERVERS[@]}) Review if any server not status 0 ah-server list $SERVERS_CSV -w status!=0 Determine if a server not status 0 will be status 0 soon. Example: wait for a launch to finish its transition from status 2 to 0. If not status 0 servers continues, comment about it in JIRA ticket as the auditors will be interested in providing a replacement server for the one not available. Data Backup Logs (echo \"For $SERVERS;date;ah-backup list-run\" \\ && for ser in ${SERVERS[@]};do date;echo $ser; \\ ah-backup list-runs $ser;done) \\ | tee /mnt/ahops/tmp/${USER}/${JIRA}/${STAGE}_Data_Backup_Log.txt Clock Place the bastion terminal and a clock and date application inside a screen capture window on the computer screen. Take the screen snapshot and save to a file to local machine, attach to Jira ticket and delete file. As example, shift-command-4 on a YR2019 MAC/OS will capture a screen. The request is to know when the data was pulled. The current scroll of the bastion terminal screen itself needs to only show partial data, you will always be providing a complete file of data pulled. SCP scp files to your local machine,attach to Jira ticket,delete from local machine and bastion.","title":"Audit Data Backup Log"},{"location":"realm_management/audit_data_backup/#audit-data-backup-log","text":"InfoSec group will request lists that Operations group provides. The Jira ticket is typically titled \"Audit Request - Example Data Backup Log\". Generate the files containing the lists. The titles for files are typically ACE_Data_Backup_Log.txt ACSF_Data_Backup_Log.txt and the request could be for other realms as well. A common step will be to scp a file to your local machine,attach to Jira ticket,delete from local machine and bastion.","title":"Audit Data Backup Log"},{"location":"realm_management/audit_data_backup/#set-filename-variable","text":"if [ \"$FIELDS_STAGE\" == 'prod' ] ; then STAGE=ACE; \\ elif [ \"$FIELDS_STAGE\" == 'enterprise-g1' ] ; then STAGE=ACSF; \\ else STAGE=$(echo ${FIELDS_STAGE} | sed -e 's/-//g'); fi JIRA= mkdir /mnt/ahops/tmp/${USER}/${JIRA}/","title":"Set filename variable"},{"location":"realm_management/audit_data_backup/#create-server-list","text":"The ticket will always provide a reasonable short list of servers. Put a list of them into variables. declare -a SERVERS=(ded-12316 ded-12317 ded-12341 ded-12342) SERVERS_CSV=$(array-csv ${SERVERS[@]}) Review if any server not status 0 ah-server list $SERVERS_CSV -w status!=0 Determine if a server not status 0 will be status 0 soon. Example: wait for a launch to finish its transition from status 2 to 0. If not status 0 servers continues, comment about it in JIRA ticket as the auditors will be interested in providing a replacement server for the one not available.","title":"Create Server List"},{"location":"realm_management/audit_data_backup/#data-backup-logs","text":"(echo \"For $SERVERS;date;ah-backup list-run\" \\ && for ser in ${SERVERS[@]};do date;echo $ser; \\ ah-backup list-runs $ser;done) \\ | tee /mnt/ahops/tmp/${USER}/${JIRA}/${STAGE}_Data_Backup_Log.txt","title":"Data Backup Logs"},{"location":"realm_management/audit_data_backup/#clock","text":"Place the bastion terminal and a clock and date application inside a screen capture window on the computer screen. Take the screen snapshot and save to a file to local machine, attach to Jira ticket and delete file. As example, shift-command-4 on a YR2019 MAC/OS will capture a screen. The request is to know when the data was pulled. The current scroll of the bastion terminal screen itself needs to only show partial data, you will always be providing a complete file of data pulled.","title":"Clock"},{"location":"realm_management/audit_data_backup/#scp","text":"scp files to your local machine,attach to Jira ticket,delete from local machine and bastion.","title":"SCP"},{"location":"realm_management/audit_iptables_sgroups/","text":"Audit IPtables Security Groups InfoSec will request lists that operations provides. The Jira ticket is typically titled \"Audit Request - IPtables & AWS Security Groups\". Generate the files containing the lists. The titles for files are typically ACE_Balancers_iptables.txt ACE_Balancers_nginx_config.txt ACE_Balancers_Security_groups.txt ACE_Non_Balancers_iptables.txt ACE_Non_Balancers_Security_groups.txt and the request could be for other realms as well. A common step will be to scp a file to your local machine,attach to Jira ticket,delete from local machine and bastion. Set filename variable if [ \"$FIELDS_STAGE\" == 'prod' ] ; then STAGE=ACE; \\ elif [ \"$FIELDS_STAGE\" == 'enterprise-g1' ] ; then STAGE=ACSF; \\ else STAGE=$(echo ${FIELDS_STAGE} | sed -e 's/-//g'); fi JIRA= mkdir /mnt/ahops/tmp/${USER}/${JIRA}/ Create Server List The ticket will always provide a reasonable short list of servers. Put a list of them into variables. BALANCERS_CSV=bal-20331,bal-12324,bal-15407 NON_BALANCERS_CSV=fsdbmesh-22793,web-22802 Review if any server not status 0 ah-server list $BALANCERS_CSV -w status!=0 Determine if a server not status 0 will be status 0 soon. Example: wait for a launch to finish its transition from status 2 to 0. If not status 0 servers continues, comment about it in JIRA ticket as the auditors will be interested in providing a replacement server for the one not available. NGINX (echo \"fpdsh -l $BALANCERS_CSV -p 1 -c \"cat /etc/nginx/nginx.conf\"\" \\ && fpdsh -l $BALANCERS_CSV -p 1 -c \"cat /etc/nginx/nginx.conf\") | tee /mnt/ahops/tmp/${USER}/${JIRA}/${STAGE}_Balancers_nginx_conf.txt IPTABLES (echo \"fpdsh -l $BALANCERS_CSV -p 1 -c \"sudo iptables -L\"\" \\ && fpdsh -l $BALANCERS_CSV -p 1 -c \"sudo iptables -L\") | tee /mnt/ahops/tmp/${USER}/${JIRA}/${STAGE}_Balancers_iptables.txt (echo \"fpdsh -l $NON_BALANCERS_CSV -p 1 -c \"sudo iptables -L\"\" \\ && fpdsh -l $NON_BALANCERS_CSV -p 1 -c \"sudo iptables -L\") | tee /mnt/ahops/tmp/${USER}/${JIRA}/${STAGE}_Non_Balancers_iptables.txt Security Groups List Instance ids (echo \"=== Listing Instance ids and region whose status is 0 ===\" \\ && ah-server list $BALANCERS_CSV -w status=0 -c ec2_id ec2_region | sort -k 3 ) \\ | tee /mnt/ahops/tmp/${USER}/${JIRA}/${STAGE}_Balancers_Security_groups.txt (echo \"=== Listing Instance ids and region whose status is 0 ===\" \\ && ah-server list $NON_BALANCERS_CSV -w status=0 -c ec2_id ec2_region | sort -k 3 ) \\ | tee /mnt/ahops/tmp/${USER}/${JIRA}/${STAGE}_Non_Balancers_Security_groups.txt List Security Group Repeat for each region observed in last step. REGION= The instances in the region: BAL_INSTANCES=($(ah-server list $BALANCERS_CSV -w ec2_region=$REGION --no-name -c ec2_id|paste -sd \" \")) NON_BAL_INSTANCES=($(ah-server list $NON_BALANCERS_CSV -w ec2_region=$REGION --no-name -c ec2_id|paste -sd \" \")) (echo;echo \"=== $REGION, Listing all the security group ids associated with each ec2 instance\" \\ && aws ec2 describe-instances --instance-ids ${BAL_INSTANCES[@]} --region $REGION --query 'Reservations[*].Instances[*].[SecurityGroups[*].GroupId]' \\ --output text | awk 'BEGIN { OFS=\"\\n\"}; {$1=$1; print $0 }' | sort | uniq) \\ | tee -a /mnt/ahops/tmp/${USER}/${JIRA}/${STAGE}_Balancers_Security_groups.txt (echo;echo \"=== $REGION, Listing all the security group ids associated with each ec2 instance\" \\ && aws ec2 describe-instances --instance-ids ${NON_BAL_INSTANCES[@]} --region $REGION --query 'Reservations[*].Instances[*].[SecurityGroups[*].GroupId]' \\ --output text | awk 'BEGIN { OFS=\"\\n\"}; {$1=$1; print $0 }' | sort | uniq) \\ | tee -a /mnt/ahops/tmp/${USER}/${JIRA}/${STAGE}_Non_Balancers_Security_groups.txt Details of each security group Repeat for each region. REGION= The security group in the region: SG_BAL=\"sg-22a16458 sg-9220d0fb sg-dea164a4\" SG_NON= (echo;echo \"=== $REGION, Details of each security group\" \\ && aws ec2 describe-security-groups --group-ids ${SG_BAL[@]} --region $REGION) \\ | tee -a /mnt/ahops/tmp/${USER}/${JIRA}/${STAGE}_Balancers_Security_groups.txt (echo;echo \"=== $REGION, Details of each security group\" \\ && aws ec2 describe-security-groups --group-ids ${SG_NON[@]} --region $REGION) \\ | tee -a /mnt/ahops/tmp/${USER}/${JIRA}/${STAGE}_Non_Balancers_Security_groups.txt SCP scp files to your local machine,attach to Jira ticket,delete from local machine and bastion.","title":"Audit IPtables Security Groups"},{"location":"realm_management/audit_iptables_sgroups/#audit-iptables-security-groups","text":"InfoSec will request lists that operations provides. The Jira ticket is typically titled \"Audit Request - IPtables & AWS Security Groups\". Generate the files containing the lists. The titles for files are typically ACE_Balancers_iptables.txt ACE_Balancers_nginx_config.txt ACE_Balancers_Security_groups.txt ACE_Non_Balancers_iptables.txt ACE_Non_Balancers_Security_groups.txt and the request could be for other realms as well. A common step will be to scp a file to your local machine,attach to Jira ticket,delete from local machine and bastion.","title":"Audit IPtables Security Groups"},{"location":"realm_management/audit_iptables_sgroups/#set-filename-variable","text":"if [ \"$FIELDS_STAGE\" == 'prod' ] ; then STAGE=ACE; \\ elif [ \"$FIELDS_STAGE\" == 'enterprise-g1' ] ; then STAGE=ACSF; \\ else STAGE=$(echo ${FIELDS_STAGE} | sed -e 's/-//g'); fi JIRA= mkdir /mnt/ahops/tmp/${USER}/${JIRA}/","title":"Set filename variable"},{"location":"realm_management/audit_iptables_sgroups/#create-server-list","text":"The ticket will always provide a reasonable short list of servers. Put a list of them into variables. BALANCERS_CSV=bal-20331,bal-12324,bal-15407 NON_BALANCERS_CSV=fsdbmesh-22793,web-22802 Review if any server not status 0 ah-server list $BALANCERS_CSV -w status!=0 Determine if a server not status 0 will be status 0 soon. Example: wait for a launch to finish its transition from status 2 to 0. If not status 0 servers continues, comment about it in JIRA ticket as the auditors will be interested in providing a replacement server for the one not available.","title":"Create Server List"},{"location":"realm_management/audit_iptables_sgroups/#nginx","text":"(echo \"fpdsh -l $BALANCERS_CSV -p 1 -c \"cat /etc/nginx/nginx.conf\"\" \\ && fpdsh -l $BALANCERS_CSV -p 1 -c \"cat /etc/nginx/nginx.conf\") | tee /mnt/ahops/tmp/${USER}/${JIRA}/${STAGE}_Balancers_nginx_conf.txt","title":"NGINX"},{"location":"realm_management/audit_iptables_sgroups/#iptables","text":"(echo \"fpdsh -l $BALANCERS_CSV -p 1 -c \"sudo iptables -L\"\" \\ && fpdsh -l $BALANCERS_CSV -p 1 -c \"sudo iptables -L\") | tee /mnt/ahops/tmp/${USER}/${JIRA}/${STAGE}_Balancers_iptables.txt (echo \"fpdsh -l $NON_BALANCERS_CSV -p 1 -c \"sudo iptables -L\"\" \\ && fpdsh -l $NON_BALANCERS_CSV -p 1 -c \"sudo iptables -L\") | tee /mnt/ahops/tmp/${USER}/${JIRA}/${STAGE}_Non_Balancers_iptables.txt","title":"IPTABLES"},{"location":"realm_management/audit_iptables_sgroups/#security-groups","text":"List Instance ids (echo \"=== Listing Instance ids and region whose status is 0 ===\" \\ && ah-server list $BALANCERS_CSV -w status=0 -c ec2_id ec2_region | sort -k 3 ) \\ | tee /mnt/ahops/tmp/${USER}/${JIRA}/${STAGE}_Balancers_Security_groups.txt (echo \"=== Listing Instance ids and region whose status is 0 ===\" \\ && ah-server list $NON_BALANCERS_CSV -w status=0 -c ec2_id ec2_region | sort -k 3 ) \\ | tee /mnt/ahops/tmp/${USER}/${JIRA}/${STAGE}_Non_Balancers_Security_groups.txt List Security Group Repeat for each region observed in last step. REGION= The instances in the region: BAL_INSTANCES=($(ah-server list $BALANCERS_CSV -w ec2_region=$REGION --no-name -c ec2_id|paste -sd \" \")) NON_BAL_INSTANCES=($(ah-server list $NON_BALANCERS_CSV -w ec2_region=$REGION --no-name -c ec2_id|paste -sd \" \")) (echo;echo \"=== $REGION, Listing all the security group ids associated with each ec2 instance\" \\ && aws ec2 describe-instances --instance-ids ${BAL_INSTANCES[@]} --region $REGION --query 'Reservations[*].Instances[*].[SecurityGroups[*].GroupId]' \\ --output text | awk 'BEGIN { OFS=\"\\n\"}; {$1=$1; print $0 }' | sort | uniq) \\ | tee -a /mnt/ahops/tmp/${USER}/${JIRA}/${STAGE}_Balancers_Security_groups.txt (echo;echo \"=== $REGION, Listing all the security group ids associated with each ec2 instance\" \\ && aws ec2 describe-instances --instance-ids ${NON_BAL_INSTANCES[@]} --region $REGION --query 'Reservations[*].Instances[*].[SecurityGroups[*].GroupId]' \\ --output text | awk 'BEGIN { OFS=\"\\n\"}; {$1=$1; print $0 }' | sort | uniq) \\ | tee -a /mnt/ahops/tmp/${USER}/${JIRA}/${STAGE}_Non_Balancers_Security_groups.txt Details of each security group Repeat for each region. REGION= The security group in the region: SG_BAL=\"sg-22a16458 sg-9220d0fb sg-dea164a4\" SG_NON= (echo;echo \"=== $REGION, Details of each security group\" \\ && aws ec2 describe-security-groups --group-ids ${SG_BAL[@]} --region $REGION) \\ | tee -a /mnt/ahops/tmp/${USER}/${JIRA}/${STAGE}_Balancers_Security_groups.txt (echo;echo \"=== $REGION, Details of each security group\" \\ && aws ec2 describe-security-groups --group-ids ${SG_NON[@]} --region $REGION) \\ | tee -a /mnt/ahops/tmp/${USER}/${JIRA}/${STAGE}_Non_Balancers_Security_groups.txt","title":"Security Groups"},{"location":"realm_management/audit_iptables_sgroups/#scp","text":"scp files to your local machine,attach to Jira ticket,delete from local machine and bastion.","title":"SCP"},{"location":"realm_management/audit_services_protocols_ports/","text":"Audit Services Protocols Ports InfoSec will request lists that operations provides. The Jira ticket is typically titled \"Audit Request - Services,Protocols, and Ports\". Generate the files containing the lists. The titles for files are typically ACE_netstat.txt ACE_systemctl.txt and the request could be for other realms as well. A common step will be to scp a file to your local machine,attach to Jira ticket,delete from local machine and bastion. Set filename variable if [ \"$FIELDS_STAGE\" == 'prod' ] ; then STAGE=ACE; \\ elif [ \"$FIELDS_STAGE\" == 'enterprise-g1' ] ; then STAGE=ACSF; \\ else STAGE=$(echo ${FIELDS_STAGE} | sed -e 's/-//g'); fi JIRA= mkdir /mnt/ahops/tmp/${USER}/${JIRA}/ Create Server List The ticket will always provide a reasonable short list of servers. Put a list of them into variables. SERVERS_CSV=staging-31610,svn-29892,web-15159 Review if any server not status 0 ah-server list $SERVERS_CSV -w status!=0 Determine if a server not status 0 will be status 0 soon. Example: wait for a launch to finish its transition from status 2 to 0. Otherwise remove any not 0 servers from $SERVERS_CSV and comment about it in JIRA ticket. NETSTAT (echo \"fpdsh -l $SERVERS_CSV -p 1 -c \"sudo netstat -plnt\"\" \\ && fpdsh -l $SERVERS_CSV -p 1 -c \"sudo netstat -plnt\") | tee /mnt/ahops/tmp/${USER}/${JIRA}/${STAGE}_netstat.txt Systemctl (echo \"fpdsh -l $SERVERS_CSV -p 1 -c \"systemctl list-units --type service\"\" \\ && fpdsh -l $SERVERS_CSV -p 1 -c \"systemctl list-units --type service\") | tee /mnt/ahops/tmp/${USER}/${JIRA}/${STAGE}_systemctl.txt SCP scp files to your local machine,attach to Jira ticket,delete from local machine and bastion.","title":"Audit Services Protocols Ports"},{"location":"realm_management/audit_services_protocols_ports/#audit-services-protocols-ports","text":"InfoSec will request lists that operations provides. The Jira ticket is typically titled \"Audit Request - Services,Protocols, and Ports\". Generate the files containing the lists. The titles for files are typically ACE_netstat.txt ACE_systemctl.txt and the request could be for other realms as well. A common step will be to scp a file to your local machine,attach to Jira ticket,delete from local machine and bastion.","title":"Audit Services Protocols Ports"},{"location":"realm_management/audit_services_protocols_ports/#set-filename-variable","text":"if [ \"$FIELDS_STAGE\" == 'prod' ] ; then STAGE=ACE; \\ elif [ \"$FIELDS_STAGE\" == 'enterprise-g1' ] ; then STAGE=ACSF; \\ else STAGE=$(echo ${FIELDS_STAGE} | sed -e 's/-//g'); fi JIRA= mkdir /mnt/ahops/tmp/${USER}/${JIRA}/","title":"Set filename variable"},{"location":"realm_management/audit_services_protocols_ports/#create-server-list","text":"The ticket will always provide a reasonable short list of servers. Put a list of them into variables. SERVERS_CSV=staging-31610,svn-29892,web-15159 Review if any server not status 0 ah-server list $SERVERS_CSV -w status!=0 Determine if a server not status 0 will be status 0 soon. Example: wait for a launch to finish its transition from status 2 to 0. Otherwise remove any not 0 servers from $SERVERS_CSV and comment about it in JIRA ticket.","title":"Create Server List"},{"location":"realm_management/audit_services_protocols_ports/#netstat","text":"(echo \"fpdsh -l $SERVERS_CSV -p 1 -c \"sudo netstat -plnt\"\" \\ && fpdsh -l $SERVERS_CSV -p 1 -c \"sudo netstat -plnt\") | tee /mnt/ahops/tmp/${USER}/${JIRA}/${STAGE}_netstat.txt","title":"NETSTAT"},{"location":"realm_management/audit_services_protocols_ports/#systemctl","text":"(echo \"fpdsh -l $SERVERS_CSV -p 1 -c \"systemctl list-units --type service\"\" \\ && fpdsh -l $SERVERS_CSV -p 1 -c \"systemctl list-units --type service\") | tee /mnt/ahops/tmp/${USER}/${JIRA}/${STAGE}_systemctl.txt","title":"Systemctl"},{"location":"realm_management/audit_services_protocols_ports/#scp","text":"scp files to your local machine,attach to Jira ticket,delete from local machine and bastion.","title":"SCP"},{"location":"realm_management/audit_sudoers/","text":"Audit Sudoers InfoSec will request lists that operations provides. The Jira ticket is typically titled \"Audit Request - Sudoers File\". Generate the files containing the lists. The titles for files are typically ACE_Sudoers.txt ACSF_Sudoers.txt and the request could be for other realms as well. A common step will be to scp a file to your local machine,attach to Jira ticket,delete from local machine and bastion. Set filename variable if [ \"$FIELDS_STAGE\" == 'prod' ] ; then STAGE=ACE; \\ elif [ \"$FIELDS_STAGE\" == 'enterprise-g1' ] ; then STAGE=ACSF; \\ else STAGE=$(echo ${FIELDS_STAGE} | sed -e 's/-//g'); fi JIRA= mkdir /mnt/ahops/tmp/${USER}/${JIRA}/ Create Server List The ticket will always provide a reasonable short list of servers. Put a list of them into variables. SERVERS_CSV=bal-20331,bal-12324,bal-15407 Review if any server not status 0 ah-server list $SERVERS_CSV -w status!=0 Determine if a server not status 0 will be status 0 soon. Example: wait for a launch to finish its transition from status 2 to 0. Otherwise remove any not 0 servers from $SERVERS_CSV and comment about it in JIRA ticket. SUDOERS (echo \"fpdsh -l $SERVERS_CSV -p 1 -c \"sudo cat /etc/sudoers\"\" \\ && fpdsh -l $SERVERS_CSV -p 1 -c \"sudo cat /etc/sudoers\") | tee /mnt/ahops/tmp/${USER}/${JIRA}/${STAGE}_Sudoers.txt SCP scp files to your local machine,attach to Jira ticket,delete from local machine and bastion.","title":"Audit Sudoers"},{"location":"realm_management/audit_sudoers/#audit-sudoers","text":"InfoSec will request lists that operations provides. The Jira ticket is typically titled \"Audit Request - Sudoers File\". Generate the files containing the lists. The titles for files are typically ACE_Sudoers.txt ACSF_Sudoers.txt and the request could be for other realms as well. A common step will be to scp a file to your local machine,attach to Jira ticket,delete from local machine and bastion.","title":"Audit Sudoers"},{"location":"realm_management/audit_sudoers/#set-filename-variable","text":"if [ \"$FIELDS_STAGE\" == 'prod' ] ; then STAGE=ACE; \\ elif [ \"$FIELDS_STAGE\" == 'enterprise-g1' ] ; then STAGE=ACSF; \\ else STAGE=$(echo ${FIELDS_STAGE} | sed -e 's/-//g'); fi JIRA= mkdir /mnt/ahops/tmp/${USER}/${JIRA}/","title":"Set filename variable"},{"location":"realm_management/audit_sudoers/#create-server-list","text":"The ticket will always provide a reasonable short list of servers. Put a list of them into variables. SERVERS_CSV=bal-20331,bal-12324,bal-15407 Review if any server not status 0 ah-server list $SERVERS_CSV -w status!=0 Determine if a server not status 0 will be status 0 soon. Example: wait for a launch to finish its transition from status 2 to 0. Otherwise remove any not 0 servers from $SERVERS_CSV and comment about it in JIRA ticket.","title":"Create Server List"},{"location":"realm_management/audit_sudoers/#sudoers","text":"(echo \"fpdsh -l $SERVERS_CSV -p 1 -c \"sudo cat /etc/sudoers\"\" \\ && fpdsh -l $SERVERS_CSV -p 1 -c \"sudo cat /etc/sudoers\") | tee /mnt/ahops/tmp/${USER}/${JIRA}/${STAGE}_Sudoers.txt","title":"SUDOERS"},{"location":"realm_management/audit_sudoers/#scp","text":"scp files to your local machine,attach to Jira ticket,delete from local machine and bastion.","title":"SCP"},{"location":"realm_management/audit_user_access/","text":"User Access Audit InfoSec will request lists that operations provides. The Jira ticket is typically titled \"Q[1,2,3,4] Year - User Acess Review\". Generate the files containing the lists. The titles for files are typically UserAccessReviewReport-$DATE.csv yubikey-users.txt A common step will be to scp a file to your local machine,attach to Jira ticket,delete from local machine and bastion. Set filename variable JIRA= mkdir /mnt/ahops/tmp/${USER}/${JIRA}/ Tooling to generate the report: admin-userreport The tool will indicate where the report(csv) has been saved in your bastion user directory so please take note of it in order to transfer it to your local machine. admin-userreport ${JIRA} scp the files to your local machine,attach to Jira ticket,delete from local machine and bastion. The tool currently has an instruction to generate wikid files which can be ignored, there is a kanban ticket to remove instruction. Bastion YubiKey Access List On the bastion, run the following to get a list of all public keys for users. ls -1 /vol/ebs1/keys/authorized_keys > /mnt/ahops/tmp/${USER}/${JIRA}/yubikey-users.txt scp the text file to your local machine,attach to Jira ticket,delete from local machine and bastion.","title":"User Access Audit"},{"location":"realm_management/audit_user_access/#user-access-audit","text":"InfoSec will request lists that operations provides. The Jira ticket is typically titled \"Q[1,2,3,4] Year - User Acess Review\". Generate the files containing the lists. The titles for files are typically UserAccessReviewReport-$DATE.csv yubikey-users.txt A common step will be to scp a file to your local machine,attach to Jira ticket,delete from local machine and bastion.","title":"User Access Audit"},{"location":"realm_management/audit_user_access/#set-filename-variable","text":"JIRA= mkdir /mnt/ahops/tmp/${USER}/${JIRA}/","title":"Set filename variable"},{"location":"realm_management/audit_user_access/#tooling-to-generate-the-report-admin-userreport","text":"The tool will indicate where the report(csv) has been saved in your bastion user directory so please take note of it in order to transfer it to your local machine. admin-userreport ${JIRA} scp the files to your local machine,attach to Jira ticket,delete from local machine and bastion. The tool currently has an instruction to generate wikid files which can be ignored, there is a kanban ticket to remove instruction.","title":"Tooling to generate the report: admin-userreport"},{"location":"realm_management/audit_user_access/#bastion-yubikey-access-list","text":"On the bastion, run the following to get a list of all public keys for users. ls -1 /vol/ebs1/keys/authorized_keys > /mnt/ahops/tmp/${USER}/${JIRA}/yubikey-users.txt scp the text file to your local machine,attach to Jira ticket,delete from local machine and bastion.","title":"Bastion YubiKey Access List"},{"location":"realm_management/mntfs-volume-reaping/","text":"Reaping of Unused /mnt EBS Volumes As outlined in OP-199692 , when a server that has EBS volume for /mnt is relaunched, the old /mnt mounting EBS volume is tagged with ah_terminated but it is not reaped. Those volumes dangle around in AWS and they cost Acquia for doing nothing. These volumes should be routinly cleaned up manually until we have a mechanism in place where these volumes are taken careful automatically. Use the following steps to reap the /mnt mounting volumes that are not used and tagged with ah_terminated . Please follow the steps below to clean up these unsued volumes in a fields stage. Step 1: Switch to required stage in Bastion a(STAGE_NAME) example: aprod, adevcloud,aenterpriseg1 Step 2: Create directory to store interim files used for reaping VOLUME_DIR=${HOME}/${FIELDS_STAGE}_unused_mnt_vol_audit_$(date +%Y-%m-%d_%H-%M-%S) echo ${VOLUME_DIR} mkdir -p ${VOLUME_DIR} cd ${VOLUME_DIR}/ Step 3: Find volumes that are tagged with ah_terminated for region in $(aws ec2 describe-regions --query 'Regions[*].[RegionName]' --region us-east-1 --output text); do echo -n \"${region}: \"; aws ec2 describe-volumes \\ --filters 'Name=tag:ah_terminated,Values=*' \\ --query 'Volumes[*].{ID:VolumeId,State:State,CreationTime:CreateTime,Size:Size,mount_point:Tags[?Key==`ah_attach_to_device`].Value|[0],server_id:Tags[?Key==`ah_terminated`].Value|[0]}' \\ --output text \\ --region ${region} \\ | tr \"\\t\" \",\" \\ | tee ${VOLUME_DIR}/${FIELDS_STAGE}.ah_terminated.available.volumes.${region} \\ | wc -l; done Step 4: List the volumes that are tagged with ah_terminated cat ${VOLUME_DIR}/${FIELDS_STAGE}.* Step 5: Reap the /mnt mounting unsued volumes that are tagged with ah_terminated for region in $(aws ec2 describe-regions --query 'Regions[*].[RegionName]' --region us-east-1 --output text); do echo \"${region}\"; if [[ -s ${VOLUME_DIR}/${FIELDS_STAGE}.ah_terminated.available.volumes.${region} ]]; then echo \"Deleting volumes tagged ah_terminated in ${region}\"; cat ${VOLUME_DIR}/${FIELDS_STAGE}.ah_terminated.available.volumes.${region} \\ | grep \"available\" \\ | grep \"/dev/xvdb\" \\ | awk -F, '{print $2}' \\ | xargs -I{} -n1 aws ec2 delete-volume --volume-id {} --region ${region}; else echo \"No volumes to clean up in ${region}\"; fi echo; done NOTE : Please record the output of above commands for history to related ticket in JIRA","title":"Reaping of Unused `/mnt` EBS Volumes"},{"location":"realm_management/mntfs-volume-reaping/#reaping-of-unused-mnt-ebs-volumes","text":"As outlined in OP-199692 , when a server that has EBS volume for /mnt is relaunched, the old /mnt mounting EBS volume is tagged with ah_terminated but it is not reaped. Those volumes dangle around in AWS and they cost Acquia for doing nothing. These volumes should be routinly cleaned up manually until we have a mechanism in place where these volumes are taken careful automatically. Use the following steps to reap the /mnt mounting volumes that are not used and tagged with ah_terminated . Please follow the steps below to clean up these unsued volumes in a fields stage.","title":"Reaping of Unused /mnt EBS Volumes"},{"location":"realm_management/mntfs-volume-reaping/#step-1-switch-to-required-stage-in-bastion","text":"a(STAGE_NAME) example: aprod, adevcloud,aenterpriseg1","title":"Step 1: Switch to required stage in Bastion"},{"location":"realm_management/mntfs-volume-reaping/#step-2-create-directory-to-store-interim-files-used-for-reaping","text":"VOLUME_DIR=${HOME}/${FIELDS_STAGE}_unused_mnt_vol_audit_$(date +%Y-%m-%d_%H-%M-%S) echo ${VOLUME_DIR} mkdir -p ${VOLUME_DIR} cd ${VOLUME_DIR}/","title":"Step 2: Create directory to store interim files used for reaping"},{"location":"realm_management/mntfs-volume-reaping/#step-3-find-volumes-that-are-tagged-with-ah_terminated","text":"for region in $(aws ec2 describe-regions --query 'Regions[*].[RegionName]' --region us-east-1 --output text); do echo -n \"${region}: \"; aws ec2 describe-volumes \\ --filters 'Name=tag:ah_terminated,Values=*' \\ --query 'Volumes[*].{ID:VolumeId,State:State,CreationTime:CreateTime,Size:Size,mount_point:Tags[?Key==`ah_attach_to_device`].Value|[0],server_id:Tags[?Key==`ah_terminated`].Value|[0]}' \\ --output text \\ --region ${region} \\ | tr \"\\t\" \",\" \\ | tee ${VOLUME_DIR}/${FIELDS_STAGE}.ah_terminated.available.volumes.${region} \\ | wc -l; done","title":"Step 3: Find volumes that are tagged with ah_terminated"},{"location":"realm_management/mntfs-volume-reaping/#step-4-list-the-volumes-that-are-tagged-with-ah_terminated","text":"cat ${VOLUME_DIR}/${FIELDS_STAGE}.*","title":"Step 4: List the volumes that are tagged with ah_terminated"},{"location":"realm_management/mntfs-volume-reaping/#step-5-reap-the-mnt-mounting-unsued-volumes-that-are-tagged-with-ah_terminated","text":"for region in $(aws ec2 describe-regions --query 'Regions[*].[RegionName]' --region us-east-1 --output text); do echo \"${region}\"; if [[ -s ${VOLUME_DIR}/${FIELDS_STAGE}.ah_terminated.available.volumes.${region} ]]; then echo \"Deleting volumes tagged ah_terminated in ${region}\"; cat ${VOLUME_DIR}/${FIELDS_STAGE}.ah_terminated.available.volumes.${region} \\ | grep \"available\" \\ | grep \"/dev/xvdb\" \\ | awk -F, '{print $2}' \\ | xargs -I{} -n1 aws ec2 delete-volume --volume-id {} --region ${region}; else echo \"No volumes to clean up in ${region}\"; fi echo; done NOTE : Please record the output of above commands for history to related ticket in JIRA","title":"Step 5: Reap the /mnt mounting unsued volumes that are tagged with ah_terminated"},{"location":"realm_management/mysql_restarts/","text":"MySQL Restart Mass Process Servers with no replication One-off Procedure Any servers without MySQL replication, like srv and staging, will have mysql restarted with: REGION= SERVERS_CSV= NON_HA=$(ah-server list % \\ -w status=0 typeINsrv,staging,api,free ec2_region=${REGION} \"name IN ${SERVERS_CSV}\" | paste -sd,) fpdsh -p 100 -l $NON_HA -c \"sudo service mysql restart\" Servers with replication Preparation Create a list of all the database servers for the specified region. REGION= SERVERS_CSV= ah-server list % \\ -w status=0 typeINded,fsdb,dbmaster ec2_region=${REGION} \"name IN ${SERVERS_CSV}\" \\ | sort -V > $OPSTMP/all_dbs Check for replication lag. fpdsh -p 100 -l $(paste -sd, < $OPSTMP/all_dbs) \\ -c \"sudo ruby -e 'require \\\"aq\\\"; \\ s=Aq::Hosting::Server.from_local(); \\ puts s.services.mysql.heartbeat_info.lag_max'\" | egrep -v ' [0-4]$' If there is any replication lag (more than a few seconds), resolve it, or remove both servers in the lagging cluster from $OPSTMP/all_dbs . Find all the active and passive database servers. eval $(sv-dbprisec $(paste -sd, $OPSTMP/all_dbs)) Create an active and passive file echo ${PRIMARY_DBS[@]} > $OPSTMP/active_dbs echo ${SECONDARY_DBS[@]} > $OPSTMP/passive_dbs Procedure Check for locked DB clusters. sv-dbislocked $(paste -sd, $OPSTMP/active_dbs) Unlock any unintentionally locked DB clusters with ah-db-cluster unlock. If any DB clusters are intentionally locked and should not be unlocked, remove them from your lists. Lock all the DB clusters. If any of the resultant tasks fail, inspect the statuses of those that failed. LATESTTASKID=$(ah-task list -w queue=db-cluster-action | tail -n 1) echo ${PRIMARY_DBS[@]} | tr -d '\\n' | xargs -n1 -P10 -I{} -d ' ' ah-db-cluster lock {} if [[ \"$?\" -ne \"0\" ]]; then echo \"Investigate these failed task IDs:\" ah-task list -w queue=db-cluster-action \"state IN error,failed,killed\" \"id>${LATESTTASKID}\" -c state done Restart mysql on passive database servers. fpdsh -p 100 -l $SECONDARY_DBS_CSV -c \"sudo service mysql restart\" Wait for replication on all the passive database servers to catch up. fpdsh -p 100 -l $(paste -sd, < $OPSTMP/all_dbs) \\ -c \"sudo ruby -e 'require \\\"aq\\\"; \\ s=Aq::Hosting::Server.from_local(); \\ puts s.services.mysql.heartbeat_info.lag_max'\" | egrep -v ' [0-4]$' Unlock the DB clusters you had previously locked. If any of the resultant tasks fail, inspect the statuses of those that failed. LATESTTASKID=$(ah-task list -w queue=db-cluster-action | tail -n 1) echo ${PRIMARY_DBS[@]} | tr -d '\\n' | xargs -n1 -P10 -I{} -d ' ' ah-db-cluster unlock {} if [[ \"$?\" -ne \"0\" ]]; then echo \"Investigate these failed task IDs:\" ah-task list -w queue=db-cluster-action \"state IN error,failed,killed\" \"id>${LATESTTASKID}\" -c state done Fail over all of the databases. sv-dbmultifailover $(paste -sd' ' $OPSTMP/passive_dbs) Lock all the DB clusters. If any of the resultant tasks fail, inspect the statuses of those that failed. LATESTTASKID=$(ah-task list -w queue=db-cluster-action | tail -n 1) echo ${SECONDARY_DBS[@]} | tr -d '\\n' | xargs -n1 -P10 -I{} -d ' ' ah-db-cluster lock {} if [[ \"$?\" -ne \"0\" ]]; then echo \"Investigate these failed task IDs:\" ah-task list -w queue=db-cluster-action \"state IN error,failed,killed\" \"id>${LATESTTASKID}\" -c state done Restart mysql in the primary (failed-away-from) database servers. fpdsh -p 100 -l $PRIMARY_DBS_CSV -c \"sudo service mysql restart\" Wait for replication on all the passive database servers to catch up. fpdsh -p 100 -l $(paste -sd, < $OPSTMP/all_dbs) \\ -c \"sudo ruby -e 'require \\\"aq\\\"; \\ s=Aq::Hosting::Server.from_local(); \\ puts s.services.mysql.heartbeat_info.lag_max'\" | egrep -v ' [0-4]$' Cleanup Unlock the DB clusters you had previously locked. If any of the resultant tasks fail, inspect the statuses of those that failed. LATESTTASKID=$(ah-task list -w queue=db-cluster-action | tail -n 1) echo ${SECONDARY_DBS[@]} | tr -d '\\n' | xargs -n1 -P10 -I{} -d ' ' ah-db-cluster unlock {} if [[ \"$?\" -ne \"0\" ]]; then echo \"Investigate these failed task IDs:\" ah-task list -w queue=db-cluster-action \"state IN error,failed,killed\" \"id>${LATESTTASKID}\" -c state done Fail the database cluster back to the primary database servers. sv-dbmultifailover $(paste -sd' ' $OPSTMP/active_dbs)","title":"MySQL Restart Mass Process"},{"location":"realm_management/mysql_restarts/#mysql-restart-mass-process","text":"","title":"MySQL Restart Mass Process"},{"location":"realm_management/mysql_restarts/#servers-with-no-replication","text":"","title":"Servers with no replication"},{"location":"realm_management/mysql_restarts/#one-off-procedure","text":"Any servers without MySQL replication, like srv and staging, will have mysql restarted with: REGION= SERVERS_CSV= NON_HA=$(ah-server list % \\ -w status=0 typeINsrv,staging,api,free ec2_region=${REGION} \"name IN ${SERVERS_CSV}\" | paste -sd,) fpdsh -p 100 -l $NON_HA -c \"sudo service mysql restart\"","title":"One-off Procedure"},{"location":"realm_management/mysql_restarts/#servers-with-replication","text":"","title":"Servers with replication"},{"location":"realm_management/mysql_restarts/#preparation","text":"Create a list of all the database servers for the specified region. REGION= SERVERS_CSV= ah-server list % \\ -w status=0 typeINded,fsdb,dbmaster ec2_region=${REGION} \"name IN ${SERVERS_CSV}\" \\ | sort -V > $OPSTMP/all_dbs Check for replication lag. fpdsh -p 100 -l $(paste -sd, < $OPSTMP/all_dbs) \\ -c \"sudo ruby -e 'require \\\"aq\\\"; \\ s=Aq::Hosting::Server.from_local(); \\ puts s.services.mysql.heartbeat_info.lag_max'\" | egrep -v ' [0-4]$' If there is any replication lag (more than a few seconds), resolve it, or remove both servers in the lagging cluster from $OPSTMP/all_dbs . Find all the active and passive database servers. eval $(sv-dbprisec $(paste -sd, $OPSTMP/all_dbs)) Create an active and passive file echo ${PRIMARY_DBS[@]} > $OPSTMP/active_dbs echo ${SECONDARY_DBS[@]} > $OPSTMP/passive_dbs","title":"Preparation"},{"location":"realm_management/mysql_restarts/#procedure","text":"Check for locked DB clusters. sv-dbislocked $(paste -sd, $OPSTMP/active_dbs) Unlock any unintentionally locked DB clusters with ah-db-cluster unlock. If any DB clusters are intentionally locked and should not be unlocked, remove them from your lists. Lock all the DB clusters. If any of the resultant tasks fail, inspect the statuses of those that failed. LATESTTASKID=$(ah-task list -w queue=db-cluster-action | tail -n 1) echo ${PRIMARY_DBS[@]} | tr -d '\\n' | xargs -n1 -P10 -I{} -d ' ' ah-db-cluster lock {} if [[ \"$?\" -ne \"0\" ]]; then echo \"Investigate these failed task IDs:\" ah-task list -w queue=db-cluster-action \"state IN error,failed,killed\" \"id>${LATESTTASKID}\" -c state done Restart mysql on passive database servers. fpdsh -p 100 -l $SECONDARY_DBS_CSV -c \"sudo service mysql restart\" Wait for replication on all the passive database servers to catch up. fpdsh -p 100 -l $(paste -sd, < $OPSTMP/all_dbs) \\ -c \"sudo ruby -e 'require \\\"aq\\\"; \\ s=Aq::Hosting::Server.from_local(); \\ puts s.services.mysql.heartbeat_info.lag_max'\" | egrep -v ' [0-4]$' Unlock the DB clusters you had previously locked. If any of the resultant tasks fail, inspect the statuses of those that failed. LATESTTASKID=$(ah-task list -w queue=db-cluster-action | tail -n 1) echo ${PRIMARY_DBS[@]} | tr -d '\\n' | xargs -n1 -P10 -I{} -d ' ' ah-db-cluster unlock {} if [[ \"$?\" -ne \"0\" ]]; then echo \"Investigate these failed task IDs:\" ah-task list -w queue=db-cluster-action \"state IN error,failed,killed\" \"id>${LATESTTASKID}\" -c state done Fail over all of the databases. sv-dbmultifailover $(paste -sd' ' $OPSTMP/passive_dbs) Lock all the DB clusters. If any of the resultant tasks fail, inspect the statuses of those that failed. LATESTTASKID=$(ah-task list -w queue=db-cluster-action | tail -n 1) echo ${SECONDARY_DBS[@]} | tr -d '\\n' | xargs -n1 -P10 -I{} -d ' ' ah-db-cluster lock {} if [[ \"$?\" -ne \"0\" ]]; then echo \"Investigate these failed task IDs:\" ah-task list -w queue=db-cluster-action \"state IN error,failed,killed\" \"id>${LATESTTASKID}\" -c state done Restart mysql in the primary (failed-away-from) database servers. fpdsh -p 100 -l $PRIMARY_DBS_CSV -c \"sudo service mysql restart\" Wait for replication on all the passive database servers to catch up. fpdsh -p 100 -l $(paste -sd, < $OPSTMP/all_dbs) \\ -c \"sudo ruby -e 'require \\\"aq\\\"; \\ s=Aq::Hosting::Server.from_local(); \\ puts s.services.mysql.heartbeat_info.lag_max'\" | egrep -v ' [0-4]$'","title":"Procedure"},{"location":"realm_management/mysql_restarts/#cleanup","text":"Unlock the DB clusters you had previously locked. If any of the resultant tasks fail, inspect the statuses of those that failed. LATESTTASKID=$(ah-task list -w queue=db-cluster-action | tail -n 1) echo ${SECONDARY_DBS[@]} | tr -d '\\n' | xargs -n1 -P10 -I{} -d ' ' ah-db-cluster unlock {} if [[ \"$?\" -ne \"0\" ]]; then echo \"Investigate these failed task IDs:\" ah-task list -w queue=db-cluster-action \"state IN error,failed,killed\" \"id>${LATESTTASKID}\" -c state done Fail the database cluster back to the primary database servers. sv-dbmultifailover $(paste -sd' ' $OPSTMP/active_dbs)","title":"Cleanup"},{"location":"realm_management/patching/","text":"Mass patching Note: To login Search jumpboxes, follow these instructions Preparation Set some variables AZ= SERVERS=$(ah-server list % -w status=0 ec2_availability_zone=${AZ} \\ | paste -sd,) Ensure hosts have enough free inodes on root filesystem In order for a mass patching to complete successfully, inodes must be available on the root filesystem ( /dev/xvda ) to be able to run apt correctly. Audit on a per-region basis: fpdsh -t % -r ${REGION} -c \"df -i | grep xvda | egrep '[89][0-9]%|100%' || exit 0\" Volumes that are not 100% full can be cleaned with apt : sudo apt-get -y autoremove Volumes that are using 100% of inodes require special care. File a separate ticket linked against your patching ticket and escalate to a senior Ops team member. Patching See below for patching search servers . Patch all the servers in the first AZ fpdsh -l $SERVERS -p 250 -c \"sudo /usr/local/sbin/apt-get-retry update \\ && sudo DEBIAN_FRONTEND=noninteractive /usr/local/sbin/apt-get-retry \\ dist-upgrade -y \\ -o Dpkg::Options::='--force-confdef' \\ -o Dpkg::Options::='--force-confold';\" \\ | tee -a ${OPSLOG}/${USER}.${FIELDS_STAGE}.${AZ}.$(date +%F).log Repeat for each AZ in your region Patching search If the patching involves a reboot, please follow the procedure indicated on the search mass reboot page. Please check the Jira ticket to verify that no packages are to be held from updates. Patch the Trusty fleet. ah-server patch % -o trusty -c 50 [-p <comma-separated list of packages to exclude>] Proceed to the restart services section NOTE : The modified ah-server patch command has additional options such as doing by AZ, server type (i.e. javasrv, javaephem, etc.), as well as others. To see all of the available options, just execute the following command. ah-server help patch Restart services Sometimes patching will require service restart. Follow the sections for the packages affected by your patching. if OpenSSL was updated Set some variables. [ NOTE : For the search account, only Trusty servers are patched, so adjust the following accordingly ]. SERVERS_NGINX=$(ah-server list $SERVERS -w status=0 typeINbal,nxephem \\ | paste -sd,) SERVERS_APACHE=$(ah-server list $SERVERS -w status=0 \\ typeINmon,monui,svn | paste -sd,) SERVERS_PHP=$(ah-server list $SERVERS -w status=0 \\ typeINapi,ded,free,managed,srv,staging,web | paste -sd,) Restart common services fpdsh -l $SERVERS -p 500 -c \"\\ sudo service td-agent restart ;\\ sudo service meh restart ; \\ sudo service nagios-nrpe-server restart ; \\ sudo service ah-dpld restart ; \\ sudo service ah-logtailord restart ; \\ sudo service fcw-admin-user-worker restart \" \\ | tee -a ${OPSLOG}/${USER}.${FIELDS_STAGE}.${AZ}.$(date +%F).log Restart nginx fpdsh -l $SERVERS_NGINX -p 500 -c 'sudo service nginx restart' \\ | tee -a ${OPSLOG}/${USER}.${FIELDS_STAGE}.${AZ}.$(date +%F).log Restart apache fpdsh -l $SERVERS_APACHE -p 500 -c 'sudo service apache2 restart' \\ | tee -a ${OPSLOG}/${USER}.${FIELDS_STAGE}.${AZ}.$(date +%F).log Restart php-fpm fpdsh -l $SERVERS_PHP -p 500 -c \"for service in /etc/init.d/php-fpm-* ; \\ do sudo service \\${service##*/} restart_all;done\" \\ | tee -a ${OPSLOG}/${USER}.${FIELDS_STAGE}.${AZ}.$(date +%F).log Repeat for each AZ in your region Verification Verify all servers have been patched fpdsh -l $SERVERS -p 500 -c \" \\ sudo /usr/local/sbin/apt-get-retry update > /dev/null && \\ sudo /usr/local/sbin/apt-get-retry dist-upgrade --dry-run -y -o \\ Dpkg::Options::='--force-confdef' -o \\ Dpkg::Options::='--force-confold' | tail -n1\" \\ | grep -v \" 0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\" Repeat for each AZ","title":"Mass patching"},{"location":"realm_management/patching/#mass-patching","text":"Note: To login Search jumpboxes, follow these instructions","title":"Mass patching"},{"location":"realm_management/patching/#preparation","text":"Set some variables AZ= SERVERS=$(ah-server list % -w status=0 ec2_availability_zone=${AZ} \\ | paste -sd,)","title":"Preparation"},{"location":"realm_management/patching/#ensure-hosts-have-enough-free-inodes-on-root-filesystem","text":"In order for a mass patching to complete successfully, inodes must be available on the root filesystem ( /dev/xvda ) to be able to run apt correctly. Audit on a per-region basis: fpdsh -t % -r ${REGION} -c \"df -i | grep xvda | egrep '[89][0-9]%|100%' || exit 0\" Volumes that are not 100% full can be cleaned with apt : sudo apt-get -y autoremove Volumes that are using 100% of inodes require special care. File a separate ticket linked against your patching ticket and escalate to a senior Ops team member.","title":"Ensure hosts have enough free inodes on root filesystem"},{"location":"realm_management/patching/#patching","text":"See below for patching search servers . Patch all the servers in the first AZ fpdsh -l $SERVERS -p 250 -c \"sudo /usr/local/sbin/apt-get-retry update \\ && sudo DEBIAN_FRONTEND=noninteractive /usr/local/sbin/apt-get-retry \\ dist-upgrade -y \\ -o Dpkg::Options::='--force-confdef' \\ -o Dpkg::Options::='--force-confold';\" \\ | tee -a ${OPSLOG}/${USER}.${FIELDS_STAGE}.${AZ}.$(date +%F).log Repeat for each AZ in your region","title":"Patching"},{"location":"realm_management/patching/#patching-search","text":"If the patching involves a reboot, please follow the procedure indicated on the search mass reboot page. Please check the Jira ticket to verify that no packages are to be held from updates. Patch the Trusty fleet. ah-server patch % -o trusty -c 50 [-p <comma-separated list of packages to exclude>] Proceed to the restart services section NOTE : The modified ah-server patch command has additional options such as doing by AZ, server type (i.e. javasrv, javaephem, etc.), as well as others. To see all of the available options, just execute the following command. ah-server help patch","title":"Patching search"},{"location":"realm_management/patching/#restart-services","text":"Sometimes patching will require service restart. Follow the sections for the packages affected by your patching.","title":"Restart services"},{"location":"realm_management/patching/#if-openssl-was-updated","text":"Set some variables. [ NOTE : For the search account, only Trusty servers are patched, so adjust the following accordingly ]. SERVERS_NGINX=$(ah-server list $SERVERS -w status=0 typeINbal,nxephem \\ | paste -sd,) SERVERS_APACHE=$(ah-server list $SERVERS -w status=0 \\ typeINmon,monui,svn | paste -sd,) SERVERS_PHP=$(ah-server list $SERVERS -w status=0 \\ typeINapi,ded,free,managed,srv,staging,web | paste -sd,) Restart common services fpdsh -l $SERVERS -p 500 -c \"\\ sudo service td-agent restart ;\\ sudo service meh restart ; \\ sudo service nagios-nrpe-server restart ; \\ sudo service ah-dpld restart ; \\ sudo service ah-logtailord restart ; \\ sudo service fcw-admin-user-worker restart \" \\ | tee -a ${OPSLOG}/${USER}.${FIELDS_STAGE}.${AZ}.$(date +%F).log Restart nginx fpdsh -l $SERVERS_NGINX -p 500 -c 'sudo service nginx restart' \\ | tee -a ${OPSLOG}/${USER}.${FIELDS_STAGE}.${AZ}.$(date +%F).log Restart apache fpdsh -l $SERVERS_APACHE -p 500 -c 'sudo service apache2 restart' \\ | tee -a ${OPSLOG}/${USER}.${FIELDS_STAGE}.${AZ}.$(date +%F).log Restart php-fpm fpdsh -l $SERVERS_PHP -p 500 -c \"for service in /etc/init.d/php-fpm-* ; \\ do sudo service \\${service##*/} restart_all;done\" \\ | tee -a ${OPSLOG}/${USER}.${FIELDS_STAGE}.${AZ}.$(date +%F).log Repeat for each AZ in your region","title":"if OpenSSL was updated"},{"location":"realm_management/patching/#verification","text":"Verify all servers have been patched fpdsh -l $SERVERS -p 500 -c \" \\ sudo /usr/local/sbin/apt-get-retry update > /dev/null && \\ sudo /usr/local/sbin/apt-get-retry dist-upgrade --dry-run -y -o \\ Dpkg::Options::='--force-confdef' -o \\ Dpkg::Options::='--force-confold' | tail -n1\" \\ | grep -v \" 0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\" Repeat for each AZ","title":"Verification"},{"location":"realm_management/provision_new_region/","text":"Provision New Region In order for fields to work as expected in a region, certain AWS objects need to exist, and control plane servers need to be launched. Init Choose the closest region to the new region for MON_REGION REGION= MON_REGION= Preparation Verify that AMI's have been created for the region: FIELDS_AMIS=( $(bundle exec ruby -e \"require 'aq'; Aq.hosting_api.call('aws.availability.zones')['${REGION}'].keys.map {|k| puts k}\") ) EC2_AMIS=( $(aws ec2 describe-availability-zones --region ${REGION} \\ --query '*[].[ZoneName]' --output text) ) if [[ \"${FIELDS_AMIS[@]}\" == \"${EC2_AMIS[@]}\" ]]; then echo Fields has AMIs for all AZs else echo Fields is missing AMIs for the following AZs: comm <(echo ${FIELDS_AMIS[@]} | xargs -n1) <(echo ${EC2_AMIS[@]} | xargs -n1) -1 -3 fi Verify that CloudTrail is enabled TRAILS=$(aws cloudtrail describe-trails --region ${REGION} --query '*[].Name' --output text | wc -w) if [[ ${TRAILS} -gt 0 ]]; then echo CloudTrail enabled for $REGION else echo CloudTrail not enabled for $REGION fi If we don't have AMI's, have Cloud create them. They have a CI job that handles this. We can't launch instances until they create the AMI's. We can proceed without CloudTrail, but be sure to escalate the issue to management. Procedure Import the public key into the new region ssh-keygen -y -f ${FIELDS_SSH_ID} > ${FIELDS_SSH_ID}.pub aws ec2 import-key-pair --region ${REGION} --key-name hosting-prod \\ --public-key-material \"$(cat ${FIELDS_SSH_ID}.pub)\" Create the shared vpc ah-vpc create shared-vpc-${REGION} --wait-for-task ah-vpc tag add shared-vpc-${REGION} -t shared ah-vpc set-default shared-vpc-${REGION} VPC_ID=$(ah-vpc list shared-vpc-${REGION} --no-name -c id) Launch a mon follow the directions here but set the MON_SERVER_NAME to that of a mon server in a nearby region. MON_SERVER_NAME=$(ah-server list mon-% -w ec2_region=${MON_REGION} | tail -n1) Launch a dns DNS=$(ah-server allocate dns -r ${REGION} -t m5.large -z ${REGION}b -v ${VPC_ID}) sv-taskrelaunch server $DNS Launch a log cluster follow directions here and note the log_cluster_id , which you will need below. Add all running servers to the log cluster LOG_CLUSTER_ID= for SERVER in $(ah-server list % -w ec2_region=${REGION} status=0); do ah-log server add ${LOG_CLUSTER_ID} ${SERVER} done Launch a ossec Follow the directions here and then update existing servers ah-server edit $(ah-server list % -w ec2_region=${REGION} status=0 | paste -sd,) \\ -s ossec_server_id=${OSSEC#*-} fpdsh -r ${REGION} -t % -c 'sudo ah-config-ossec' Launch a svn follow the directions here Launch a shared production bal pair and a shared non-production bal pair - ACE only follow the directions here Launch a shared staging server - ACE only follow the directions here","title":"Provision New Region"},{"location":"realm_management/provision_new_region/#provision-new-region","text":"In order for fields to work as expected in a region, certain AWS objects need to exist, and control plane servers need to be launched.","title":"Provision New Region"},{"location":"realm_management/provision_new_region/#init","text":"Choose the closest region to the new region for MON_REGION REGION= MON_REGION=","title":"Init"},{"location":"realm_management/provision_new_region/#preparation","text":"Verify that AMI's have been created for the region: FIELDS_AMIS=( $(bundle exec ruby -e \"require 'aq'; Aq.hosting_api.call('aws.availability.zones')['${REGION}'].keys.map {|k| puts k}\") ) EC2_AMIS=( $(aws ec2 describe-availability-zones --region ${REGION} \\ --query '*[].[ZoneName]' --output text) ) if [[ \"${FIELDS_AMIS[@]}\" == \"${EC2_AMIS[@]}\" ]]; then echo Fields has AMIs for all AZs else echo Fields is missing AMIs for the following AZs: comm <(echo ${FIELDS_AMIS[@]} | xargs -n1) <(echo ${EC2_AMIS[@]} | xargs -n1) -1 -3 fi Verify that CloudTrail is enabled TRAILS=$(aws cloudtrail describe-trails --region ${REGION} --query '*[].Name' --output text | wc -w) if [[ ${TRAILS} -gt 0 ]]; then echo CloudTrail enabled for $REGION else echo CloudTrail not enabled for $REGION fi If we don't have AMI's, have Cloud create them. They have a CI job that handles this. We can't launch instances until they create the AMI's. We can proceed without CloudTrail, but be sure to escalate the issue to management.","title":"Preparation"},{"location":"realm_management/provision_new_region/#procedure","text":"","title":"Procedure"},{"location":"realm_management/provision_new_region/#import-the-public-key-into-the-new-region","text":"ssh-keygen -y -f ${FIELDS_SSH_ID} > ${FIELDS_SSH_ID}.pub aws ec2 import-key-pair --region ${REGION} --key-name hosting-prod \\ --public-key-material \"$(cat ${FIELDS_SSH_ID}.pub)\"","title":"Import the public key into the new region"},{"location":"realm_management/provision_new_region/#create-the-shared-vpc","text":"ah-vpc create shared-vpc-${REGION} --wait-for-task ah-vpc tag add shared-vpc-${REGION} -t shared ah-vpc set-default shared-vpc-${REGION} VPC_ID=$(ah-vpc list shared-vpc-${REGION} --no-name -c id)","title":"Create the shared vpc"},{"location":"realm_management/provision_new_region/#launch-a-mon","text":"follow the directions here but set the MON_SERVER_NAME to that of a mon server in a nearby region. MON_SERVER_NAME=$(ah-server list mon-% -w ec2_region=${MON_REGION} | tail -n1)","title":"Launch a mon"},{"location":"realm_management/provision_new_region/#launch-a-dns","text":"DNS=$(ah-server allocate dns -r ${REGION} -t m5.large -z ${REGION}b -v ${VPC_ID}) sv-taskrelaunch server $DNS","title":"Launch a dns"},{"location":"realm_management/provision_new_region/#launch-a-log-cluster","text":"follow directions here and note the log_cluster_id , which you will need below. Add all running servers to the log cluster LOG_CLUSTER_ID= for SERVER in $(ah-server list % -w ec2_region=${REGION} status=0); do ah-log server add ${LOG_CLUSTER_ID} ${SERVER} done","title":"Launch a log cluster"},{"location":"realm_management/provision_new_region/#launch-a-ossec","text":"Follow the directions here and then update existing servers ah-server edit $(ah-server list % -w ec2_region=${REGION} status=0 | paste -sd,) \\ -s ossec_server_id=${OSSEC#*-} fpdsh -r ${REGION} -t % -c 'sudo ah-config-ossec'","title":"Launch a ossec"},{"location":"realm_management/provision_new_region/#launch-a-svn","text":"follow the directions here","title":"Launch a svn"},{"location":"realm_management/provision_new_region/#launch-a-shared-production-bal-pair-and-a-shared-non-production-bal-pair-ace-only","text":"follow the directions here","title":"Launch a shared production bal pair and a shared non-production bal pair - ACE only"},{"location":"realm_management/provision_new_region/#launch-a-shared-staging-server-ace-only","text":"follow the directions here","title":"Launch a shared staging server - ACE only"},{"location":"realm_management/qna_on_reboot_relaunches/","text":"Frequently Asked Questions on Reboots and Relaunches We usually face couple of issues while doing mass reboots and relaunches. This runbook describe couple of main issues that usually occurs during reboots/relaunches: Gluster stuck on 'preprocessing_smoke_check_gluster_health' or 'smoke_check_gluster_health' step This is a known issue with gluster that sometimes reboot/relaunch workflow get stuck at 'preprocessing_smoke_check_gluster_health' step. If you notice that workflow get stuck at 'preprocessing_smoke_check_gluster_health' for long time (normal than usual), then do the following things: check the workflow logs or the output of 'ah-workflow watch-queue' to see if you find any server with gluster issue. If you find any such server then fix the gluster issue and then monitor the progress of workflow. check with hotseat person if he/she receive any gluster alert related to the reboot/relaunch workflow. Sometime when the workflow get stuck then it doesn't show the gluster errors, however it alert over the PD. so it is advisable to check the PD and take actions accordingly. Check the gluster service of all the servers of the current workflow queue and take an action accordingly. If you couldn't resolve issue with the above steps, then try to fail the workflow so that you can get some error logs under workflow tasks. You can fail the workflow by remounting all the servers related to the current queue. If you couldn't resolve issue with all such steps, then escalate the issue to cloud team here Workflow keep failing on Gluster checks even after manual remounts It is often observed that reboot/relaunch workflow gets failed at 'preprocessing_smoke_check_gluster_health' step even after manual remount. In that case we should follow the steps mentioned below: check the gluster logs of the corresponding server and take actions accordingly. However if you don't find any issue then hard mount the gluster to see if it helps. If you couldn't resolve issue with above step and workflow still get failed, then its best to skip the gluster step with the following command: WORKFLOW_ID = NEXT_STEP_NAME = ah-workflow set-step $WORKFLOW_ID $NEXT_STEP_NAME Afterwards resume the workflow: ah-workflow resume $WORKFLOW_ID Replication issues in database (non-multi-region) This is a common issue which happens when we reboot/relaunch db servers. While rebooting/relaunching db servers if the replication time goes high at step 'wait_for_db_replication' then the workflow get reach to the error pause state. We should follow this runbook Mysql Replication Lag if such issue arises. Replication/Tungsten issues in multi-region This is a common issue which happens when we reboot/relaunch multi-region db servers. While rebooting/relaunching db servers if the replication time goes high at step 'wait_for_db_replication' then the workflow get reach to the error pause state. We should follow this runbook Tungsten Troubleshooting if such issue arises. disable_db_services taking time or get stuck This is one of the uncommon issue which happens when the workflow get stuck or takes too much time at step 'disable_db_services'. This happens mostly because few processes get stuck and causes the subtasks to put in hang state. To resolve this issue, we should follow the steps mentioned below: find the subtask of 'disable_db_services' which get stuck. After running the below command, you may get number of task ids, you need to use the last task_id. ah-workflow get $WORKFLOW_ID | grep task_ids kill the last/current task that's got stuck: ah-task kill TASK_ID workflow will reach to error pause state afterwards. So you need to resume the workflow: ah-workflow resume $WORKFLOW_ID if the workflow again get stuck at the same step, then you need to follow the 1st step and then resume the workflow by skipping the 'disable_db_services' step. Debugging reboot/relaunch task failures The reboot/relaunch tasks may get failed due to numbers of reasons. The reasons could be: If you are rebooting/relaunching a server, if it get failed and you didn't find anything under workflow logs other than timeout error, that means the subtask of workflow get failed due to timeout. In that case we can either try to restart the failed task or reboot/relaunch the corresponding server manually. We can restart the corresponding task with following command: ah-task restart TASK_ID The relaunch task may get failed if the vcs_path of any of the hosted site is not correct. In that case we need to correct the vcs path and only then we can complete the relaunch task. For more information, refer this runbook In addition to that I would suggest to go through the runbook workflow errors for more information about the workflow errors.","title":"Frequently Asked Questions on Reboots and Relaunches"},{"location":"realm_management/qna_on_reboot_relaunches/#frequently-asked-questions-on-reboots-and-relaunches","text":"We usually face couple of issues while doing mass reboots and relaunches. This runbook describe couple of main issues that usually occurs during reboots/relaunches:","title":"Frequently Asked Questions on Reboots and Relaunches"},{"location":"realm_management/qna_on_reboot_relaunches/#gluster-stuck-on-preprocessing_smoke_check_gluster_health-or-smoke_check_gluster_health-step","text":"This is a known issue with gluster that sometimes reboot/relaunch workflow get stuck at 'preprocessing_smoke_check_gluster_health' step. If you notice that workflow get stuck at 'preprocessing_smoke_check_gluster_health' for long time (normal than usual), then do the following things: check the workflow logs or the output of 'ah-workflow watch-queue' to see if you find any server with gluster issue. If you find any such server then fix the gluster issue and then monitor the progress of workflow. check with hotseat person if he/she receive any gluster alert related to the reboot/relaunch workflow. Sometime when the workflow get stuck then it doesn't show the gluster errors, however it alert over the PD. so it is advisable to check the PD and take actions accordingly. Check the gluster service of all the servers of the current workflow queue and take an action accordingly. If you couldn't resolve issue with the above steps, then try to fail the workflow so that you can get some error logs under workflow tasks. You can fail the workflow by remounting all the servers related to the current queue. If you couldn't resolve issue with all such steps, then escalate the issue to cloud team here","title":"Gluster stuck on 'preprocessing_smoke_check_gluster_health' or 'smoke_check_gluster_health' step"},{"location":"realm_management/qna_on_reboot_relaunches/#workflow-keep-failing-on-gluster-checks-even-after-manual-remounts","text":"It is often observed that reboot/relaunch workflow gets failed at 'preprocessing_smoke_check_gluster_health' step even after manual remount. In that case we should follow the steps mentioned below: check the gluster logs of the corresponding server and take actions accordingly. However if you don't find any issue then hard mount the gluster to see if it helps. If you couldn't resolve issue with above step and workflow still get failed, then its best to skip the gluster step with the following command: WORKFLOW_ID = NEXT_STEP_NAME = ah-workflow set-step $WORKFLOW_ID $NEXT_STEP_NAME Afterwards resume the workflow: ah-workflow resume $WORKFLOW_ID","title":"Workflow keep failing on Gluster checks even after manual remounts"},{"location":"realm_management/qna_on_reboot_relaunches/#replication-issues-in-database-non-multi-region","text":"This is a common issue which happens when we reboot/relaunch db servers. While rebooting/relaunching db servers if the replication time goes high at step 'wait_for_db_replication' then the workflow get reach to the error pause state. We should follow this runbook Mysql Replication Lag if such issue arises.","title":"Replication issues in database (non-multi-region)"},{"location":"realm_management/qna_on_reboot_relaunches/#replicationtungsten-issues-in-multi-region","text":"This is a common issue which happens when we reboot/relaunch multi-region db servers. While rebooting/relaunching db servers if the replication time goes high at step 'wait_for_db_replication' then the workflow get reach to the error pause state. We should follow this runbook Tungsten Troubleshooting if such issue arises.","title":"Replication/Tungsten issues in multi-region"},{"location":"realm_management/qna_on_reboot_relaunches/#disable_db_services-taking-time-or-get-stuck","text":"This is one of the uncommon issue which happens when the workflow get stuck or takes too much time at step 'disable_db_services'. This happens mostly because few processes get stuck and causes the subtasks to put in hang state. To resolve this issue, we should follow the steps mentioned below: find the subtask of 'disable_db_services' which get stuck. After running the below command, you may get number of task ids, you need to use the last task_id. ah-workflow get $WORKFLOW_ID | grep task_ids kill the last/current task that's got stuck: ah-task kill TASK_ID workflow will reach to error pause state afterwards. So you need to resume the workflow: ah-workflow resume $WORKFLOW_ID if the workflow again get stuck at the same step, then you need to follow the 1st step and then resume the workflow by skipping the 'disable_db_services' step.","title":"disable_db_services taking time or get stuck"},{"location":"realm_management/qna_on_reboot_relaunches/#debugging-rebootrelaunch-task-failures","text":"The reboot/relaunch tasks may get failed due to numbers of reasons. The reasons could be: If you are rebooting/relaunching a server, if it get failed and you didn't find anything under workflow logs other than timeout error, that means the subtask of workflow get failed due to timeout. In that case we can either try to restart the failed task or reboot/relaunch the corresponding server manually. We can restart the corresponding task with following command: ah-task restart TASK_ID The relaunch task may get failed if the vcs_path of any of the hosted site is not correct. In that case we need to correct the vcs path and only then we can complete the relaunch task. For more information, refer this runbook In addition to that I would suggest to go through the runbook workflow errors for more information about the workflow errors.","title":"Debugging reboot/relaunch task failures"},{"location":"realm_management/reboot_balancers/","text":"Reboot Bals Using Workflow Bals for a site or multiple sites can be rebooted using ah-bal-cluster command which will trigger a workflow based reboot with necessary failover of EIP of an active bal before starting a reboot task. Notes : * This method only works for standard bals where a bal is a part of a bal cluster (2 bals in a cluster having same bal_cluster_id fields property) * The ah-bal-cluster command option -V --vpc_id is ignored for edge clusters since it's elements can't be in different VPCs Variable setup If you are going to reboot a site's bals, find its bals as follows: SITE= BALS=($(ah-server list site:${SITE} -w type=bal)) REBOOT_OR_RELAUNCH=reboot If you are rebooting bals for multiple sites, fill the SITES array with the list of sites: SITES=() BALS=($(printf \"%s\\n\" ${SITES[@]} | xargs -P10 -I{} ah-server list site:{} -w type=bal)) REBOOT_OR_RELAUNCH=reboot Reboot bals ah-bal-cluster ${REBOOT_OR_RELAUNCH} --batch 20 ${BALS[@]} Note the workflow ID created and watch the workflow to completion.","title":"Reboot Bals Using Workflow"},{"location":"realm_management/reboot_balancers/#reboot-bals-using-workflow","text":"Bals for a site or multiple sites can be rebooted using ah-bal-cluster command which will trigger a workflow based reboot with necessary failover of EIP of an active bal before starting a reboot task. Notes : * This method only works for standard bals where a bal is a part of a bal cluster (2 bals in a cluster having same bal_cluster_id fields property) * The ah-bal-cluster command option -V --vpc_id is ignored for edge clusters since it's elements can't be in different VPCs","title":"Reboot Bals Using Workflow"},{"location":"realm_management/reboot_balancers/#variable-setup","text":"If you are going to reboot a site's bals, find its bals as follows: SITE= BALS=($(ah-server list site:${SITE} -w type=bal)) REBOOT_OR_RELAUNCH=reboot If you are rebooting bals for multiple sites, fill the SITES array with the list of sites: SITES=() BALS=($(printf \"%s\\n\" ${SITES[@]} | xargs -P10 -I{} ah-server list site:{} -w type=bal)) REBOOT_OR_RELAUNCH=reboot","title":"Variable setup"},{"location":"realm_management/reboot_balancers/#reboot-bals","text":"ah-bal-cluster ${REBOOT_OR_RELAUNCH} --batch 20 ${BALS[@]} Note the workflow ID created and watch the workflow to completion.","title":"Reboot bals"},{"location":"realm_management/reboot_master/","text":"Reboot a Master This guide assumes you have first read and followed the direction in the master down alert procedure . You must follow through it first before continuing, even if you are performing planned maintenance. There is information and a procedure for dealing with task and backup servers. Find the master The Master doesn't have a presence in the fields_master DB, so we have to find it in a very unique way Get the ip address MASTER_IP=$(host master.e.${FIELDS_STAGE}.f.e2a.us \\ | grep -Po '\\d+\\.\\d+\\.\\d+\\.\\d+$') Find the instance id: MASTER_INSTANCE_ID=$(aws ec2 describe-instances \\ --region=us-east-1 \\ --filters \"Name=ip-address,Values=${MASTER_IP}\" \\ --query 'Reservations[*].Instances[*].InstanceId' \\ --output text) Rebooting Check the status of the instance a couple of times to ensure it's not a double fail. A single fail can be fixed by rebooting. aws ec2 describe-instance-status \\ --region=us-east-1 \\ --instance-id=${MASTER_INSTANCE_ID} Reboot it with force aws ec2 reboot-instances --instance-ids=${MASTER_INSTANCE_ID} aws ec2 reboot-instances --instance-ids=${MASTER_INSTANCE_ID} As soon as the master is back from near death. fssh master sudo su - run-puppet Post Reboot Set variables OP= Check for stale task processes on task-% and kill as needed. fpdsh -t task-% -c \"sudo ps auxw | grep task\" Handle any stuck tasks before proceeding. Re-enable task and backup servers fpdsh -t task-%,backup-% \\ -c \"sudo puppet agent --enable && sudo puppet agent -t\" OR in Masterless Puppet mode fpdsh -t task-%,backup-% \\ -c \"sudo ah-puppet-enable && sudo run-puppet\" Check for hung ah-fields- processes across the stage. fpdsh -t % -p 100 -c \"ps auxww \\ | egrep '[a]h-admin-users|[a]h-config-hosts|[a]h-config-iptables'\" profit.","title":"Reboot a Master"},{"location":"realm_management/reboot_master/#reboot-a-master","text":"This guide assumes you have first read and followed the direction in the master down alert procedure . You must follow through it first before continuing, even if you are performing planned maintenance. There is information and a procedure for dealing with task and backup servers.","title":"Reboot a Master"},{"location":"realm_management/reboot_master/#find-the-master","text":"The Master doesn't have a presence in the fields_master DB, so we have to find it in a very unique way Get the ip address MASTER_IP=$(host master.e.${FIELDS_STAGE}.f.e2a.us \\ | grep -Po '\\d+\\.\\d+\\.\\d+\\.\\d+$') Find the instance id: MASTER_INSTANCE_ID=$(aws ec2 describe-instances \\ --region=us-east-1 \\ --filters \"Name=ip-address,Values=${MASTER_IP}\" \\ --query 'Reservations[*].Instances[*].InstanceId' \\ --output text)","title":"Find the master"},{"location":"realm_management/reboot_master/#rebooting","text":"Check the status of the instance a couple of times to ensure it's not a double fail. A single fail can be fixed by rebooting. aws ec2 describe-instance-status \\ --region=us-east-1 \\ --instance-id=${MASTER_INSTANCE_ID} Reboot it with force aws ec2 reboot-instances --instance-ids=${MASTER_INSTANCE_ID} aws ec2 reboot-instances --instance-ids=${MASTER_INSTANCE_ID} As soon as the master is back from near death. fssh master sudo su - run-puppet","title":"Rebooting"},{"location":"realm_management/reboot_master/#post-reboot","text":"Set variables OP= Check for stale task processes on task-% and kill as needed. fpdsh -t task-% -c \"sudo ps auxw | grep task\" Handle any stuck tasks before proceeding. Re-enable task and backup servers fpdsh -t task-%,backup-% \\ -c \"sudo puppet agent --enable && sudo puppet agent -t\" OR in Masterless Puppet mode fpdsh -t task-%,backup-% \\ -c \"sudo ah-puppet-enable && sudo run-puppet\" Check for hung ah-fields- processes across the stage. fpdsh -t % -p 100 -c \"ps auxww \\ | egrep '[a]h-admin-users|[a]h-config-hosts|[a]h-config-iptables'\" profit.","title":"Post Reboot"},{"location":"realm_management/reboot_search/","text":"Mass Rebooting Search Servers Note: To login Search jumpboxes, follow these instructions Prequisites Before you begin, you need to verify that the proper version of ah-server is used, should be the version located within the fields 1.81 subdirectory. which ah-server Patching To facilitate an easier patch/reboot cycle for legacy search, ah-server has been modified adding a patch (-p) flag. When this flag is used, ah-server will log onto each server, do an apt-get update , then an apt-get dist-upgrade before rebooting the server. Additionally, for situations in which we want to patch a server, but for some reason we do not want a package updated, a command has been added to ah-server to allow for holding and unholding packages. Below are examples of each command. ah-server hold <server>[,SERVER,...] -p git ah-server unhold <server>[,SERVER,...] -p git,apache2 Rebooting All Servers For rebooting ALL servers in the Search realm. [OPTIONAL] If there is a package or packages that shouldn't be upgraded, you can mark said package or packages to not be upgraded. This will just mark the packages so that they do not get updated when using the -p flag below. ah-server hold $(ah-server list % -w os=trusty | paste -sd,) -p {package} Reboot all the javaephem s (they make READ-HA with the javasrv s). ah-server reboot % -t javaephem -c 64 [-p] If the javaephem is an extractor, verify that it is functioning properly. Once all of the javaephem s are up and functioning properly, reboot all the javasrv s. ah-server reboot % -t javasrv -c 64 [-p] Reboot all nxephem servers Nginx package should not be updated when nxephems are patched. ah-server hold $(ah-server list % -w type=nxephem | paste -sd,) -p nginx Gather all the nxephem s by availability zone across all regions. AZS_1=ap-southeast-1a,ap-southeast-2a,eu-west-1a,us-west-2a,us-east-1b AZS_2=ap-southeast-1b,ap-southeast-2b,eu-west-1b,us-west-2b,us-east-1c AZS_3=eu-west-1c,us-east-1d,us-west-2c AZ_GROUP_1=$(ah-server list % -w status=0 type=nxephem \"ec2_availability_zone IN ${AZS_1}\" | paste -sd,) AZ_GROUP_2=$(ah-server list % -w status=0 type=nxephem \"ec2_availability_zone IN ${AZS_2}\" | paste -sd,) AZ_GROUP_3=$(ah-server list % -w status=0 type=nxephem \"ec2_availability_zone IN ${AZS_3}\" | paste -sd,) For each AZ_GROUP_X (Replace AZ_GROUP_X with the appropriate group where X would be one of 1 , 2 , or 3 .), Reboot all the nxephem s on the AZ group. ah-server reboot ${AZ_GROUP_X} -c 30 [-p] Verify that each nxephem is back in the ELB rotation before moving onto the next AZ group: for i in $(site-list ${AZ_GROUP_X} -v); do bundle exec site-elbdescribe ${i} done Repeat the above steps for each AZ group. Unhold nginx package after patch/rebooting all nxephem servers. ah-server unhold $(ah-server list % -w type=nxephem | paste -sd,) -p nginx Reboot the log servers with a concurrency of 1. ah-server reboot % -t log -c 1 [-p] Reboot the svn server. ah-server reboot svn-3 [-p] Reboot mon servers with a concurrency of 1. ah-server reboot % -t mon -c 1 [-p] Reboot stats servers. ah-server reboot % -t stats [-p] Reboot ossec servers. ah-server reboot % -t ossec [-p] Reboot the backup server. ah-server reboot backup-4 [-p] [OPTIONAL] If you held a package before patch/rebooting(in step 1), you will need to mark it an unheld. ah-server unhold $(ah-server list % -w os=trusty | paste -sd,) -p {package} Rebooting All Servers By Region For rebooting servers in the Search realm by region. [OPTIONAL] If there is a package or packages that shouldn't be upgraded, you can mark said package or packages to not be upgraded. ah-server hold $(ah-server list % -w os=trusty ec2_region=${REGION} | paste -sd,) -p {package} Reboot all the javaephem s in the region (they make READ-HA with the javasrv s). REGION= AZ= ah-server reboot % -t javaephem -r ${REGION} -c 64 [-p] If the javaephem is an extractor, verify that it is functioning properly. Once all of the javaephem s are up and functioning properly, reboot all the javasrv s. ah-server reboot % -t javasrv -r ${REGION} -c 64 [-p] Reboot all the nxephem s by AZ. Hold Nginx package if you are also patching the servers. ah-server hold $(ah-server list % -w type=nxephem ec2_region=${REGION} | paste -sd,) -p nginx Get availability zones of the region ah-server list % -w type=nxephem ec2_region=${REGION} --no-name -c ec2_availability_zone | sort | uniq For each availability zone, Reboot nxephems using below commands. AZ= ah-server reboot % -t nxephem -a ${AZ} -c 64 [-p] Verify that each nxephem is back in the ELB rotation before moving onto the next AZ: NXEPHEMS=$(ah-server list % -w ec2_availability_zone=${AZ} type=nxephem status=0 | paste -sd,) for i in $(site-list ${NXEPHEMS} -v); do bundle exec site-elbdescribe ${i} done Repeat same steps for all availability zones. Unhold Nginx package after rebooting all nxephem servers. ah-server unhold $(ah-server list % -w type=nxephem ec2_region=${REGION} | paste -sd,) -p nginx Reboot the log servers. ah-server reboot % -t log -r ${REGION} -c 1 [-p] Reboot the svn server. ah-server reboot svn-3 Patch/reboot mon servers with a concurrency of 1. ah-server reboot $(ah-server list % -w type=mon status=0 | paste -sd,) -c 1 [-p] [OPTIONAL] If you held a package before patch/rebooting, you will need to mark it an unheld. ah-server unhold $(ah-server list % -w os=trusty ec2_region=${REGION} | paste -sd,) -p {package} Rebooting a Subset of Servers For more granularity in your reboots, you will need to build a list of servers to reboot and manage them appropriately. Ideally, the Jira ticket should provide a fields query to produce these lists; examples are provided here as a potential default. Create your comma-delimited list of servers: SERVERS= [OPTIONAL] If there is a package or packages that shouldn't be upgraded, you can mark said package or packages to not be upgraded (eg: Nginx package must be held if you are patching nxephem servers) ah-server hold $SERVERS -p {package} Reboot the servers : ah-server reboot $SERVERS -c 64 [-p] [OPTIONAL] If you held a package before patch/rebooting, you will need to mark it an unheld. ah-server unhold $SERVERS -p {package} Rebooting the Master Patching and rebooting the master requires a manual approach. Log into the master instance: fssh master Become root, update repos and upgrade packages: apt-get update ; apt-get -y -q dist-upgrade -o Dpkg::Options::=\"--force-confdef\" -o Dpkg::Options::=\"--force-confold\" Reboot: reboot After a couple minutes, verify you can log back into the master and make sure the kernel is in the target version: uname -r Troubleshooting Disabling monitoring failed Squelching of index checks failed Server patching fails Server reboot failed Server fails to register with the Governor Rake rebuild fails Index unsquelch fails Re-enabling monitoring fails Reboot command errors out Disabling monitoring failed Disabling of the monitoring can fail for a number of reasons. When you see this, you should verify that monitoring is disabled by running the following, the result returned should be 1 : SERVER= ah-server list $SERVER -c monitoring_status If the result returned is 2 , you will need to disable monitoring as follows: ah-server edit $SERVER -s monitoring_status=1` Squelching of index checks failed This only effects javasrv's and javaephem's that are acting as slaves (meaning not extractors). If squelching fails, the operation's hot seat will receive index check failure alerts for the instance being rebooted, and this can result in the said operations person taking action which could interfere with your patch/rebooting. So you will want to try and manually squelching the index checks for the server as follows: TICKET= SERVER= ah-server searchindex $SERVER -s -r \"Patch/reboot - ${TICKET}\" Server patching fails This usually occurs because of one of two reasons. First, the server has already been patched meaning that patching was unnecessary. This can be confirmed by logging onto the server and running a sudo apt-get update and sudo apt-get upgrade . If no errors are returned, you can just reboot the server (i.e. sudo reboot ). If the package upgrade runs into errors, usually the quickest remedy is to just relaunch the instance. Server reboot failed If a server reboot has failed, more then likely the instance is impaired, so the best course of action is to relaunch the instance. Server fails to register with the Governor When it comes to reboots, this issue only occurs with javaephems . The reason for this is that the javasrvs have an EBS volume attached which stores the cores, so when the server is rebooted it doesn't have to get the core info from the Governor as it already has that info. The javaephem on the other hand doesn't use an EBS volume but instead relies upon ephemeral storage. So when the instance is rebooted, the server has to re-register with the Governor so that the list of cores can be retrieved from it. A server failing to register is usually caused by a stuck or backlogged queue. The Governor has only a single queue and is single-threaded, FIFO. To detect and fix the queue issues is a very delicate task as it requires direct manipulation of the Governor's database. To check the status of the queue,fo the following: anetwork fssh ded-177 sudo su mysql guvannuh To prevent any issues, we only concern ourselves with update_server tasks. They are regularly triggered via cron on each search server so emptying these tasks from the queue will have no long-term impact. However, before we clean out these tasks, we need to verify that it is an issue by executing the following query: select * from queue where data like '%update_server%'; If this query returns a significant number of records, things are getting hung up and it would be wise to clear these tasks out of the queue. It should be noted that it may take several attempts of clearing these tasks from the queue to get things moving again. To empty the queue of these tasks, execute the following query: delete from queue where data like '%update_server%'; To verify that the server has registered with the Governor , log onto the affected server and become the search UNIX user for the server. If you see a Rakefile in the home directory of the user, the server has been registered. Once the server has been registered, the rake dance will commence automatically, but it is often a good idea to follow up with a manual run to make sure all is well. Rake rebuild fails If a farm has a lot of cores with custom configs, it can take longer for the rake rebuild to run then the preset timeout. The usual resolution to this issue is to log onto the affected server and do the rake dance manually as follows: NOTE : If the server is a javaephem and is an extractor, you can ignore. Otherwise, you will need to determine the search UNIX user for the server, it is usually the region sans dashes with an as postfix (ex. useast1as). USERNAME= sudo su - $USERNAME rake rebuild rake cron If your should encounter and error doing running rake rebuild , refer to the this operation's runbook page. Index unsquelch fails The index check squelch is designed to last for only a hour, but unless a reboot has lasted for more then 50 minutes , it is best policy to attempt to manually unsquelch the index check for the affected server manually as follows: SERVER= ah-server search-index $SERVER --no-squelch Re-enabling monitoring fails You will need to manually verify that the server is being monitored by executing the following: SERVER= ah-server list $SERVER -c monitoring_status If the result returned is 1 then you will need to manually re-enable monitoring as follows: ah-server edit $SERVER -s monitoring_status=2 Reboot command errors out On occasion, an error will occur that will trigger the ah-server reboot command to error out to the command prompt, leaving you with little knowledge as to what has and hasn't been patched. This is a worse case scenario. Determine where in the process and on what server the issue occurred, this server will definitely have to be done manually by itself. Next you need to determine which servers were rebooted, the easiest way to determine this is to execute a fpdsh command and retrieving the server uptime, anything with an uptime within the window of starting the patch/reboot and executing the fpdsh command can be assumed to have been patched/rebooted. Below is an example if the list of servers being rebooted are javaephems: fpdsh -l $(ah-server list % -w type=javaephem status=0 | paste -sd,) -c uptime Any server that doesn't fall within that window still need to be patched/rebooted. You will need to gather these servers and assign them to a variable and supply the ah-server reboot command said variable. Once all of the patch/reboots have been completed, you will be perform an audit so you will be able to catch any servers that were missed at that point.","title":"Mass Rebooting Search Servers"},{"location":"realm_management/reboot_search/#mass-rebooting-search-servers","text":"Note: To login Search jumpboxes, follow these instructions","title":"Mass Rebooting Search Servers"},{"location":"realm_management/reboot_search/#prequisites","text":"Before you begin, you need to verify that the proper version of ah-server is used, should be the version located within the fields 1.81 subdirectory. which ah-server","title":"Prequisites"},{"location":"realm_management/reboot_search/#patching","text":"To facilitate an easier patch/reboot cycle for legacy search, ah-server has been modified adding a patch (-p) flag. When this flag is used, ah-server will log onto each server, do an apt-get update , then an apt-get dist-upgrade before rebooting the server. Additionally, for situations in which we want to patch a server, but for some reason we do not want a package updated, a command has been added to ah-server to allow for holding and unholding packages. Below are examples of each command. ah-server hold <server>[,SERVER,...] -p git ah-server unhold <server>[,SERVER,...] -p git,apache2","title":"Patching"},{"location":"realm_management/reboot_search/#rebooting-all-servers","text":"For rebooting ALL servers in the Search realm. [OPTIONAL] If there is a package or packages that shouldn't be upgraded, you can mark said package or packages to not be upgraded. This will just mark the packages so that they do not get updated when using the -p flag below. ah-server hold $(ah-server list % -w os=trusty | paste -sd,) -p {package} Reboot all the javaephem s (they make READ-HA with the javasrv s). ah-server reboot % -t javaephem -c 64 [-p] If the javaephem is an extractor, verify that it is functioning properly. Once all of the javaephem s are up and functioning properly, reboot all the javasrv s. ah-server reboot % -t javasrv -c 64 [-p] Reboot all nxephem servers Nginx package should not be updated when nxephems are patched. ah-server hold $(ah-server list % -w type=nxephem | paste -sd,) -p nginx Gather all the nxephem s by availability zone across all regions. AZS_1=ap-southeast-1a,ap-southeast-2a,eu-west-1a,us-west-2a,us-east-1b AZS_2=ap-southeast-1b,ap-southeast-2b,eu-west-1b,us-west-2b,us-east-1c AZS_3=eu-west-1c,us-east-1d,us-west-2c AZ_GROUP_1=$(ah-server list % -w status=0 type=nxephem \"ec2_availability_zone IN ${AZS_1}\" | paste -sd,) AZ_GROUP_2=$(ah-server list % -w status=0 type=nxephem \"ec2_availability_zone IN ${AZS_2}\" | paste -sd,) AZ_GROUP_3=$(ah-server list % -w status=0 type=nxephem \"ec2_availability_zone IN ${AZS_3}\" | paste -sd,) For each AZ_GROUP_X (Replace AZ_GROUP_X with the appropriate group where X would be one of 1 , 2 , or 3 .), Reboot all the nxephem s on the AZ group. ah-server reboot ${AZ_GROUP_X} -c 30 [-p] Verify that each nxephem is back in the ELB rotation before moving onto the next AZ group: for i in $(site-list ${AZ_GROUP_X} -v); do bundle exec site-elbdescribe ${i} done Repeat the above steps for each AZ group. Unhold nginx package after patch/rebooting all nxephem servers. ah-server unhold $(ah-server list % -w type=nxephem | paste -sd,) -p nginx Reboot the log servers with a concurrency of 1. ah-server reboot % -t log -c 1 [-p] Reboot the svn server. ah-server reboot svn-3 [-p] Reboot mon servers with a concurrency of 1. ah-server reboot % -t mon -c 1 [-p] Reboot stats servers. ah-server reboot % -t stats [-p] Reboot ossec servers. ah-server reboot % -t ossec [-p] Reboot the backup server. ah-server reboot backup-4 [-p] [OPTIONAL] If you held a package before patch/rebooting(in step 1), you will need to mark it an unheld. ah-server unhold $(ah-server list % -w os=trusty | paste -sd,) -p {package}","title":"Rebooting All Servers"},{"location":"realm_management/reboot_search/#rebooting-all-servers-by-region","text":"For rebooting servers in the Search realm by region. [OPTIONAL] If there is a package or packages that shouldn't be upgraded, you can mark said package or packages to not be upgraded. ah-server hold $(ah-server list % -w os=trusty ec2_region=${REGION} | paste -sd,) -p {package} Reboot all the javaephem s in the region (they make READ-HA with the javasrv s). REGION= AZ= ah-server reboot % -t javaephem -r ${REGION} -c 64 [-p] If the javaephem is an extractor, verify that it is functioning properly. Once all of the javaephem s are up and functioning properly, reboot all the javasrv s. ah-server reboot % -t javasrv -r ${REGION} -c 64 [-p] Reboot all the nxephem s by AZ. Hold Nginx package if you are also patching the servers. ah-server hold $(ah-server list % -w type=nxephem ec2_region=${REGION} | paste -sd,) -p nginx Get availability zones of the region ah-server list % -w type=nxephem ec2_region=${REGION} --no-name -c ec2_availability_zone | sort | uniq For each availability zone, Reboot nxephems using below commands. AZ= ah-server reboot % -t nxephem -a ${AZ} -c 64 [-p] Verify that each nxephem is back in the ELB rotation before moving onto the next AZ: NXEPHEMS=$(ah-server list % -w ec2_availability_zone=${AZ} type=nxephem status=0 | paste -sd,) for i in $(site-list ${NXEPHEMS} -v); do bundle exec site-elbdescribe ${i} done Repeat same steps for all availability zones. Unhold Nginx package after rebooting all nxephem servers. ah-server unhold $(ah-server list % -w type=nxephem ec2_region=${REGION} | paste -sd,) -p nginx Reboot the log servers. ah-server reboot % -t log -r ${REGION} -c 1 [-p] Reboot the svn server. ah-server reboot svn-3 Patch/reboot mon servers with a concurrency of 1. ah-server reboot $(ah-server list % -w type=mon status=0 | paste -sd,) -c 1 [-p] [OPTIONAL] If you held a package before patch/rebooting, you will need to mark it an unheld. ah-server unhold $(ah-server list % -w os=trusty ec2_region=${REGION} | paste -sd,) -p {package}","title":"Rebooting All Servers By Region"},{"location":"realm_management/reboot_search/#rebooting-a-subset-of-servers","text":"For more granularity in your reboots, you will need to build a list of servers to reboot and manage them appropriately. Ideally, the Jira ticket should provide a fields query to produce these lists; examples are provided here as a potential default. Create your comma-delimited list of servers: SERVERS= [OPTIONAL] If there is a package or packages that shouldn't be upgraded, you can mark said package or packages to not be upgraded (eg: Nginx package must be held if you are patching nxephem servers) ah-server hold $SERVERS -p {package} Reboot the servers : ah-server reboot $SERVERS -c 64 [-p] [OPTIONAL] If you held a package before patch/rebooting, you will need to mark it an unheld. ah-server unhold $SERVERS -p {package}","title":"Rebooting a Subset of Servers"},{"location":"realm_management/reboot_search/#rebooting-the-master","text":"Patching and rebooting the master requires a manual approach. Log into the master instance: fssh master Become root, update repos and upgrade packages: apt-get update ; apt-get -y -q dist-upgrade -o Dpkg::Options::=\"--force-confdef\" -o Dpkg::Options::=\"--force-confold\" Reboot: reboot After a couple minutes, verify you can log back into the master and make sure the kernel is in the target version: uname -r","title":"Rebooting the Master"},{"location":"realm_management/reboot_search/#troubleshooting","text":"Disabling monitoring failed Squelching of index checks failed Server patching fails Server reboot failed Server fails to register with the Governor Rake rebuild fails Index unsquelch fails Re-enabling monitoring fails Reboot command errors out","title":"Troubleshooting"},{"location":"realm_management/reboot_search/#disabling-monitoring-failed","text":"Disabling of the monitoring can fail for a number of reasons. When you see this, you should verify that monitoring is disabled by running the following, the result returned should be 1 : SERVER= ah-server list $SERVER -c monitoring_status If the result returned is 2 , you will need to disable monitoring as follows: ah-server edit $SERVER -s monitoring_status=1`","title":"Disabling monitoring failed"},{"location":"realm_management/reboot_search/#squelching-of-index-checks-failed","text":"This only effects javasrv's and javaephem's that are acting as slaves (meaning not extractors). If squelching fails, the operation's hot seat will receive index check failure alerts for the instance being rebooted, and this can result in the said operations person taking action which could interfere with your patch/rebooting. So you will want to try and manually squelching the index checks for the server as follows: TICKET= SERVER= ah-server searchindex $SERVER -s -r \"Patch/reboot - ${TICKET}\"","title":"Squelching of index checks failed"},{"location":"realm_management/reboot_search/#server-patching-fails","text":"This usually occurs because of one of two reasons. First, the server has already been patched meaning that patching was unnecessary. This can be confirmed by logging onto the server and running a sudo apt-get update and sudo apt-get upgrade . If no errors are returned, you can just reboot the server (i.e. sudo reboot ). If the package upgrade runs into errors, usually the quickest remedy is to just relaunch the instance.","title":"Server patching fails"},{"location":"realm_management/reboot_search/#server-reboot-failed","text":"If a server reboot has failed, more then likely the instance is impaired, so the best course of action is to relaunch the instance.","title":"Server reboot failed"},{"location":"realm_management/reboot_search/#server-fails-to-register-with-the-governor","text":"When it comes to reboots, this issue only occurs with javaephems . The reason for this is that the javasrvs have an EBS volume attached which stores the cores, so when the server is rebooted it doesn't have to get the core info from the Governor as it already has that info. The javaephem on the other hand doesn't use an EBS volume but instead relies upon ephemeral storage. So when the instance is rebooted, the server has to re-register with the Governor so that the list of cores can be retrieved from it. A server failing to register is usually caused by a stuck or backlogged queue. The Governor has only a single queue and is single-threaded, FIFO. To detect and fix the queue issues is a very delicate task as it requires direct manipulation of the Governor's database. To check the status of the queue,fo the following: anetwork fssh ded-177 sudo su mysql guvannuh To prevent any issues, we only concern ourselves with update_server tasks. They are regularly triggered via cron on each search server so emptying these tasks from the queue will have no long-term impact. However, before we clean out these tasks, we need to verify that it is an issue by executing the following query: select * from queue where data like '%update_server%'; If this query returns a significant number of records, things are getting hung up and it would be wise to clear these tasks out of the queue. It should be noted that it may take several attempts of clearing these tasks from the queue to get things moving again. To empty the queue of these tasks, execute the following query: delete from queue where data like '%update_server%'; To verify that the server has registered with the Governor , log onto the affected server and become the search UNIX user for the server. If you see a Rakefile in the home directory of the user, the server has been registered. Once the server has been registered, the rake dance will commence automatically, but it is often a good idea to follow up with a manual run to make sure all is well.","title":"Server fails to register with the Governor"},{"location":"realm_management/reboot_search/#rake-rebuild-fails","text":"If a farm has a lot of cores with custom configs, it can take longer for the rake rebuild to run then the preset timeout. The usual resolution to this issue is to log onto the affected server and do the rake dance manually as follows: NOTE : If the server is a javaephem and is an extractor, you can ignore. Otherwise, you will need to determine the search UNIX user for the server, it is usually the region sans dashes with an as postfix (ex. useast1as). USERNAME= sudo su - $USERNAME rake rebuild rake cron If your should encounter and error doing running rake rebuild , refer to the this operation's runbook page.","title":"Rake rebuild fails"},{"location":"realm_management/reboot_search/#index-unsquelch-fails","text":"The index check squelch is designed to last for only a hour, but unless a reboot has lasted for more then 50 minutes , it is best policy to attempt to manually unsquelch the index check for the affected server manually as follows: SERVER= ah-server search-index $SERVER --no-squelch","title":"Index unsquelch fails"},{"location":"realm_management/reboot_search/#re-enabling-monitoring-fails","text":"You will need to manually verify that the server is being monitored by executing the following: SERVER= ah-server list $SERVER -c monitoring_status If the result returned is 1 then you will need to manually re-enable monitoring as follows: ah-server edit $SERVER -s monitoring_status=2","title":"Re-enabling monitoring fails"},{"location":"realm_management/reboot_search/#reboot-command-errors-out","text":"On occasion, an error will occur that will trigger the ah-server reboot command to error out to the command prompt, leaving you with little knowledge as to what has and hasn't been patched. This is a worse case scenario. Determine where in the process and on what server the issue occurred, this server will definitely have to be done manually by itself. Next you need to determine which servers were rebooted, the easiest way to determine this is to execute a fpdsh command and retrieving the server uptime, anything with an uptime within the window of starting the patch/reboot and executing the fpdsh command can be assumed to have been patched/rebooted. Below is an example if the list of servers being rebooted are javaephems: fpdsh -l $(ah-server list % -w type=javaephem status=0 | paste -sd,) -c uptime Any server that doesn't fall within that window still need to be patched/rebooted. You will need to gather these servers and assign them to a variable and supply the ah-server reboot command said variable. Once all of the patch/reboots have been completed, you will be perform an audit so you will be able to catch any servers that were missed at that point.","title":"Reboot command errors out"},{"location":"realm_management/rebooting_aws/","text":"Mass patching using AWS method We are using a new method to reboot servers directly using AWS and other Ops commands. We have developed a tool which will print all the commands which need to be executed on the terminal including monitoring enable, disable, service checks and fs remount commands. This tool supports staging, free, srv, ded, dbmaster, fsdb and web type servers where servers like webs and fs will be rebooted AZ wise and rest all like staging, ded, dbmaster, srv etc will be rebooted region wise while maintaining the HA if required. [cloudservicesprod|devcloud:devcloud] ~/fields/1.149$ ahops-reboot-aws Some inputs are missing Usage: ahops-reboot-aws options: -t : SERVER_TYPE : # Supported are free web srv fs staging ded fsdb dbmaster -r : REGION : # Region like us-east-1 us-west-2 eu-central-1 etc. -a : AVAILABILITY_ZONE : # AZ like us-east-1e us-west-2a eu-central-1a etc and only works with webs and fs. -s : SERVER_LIST : # Server list is all the servers need to reboot with delimeter separated. -h : HELP : # To check the script usage. For cplane, dbmesh, fsdbmesh or bal servers use normal workflows. Preparation Set variables as mentioned in the ticket's description till updating packages and then follow below commands per server type. Non HA servers Free REGION= #Get this from the maintenance ticket TYPE=free FREE_SRVS=$(ah-server list % -w \"name IN ${SERVERS}\" typeINfree | sort -V | paste -sd,) ahops-reboot-aws -t $TYPE -r $REGION -s $FREE_SRVS SRV REGION= #Get this from the maintenance ticket TYPE=srv SRV_SRVS=$(ah-server list % -w \"name IN ${SERVERS}\" typeINsrv | sort -V | paste -sd,) ahops-reboot-aws -t $TYPE -r $REGION -s $SRV_SRVS Staging REGION= #Get this from the maintenance ticket TYPE=staging STG_SRVS=$(ah-server list % -w \"name IN ${SERVERS}\" typeINstaging | sort -V | paste -sd,) ahops-reboot-aws -t $TYPE -r $REGION -s $STG_SRVS Database Servers Create a list of all the database servers: ALL_DBS=$(ah-server list % -w \"name IN ${SERVERS}\" typeINded,fsdb,dbmaster | paste -sd,) Deds Run this command to generate the required commands to perform action: REGION= #Get this from the maintenance ticket TYPE=ded DED_SRVS=$(ah-server list % -w \"name IN ${ALL_DBS}\" typeINded | paste -sd,) ahops-reboot-aws -t $TYPE -r $REGION -s $DED_SRVS Fsdb Run this command to generate the required commands to perform action: REGION= #Get this from the maintenance ticket TYPE=fsdb FSDB_SRVS=$(ah-server list % -w \"name IN ${ALL_DBS}\" typeINfsdb | paste -sd,) ahops-reboot-aws -t $TYPE -r $REGION -s $FSDB_SRVS DB master Run this command to generate the required commands to perform action: REGION= #Get this from the maintenance ticket TYPE=dbmaster DBMASTER_SRVS=$(ah-server list % -w \"name IN ${ALL_DBS}\" typeINdbmaster | paste -sd,) ahops-reboot-aws -t $TYPE -r $REGION -s $DBMASTER_SRVS File System servers FS TYPE=fs for FS_AZ in $(aws ec2 describe-availability-zones --region $REGION | grep ZoneName |cut -f4 -d '\"' | paste -sd \" \") ; do echo \"List of fs in \"$FS_AZ\" zone\"; echo \"FS_SRVS=\"$(ah-server list % -w \"name IN ${SERVERS}\" typeINfs ec2_availability_zone=$FS_AZ | paste -sd,) echo \"AVAILABILITY_ZONE=$FS_AZ\" echo done Set the variable FS_SRVS and AVAILABILITY_ZONE for each availability zone and reboot the servers. ahops-reboot-aws -t $TYPE -a $AVAILABILITY_ZONE -s $FS_SRVS Web Servers Webs TYPE=web for WEB_AZ in $(aws ec2 describe-availability-zones --region $REGION | grep ZoneName |cut -f4 -d '\"' | paste -sd \" \") ; do echo \"List of webs in \"$WEB_AZ\" zone\"; echo \"WEB_SRVS=\"$(ah-server list % -w \"name IN ${SERVERS}\" typeINweb ec2_availability_zone=$WEB_AZ | paste -sd,) echo \"AVAILABILITY_ZONE=$WEB_AZ\" echo done Set the variable WEB_SRVS and AVAILABILITY_ZONE for each availability zone and reboot the servers. ahops-reboot-aws -t $TYPE -a $AVAILABILITY_ZONE -s $WEB_SRVS","title":"Mass patching using AWS method"},{"location":"realm_management/rebooting_aws/#mass-patching-using-aws-method","text":"We are using a new method to reboot servers directly using AWS and other Ops commands. We have developed a tool which will print all the commands which need to be executed on the terminal including monitoring enable, disable, service checks and fs remount commands. This tool supports staging, free, srv, ded, dbmaster, fsdb and web type servers where servers like webs and fs will be rebooted AZ wise and rest all like staging, ded, dbmaster, srv etc will be rebooted region wise while maintaining the HA if required. [cloudservicesprod|devcloud:devcloud] ~/fields/1.149$ ahops-reboot-aws Some inputs are missing Usage: ahops-reboot-aws options: -t : SERVER_TYPE : # Supported are free web srv fs staging ded fsdb dbmaster -r : REGION : # Region like us-east-1 us-west-2 eu-central-1 etc. -a : AVAILABILITY_ZONE : # AZ like us-east-1e us-west-2a eu-central-1a etc and only works with webs and fs. -s : SERVER_LIST : # Server list is all the servers need to reboot with delimeter separated. -h : HELP : # To check the script usage. For cplane, dbmesh, fsdbmesh or bal servers use normal workflows.","title":"Mass patching using AWS method"},{"location":"realm_management/rebooting_aws/#preparation","text":"Set variables as mentioned in the ticket's description till updating packages and then follow below commands per server type.","title":"Preparation"},{"location":"realm_management/rebooting_aws/#non-ha-servers","text":"","title":"Non HA servers"},{"location":"realm_management/rebooting_aws/#free","text":"REGION= #Get this from the maintenance ticket TYPE=free FREE_SRVS=$(ah-server list % -w \"name IN ${SERVERS}\" typeINfree | sort -V | paste -sd,) ahops-reboot-aws -t $TYPE -r $REGION -s $FREE_SRVS","title":"Free"},{"location":"realm_management/rebooting_aws/#srv","text":"REGION= #Get this from the maintenance ticket TYPE=srv SRV_SRVS=$(ah-server list % -w \"name IN ${SERVERS}\" typeINsrv | sort -V | paste -sd,) ahops-reboot-aws -t $TYPE -r $REGION -s $SRV_SRVS","title":"SRV"},{"location":"realm_management/rebooting_aws/#staging","text":"REGION= #Get this from the maintenance ticket TYPE=staging STG_SRVS=$(ah-server list % -w \"name IN ${SERVERS}\" typeINstaging | sort -V | paste -sd,) ahops-reboot-aws -t $TYPE -r $REGION -s $STG_SRVS","title":"Staging"},{"location":"realm_management/rebooting_aws/#database-servers","text":"Create a list of all the database servers: ALL_DBS=$(ah-server list % -w \"name IN ${SERVERS}\" typeINded,fsdb,dbmaster | paste -sd,)","title":"Database Servers"},{"location":"realm_management/rebooting_aws/#deds","text":"Run this command to generate the required commands to perform action: REGION= #Get this from the maintenance ticket TYPE=ded DED_SRVS=$(ah-server list % -w \"name IN ${ALL_DBS}\" typeINded | paste -sd,) ahops-reboot-aws -t $TYPE -r $REGION -s $DED_SRVS","title":"Deds"},{"location":"realm_management/rebooting_aws/#fsdb","text":"Run this command to generate the required commands to perform action: REGION= #Get this from the maintenance ticket TYPE=fsdb FSDB_SRVS=$(ah-server list % -w \"name IN ${ALL_DBS}\" typeINfsdb | paste -sd,) ahops-reboot-aws -t $TYPE -r $REGION -s $FSDB_SRVS","title":"Fsdb"},{"location":"realm_management/rebooting_aws/#db-master","text":"Run this command to generate the required commands to perform action: REGION= #Get this from the maintenance ticket TYPE=dbmaster DBMASTER_SRVS=$(ah-server list % -w \"name IN ${ALL_DBS}\" typeINdbmaster | paste -sd,) ahops-reboot-aws -t $TYPE -r $REGION -s $DBMASTER_SRVS","title":"DB master"},{"location":"realm_management/rebooting_aws/#file-system-servers","text":"","title":"File System servers"},{"location":"realm_management/rebooting_aws/#fs","text":"TYPE=fs for FS_AZ in $(aws ec2 describe-availability-zones --region $REGION | grep ZoneName |cut -f4 -d '\"' | paste -sd \" \") ; do echo \"List of fs in \"$FS_AZ\" zone\"; echo \"FS_SRVS=\"$(ah-server list % -w \"name IN ${SERVERS}\" typeINfs ec2_availability_zone=$FS_AZ | paste -sd,) echo \"AVAILABILITY_ZONE=$FS_AZ\" echo done Set the variable FS_SRVS and AVAILABILITY_ZONE for each availability zone and reboot the servers. ahops-reboot-aws -t $TYPE -a $AVAILABILITY_ZONE -s $FS_SRVS","title":"FS"},{"location":"realm_management/rebooting_aws/#web-servers","text":"","title":"Web Servers"},{"location":"realm_management/rebooting_aws/#webs","text":"TYPE=web for WEB_AZ in $(aws ec2 describe-availability-zones --region $REGION | grep ZoneName |cut -f4 -d '\"' | paste -sd \" \") ; do echo \"List of webs in \"$WEB_AZ\" zone\"; echo \"WEB_SRVS=\"$(ah-server list % -w \"name IN ${SERVERS}\" typeINweb ec2_availability_zone=$WEB_AZ | paste -sd,) echo \"AVAILABILITY_ZONE=$WEB_AZ\" echo done Set the variable WEB_SRVS and AVAILABILITY_ZONE for each availability zone and reboot the servers. ahops-reboot-aws -t $TYPE -a $AVAILABILITY_ZONE -s $WEB_SRVS","title":"Webs"},{"location":"realm_management/rebooting_relaunching/","text":"Mass Rebooting and Relaunching Procedure Overview We maintain thousands of servers across multiple Realms for hundreds of businesses. Ensuring that each mass reboot task is suitably broken up into manageable bite sized pieces ensures we retain complete control of the process. Table of Contents IMPORTANT NOTES! ALWAYS READ ME! Credentials OS Upgrades The bulk-reboot and bulk-relaunch Workflow Monitoring the Status of Tasks and Workflows Preparation Rebooting or Relaunching Control Plane Customer Non-HA Servers Balancers Databases FS Servers Multiregion Databases Webs Search Servers Custom Servers Node/Nodebal Servers Audit for completion Dealing with Workflow errors IMPORTANT NOTES The bulk-reboot Workflow TODO: Update this runbook once AUTO-1650 is fixed to allow multiple server types per invocation of bulk-reboot . TODO: Update this runbook once AUTO-1681 is fixed to allow duplicate server names in lists. Monitoring Tasks and Workflows TODO: Currently, watch-queue only works with web , fs , and db type bulk workflows. Update this runbook once AUTO confirms all types are ported over to the queued system. Certain bulk workflows can be tracked using the ah-workflow watch-queue tool. At this time it does not auto refresh so we will use watch to self automate this. WORKFLOW_ID= watch -n 30 \"ah-workflow watch-queue ${WORKFLOW_ID}\" Here is a sample output of ah-workflow watch-queue . The numbers in parentheses display the reboot task ID for each server. Queued status (3 entities, 16.67% of the queue) web-138, web-139, web-140 Processing status (1 entities, 5.56% of the queue) web-129 (1704129) Postprocessing status (5 entities, 27.78% of the queue) web-65 (1703749), web-69 (1703752), web-70 (1703753), web-127 (1704128), web-137 (1703757) Done status (4 entities, 22.22% of the queue) web-67 (1703750), web-68 (1703751), web-126 (1703755), web-128 (1703756) Failed status (1 entities, 5.56% of the queue) web-77 (1703754) Skipped status (4 entities, 22.22% of the queue) web-66, web-78, web-79, web-80 If you need to watch the progress of a running task, run: sv-streamrunningtask ${TASK_ID} If you want to only see what servers are being processed at this time you can use the following one-liner: ah-workflow watch-queue ${WORKFLOW_ID} | grep -A 2 \"Processing status\" If a failure occurs the server will be marked as failed and a notification will be sent to the hipchat channel Operations or Workflow Notifications indicating that the workflow has a failure. This does not mean that the workflow has failed, it means that a task within that workflow requires attention. Important Note Do not abort workflows! If you are unable to resolve a problem with a workflow, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership Credentials Ensure you have credentials for the following items in your realm-specific netrc file. This list is not exhaustive, so if you're unsure, ask another Ops person. If you relaunch a host and it seems to not be working or the launch fails, it's likely that you're missing credentials from that realm's netrc file. machine nettica.client ... fields.rpc.acquia.com ... machine sumologic.id ... backup.ec2.client ... Scheduling maintenance for AMI type Change If you need to start at a specific time, calculate the UNIX_START_TIME variable: UNIX_START_TIME=$(date -d '2018/03/22 20:00 UTC' +\"%s\") add the following flag to your ah-server bulk-relaunch command: --scheduled-time ${UNIX_START_TIME} Below command is suitable for all servers except bals and Mesh servers. AMI_TYPE= ah-server bulk-relaunch s-xxxx s-yyyy --batch 1 --ami-type $AMI_TYPE --scheduled-time ${UNIX_START_TIME} Use below commands for Bals Only. ah-bal-cluster relaunch bal-xxxx bal-yyyy --batch 1 --ami-type $AMI_TYPE --scheduled-time ${UNIX_START_TIME} Notes : * This method only works for standard bals where a bal is a part of a bal cluster (2 bals in a cluster having same bal_cluster_id fields property) * The ah-bal-cluster command option -V --vpc_id is ignored for edge clusters since it's elements can't be in different VPCs To Check scheduled maintenance information and status, Run scheduled_task=$(ah-workflow get ${WORKFLOW_ID} | grep -w \"scheduled_task_ids.0\"|cut -d: -f2) wf-scheduled or ah-scheduled-task get $scheduled_task To Cancel/Remove the scheduled task in case if your maintenance will cancelled, Run ah-scheduled-task kill $scheduled_task Beware: Always check the last hrs update in your maintenance ticket for cancellation updates if any. Note : Above workflow will only supports same type of servers. Please refer below recommended batch size. OS Upgrades If you are upgrading systems to Ubuntu Xenial 16.04, you must specify as such by giving the -o xenial option to ah-server bulk-relaunch or ah-bal-cluster relaunch . For example: UPGRADE_OS=\"-o xenial\" ah-server bulk-relaunch ${UPGRADE_OS} ${LIST_OF_SERVERS} --send-notifications false Note : Use the \u2014batch-size option when performing single site relaunches(logical stack) due to a bug . Batch size can be selected as per the table given below: Web count Batch size 1 1 2 1 3 1 4 1 5 1 6 1 7 1 8 2 9 2 10 2 11 2 12 3 13 3 14 3 15 3 16 4 Note : In order to receive workflow failure notifications --send-notications false flag can be avoided. Or: sv-taskrelaunch server -m 1 -o xenial ${CSV_OF_SERVERS} If you use UPGRADE_OS , you must declare it as a full string \"-o xenial\" or \"-o precise\" . If, for some reason, these commands do not work you can manually edit the os config in fields and relaunch: ah-server edit ${SERVER_NAME} -s os=xenial ah-server relaunch ${SERVER_NAME} If something goes wrong, revert to Precise by specifying precise with any of the above commands. Currently supported Xenial Server types for upgrade are: api, backup, bal, custom, dbmaster, dbmesh, ded, dns, free, fs, fsdb, fsdbmesh, log, managed, ossec, srv, staging, svn, task, web . Availability Zone Check Now we have a script that will check if high availability is maintained in the site by having different availability zones for webs, fsdb, ded, bal, fs, dbmaster, fsdbmesh and dbmesh in a single region. Before doing mass reboot, you can use this script to verify that a site must not go down due to rebooting webs, fsdb, ded, bal, fs, dbmaster, fsdbmesh or dbmesh in a same availability zone. To use this tool supply the list of servers on which you want to verify the availability zone and it will list down all the servers belonging to same site in same availability zone. For any given list of servers, for any given sitegroup in all realms the following conditions will be true: Fsdb,ded,bal,fs,db-master,fsdb-mesh,db-mesh pairs have 2 AZs. Amount of webs=2 should have 2 AZs. Amount of webs>2 should have 2 or more AZs. A single AZ should not total over 50% of the amount of webs on a sitegroup. Cron and memcache labeled webs should be excluded from amount of webs. Srv, Svn and staging type servers are excluded from AZ check. SERVER_CSV= sv-azcheck ${SERVER_CSV} Preparation Before any mass reboot task can be scheduled and actioned all patching and preparation steps must first be completed. For mass patching you must first follow the Mass Patching Procedure document. Between the different types, or classes, of servers the reboot procedure changes. To make mass reboots easier, lists should be broken up in to server type and then AZ. Additionally, since servers are rebooted and re-launched between the filing of a ticket and its execution, the ticket for the reboots should provide a command that generates a list of servers to reboot in CSV format and stores it in SERVERS , for example: OP= REBOOT_OR_RELAUNCH= # valid values: reboot,relaunch REGION= SERVERS=$(ah-server list % -w status=0 ec2_region=${REGION} | sort -V | paste -sd,) Note: Servers cannot be upgraded to Xenial by rebooting them! Xenial upgrades must be relaunched ! All mass maintenance runbooks require that SERVERS , REGION , REBOOT_OR_RELAUNCH and OP are properly initialized! Rebooting or Relaunching Rebooting or Relaunching master , backup , and task servers are done once for every realm and requires special care, since they can potentially impact the performance of an entire realm. Use the following runbooks to handle these types of servers: Master Backup Task CPLANE ( dns , ossec , stats , log , svn ) CPLANE Customer Non-HA Servers ( free , srv , staging , api ) NON-HA Balancers ( bal ) Balancers Databases ( ded , fsdb , dbmaster ) Database Servers Manual Database Servers Filesystem-only servers ( fs ) Filesystem Servers Manual Filesystem Severs Tungsten Multiregion servers ( fsdbmesh , dbmesh ) Multiregion Databases Webs ( managed , web ) Webs and Managed Servers Maual Webs and Managed Servers Custom servers ( custom ) Custom Servers Search Servers ( nxephem , javasrv , javaephem ) Rebooting Search Servers Relaunching Search Servers Node servers ( node , nodebal ) Relaunching Node Servers Rebooting Node Servers Dealing with Workflow errors Workflow Recovery Auditing When all of the reboots are done, you should audit to check they all succeeded. Make sure SERVERS is set correctly. HOURS_SINCE_START= fpdsh -l ${SERVERS} -p 100 -c \"awk '{print int(\\$1/$((60*60)))}' /proc/uptime\" | awk \"\\$2 > ${HOURS_SINCE_START}\" TODO: Check version of kernel and important packages updated.","title":"Mass Rebooting and Relaunching Procedure"},{"location":"realm_management/rebooting_relaunching/#mass-rebooting-and-relaunching-procedure","text":"","title":"Mass Rebooting and Relaunching Procedure"},{"location":"realm_management/rebooting_relaunching/#overview","text":"We maintain thousands of servers across multiple Realms for hundreds of businesses. Ensuring that each mass reboot task is suitably broken up into manageable bite sized pieces ensures we retain complete control of the process.","title":"Overview"},{"location":"realm_management/rebooting_relaunching/#table-of-contents","text":"IMPORTANT NOTES! ALWAYS READ ME! Credentials OS Upgrades The bulk-reboot and bulk-relaunch Workflow Monitoring the Status of Tasks and Workflows Preparation Rebooting or Relaunching Control Plane Customer Non-HA Servers Balancers Databases FS Servers Multiregion Databases Webs Search Servers Custom Servers Node/Nodebal Servers Audit for completion Dealing with Workflow errors","title":"Table of Contents"},{"location":"realm_management/rebooting_relaunching/#important-notes","text":"","title":"IMPORTANT NOTES"},{"location":"realm_management/rebooting_relaunching/#the-bulk-reboot-workflow","text":"TODO: Update this runbook once AUTO-1650 is fixed to allow multiple server types per invocation of bulk-reboot . TODO: Update this runbook once AUTO-1681 is fixed to allow duplicate server names in lists.","title":"The bulk-reboot Workflow"},{"location":"realm_management/rebooting_relaunching/#monitoring-tasks-and-workflows","text":"TODO: Currently, watch-queue only works with web , fs , and db type bulk workflows. Update this runbook once AUTO confirms all types are ported over to the queued system. Certain bulk workflows can be tracked using the ah-workflow watch-queue tool. At this time it does not auto refresh so we will use watch to self automate this. WORKFLOW_ID= watch -n 30 \"ah-workflow watch-queue ${WORKFLOW_ID}\" Here is a sample output of ah-workflow watch-queue . The numbers in parentheses display the reboot task ID for each server. Queued status (3 entities, 16.67% of the queue) web-138, web-139, web-140 Processing status (1 entities, 5.56% of the queue) web-129 (1704129) Postprocessing status (5 entities, 27.78% of the queue) web-65 (1703749), web-69 (1703752), web-70 (1703753), web-127 (1704128), web-137 (1703757) Done status (4 entities, 22.22% of the queue) web-67 (1703750), web-68 (1703751), web-126 (1703755), web-128 (1703756) Failed status (1 entities, 5.56% of the queue) web-77 (1703754) Skipped status (4 entities, 22.22% of the queue) web-66, web-78, web-79, web-80 If you need to watch the progress of a running task, run: sv-streamrunningtask ${TASK_ID} If you want to only see what servers are being processed at this time you can use the following one-liner: ah-workflow watch-queue ${WORKFLOW_ID} | grep -A 2 \"Processing status\" If a failure occurs the server will be marked as failed and a notification will be sent to the hipchat channel Operations or Workflow Notifications indicating that the workflow has a failure. This does not mean that the workflow has failed, it means that a task within that workflow requires attention.","title":"Monitoring Tasks and Workflows"},{"location":"realm_management/rebooting_relaunching/#important-note","text":"Do not abort workflows! If you are unable to resolve a problem with a workflow, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership","title":"Important Note"},{"location":"realm_management/rebooting_relaunching/#credentials","text":"Ensure you have credentials for the following items in your realm-specific netrc file. This list is not exhaustive, so if you're unsure, ask another Ops person. If you relaunch a host and it seems to not be working or the launch fails, it's likely that you're missing credentials from that realm's netrc file. machine nettica.client ... fields.rpc.acquia.com ... machine sumologic.id ... backup.ec2.client ...","title":"Credentials"},{"location":"realm_management/rebooting_relaunching/#scheduling-maintenance-for-ami-type-change","text":"If you need to start at a specific time, calculate the UNIX_START_TIME variable: UNIX_START_TIME=$(date -d '2018/03/22 20:00 UTC' +\"%s\") add the following flag to your ah-server bulk-relaunch command: --scheduled-time ${UNIX_START_TIME} Below command is suitable for all servers except bals and Mesh servers. AMI_TYPE= ah-server bulk-relaunch s-xxxx s-yyyy --batch 1 --ami-type $AMI_TYPE --scheduled-time ${UNIX_START_TIME} Use below commands for Bals Only. ah-bal-cluster relaunch bal-xxxx bal-yyyy --batch 1 --ami-type $AMI_TYPE --scheduled-time ${UNIX_START_TIME} Notes : * This method only works for standard bals where a bal is a part of a bal cluster (2 bals in a cluster having same bal_cluster_id fields property) * The ah-bal-cluster command option -V --vpc_id is ignored for edge clusters since it's elements can't be in different VPCs To Check scheduled maintenance information and status, Run scheduled_task=$(ah-workflow get ${WORKFLOW_ID} | grep -w \"scheduled_task_ids.0\"|cut -d: -f2) wf-scheduled or ah-scheduled-task get $scheduled_task To Cancel/Remove the scheduled task in case if your maintenance will cancelled, Run ah-scheduled-task kill $scheduled_task Beware: Always check the last hrs update in your maintenance ticket for cancellation updates if any. Note : Above workflow will only supports same type of servers. Please refer below recommended batch size.","title":"Scheduling maintenance for AMI type Change"},{"location":"realm_management/rebooting_relaunching/#os-upgrades","text":"If you are upgrading systems to Ubuntu Xenial 16.04, you must specify as such by giving the -o xenial option to ah-server bulk-relaunch or ah-bal-cluster relaunch . For example: UPGRADE_OS=\"-o xenial\" ah-server bulk-relaunch ${UPGRADE_OS} ${LIST_OF_SERVERS} --send-notifications false Note : Use the \u2014batch-size option when performing single site relaunches(logical stack) due to a bug . Batch size can be selected as per the table given below: Web count Batch size 1 1 2 1 3 1 4 1 5 1 6 1 7 1 8 2 9 2 10 2 11 2 12 3 13 3 14 3 15 3 16 4 Note : In order to receive workflow failure notifications --send-notications false flag can be avoided. Or: sv-taskrelaunch server -m 1 -o xenial ${CSV_OF_SERVERS} If you use UPGRADE_OS , you must declare it as a full string \"-o xenial\" or \"-o precise\" . If, for some reason, these commands do not work you can manually edit the os config in fields and relaunch: ah-server edit ${SERVER_NAME} -s os=xenial ah-server relaunch ${SERVER_NAME} If something goes wrong, revert to Precise by specifying precise with any of the above commands. Currently supported Xenial Server types for upgrade are: api, backup, bal, custom, dbmaster, dbmesh, ded, dns, free, fs, fsdb, fsdbmesh, log, managed, ossec, srv, staging, svn, task, web .","title":"OS Upgrades"},{"location":"realm_management/rebooting_relaunching/#availability-zone-check","text":"Now we have a script that will check if high availability is maintained in the site by having different availability zones for webs, fsdb, ded, bal, fs, dbmaster, fsdbmesh and dbmesh in a single region. Before doing mass reboot, you can use this script to verify that a site must not go down due to rebooting webs, fsdb, ded, bal, fs, dbmaster, fsdbmesh or dbmesh in a same availability zone. To use this tool supply the list of servers on which you want to verify the availability zone and it will list down all the servers belonging to same site in same availability zone. For any given list of servers, for any given sitegroup in all realms the following conditions will be true: Fsdb,ded,bal,fs,db-master,fsdb-mesh,db-mesh pairs have 2 AZs. Amount of webs=2 should have 2 AZs. Amount of webs>2 should have 2 or more AZs. A single AZ should not total over 50% of the amount of webs on a sitegroup. Cron and memcache labeled webs should be excluded from amount of webs. Srv, Svn and staging type servers are excluded from AZ check. SERVER_CSV= sv-azcheck ${SERVER_CSV}","title":"Availability Zone Check"},{"location":"realm_management/rebooting_relaunching/#preparation","text":"Before any mass reboot task can be scheduled and actioned all patching and preparation steps must first be completed. For mass patching you must first follow the Mass Patching Procedure document. Between the different types, or classes, of servers the reboot procedure changes. To make mass reboots easier, lists should be broken up in to server type and then AZ. Additionally, since servers are rebooted and re-launched between the filing of a ticket and its execution, the ticket for the reboots should provide a command that generates a list of servers to reboot in CSV format and stores it in SERVERS , for example: OP= REBOOT_OR_RELAUNCH= # valid values: reboot,relaunch REGION= SERVERS=$(ah-server list % -w status=0 ec2_region=${REGION} | sort -V | paste -sd,) Note: Servers cannot be upgraded to Xenial by rebooting them! Xenial upgrades must be relaunched ! All mass maintenance runbooks require that SERVERS , REGION , REBOOT_OR_RELAUNCH and OP are properly initialized!","title":"Preparation"},{"location":"realm_management/rebooting_relaunching/#rebooting-or-relaunching","text":"Rebooting or Relaunching master , backup , and task servers are done once for every realm and requires special care, since they can potentially impact the performance of an entire realm. Use the following runbooks to handle these types of servers: Master Backup Task","title":"Rebooting or Relaunching"},{"location":"realm_management/rebooting_relaunching/#cplane-dns-ossec-stats-log-svn","text":"CPLANE","title":"CPLANE (dns, ossec, stats, log, svn)"},{"location":"realm_management/rebooting_relaunching/#customer-non-ha-servers-free-srv-staging-api","text":"NON-HA","title":"Customer Non-HA Servers (free, srv, staging, api)"},{"location":"realm_management/rebooting_relaunching/#balancers-bal","text":"Balancers","title":"Balancers (bal)"},{"location":"realm_management/rebooting_relaunching/#databases-ded-fsdb-dbmaster","text":"Database Servers Manual Database Servers","title":"Databases (ded, fsdb, dbmaster)"},{"location":"realm_management/rebooting_relaunching/#filesystem-only-servers-fs","text":"Filesystem Servers Manual Filesystem Severs","title":"Filesystem-only servers (fs)"},{"location":"realm_management/rebooting_relaunching/#tungsten-multiregion-servers-fsdbmesh-dbmesh","text":"Multiregion Databases","title":"Tungsten Multiregion servers (fsdbmesh, dbmesh)"},{"location":"realm_management/rebooting_relaunching/#webs-managed-web","text":"Webs and Managed Servers Maual Webs and Managed Servers","title":"Webs (managed, web)"},{"location":"realm_management/rebooting_relaunching/#custom-servers-custom","text":"Custom Servers","title":"Custom servers (custom)"},{"location":"realm_management/rebooting_relaunching/#search-servers-nxephem-javasrv-javaephem","text":"Rebooting Search Servers Relaunching Search Servers","title":"Search Servers (nxephem, javasrv, javaephem)"},{"location":"realm_management/rebooting_relaunching/#node-servers-node-nodebal","text":"Relaunching Node Servers Rebooting Node Servers","title":"Node servers (node, nodebal)"},{"location":"realm_management/rebooting_relaunching/#dealing-with-workflow-errors","text":"Workflow Recovery","title":"Dealing with Workflow errors"},{"location":"realm_management/rebooting_relaunching/#auditing","text":"When all of the reboots are done, you should audit to check they all succeeded. Make sure SERVERS is set correctly. HOURS_SINCE_START= fpdsh -l ${SERVERS} -p 100 -c \"awk '{print int(\\$1/$((60*60)))}' /proc/uptime\" | awk \"\\$2 > ${HOURS_SINCE_START}\"","title":"Auditing"},{"location":"realm_management/rebooting_relaunching/#todo-check-version-of-kernel-and-important-packages-updated","text":"","title":"TODO: Check version of kernel and important packages updated."},{"location":"realm_management/relaunch/","text":"Relaunch Instances Depending on the class of an instance you are relaunching there may be several pre-relaunch steps to action. NOTE: Some server types have multiple classes, so you may have to execute multiple pre-relaunch steps. Also when relaunching more than 1 servers of a same type/class, please use workflow as its recommended or relaunch one server at a time to prevent any downtime for the customer. web (ded,managed,staging,web) fs (ded,fs,fsdb,fsdbmesh,staging) db (ded,fsdb,fsdbmesh,dbmaster) svn (svn) balancers bastion master backup Pre-Relaunch Steps Web Class (ded,managed,staging,web) Take the web out of rotation. sv-webdisable $SERVER Relaunch the instance Check the status of all web nodes in the stack. site-checkwebs $SITE If the server you relaunched is a ded site-fsremount $SITE Add the web back to rotation. sv-webenable $SERVER FS Class (ded,fs,fsdb,fsdbmesh,staging) Because gluster service logs are not sent to sumologic, if this an emergency relauch and an investigation of the issue is needed afterwards, it is recommended to save some logs and attach them to the Jira ticket, before the relaunch: Capture these logs into the Jira ticket: /var/log/glusterfs/*.log /var/log/cron.log /var/log/daemon.log After relaunching an fs class server. You need to remount Gluster. site-fsremount $SITE DB Class (ded,fsdb,fsdbmesh,dbmaster) Fail over the DB before relaunching if the server is the active DB. ah-db-cluster status ${SERVER} CLUSTER= PASSIVE= dns-update ${CLUSTER} ${PASSIVE} Downtime the current active DB for a sufficient duration of time (in minutes) out of kindness for the Ops hotseat. ACTIVE= DURATION= sv-downtimeservice ${ACTIVE} 'Mysql Available' ${DURATION} \"${OP} - Relaunching passive DB\" Notify the Ops hotseat that you are working on these DB servers, as they still receive an unavoidable alert for 'MySQL Failover' from the DNS server. Relaunch the instance Ensure the cluster is restored such that the primary DB is active and unlocked. Relaunching Procedures Note! Relaunching servers in FIPS mode is described in Enable FIPS runbook. Relaunching Failed Instances Use the sv-getstatus function to gather basic information about the instance. sv-getstatus runs ah-server status to poll AWS for instance health. $ sv-getstatus web-4950 name: web-4950 ami_type: m5.large ec2_id: i-6ffd1ae5 ec2_availability_zone: eu-west-1b eip_id: 3272 web_service_status: 2 os: precise external_ip: 54.247.108.213 internal_ip: 10.100.149.233 launched: 2016-02-05T21:07:00Z status: system_status impaired [{:name=>\"reachability\", :status=>\"failed\", :impaired_since=>2015-05-22 17:50:00 UTC}] instance_status impaired [{:name=>\"reachability\", :status=>\"failed\", :impaired_since=>2015-05-22 17:50:00 UTC}] sites: capgeminimc Fields status: web-4950, 0 If the instance_status is impaired and the system_status is ok, proceed with the normal relaunch . If both the system_status and instance_status are impaired, perform a forced relaunch . If system_status is impaired, but instance_status is ok, then you have found a Unicorn. This should not be possible as if a system is in any way impaired, then so are its instances. Because we do not want our servers on a potentially corrupt host, we attempt a normal relaunch first and wait for it to time out before attempting a forced relaunch . Normal Relaunch There are three methods of relaunching instances. In order of preference; Task, Local and Forced. NOTE: If you need to change an instance's AMI type, you should do so after suspending the server, especially if the server is a Gen3 instance. Task Relaunch NOTE: with task based relaunches you can set a concurrency pool. This is handy for the relaunching of all webs in a site's stack. If the site has 4 webs, set the concurrency pool to 2 . Use your best judgement with larger sites. sv-taskrelaunch server ${SERVER} -a suspend sv-taskrelaunch server ${SERVER} Local Relaunch For this to succeed you must not have more than five ssh keys in your agent's keychain - ssh-add -l . You must also have all of the needed creds in $NETRC . When you run aprod or adevcloud you are warned if needed creds are missing. NOTE: You can use the ops-misc z functions to remove specific keys - zprod , zdevcloud etc. ah-server suspend ${SERVER} ah-server launch ${SERVER} Forced Relaunch WARNING: This is only to be used in emergencies when the Task and Local relaunch methods fail. Get the status of the server sv-getstatus $SERVER Disable alerting: sv-downtime $SERVER 30 \"$USER: relaunching per OP-12345\" Suspend: You must attempt a regular suspend first so the command to suspend the instance is sent to AWS. If the instance is truly impaired then wait for the first suspend timeout (120 seconds) before cancelling and then using --abandon ah-server suspend $SERVER ah-server suspend $SERVER --abandon Launch: You must attempt a regular launch first. If launch is failed then launch it again by using --preserve after suspending the impaired instance. ah-server launch $SERVER ah-server launch $SERVER --preserve Note: Ops can login to the server while relaunching to diagnose problems by using ssh -p22 root@$(fqual $SERVER) Post checks after successful relaunch(Mandatory) After the relaunch has been completed, verify that the server's field status(should be 0). Use the following command to get the server's status with AWS and in fields: If the server's status is 2 after the relaunch then update the server status to 0 as follow SERVER= sv-getstatus $SERVER ah-server edit $SERVER+ -s status=0","title":"Relaunch Instances"},{"location":"realm_management/relaunch/#relaunch-instances","text":"Depending on the class of an instance you are relaunching there may be several pre-relaunch steps to action. NOTE: Some server types have multiple classes, so you may have to execute multiple pre-relaunch steps. Also when relaunching more than 1 servers of a same type/class, please use workflow as its recommended or relaunch one server at a time to prevent any downtime for the customer. web (ded,managed,staging,web) fs (ded,fs,fsdb,fsdbmesh,staging) db (ded,fsdb,fsdbmesh,dbmaster) svn (svn) balancers bastion master backup","title":"Relaunch Instances"},{"location":"realm_management/relaunch/#pre-relaunch-steps","text":"","title":"Pre-Relaunch Steps"},{"location":"realm_management/relaunch/#web-class-dedmanagedstagingweb","text":"Take the web out of rotation. sv-webdisable $SERVER Relaunch the instance Check the status of all web nodes in the stack. site-checkwebs $SITE If the server you relaunched is a ded site-fsremount $SITE Add the web back to rotation. sv-webenable $SERVER","title":"Web Class (ded,managed,staging,web)"},{"location":"realm_management/relaunch/#fs-class-dedfsfsdbfsdbmeshstaging","text":"Because gluster service logs are not sent to sumologic, if this an emergency relauch and an investigation of the issue is needed afterwards, it is recommended to save some logs and attach them to the Jira ticket, before the relaunch: Capture these logs into the Jira ticket: /var/log/glusterfs/*.log /var/log/cron.log /var/log/daemon.log After relaunching an fs class server. You need to remount Gluster. site-fsremount $SITE","title":"FS Class (ded,fs,fsdb,fsdbmesh,staging)"},{"location":"realm_management/relaunch/#db-class-dedfsdbfsdbmeshdbmaster","text":"Fail over the DB before relaunching if the server is the active DB. ah-db-cluster status ${SERVER} CLUSTER= PASSIVE= dns-update ${CLUSTER} ${PASSIVE} Downtime the current active DB for a sufficient duration of time (in minutes) out of kindness for the Ops hotseat. ACTIVE= DURATION= sv-downtimeservice ${ACTIVE} 'Mysql Available' ${DURATION} \"${OP} - Relaunching passive DB\" Notify the Ops hotseat that you are working on these DB servers, as they still receive an unavoidable alert for 'MySQL Failover' from the DNS server. Relaunch the instance Ensure the cluster is restored such that the primary DB is active and unlocked.","title":"DB Class (ded,fsdb,fsdbmesh,dbmaster)"},{"location":"realm_management/relaunch/#relaunching-procedures","text":"Note! Relaunching servers in FIPS mode is described in Enable FIPS runbook.","title":"Relaunching Procedures"},{"location":"realm_management/relaunch/#relaunching-failed-instances","text":"Use the sv-getstatus function to gather basic information about the instance. sv-getstatus runs ah-server status to poll AWS for instance health. $ sv-getstatus web-4950 name: web-4950 ami_type: m5.large ec2_id: i-6ffd1ae5 ec2_availability_zone: eu-west-1b eip_id: 3272 web_service_status: 2 os: precise external_ip: 54.247.108.213 internal_ip: 10.100.149.233 launched: 2016-02-05T21:07:00Z status: system_status impaired [{:name=>\"reachability\", :status=>\"failed\", :impaired_since=>2015-05-22 17:50:00 UTC}] instance_status impaired [{:name=>\"reachability\", :status=>\"failed\", :impaired_since=>2015-05-22 17:50:00 UTC}] sites: capgeminimc Fields status: web-4950, 0 If the instance_status is impaired and the system_status is ok, proceed with the normal relaunch . If both the system_status and instance_status are impaired, perform a forced relaunch . If system_status is impaired, but instance_status is ok, then you have found a Unicorn. This should not be possible as if a system is in any way impaired, then so are its instances. Because we do not want our servers on a potentially corrupt host, we attempt a normal relaunch first and wait for it to time out before attempting a forced relaunch .","title":"Relaunching Failed Instances"},{"location":"realm_management/relaunch/#normal-relaunch","text":"There are three methods of relaunching instances. In order of preference; Task, Local and Forced. NOTE: If you need to change an instance's AMI type, you should do so after suspending the server, especially if the server is a Gen3 instance.","title":"Normal Relaunch"},{"location":"realm_management/relaunch/#task-relaunch","text":"NOTE: with task based relaunches you can set a concurrency pool. This is handy for the relaunching of all webs in a site's stack. If the site has 4 webs, set the concurrency pool to 2 . Use your best judgement with larger sites. sv-taskrelaunch server ${SERVER} -a suspend sv-taskrelaunch server ${SERVER}","title":"Task Relaunch"},{"location":"realm_management/relaunch/#local-relaunch","text":"For this to succeed you must not have more than five ssh keys in your agent's keychain - ssh-add -l . You must also have all of the needed creds in $NETRC . When you run aprod or adevcloud you are warned if needed creds are missing. NOTE: You can use the ops-misc z functions to remove specific keys - zprod , zdevcloud etc. ah-server suspend ${SERVER} ah-server launch ${SERVER}","title":"Local Relaunch"},{"location":"realm_management/relaunch/#forced-relaunch","text":"WARNING: This is only to be used in emergencies when the Task and Local relaunch methods fail. Get the status of the server sv-getstatus $SERVER Disable alerting: sv-downtime $SERVER 30 \"$USER: relaunching per OP-12345\" Suspend: You must attempt a regular suspend first so the command to suspend the instance is sent to AWS. If the instance is truly impaired then wait for the first suspend timeout (120 seconds) before cancelling and then using --abandon ah-server suspend $SERVER ah-server suspend $SERVER --abandon Launch: You must attempt a regular launch first. If launch is failed then launch it again by using --preserve after suspending the impaired instance. ah-server launch $SERVER ah-server launch $SERVER --preserve Note: Ops can login to the server while relaunching to diagnose problems by using ssh -p22 root@$(fqual $SERVER)","title":"Forced Relaunch"},{"location":"realm_management/relaunch/#post-checks-after-successful-relaunchmandatory","text":"After the relaunch has been completed, verify that the server's field status(should be 0). Use the following command to get the server's status with AWS and in fields: If the server's status is 2 after the relaunch then update the server status to 0 as follow SERVER= sv-getstatus $SERVER ah-server edit $SERVER+ -s status=0","title":"Post checks after successful relaunch(Mandatory)"},{"location":"realm_management/relaunch_backup/","text":"Backup Server Backup servers don't require much administration, but there are some bugs with relaunching. Relaunch Bugs Backup Credentials NOTE: This section is only relevant for Search as it is pre 1.83. In your $NETRC you must have the following entry: $ echo $NETRC /vol/ebs1/home/$USER/keys/ec2/hosting-prod/netrc $ grep -A2 backup.ec2.client $NETRC machine backup.ec2.client login REDACTED password REDACTED This credential gets copied to the backup server during launch and is required for the entire backup process to succeed. If you do not have this in your $NETRC you must acquire the credentials first. Rogue EBS Volumes Backup servers are entirely ephemeral, but because of leaks in the fields code a backup server may have multiple volumes assigned to it, for example: $ sv-vollist backup-30 name: backup-30 ec2_id: i-5225dcf2 ec2_availability_zone: us-east-1c Fields: /dev/sdr: vol-6130f69d id: 1521909 encrypted: 0 mountpoint: /dev/sdr: vol-e8aec512 id: 1258222 encrypted: 0 mountpoint: /dev/sdv: vol-152393ef id: 1223009 encrypted: 0 mountpoint: /dev/sdw: vol-351fe9cf id: 1167278 encrypted: 0 mountpoint: AWS: /dev/sdv: vol-152393ef This is a bug that must be fixed - CL-3385 Set a var: BACKUP_SERVER= Get the fields volume IDs: VOL_IDS=($(ruby -e \"require 'aq'; \\ puts Aq::Hosting::Server.from_query({'name' => '${BACKUP_SERVER}'}).record['volumes'].keys\")) Set the server_id for each volume to zero: for vol_id in ${VOL_IDS[@]}; do ah-volume edit ${vol_id} -s server_id=0 done Relaunch the backup server: ah-server relaunch ${BACKUP_SERVER} If you are upgrading to Ubuntu Xenial 16.04, you may upgrade a backup server with: ah-server edit ${BACKUP_SERVER} -s os=xenial","title":"Backup Server"},{"location":"realm_management/relaunch_backup/#backup-server","text":"Backup servers don't require much administration, but there are some bugs with relaunching.","title":"Backup Server"},{"location":"realm_management/relaunch_backup/#relaunch-bugs","text":"","title":"Relaunch Bugs"},{"location":"realm_management/relaunch_backup/#backup-credentials","text":"NOTE: This section is only relevant for Search as it is pre 1.83. In your $NETRC you must have the following entry: $ echo $NETRC /vol/ebs1/home/$USER/keys/ec2/hosting-prod/netrc $ grep -A2 backup.ec2.client $NETRC machine backup.ec2.client login REDACTED password REDACTED This credential gets copied to the backup server during launch and is required for the entire backup process to succeed. If you do not have this in your $NETRC you must acquire the credentials first.","title":"Backup Credentials"},{"location":"realm_management/relaunch_backup/#rogue-ebs-volumes","text":"Backup servers are entirely ephemeral, but because of leaks in the fields code a backup server may have multiple volumes assigned to it, for example: $ sv-vollist backup-30 name: backup-30 ec2_id: i-5225dcf2 ec2_availability_zone: us-east-1c Fields: /dev/sdr: vol-6130f69d id: 1521909 encrypted: 0 mountpoint: /dev/sdr: vol-e8aec512 id: 1258222 encrypted: 0 mountpoint: /dev/sdv: vol-152393ef id: 1223009 encrypted: 0 mountpoint: /dev/sdw: vol-351fe9cf id: 1167278 encrypted: 0 mountpoint: AWS: /dev/sdv: vol-152393ef This is a bug that must be fixed - CL-3385 Set a var: BACKUP_SERVER= Get the fields volume IDs: VOL_IDS=($(ruby -e \"require 'aq'; \\ puts Aq::Hosting::Server.from_query({'name' => '${BACKUP_SERVER}'}).record['volumes'].keys\")) Set the server_id for each volume to zero: for vol_id in ${VOL_IDS[@]}; do ah-volume edit ${vol_id} -s server_id=0 done Relaunch the backup server: ah-server relaunch ${BACKUP_SERVER} If you are upgrading to Ubuntu Xenial 16.04, you may upgrade a backup server with: ah-server edit ${BACKUP_SERVER} -s os=xenial","title":"Rogue EBS Volumes"},{"location":"realm_management/relaunch_balancers/","text":"Relaunch Bals Using Workflow Bals for a site or multiple sites can be relaunched using ah-bal-cluster command which will trigger a workflow based relaunch with necessary failover of EIP of an active bal before starting a relaunch task. Notes : * This method only works for standard bals where a bal is a part of a bal cluster (2 bals in a cluster having same bal_cluster_id fields property) * The ah-bal-cluster command option -V --vpc_id is ignored for edge clusters since it's elements can't be in different VPCs Variable setup If you are going to reboot a site's bals, find its bals as follows: SITE= BALS=($(ah-server list site:${SITE} -w type=bal)) REBOOT_OR_RELAUNCH=relaunch If you are rebooting bals for multiple sites, fill the SITES array with the list of sites: SITES=() BALS=($(printf \"%s\\n\" ${SITES[@]} | xargs -P10 -I{} ah-server list site:{} -w type=bal)) REBOOT_OR_RELAUNCH=relaunch If upsizing/downsizing bals to a different AMI, set the AMI_TYPE variable: AMI_TYPE= # set required AWS ec2 ami type if [[ ! \"$REBOOT_OR_RELAUNCH\" == \"relaunch\" ]]; then unset AMI_OPTION echo \"AMI change requires relaunching, \\$REBOOT_OR_RELAUNCH has not been set properly\" else AMI_OPTION=\"-a $AMI_TYPE\" fi If you need to start at a specific time, calculate the UNIX_START_TIME variable: UNIX_START_TIME=$(date -d '2018/03/22 20:00 UTC' +\"%s\") add the following flag to your ah-bal-cluster relaunch command: --scheduled-time ${UNIX_START_TIME} If you want to resume a workflow task at a specific time, calculate UNIX_START_TIME as above, then schedule it to resume (you must do this after starting the workflow with ah-bal-cluster relaunch below): WORKFLOW_ID= ah-workflow schedule-resume ${WORKFLOW_ID} \\ --scheduled-time ${UNIX_START_TIME} To find/Check scheduled maintenance information and status, Run scheduled_task=$(ah-workflow get ${WORKFLOW_ID} | grep -w \"scheduled_task_ids.0\"|cut -d: -f2) wf-scheduled or ah-scheduled-task get $scheduled_task To Cancel/Remove the scheduled task in case if your maintenance will be cancelled, Run ah-scheduled-task kill $scheduled_task Beware: Always check the last hrs update in your maintenance ticket for cancellation updates if any. Relaunch bals ah-bal-cluster ${REBOOT_OR_RELAUNCH} --batch 10 ${BALS[@]} ${AMI_OPTION} Note the workflow ID created and watch the workflow to completion. Note for Xenial Balancers on pre-1.99 realms: If you are relaunching Xenial balancers in realms running older versions of fields (i.e. <= 1.98), you must restart nginx after each relaunch. XEN_BAL= # Manually check to see if the server is running xenial fssh ${XEN_BAL} 'sudo sh -c \"service nginx stop; pkill nginx; service nginx restart\"'","title":"Relaunch Bals Using Workflow"},{"location":"realm_management/relaunch_balancers/#relaunch-bals-using-workflow","text":"Bals for a site or multiple sites can be relaunched using ah-bal-cluster command which will trigger a workflow based relaunch with necessary failover of EIP of an active bal before starting a relaunch task. Notes : * This method only works for standard bals where a bal is a part of a bal cluster (2 bals in a cluster having same bal_cluster_id fields property) * The ah-bal-cluster command option -V --vpc_id is ignored for edge clusters since it's elements can't be in different VPCs","title":"Relaunch Bals Using Workflow"},{"location":"realm_management/relaunch_balancers/#variable-setup","text":"If you are going to reboot a site's bals, find its bals as follows: SITE= BALS=($(ah-server list site:${SITE} -w type=bal)) REBOOT_OR_RELAUNCH=relaunch If you are rebooting bals for multiple sites, fill the SITES array with the list of sites: SITES=() BALS=($(printf \"%s\\n\" ${SITES[@]} | xargs -P10 -I{} ah-server list site:{} -w type=bal)) REBOOT_OR_RELAUNCH=relaunch If upsizing/downsizing bals to a different AMI, set the AMI_TYPE variable: AMI_TYPE= # set required AWS ec2 ami type if [[ ! \"$REBOOT_OR_RELAUNCH\" == \"relaunch\" ]]; then unset AMI_OPTION echo \"AMI change requires relaunching, \\$REBOOT_OR_RELAUNCH has not been set properly\" else AMI_OPTION=\"-a $AMI_TYPE\" fi If you need to start at a specific time, calculate the UNIX_START_TIME variable: UNIX_START_TIME=$(date -d '2018/03/22 20:00 UTC' +\"%s\") add the following flag to your ah-bal-cluster relaunch command: --scheduled-time ${UNIX_START_TIME} If you want to resume a workflow task at a specific time, calculate UNIX_START_TIME as above, then schedule it to resume (you must do this after starting the workflow with ah-bal-cluster relaunch below): WORKFLOW_ID= ah-workflow schedule-resume ${WORKFLOW_ID} \\ --scheduled-time ${UNIX_START_TIME} To find/Check scheduled maintenance information and status, Run scheduled_task=$(ah-workflow get ${WORKFLOW_ID} | grep -w \"scheduled_task_ids.0\"|cut -d: -f2) wf-scheduled or ah-scheduled-task get $scheduled_task To Cancel/Remove the scheduled task in case if your maintenance will be cancelled, Run ah-scheduled-task kill $scheduled_task Beware: Always check the last hrs update in your maintenance ticket for cancellation updates if any.","title":"Variable setup"},{"location":"realm_management/relaunch_balancers/#relaunch-bals","text":"ah-bal-cluster ${REBOOT_OR_RELAUNCH} --batch 10 ${BALS[@]} ${AMI_OPTION} Note the workflow ID created and watch the workflow to completion. Note for Xenial Balancers on pre-1.99 realms: If you are relaunching Xenial balancers in realms running older versions of fields (i.e. <= 1.98), you must restart nginx after each relaunch. XEN_BAL= # Manually check to see if the server is running xenial fssh ${XEN_BAL} 'sudo sh -c \"service nginx stop; pkill nginx; service nginx restart\"'","title":"Relaunch bals"},{"location":"realm_management/relaunch_master/","text":"Relaunch a Master This guide is valid for hosting versions 1.103 and above. For relaunching master on search stage, please refer to the manual relaunch guide . Setting up the variables The very first variable we want to set is the Ubuntu version. If this relaunch is part of an OS upgrade, then we will set the new version here, for example: OS=xenial If we are not changing the Ubuntu version on this relaunch, just use the current one: OS=$(bundle exec ruby bin/ah-master get | grep ^os: | awk '{ print $2 }') With the OS variable set, we can proceed to populate everything else: EBS_ID=$(bundle exec ruby bin/ah-master get | grep ^ebs_id: | awk '{ print $2 }') HOSTING_VERSION=$(bundle exec ruby bin/ah-master get | grep ^hosting_version: | awk '{ print $2 }') OLD_EC2_ID=$(bundle exec ruby bin/ah-master get | grep ^ec2_id: | awk '{ print $2 }') EC2_REGION=$(bundle exec ruby bin/ah-master get | grep ^ec2_region: | awk '{ print $2 }') If this relaunch is part of an instance upsize, then we will set the new ec2 instance type, for example: AMI_TYPE=c5.xlarge If we are not changing the AMI type on this relaunch, just use the current one: AMI_TYPE=$(bundle exec ruby bin/ah-master get | grep ^ami_type: | awk '{ print $2 }') Now we can proceed to double check the variables and paste them into JIRA ticket. Note that none of the variables are allowed to be empty: echo \"{noformat:title=Variables}\" \\ && echo \"OS=${OS}\" \\ && echo \"AMI_TYPE=${AMI_TYPE}\" \\ && echo \"EBS_ID=${EBS_ID}\" \\ && echo \"HOSTING_VERSION=${HOSTING_VERSION}\" \\ && echo \"OLD_EC2_ID=${OLD_EC2_ID}\" \\ && echo \"EC2_REGION=${EC2_REGION}\" \\ && echo \"{noformat}\" Prepare for relaunch A bug in ruby classifier skips mounting EBS volume to /vol/ebs1 . Check whether /vol/ebs1 is actually mounted: fssh master mountpoint /vol/ebs1 || \\ echo 'CRITICAL: /vol/ebs1 is not mounted! Do not proceed until this is resolved!' Until the fix CL-36487 is not released to the stage, that you are operating on, use the following manual steps to fix EBS volume mount if the previous check command failed: MOUNT_OPTIONS=nofail,nouuid,nodiratime,relatime,nobarrier,logbufs=8,logbsize=32k fssh master \"sudo sed -i -e '\\\\|^/dev/xvdm|d' /etc/fstab\" fssh master \"sudo sh -c '/bin/echo -e \\\"/dev/xvdm\\t/vol/ebs1\\txfs\\t${MOUNT_OPTIONS}\\t0\\t0\\\" >> /etc/fstab'\" fssh master sudo mount /vol/ebs1 Now we can use the ah-master prep-relaunch tool to do the remaining prep work on the master itself: bundle exec ruby bin/ah-master prep-relaunch Make sure your key doesn't violate the current internal minimal bit length ah-admin-user audit-keys $(whoami) --list-violators Relaunch Now we can perform the actual relaunch. This should take around 10 minutes. bundle exec ruby bin/ah-master relaunch ${EBS_ID} --os=${OS} --force-detach --hosting-version ${HOSTING_VERSION} --instance-type ${AMI_TYPE} --vpc --debug Post relaunch Once the master has finished relaunching, we can use a Nagios plugin to check all services are up and running again: fssh master sudo /usr/lib/nagios/plugins/check_services We can also check that Ubuntu is at the right version: fssh master lsb_release -a Check the EC2 metadata of the new master instance. Put the output into the JIRA ticket: fssh master ec2metadata Finally, we can enable termination protection for the new master instance: NEW_EC2_ID=$(bundle exec ruby bin/ah-master get | grep ^ec2_id: | awk '{ print $2 }') echo \"NEW_EC2_ID=${NEW_EC2_ID}\" aws ec2 modify-instance-attribute \\ --region ${EC2_REGION} \\ --instance-id ${NEW_EC2_ID} \\ --attribute disableApiTermination \\ --value true Terminating the old master Note: There is a command called ah-master stop-relaunched which would take care of this entire section for us, but unfortunately it does not currently work in production stages. This issue is being tracked in CL-20657 , and once it is closed this entire section can be updated. For now, proceed with the following. Now it's time to terminate the old master instance, but first we need to confirm that the ah_server_name tag has been updated to master-before-relaunch-(TIMESTAMP) . If the tag is still just master then stop immediately and investigate. aws ec2 describe-instances \\ --region ${EC2_REGION} \\ --instance-ids ${OLD_EC2_ID} \\ --query 'Reservations[].Instances[].Tags[?Key==`ah_server_name`].Value[]' \\ --output text Assuming everything in the previous steps has gone perfectly, we can now remove the termination protection from the old instance and finally terminate it. aws ec2 modify-instance-attribute \\ --region ${EC2_REGION} \\ --instance-id ${OLD_EC2_ID} \\ --attribute disableApiTermination \\ --value false aws ec2 terminate-instances \\ --region ${EC2_REGION} \\ --instance-ids ${OLD_EC2_ID} Congratulations, your master relaunch should now be complete! Rollback relaunch and switch back to previous master First export some variables in bash session to make them available in the next pry session. export EC2_REGION=$EC2_REGION export OLD_EC2_ID=$OLD_EC2_ID Fix master records in HAPI DB in pry with help of aq gem: pry require 'aq/aws/v2' ec2_client = Aws::EC2::Client.new(region: ENV['EC2_REGION']) old_instance = ec2_client.describe_instances(instance_ids: [ENV['OLD_EC2_ID']]).reservations.first.instances.first master = Aq::Hosting::Servers::Master.create master.ec2_id = old_instance.instance_id master.internal_ec2 = old_instance.private_dns_name master.internal_ip = old_instance.private_ip_address master.external_ec2 = old_instance.public_dns_name master.external_ip = old_instance.public_ip_address master.external_fqhn = \"master.e.#{Aq::Hosting.stage}.#{Aq::Domain.master_domain}\" master.internal_fqhn = \"master.i.#{Aq::Hosting.stage}.#{Aq::Domain.master_domain}\" master.ami_type = old_instance.instance_type master.ec2_availability_zone = old_instance.placement.availability_zone master.save Remain in the pry session and update DNS dns = Aq::Dns.new dns.clear_records('A',master.external_fqhn) dns.clear_records('A',master.internal_fqhn) dns.set_record('A', master.external_fqhn , master.external_ip) dns.set_record('A', master.internal_fqhn , master.internal_ip) Remain in the pry session and make sure that the volume is not attached to the new instance and reattach it to the restored instance master.non_root_volumes.first.detach master.non_root_volumes.first.attach Leave the pry session and continue in bash Ctrl-D Check that old master still operates [ \"$OLD_EC2_ID\" = $(fssh master ec2metadata | grep instance-id | awk '{ print $2; }') ] || \\ echo \"CRITICAL: restored master instance id mismatch. Check its external DNS entry again\\!\" Make sure that puppet master works well fssh master sudo ah-config-hosts fssh master sudo service safe-httpd restart fssh master sudo puppet agent -t DNS=$(ah-server list dns% -w status=0 | tail -1) fssh $DNS sudo puppet agent -t OR in Masterless Puppet mode fssh master sudo ah-config-hosts fssh master sudo service safe-httpd restart fssh master sudo run-puppet DNS=$(ah-server list dns% -w status=0 | tail -1) fssh $DNS sudo run-puppet Find the EC2 id of the new instance by filtering for ah_server_name tag NEW_EC2_ID=$(aws ec2 describe-instances --region ${EC2_REGION} --filters \"Name=tag:ah_server_name,Values=master\" \"Name=tag:ah_stage,Values=${FIELDS_STAGE}\" --query 'Reservations[].Instances[].InstanceId' --output text) echo $NEW_EC2_ID [ \"$OLD_EC2_ID\" != \"$NEW_EC2_ID\" ] || \\ echo \"CRITICAL: the instance tagged as master is the old intance. No need to terminate it\\!\" Terminate the \"new\" instance only if its id is different from the old one! aws ec2 terminate-instances \\ --region ${EC2_REGION} \\ --instance-ids ${NEW_EC2_ID} Reset tags on the new ec2 instance aws ec2 delete-tags --resources $OLD_EC2_ID --tags Key=ah_server_name,Value= aws ec2 create-tags --resources $OLD_EC2_ID --tags Key=ah_server_name,Value=master aws ec2 describe-instances \\ --region ${EC2_REGION} \\ --instance-ids ${OLD_EC2_ID} \\ --query 'Reservations[].Instances[].Tags[?Key==`ah_server_name`].Value[]' \\ --output text Congratulations, your previous master restoration should now be complete!","title":"Relaunch a Master"},{"location":"realm_management/relaunch_master/#relaunch-a-master","text":"This guide is valid for hosting versions 1.103 and above. For relaunching master on search stage, please refer to the manual relaunch guide .","title":"Relaunch a Master"},{"location":"realm_management/relaunch_master/#setting-up-the-variables","text":"The very first variable we want to set is the Ubuntu version. If this relaunch is part of an OS upgrade, then we will set the new version here, for example: OS=xenial If we are not changing the Ubuntu version on this relaunch, just use the current one: OS=$(bundle exec ruby bin/ah-master get | grep ^os: | awk '{ print $2 }') With the OS variable set, we can proceed to populate everything else: EBS_ID=$(bundle exec ruby bin/ah-master get | grep ^ebs_id: | awk '{ print $2 }') HOSTING_VERSION=$(bundle exec ruby bin/ah-master get | grep ^hosting_version: | awk '{ print $2 }') OLD_EC2_ID=$(bundle exec ruby bin/ah-master get | grep ^ec2_id: | awk '{ print $2 }') EC2_REGION=$(bundle exec ruby bin/ah-master get | grep ^ec2_region: | awk '{ print $2 }') If this relaunch is part of an instance upsize, then we will set the new ec2 instance type, for example: AMI_TYPE=c5.xlarge If we are not changing the AMI type on this relaunch, just use the current one: AMI_TYPE=$(bundle exec ruby bin/ah-master get | grep ^ami_type: | awk '{ print $2 }') Now we can proceed to double check the variables and paste them into JIRA ticket. Note that none of the variables are allowed to be empty: echo \"{noformat:title=Variables}\" \\ && echo \"OS=${OS}\" \\ && echo \"AMI_TYPE=${AMI_TYPE}\" \\ && echo \"EBS_ID=${EBS_ID}\" \\ && echo \"HOSTING_VERSION=${HOSTING_VERSION}\" \\ && echo \"OLD_EC2_ID=${OLD_EC2_ID}\" \\ && echo \"EC2_REGION=${EC2_REGION}\" \\ && echo \"{noformat}\"","title":"Setting up the variables"},{"location":"realm_management/relaunch_master/#prepare-for-relaunch","text":"A bug in ruby classifier skips mounting EBS volume to /vol/ebs1 . Check whether /vol/ebs1 is actually mounted: fssh master mountpoint /vol/ebs1 || \\ echo 'CRITICAL: /vol/ebs1 is not mounted! Do not proceed until this is resolved!' Until the fix CL-36487 is not released to the stage, that you are operating on, use the following manual steps to fix EBS volume mount if the previous check command failed: MOUNT_OPTIONS=nofail,nouuid,nodiratime,relatime,nobarrier,logbufs=8,logbsize=32k fssh master \"sudo sed -i -e '\\\\|^/dev/xvdm|d' /etc/fstab\" fssh master \"sudo sh -c '/bin/echo -e \\\"/dev/xvdm\\t/vol/ebs1\\txfs\\t${MOUNT_OPTIONS}\\t0\\t0\\\" >> /etc/fstab'\" fssh master sudo mount /vol/ebs1 Now we can use the ah-master prep-relaunch tool to do the remaining prep work on the master itself: bundle exec ruby bin/ah-master prep-relaunch Make sure your key doesn't violate the current internal minimal bit length ah-admin-user audit-keys $(whoami) --list-violators","title":"Prepare for relaunch"},{"location":"realm_management/relaunch_master/#relaunch","text":"Now we can perform the actual relaunch. This should take around 10 minutes. bundle exec ruby bin/ah-master relaunch ${EBS_ID} --os=${OS} --force-detach --hosting-version ${HOSTING_VERSION} --instance-type ${AMI_TYPE} --vpc --debug","title":"Relaunch"},{"location":"realm_management/relaunch_master/#post-relaunch","text":"Once the master has finished relaunching, we can use a Nagios plugin to check all services are up and running again: fssh master sudo /usr/lib/nagios/plugins/check_services We can also check that Ubuntu is at the right version: fssh master lsb_release -a Check the EC2 metadata of the new master instance. Put the output into the JIRA ticket: fssh master ec2metadata Finally, we can enable termination protection for the new master instance: NEW_EC2_ID=$(bundle exec ruby bin/ah-master get | grep ^ec2_id: | awk '{ print $2 }') echo \"NEW_EC2_ID=${NEW_EC2_ID}\" aws ec2 modify-instance-attribute \\ --region ${EC2_REGION} \\ --instance-id ${NEW_EC2_ID} \\ --attribute disableApiTermination \\ --value true","title":"Post relaunch"},{"location":"realm_management/relaunch_master/#terminating-the-old-master","text":"Note: There is a command called ah-master stop-relaunched which would take care of this entire section for us, but unfortunately it does not currently work in production stages. This issue is being tracked in CL-20657 , and once it is closed this entire section can be updated. For now, proceed with the following. Now it's time to terminate the old master instance, but first we need to confirm that the ah_server_name tag has been updated to master-before-relaunch-(TIMESTAMP) . If the tag is still just master then stop immediately and investigate. aws ec2 describe-instances \\ --region ${EC2_REGION} \\ --instance-ids ${OLD_EC2_ID} \\ --query 'Reservations[].Instances[].Tags[?Key==`ah_server_name`].Value[]' \\ --output text Assuming everything in the previous steps has gone perfectly, we can now remove the termination protection from the old instance and finally terminate it. aws ec2 modify-instance-attribute \\ --region ${EC2_REGION} \\ --instance-id ${OLD_EC2_ID} \\ --attribute disableApiTermination \\ --value false aws ec2 terminate-instances \\ --region ${EC2_REGION} \\ --instance-ids ${OLD_EC2_ID} Congratulations, your master relaunch should now be complete!","title":"Terminating the old master"},{"location":"realm_management/relaunch_master/#rollback-relaunch-and-switch-back-to-previous-master","text":"First export some variables in bash session to make them available in the next pry session. export EC2_REGION=$EC2_REGION export OLD_EC2_ID=$OLD_EC2_ID Fix master records in HAPI DB in pry with help of aq gem: pry require 'aq/aws/v2' ec2_client = Aws::EC2::Client.new(region: ENV['EC2_REGION']) old_instance = ec2_client.describe_instances(instance_ids: [ENV['OLD_EC2_ID']]).reservations.first.instances.first master = Aq::Hosting::Servers::Master.create master.ec2_id = old_instance.instance_id master.internal_ec2 = old_instance.private_dns_name master.internal_ip = old_instance.private_ip_address master.external_ec2 = old_instance.public_dns_name master.external_ip = old_instance.public_ip_address master.external_fqhn = \"master.e.#{Aq::Hosting.stage}.#{Aq::Domain.master_domain}\" master.internal_fqhn = \"master.i.#{Aq::Hosting.stage}.#{Aq::Domain.master_domain}\" master.ami_type = old_instance.instance_type master.ec2_availability_zone = old_instance.placement.availability_zone master.save Remain in the pry session and update DNS dns = Aq::Dns.new dns.clear_records('A',master.external_fqhn) dns.clear_records('A',master.internal_fqhn) dns.set_record('A', master.external_fqhn , master.external_ip) dns.set_record('A', master.internal_fqhn , master.internal_ip) Remain in the pry session and make sure that the volume is not attached to the new instance and reattach it to the restored instance master.non_root_volumes.first.detach master.non_root_volumes.first.attach Leave the pry session and continue in bash Ctrl-D Check that old master still operates [ \"$OLD_EC2_ID\" = $(fssh master ec2metadata | grep instance-id | awk '{ print $2; }') ] || \\ echo \"CRITICAL: restored master instance id mismatch. Check its external DNS entry again\\!\" Make sure that puppet master works well fssh master sudo ah-config-hosts fssh master sudo service safe-httpd restart fssh master sudo puppet agent -t DNS=$(ah-server list dns% -w status=0 | tail -1) fssh $DNS sudo puppet agent -t OR in Masterless Puppet mode fssh master sudo ah-config-hosts fssh master sudo service safe-httpd restart fssh master sudo run-puppet DNS=$(ah-server list dns% -w status=0 | tail -1) fssh $DNS sudo run-puppet Find the EC2 id of the new instance by filtering for ah_server_name tag NEW_EC2_ID=$(aws ec2 describe-instances --region ${EC2_REGION} --filters \"Name=tag:ah_server_name,Values=master\" \"Name=tag:ah_stage,Values=${FIELDS_STAGE}\" --query 'Reservations[].Instances[].InstanceId' --output text) echo $NEW_EC2_ID [ \"$OLD_EC2_ID\" != \"$NEW_EC2_ID\" ] || \\ echo \"CRITICAL: the instance tagged as master is the old intance. No need to terminate it\\!\" Terminate the \"new\" instance only if its id is different from the old one! aws ec2 terminate-instances \\ --region ${EC2_REGION} \\ --instance-ids ${NEW_EC2_ID} Reset tags on the new ec2 instance aws ec2 delete-tags --resources $OLD_EC2_ID --tags Key=ah_server_name,Value= aws ec2 create-tags --resources $OLD_EC2_ID --tags Key=ah_server_name,Value=master aws ec2 describe-instances \\ --region ${EC2_REGION} \\ --instance-ids ${OLD_EC2_ID} \\ --query 'Reservations[].Instances[].Tags[?Key==`ah_server_name`].Value[]' \\ --output text Congratulations, your previous master restoration should now be complete!","title":"Rollback relaunch and switch back to previous master"},{"location":"realm_management/relaunch_master_manual/","text":"Relaunch a Master (manual process) Since the addition of the ah-master prep-relaunch command these instructions have been simplfied. Please see the updated runbook for the current relaunch procedure. This guide assumes you have first read and followed the direction in the master down alert procedure . You must follow through it first before continuing, even if you are performing planned maintenance. There is information and a procedure for dealing with task and backup servers. Find the master The Master doesn't have a presence in the fields_master DB, so we have to find it in a very unique way Get the ip address MASTER_IP=$(host master.e.${FIELDS_STAGE}.f.e2a.us \\ | grep -Po '\\d+\\.\\d+\\.\\d+\\.\\d+$') echo ${MASTER_IP} Find the instance id: MASTER_INSTANCE_ID=$(aws ec2 describe-instances \\ --region=us-east-1 \\ --filters \"Name=ip-address,Values=${MASTER_IP}\" \\ --query 'Reservations[*].Instances[*].InstanceId' \\ --output text) echo ${MASTER_INSTANCE_ID} Find the instance type: MASTER_INSTANCE_TYPE=$(aws ec2 describe-instances \\ --region=us-east-1 \\ --instance-ids ${MASTER_INSTANCE_ID} \\ --query 'Reservations[*].Instances[*].InstanceType' \\ --output text) echo ${MASTER_INSTANCE_TYPE} Relaunch There are two things you need to know before you can relaunch a master: The volume_id or snapshot_id The HOSTING_VERSION Set the volume_id . MASTER_VOLUME_ID=$(aws ec2 describe-instances \\ --region=us-east-1 \\ --filters \"Name=instance-id,Values=${MASTER_INSTANCE_ID}\" \\ \"Name=block-device-mapping.device-name,Values=/dev/sdm\" \\ --output text \\ --query 'Reservations[*].Instances[*].BlockDeviceMappings[*].Ebs.VolumeId') echo ${MASTER_VOLUME_ID} Set the HOSTING_VERSION , if not already set. If the master is unresponsive, ssh to the backup server - detailed in the master down alert procedure . [ -z ${HOSTING_VERSION-} ] \\ && HOSTING_VERSION=$(fssh ${BACKUP_SERVER} sudo cat /var/acquia/HOSTING_VERSION) echo ${HOSTING_VERSION} Stop services on the master and umount /dev/xvdm (skip if host is down) fssh master \"sudo puppet agent --disable 'master relaunch' \\ && sudo crontab -r \\ && sudo service apache2 stop \\ && sudo service mysql stop \\ && sudo service meh stop \\ && sudo umount /dev/xvdm\" OR in Masterless Puppet mode fssh master \"sudo ah-puppet-disable 'master relaunch' \\ && sudo crontab -r \\ && sudo service apache2 stop \\ && sudo service mysql stop \\ && sudo service meh stop \\ && sudo umount /dev/xvdm\" If the master is hung create a snapshot of the volume first. MASTER_SNAPSHOT_ID=$(aws ec2 create-snapshot \\ --volume-id ${MASTER_VOLUME_ID} \\ --description \"master relaunch snapshot\" \\ --region us-east-1 \\ --query SnapshotId \\ --output text) echo ${MASTER_SNAPSHOT_ID} Detach the volume. aws ec2 detach-volume \\ --instance-id=$MASTER_INSTANCE_ID \\ --volume-id=${MASTER_VOLUME_ID} Relaunch the master. This doesn't touch the existing instance, so it will proceed even if the instance is unresponsive. It is vital that you use the exact same instance type as the previous master, unless otherwise directed. For more detailed options: bundle exec ruby bin/ah-master help relaunch . Relaunch with the original volume: bundle exec ruby bin/ah-master relaunch ${MASTER_VOLUME_ID} \\ --hosting-version=${HOSTING_VERSION} \\ --instance-type=${MASTER_INSTANCE_TYPE} Relaunch with a complete snapshot: bundle exec ruby bin/ah-master relaunch ${MASTER_SNAPSHOT_ID} \\ --hosting-version=${HOSTING_VERSION} \\ --instance-type=${MASTER_INSTANCE_TYPE} During Relaunch Once you have issued the ah-master relaunch command with the appropriate flags, due to a race-condition bug you MUST ssh into the master prior to the master running puppet in order to execute sudo ah-admin-users . When the new IP of the master becomes available, ssh on a loop from the bastion from another window/terminal using the \"default\" key appropriate for the stage: Master IP: NEW_MASTER_IP= Attempt ssh to the new master while true; do ssh -p 22 root@${NEW_MASTER_IP} sleep 3 done Once logged into the new master as root, watch the launcher output. The master will hit a loop trying to remove a specific user. At that point run: ah-admin-users Once the master has finished puppetizing, test the master's capabilities by checking the default hosting version from the bastion: ah-variable get default_hosting_version Also validate that the MySQL volume has been correctly mounted and that MySQL responds from the master itself: fssh master \"df -h /vol/ebs1 \\ && sudo mysql -e 'show status\\G'\" Post Relaunch Set variables OP= Check for stale task processes on task-% and kill as needed. fpdsh -t task-% -c \"sudo ps auxw | grep task\" Handle any stuck tasks before proceeding. Re-enable task and backup servers fpdsh -t task-%,backup-% \\ -c \"sudo puppet agent --enable && sudo puppet agent -t'\" OR in Masterless Puppet mode fpdsh -t task-%,backup-% \\ -c \"sudo ah-puppet-enable && sudo run-puppet\" Check for hung ah-fields- processes across the stage. fpdsh -t % -p 100 -c \"ps auxww \\ | egrep '[a]h-admin-users|[a]h-config-hosts|[a]h-config-iptables'\" Tag the previous master aws ec2 create-tags \\ --region us-east-1 \\ --resources ${MASTER_INSTANCE_ID} \\ --tags Key=ah_server_name,Value=\"master-before-relaunch-$(date +%s)\" Enable termination protection Find the new master NEW_MASTER_IP=$(host master.e.${FIELDS_STAGE}.f.e2a.us \\ | grep -Po '\\d+\\.\\d+\\.\\d+\\.\\d+$') echo ${NEW_MASTER_IP} NEW_MASTER_INSTANCE_ID=$(aws ec2 describe-instances \\ --region=us-east-1 \\ --filters \"Name=ip-address,Values=${NEW_MASTER_IP}\" \\ --query 'Reservations[*].Instances[*].InstanceId' \\ --output text) echo ${NEW_MASTER_INSTANCE_ID} Protect.it: aws ec2 modify-instance-attribute \\ --instance-id ${NEW_MASTER_INSTANCE_ID} \\ --disable-api-termination Create an OP ticket to handle the decommissioning of the old master instance. Also, email hosting-eng@acquia.com to ask if anyone needs information from the old master prior to termination. profit.","title":"Relaunch a Master (manual process)"},{"location":"realm_management/relaunch_master_manual/#relaunch-a-master-manual-process","text":"Since the addition of the ah-master prep-relaunch command these instructions have been simplfied. Please see the updated runbook for the current relaunch procedure. This guide assumes you have first read and followed the direction in the master down alert procedure . You must follow through it first before continuing, even if you are performing planned maintenance. There is information and a procedure for dealing with task and backup servers.","title":"Relaunch a Master (manual process)"},{"location":"realm_management/relaunch_master_manual/#find-the-master","text":"The Master doesn't have a presence in the fields_master DB, so we have to find it in a very unique way Get the ip address MASTER_IP=$(host master.e.${FIELDS_STAGE}.f.e2a.us \\ | grep -Po '\\d+\\.\\d+\\.\\d+\\.\\d+$') echo ${MASTER_IP} Find the instance id: MASTER_INSTANCE_ID=$(aws ec2 describe-instances \\ --region=us-east-1 \\ --filters \"Name=ip-address,Values=${MASTER_IP}\" \\ --query 'Reservations[*].Instances[*].InstanceId' \\ --output text) echo ${MASTER_INSTANCE_ID} Find the instance type: MASTER_INSTANCE_TYPE=$(aws ec2 describe-instances \\ --region=us-east-1 \\ --instance-ids ${MASTER_INSTANCE_ID} \\ --query 'Reservations[*].Instances[*].InstanceType' \\ --output text) echo ${MASTER_INSTANCE_TYPE}","title":"Find the master"},{"location":"realm_management/relaunch_master_manual/#relaunch","text":"There are two things you need to know before you can relaunch a master: The volume_id or snapshot_id The HOSTING_VERSION Set the volume_id . MASTER_VOLUME_ID=$(aws ec2 describe-instances \\ --region=us-east-1 \\ --filters \"Name=instance-id,Values=${MASTER_INSTANCE_ID}\" \\ \"Name=block-device-mapping.device-name,Values=/dev/sdm\" \\ --output text \\ --query 'Reservations[*].Instances[*].BlockDeviceMappings[*].Ebs.VolumeId') echo ${MASTER_VOLUME_ID} Set the HOSTING_VERSION , if not already set. If the master is unresponsive, ssh to the backup server - detailed in the master down alert procedure . [ -z ${HOSTING_VERSION-} ] \\ && HOSTING_VERSION=$(fssh ${BACKUP_SERVER} sudo cat /var/acquia/HOSTING_VERSION) echo ${HOSTING_VERSION} Stop services on the master and umount /dev/xvdm (skip if host is down) fssh master \"sudo puppet agent --disable 'master relaunch' \\ && sudo crontab -r \\ && sudo service apache2 stop \\ && sudo service mysql stop \\ && sudo service meh stop \\ && sudo umount /dev/xvdm\" OR in Masterless Puppet mode fssh master \"sudo ah-puppet-disable 'master relaunch' \\ && sudo crontab -r \\ && sudo service apache2 stop \\ && sudo service mysql stop \\ && sudo service meh stop \\ && sudo umount /dev/xvdm\" If the master is hung create a snapshot of the volume first. MASTER_SNAPSHOT_ID=$(aws ec2 create-snapshot \\ --volume-id ${MASTER_VOLUME_ID} \\ --description \"master relaunch snapshot\" \\ --region us-east-1 \\ --query SnapshotId \\ --output text) echo ${MASTER_SNAPSHOT_ID} Detach the volume. aws ec2 detach-volume \\ --instance-id=$MASTER_INSTANCE_ID \\ --volume-id=${MASTER_VOLUME_ID} Relaunch the master. This doesn't touch the existing instance, so it will proceed even if the instance is unresponsive. It is vital that you use the exact same instance type as the previous master, unless otherwise directed. For more detailed options: bundle exec ruby bin/ah-master help relaunch . Relaunch with the original volume: bundle exec ruby bin/ah-master relaunch ${MASTER_VOLUME_ID} \\ --hosting-version=${HOSTING_VERSION} \\ --instance-type=${MASTER_INSTANCE_TYPE} Relaunch with a complete snapshot: bundle exec ruby bin/ah-master relaunch ${MASTER_SNAPSHOT_ID} \\ --hosting-version=${HOSTING_VERSION} \\ --instance-type=${MASTER_INSTANCE_TYPE}","title":"Relaunch"},{"location":"realm_management/relaunch_master_manual/#during-relaunch","text":"Once you have issued the ah-master relaunch command with the appropriate flags, due to a race-condition bug you MUST ssh into the master prior to the master running puppet in order to execute sudo ah-admin-users . When the new IP of the master becomes available, ssh on a loop from the bastion from another window/terminal using the \"default\" key appropriate for the stage: Master IP: NEW_MASTER_IP= Attempt ssh to the new master while true; do ssh -p 22 root@${NEW_MASTER_IP} sleep 3 done Once logged into the new master as root, watch the launcher output. The master will hit a loop trying to remove a specific user. At that point run: ah-admin-users Once the master has finished puppetizing, test the master's capabilities by checking the default hosting version from the bastion: ah-variable get default_hosting_version Also validate that the MySQL volume has been correctly mounted and that MySQL responds from the master itself: fssh master \"df -h /vol/ebs1 \\ && sudo mysql -e 'show status\\G'\"","title":"During Relaunch"},{"location":"realm_management/relaunch_master_manual/#post-relaunch","text":"Set variables OP= Check for stale task processes on task-% and kill as needed. fpdsh -t task-% -c \"sudo ps auxw | grep task\" Handle any stuck tasks before proceeding. Re-enable task and backup servers fpdsh -t task-%,backup-% \\ -c \"sudo puppet agent --enable && sudo puppet agent -t'\" OR in Masterless Puppet mode fpdsh -t task-%,backup-% \\ -c \"sudo ah-puppet-enable && sudo run-puppet\" Check for hung ah-fields- processes across the stage. fpdsh -t % -p 100 -c \"ps auxww \\ | egrep '[a]h-admin-users|[a]h-config-hosts|[a]h-config-iptables'\" Tag the previous master aws ec2 create-tags \\ --region us-east-1 \\ --resources ${MASTER_INSTANCE_ID} \\ --tags Key=ah_server_name,Value=\"master-before-relaunch-$(date +%s)\" Enable termination protection Find the new master NEW_MASTER_IP=$(host master.e.${FIELDS_STAGE}.f.e2a.us \\ | grep -Po '\\d+\\.\\d+\\.\\d+\\.\\d+$') echo ${NEW_MASTER_IP} NEW_MASTER_INSTANCE_ID=$(aws ec2 describe-instances \\ --region=us-east-1 \\ --filters \"Name=ip-address,Values=${NEW_MASTER_IP}\" \\ --query 'Reservations[*].Instances[*].InstanceId' \\ --output text) echo ${NEW_MASTER_INSTANCE_ID} Protect.it: aws ec2 modify-instance-attribute \\ --instance-id ${NEW_MASTER_INSTANCE_ID} \\ --disable-api-termination Create an OP ticket to handle the decommissioning of the old master instance. Also, email hosting-eng@acquia.com to ask if anyone needs information from the old master prior to termination. profit.","title":"Post Relaunch"},{"location":"realm_management/relaunch_search/","text":"Mass Relaunching Search Servers Note: To login Search jumpboxes, follow these instructions Before you begin, you need to verify that the proper version of ah-server is used, should be the version located within the fields 1.81 subdirectory. which ah-server Relaunching All Servers by Region For relaunching all servers in the Search realm by region. Relaunch javapehem s ( NOTE: will need to limit the concurrency to ten to help prevent Governor queue issues): REGION= ah-server relaunch % -t javaephem -r ${REGION} -c 10 If the javaephem is an extractor, verify that it is functioning properly. Once all of the javaephem s are up and functioning properly, relaunch all the javasrv s: ah-server relaunch % -t javasrv -r ${REGION} -c 30 Relaunch all the nxephem s by AZ: AZ= ah-server relaunch % -t nxephem -a ${AZ} -c 50 Verify that each nxephem is back in the ELB before moving onto the next set: NXEPHEMS=$(ah-server list % -w ec2_availability_zone=${AZ} type=nxephem status=0 | paste -sd,) for i in $(site-list ${NXEPHEMS} -v); do bundle exec site-elbdescribe ${i} done Relaunching a Subset of Servers For more granularity in your relaunches, you will need to build a list of servers to reboot and manage them appropriately. Ideally, the Jira ticket should provide a fields query to produce these lists; examples are provided here as a potential default. Create your server lists. You should modify these statements as appropriate to your maintenance: REGION= AZS=$(aws ec2 describe-availability-zones --region ${REGION} --output text | awk {'print $4'}) JAVAEPHEMS=$(ah-server list % -w status=0 ec2_region=${REGION} type=javaephem | paste -sd,) JAVASRVS=$(ah-server list % -w status=0 ec2_region=${REGION} type=javasrv | paste -sd,) ALL_NXEPHEMS=$(ah-server list % -w status=0 ec2_region=${REGION} type=nxephem | paste -sd,) Relaunch the javaephem s. ( NOTE: You will need to limit the concurrency to ten to help prevent Governor queue issues). ah-server relaunch ${SERVERS} -c 10 If the javaephem is an extractor, verify that it is functioning properly. ah-server list tag:solrextractor -w nameIN${JAVAEPHEMS} Once all of the javaephem s are up and functioning properly (watch PagerDuty for alerts), relaunch the javasrv s: ah-server relaunch ${JAVASRVS} -c 30 Relaunch all the nxephem s. ( NOTE: Make sure that you are only relaunching one nxephem at a time per cluster to prevent an outage. One way to do this is to divide them by AZ.): echo ${AZS[@]} AZ= NXEPHEMS=$(ah-server list % -w nameIN${ALL_NXEPHEMS} ec2_availability_zones=${AZ} | paste -sd,) ah-server relaunch ${NXEPHEMS} -c 50 Verify that each nxephem is back in the ELB rotation before moving onto the next AZ: for i in $(site-list ${NXEPHEMS} -v); do bundle exec site-elbdescribe ${i} done Notes Be sure to log into the bastion from a new terminal window/session when interacting with search, as fields behavior can be unpredictable when switching to the search stage from another production stage. The tooling automatically removes the server(s) from monitoring. If the server is a javaephem or javasrv and is not an extractor, it will squelch any search index checks for the server being relaunched. Once the server is back up, the tooling makes sure that a fields-config-web.php run is complete along with a rake rebuild & rake cron before index monitoring is re-enabled. Finally, the script will verify that the server(s) are back in monitoring. A squelch/unsquelch option was added to ah-server . If, during the relaunch, the tool isn't able to complete a rake rebuild and rake cron run, the affected indexes will not be automatically unsquelched. Once you verify that the server is okay, you will need to manually unsquelch the index check. JAVASRV= ah-server searchindex ${JAVASRV} --no-squelch","title":"Mass Relaunching Search Servers"},{"location":"realm_management/relaunch_search/#mass-relaunching-search-servers","text":"Note: To login Search jumpboxes, follow these instructions Before you begin, you need to verify that the proper version of ah-server is used, should be the version located within the fields 1.81 subdirectory. which ah-server","title":"Mass Relaunching Search Servers"},{"location":"realm_management/relaunch_search/#relaunching-all-servers-by-region","text":"For relaunching all servers in the Search realm by region. Relaunch javapehem s ( NOTE: will need to limit the concurrency to ten to help prevent Governor queue issues): REGION= ah-server relaunch % -t javaephem -r ${REGION} -c 10 If the javaephem is an extractor, verify that it is functioning properly. Once all of the javaephem s are up and functioning properly, relaunch all the javasrv s: ah-server relaunch % -t javasrv -r ${REGION} -c 30 Relaunch all the nxephem s by AZ: AZ= ah-server relaunch % -t nxephem -a ${AZ} -c 50 Verify that each nxephem is back in the ELB before moving onto the next set: NXEPHEMS=$(ah-server list % -w ec2_availability_zone=${AZ} type=nxephem status=0 | paste -sd,) for i in $(site-list ${NXEPHEMS} -v); do bundle exec site-elbdescribe ${i} done","title":"Relaunching All Servers by Region"},{"location":"realm_management/relaunch_search/#relaunching-a-subset-of-servers","text":"For more granularity in your relaunches, you will need to build a list of servers to reboot and manage them appropriately. Ideally, the Jira ticket should provide a fields query to produce these lists; examples are provided here as a potential default. Create your server lists. You should modify these statements as appropriate to your maintenance: REGION= AZS=$(aws ec2 describe-availability-zones --region ${REGION} --output text | awk {'print $4'}) JAVAEPHEMS=$(ah-server list % -w status=0 ec2_region=${REGION} type=javaephem | paste -sd,) JAVASRVS=$(ah-server list % -w status=0 ec2_region=${REGION} type=javasrv | paste -sd,) ALL_NXEPHEMS=$(ah-server list % -w status=0 ec2_region=${REGION} type=nxephem | paste -sd,) Relaunch the javaephem s. ( NOTE: You will need to limit the concurrency to ten to help prevent Governor queue issues). ah-server relaunch ${SERVERS} -c 10 If the javaephem is an extractor, verify that it is functioning properly. ah-server list tag:solrextractor -w nameIN${JAVAEPHEMS} Once all of the javaephem s are up and functioning properly (watch PagerDuty for alerts), relaunch the javasrv s: ah-server relaunch ${JAVASRVS} -c 30 Relaunch all the nxephem s. ( NOTE: Make sure that you are only relaunching one nxephem at a time per cluster to prevent an outage. One way to do this is to divide them by AZ.): echo ${AZS[@]} AZ= NXEPHEMS=$(ah-server list % -w nameIN${ALL_NXEPHEMS} ec2_availability_zones=${AZ} | paste -sd,) ah-server relaunch ${NXEPHEMS} -c 50 Verify that each nxephem is back in the ELB rotation before moving onto the next AZ: for i in $(site-list ${NXEPHEMS} -v); do bundle exec site-elbdescribe ${i} done","title":"Relaunching a Subset of Servers"},{"location":"realm_management/relaunch_search/#notes","text":"Be sure to log into the bastion from a new terminal window/session when interacting with search, as fields behavior can be unpredictable when switching to the search stage from another production stage. The tooling automatically removes the server(s) from monitoring. If the server is a javaephem or javasrv and is not an extractor, it will squelch any search index checks for the server being relaunched. Once the server is back up, the tooling makes sure that a fields-config-web.php run is complete along with a rake rebuild & rake cron before index monitoring is re-enabled. Finally, the script will verify that the server(s) are back in monitoring. A squelch/unsquelch option was added to ah-server . If, during the relaunch, the tool isn't able to complete a rake rebuild and rake cron run, the affected indexes will not be automatically unsquelched. Once you verify that the server is okay, you will need to manually unsquelch the index check. JAVASRV= ah-server searchindex ${JAVASRV} --no-squelch","title":"Notes"},{"location":"realm_management/site_config_changes/","text":"Bulk config settings changes When changing the settings of more than 20 sites, the following steps are required to prevent a task storm. Procedure Set the SITES variable to a CSV list of sites SITES= Edit all the sites with --no-config-tasks CONFIG= ah-site edit ${SITES} -c ${CONFIG} --no-config-tasks Run f-c-w on all running webs for all the sites edited SERVERS=$(ah-server list site:$(echo ${SITES} | sed \"s/,/,site:/g\") \\ -w \"type IN managed,web,ded,staging,srv,free\" status=0 | paste -sd ,); fpdsh -l $SERVERS -c 'sudo fields-config-web.php' Verification Review the output of f-c-w and address any errors.","title":"Bulk config settings changes"},{"location":"realm_management/site_config_changes/#bulk-config-settings-changes","text":"When changing the settings of more than 20 sites, the following steps are required to prevent a task storm.","title":"Bulk config settings changes"},{"location":"realm_management/site_config_changes/#procedure","text":"Set the SITES variable to a CSV list of sites SITES= Edit all the sites with --no-config-tasks CONFIG= ah-site edit ${SITES} -c ${CONFIG} --no-config-tasks Run f-c-w on all running webs for all the sites edited SERVERS=$(ah-server list site:$(echo ${SITES} | sed \"s/,/,site:/g\") \\ -w \"type IN managed,web,ded,staging,srv,free\" status=0 | paste -sd ,); fpdsh -l $SERVERS -c 'sudo fields-config-web.php'","title":"Procedure"},{"location":"realm_management/site_config_changes/#verification","text":"Review the output of f-c-w and address any errors.","title":"Verification"},{"location":"realm_management/volume_relaunch_fix/","text":"Volume Relaunch Fix An instance may not be able to launch because of the volume attachments. This may be due to preserving an instance that has a mounted volume with a mountpoint such as mntfs. This situation results in AWS not being able to detach the volume. In the case of a mounted volume, the volume enters status \"busy\". At this point it can only be detached by unmounting the volume, forcing detachment, rebooting the instance, or all three. When the server cannot be relaunched because of the volumes, it is possible fix the condition by setting the ebs_id on both the server and the volumes to \"create\" to avoid using the old volumes and instead create new ones. Applicable Situations It is important to note that this solution does not preserve the original volumes. This solution should not be used in cases where the customer data cannot be restored. Diagnosing the condition This condition exists if the following error message appears in the task output during launch: TASK_ID= ah-task get $TASK_ID | grep timeout Outputs cause=timeout verifying {:status=>[:attached]} for operation volume_status with last result: <AWS::EC2::Attachment volume_id:vol-xxxxxxxx instance_id:i-xxxxxxxxxx device:/dev/xvdX> The ebs_id on both the server and the volumes should be changed from volume ids to \"create\". The status of the volumes may show up as \"busy\" in AWS aws ec2 describe-volumes --region us-east-1 --volume-ids vol-1234abcd { \"Volumes\": [ { \"AvailabilityZone\": \"us-west-2b\", \"Attachments\": [ { \"AttachTime\": \"2016-07-21T23:44:52.000Z\", \"InstanceId\": \"i-fedc9876\", \"VolumeId\": \"vol-1234abcd\", \"State\": \"busy\", \"DeleteOnTermination\": false, \"Device\": \"/dev/sdf\" } .... Workaround Set the ebs_id to create on the volume records: VOLUME_ID= # the volume id ah-volume edit $VOLUME_ID -s ebs_id=create If the volumes are Mysql or Backup volumes, we need to edit an additional server record or else the 'ah-volume edit' will be over-ridden. First check the server records: SERVER= # server name ah-server list $SERVER+ -c ebs_id ebs2_id If the volume that couldn't be attached is a primary then set ebs_id : ah-server edit $SERVER -s ebs_id=create If it's a secondary then set ebs2_id to create : ah-server edit $SERVER -s ebs2_id=create Cleanup It is good practice to clean up the leftover volumes as documented in https://runbook.ops.acquia.com/master/instance_management/resize_volumes_manual/#deleting-a-volume once this solution has worked and the customer data has been restored.","title":"Volume Relaunch Fix"},{"location":"realm_management/volume_relaunch_fix/#volume-relaunch-fix","text":"An instance may not be able to launch because of the volume attachments. This may be due to preserving an instance that has a mounted volume with a mountpoint such as mntfs. This situation results in AWS not being able to detach the volume. In the case of a mounted volume, the volume enters status \"busy\". At this point it can only be detached by unmounting the volume, forcing detachment, rebooting the instance, or all three. When the server cannot be relaunched because of the volumes, it is possible fix the condition by setting the ebs_id on both the server and the volumes to \"create\" to avoid using the old volumes and instead create new ones.","title":"Volume Relaunch Fix"},{"location":"realm_management/volume_relaunch_fix/#applicable-situations","text":"It is important to note that this solution does not preserve the original volumes. This solution should not be used in cases where the customer data cannot be restored.","title":"Applicable Situations"},{"location":"realm_management/volume_relaunch_fix/#diagnosing-the-condition","text":"This condition exists if the following error message appears in the task output during launch: TASK_ID= ah-task get $TASK_ID | grep timeout Outputs cause=timeout verifying {:status=>[:attached]} for operation volume_status with last result: <AWS::EC2::Attachment volume_id:vol-xxxxxxxx instance_id:i-xxxxxxxxxx device:/dev/xvdX> The ebs_id on both the server and the volumes should be changed from volume ids to \"create\". The status of the volumes may show up as \"busy\" in AWS aws ec2 describe-volumes --region us-east-1 --volume-ids vol-1234abcd { \"Volumes\": [ { \"AvailabilityZone\": \"us-west-2b\", \"Attachments\": [ { \"AttachTime\": \"2016-07-21T23:44:52.000Z\", \"InstanceId\": \"i-fedc9876\", \"VolumeId\": \"vol-1234abcd\", \"State\": \"busy\", \"DeleteOnTermination\": false, \"Device\": \"/dev/sdf\" } ....","title":"Diagnosing the condition"},{"location":"realm_management/volume_relaunch_fix/#workaround","text":"Set the ebs_id to create on the volume records: VOLUME_ID= # the volume id ah-volume edit $VOLUME_ID -s ebs_id=create If the volumes are Mysql or Backup volumes, we need to edit an additional server record or else the 'ah-volume edit' will be over-ridden. First check the server records: SERVER= # server name ah-server list $SERVER+ -c ebs_id ebs2_id If the volume that couldn't be attached is a primary then set ebs_id : ah-server edit $SERVER -s ebs_id=create If it's a secondary then set ebs2_id to create : ah-server edit $SERVER -s ebs2_id=create","title":"Workaround"},{"location":"realm_management/volume_relaunch_fix/#cleanup","text":"It is good practice to clean up the leftover volumes as documented in https://runbook.ops.acquia.com/master/instance_management/resize_volumes_manual/#deleting-a-volume once this solution has worked and the customer data has been restored.","title":"Cleanup"},{"location":"realm_management/procedures/backup/","text":"Reboot Backup Servers Backup servers are entirely ephemeral. Any attached EBS volumes must be cleaned up before starting this process. If a reboot fails the server must be relaunched. Fix Backup Server Relaunch Bugs Prerequisites See preparation in mass rebooting Procedure Restrict to live backup servers: BACKUP_SERVERS=$(ah-server list $SERVERS -w type=backup status=0 | paste -sd,) Reboot Backup servers: ah-server reboot ${BACKUP_SERVERS}","title":"Reboot Backup Servers"},{"location":"realm_management/procedures/backup/#reboot-backup-servers","text":"Backup servers are entirely ephemeral. Any attached EBS volumes must be cleaned up before starting this process. If a reboot fails the server must be relaunched. Fix Backup Server Relaunch Bugs","title":"Reboot Backup Servers"},{"location":"realm_management/procedures/backup/#prerequisites","text":"See preparation in mass rebooting","title":"Prerequisites"},{"location":"realm_management/procedures/backup/#procedure","text":"Restrict to live backup servers: BACKUP_SERVERS=$(ah-server list $SERVERS -w type=backup status=0 | paste -sd,) Reboot Backup servers: ah-server reboot ${BACKUP_SERVERS}","title":"Procedure"},{"location":"realm_management/procedures/balancer/","text":"Balancer Mass Reboots / Relaunches General Information Balancer clusters may be in one of four different configurations: Type Balancers EIP/s \"Standard\" >=2 1 Singleton 1 1 or 0 Non-Standard >=2 >=2 \"Standard\": The standard setup for a cluster is two balancers with one EIP. Clusters with more than two balancers but only one EIP count as standard clusters for this runbook. Singleton: Singleton clusters are typically for test balancers and may or may not have an EIP. Watch out for snowflakes. Non-Standard: These are clusters with two or more associated EIPs. Clusters with spare balancers can failover their EIPs to maintain HA. Clusters without a spare balancer cannot be failed over. Procedure Prepare lists of balancers Reboot / relaunch standard balancers Reboot / relaunch singleton balancers Reboot / relaunch non-standard balancers Important Notes Ensure you have initialized SERVERS , REGION , and OP per the main mass reboot runbook . Do not abort workflows! If you are unable to resolve a problem with a workflow, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership Preparation List all balancers: REBOOT_OR_RELAUNCH= # valid values: reboot,relaunch BALS=( $(ah-server list % -w \"name IN ${SERVERS}\" typeINbal | sort -V) ) BALS_CSV=$(array-csv ${BALS[@]}) ALL_CLUSTERS_CSV=$(ah-server list $BALS_CSV -w status=0 bal_cluster_id!=0 \\ --no-name -c bal_cluster_id | sort | uniq | paste -sd,) List single balancer clusters: SINGLE_CLUSTERS=($(ah-server list % -w bal_cluster_idIN${ALL_CLUSTERS_CSV} \\ --no-name -c bal_cluster_id | sort | uniq -u)) SINGLE_CLUSTERS_CSV=$(array-csv ${SINGLE_CLUSTERS[@]}) SINGLE_BALS=($(ah-server list ${BALS_CSV} \\ -w bal_cluster_idIN${SINGLE_CLUSTERS_CSV} | sort -V)) SINGLE_BALS_CSV=$(array-csv ${SINGLE_BALS[@]}) List non-standard balancer clusters: NONSTANDARD_CLUSTERS=($(ah-server list bal% \\ -w status=0 bal_cluster_idIN${ALL_CLUSTERS_CSV} eip_id!=nil \\ --no-name -c bal_cluster_id |sort|uniq -d)) NONSTANDARD_CLUSTERS_CSV=$(array-csv ${NONSTANDARD_CLUSTERS[@]}) NONSTANDARD_BALS=($(ah-server list $BALS_CSV \\ -w bal_cluster_idIN${NONSTANDARD_CLUSTERS_CSV} | sort -V)) NONSTANDARD_BALS_CSV=$(array-csv ${NONSTANDARD_BALS[@]}) List standard balancers: declare -a STANDARD_BALS=() BOTH=( ${NONSTANDARD_BALS[@]} ${SINGLE_BALS[@]} ) if [[ -n ${BOTH} ]]; then for bal in ${BALS[@]}; do if ! contains ${bal} ${BOTH[@]}; then STANDARD_BALS+=(${bal}) fi done else STANDARD_BALS=( ${BALS[@]} ) fi STANDARD_BALS_CSV=$(array-csv ${STANDARD_BALS[@]}) Verify lists add up to the total count and paste them into the OP : echo \"{noformat:title=Balancers lists}\" \\ && echo \"Total balancers: ${#BALS[@]}\" \\ && echo \"Total single balancers: ${#SINGLE_BALS[@]}\" \\ && echo \"Total non-standard balancers: ${#NONSTANDARD_BALS[@]}\" \\ && echo \"Total standard balancers: ${#STANDARD_BALS[@]}\" \\ && echo \"{noformat}\" If you need to start at a specific time, calculate the UNIX_START_TIME variable: UNIX_START_TIME=$(date -d '2018/03/22 20:00 UTC' +\"%s\") add the following flag to your ah-bal-cluster relaunch command: --scheduled-time ${UNIX_START_TIME} If you want to resume a workflow task at a specific time, calculate UNIX_START_TIME as above, then schedule it to resume (you must do this after starting the workflow with ah-bal-cluster relaunch below): WORKFLOW_ID= ah-workflow schedule-resume ${WORKFLOW_ID} \\ --scheduled-time ${UNIX_START_TIME} To Find/Check scheduled maintenance information and status, Run scheduled_task=$(ah-workflow get ${WORKFLOW_ID} | grep -w \"scheduled_task_ids.0\"|cut -d: -f2) wf-scheduled or ah-scheduled-task get $scheduled_task To Cancel/Remove the scheduled task in case if your maintenance will be cancelled, Run ah-scheduled-task kill $scheduled_task Beware: Always check the last hrs update in your maintenance ticket for cancellation updates if any. Reboot / Relaunch Balancers Standard Balancers Standard balancers may be restarted with a convenient, automated workflow. Disable monitoring # Copy the variables so that another terminal can be used to disable monitoring echo -e \"{code:title=servers to be rebooted or relaunched} STANDARD_BALS_CSV=${STANDARD_BALS_CSV} {code}\" # Copy above section of output in the JIRA ticket that you are working # In a separate terminal, re-populate the 'STANDARD_BALS_CSV' by copying it from the line above sv-mass-mondisable ${STANDARD_BALS_CSV} Reboot or Relaunch the standard balancers. # Generate reboot/relaunch workflow commands that can be run in parallel. # You can run upto 15 workflows in parallel ahops-workflow-batching -b 20 -t bal -m ${REBOOT_OR_RELAUNCH} -s ${STANDARD_BALS_CSV} Re-enable monitoring # Cancel the script that you ran in 'Disable monitoring' step above # Check that services are ok on all rebooted servers and fix any broken services on server/s # Re-enable monitoring on all servers # Repopulate 'STANDARD_BALS_CSV' by copying name and value for the variable from 'Disable monitoring' step above ah-server edit ${STANDARD_BALS_CSV} --no-config-tasks -s monitoring_status=2 If this is a scheduled workflow, use: ah-bal-cluster ${REBOOT_OR_RELAUNCH} --batch 10 ${STANDARD_BALS[@]} --scheduled-time ${UNIX_START_TIME} --send-notifications false Notes : * In order to receive workflow failure notifications --send-notications false flag can be avoided. * Edge balancers are included in the standard balancers and can be relaunched only using workflow during mass relaunch/reboot. * The ah-bal-cluster command option -V --vpc_id is ignored for edge clusters since it's elements can't be in different VPCs. * If you are changing tenancy for the balancers to dedicated or default use -e dedicated or -e default switch with the command. For more information, please go through link https://runbook.ops.acquia.com/master/kanban_tickets/dedicated_hypervisor/ Due to the way edge clusters are architected, sv-taskrelaunch ah-server suspend/launch shouldn't be used in production . Page edge in case the steps below are insufficient to fix the workflow failure for an edge cluster. Do not suspend bals in an edge cluster. * If the workflow stops or fails, investigate what caused it to fail. If the workflow failed... ...while rebooting: Identify why any bals failed to reboot. Reboot them manually, if necessary. ...occasionally a server reboot will take longer than 10 minutes to reboot. Either it will complete on its own or Atlas needs to be asked to check on the process. ...during EIP failover: Identify why any EIP failovers failed. Manually fail over EIPs, if necessary. Once you have resolved the problem, resume the workflow. Sometimes the workflow will forget to clean up the tags it left on the balancers. Identify the tag and remove it from any tagged servers. Singleton Balancers Clusters with single balancers are usually provisioned for VCL or load testing. However, rarely, a balancer may belong to a site balancer pair in separate clusters. Review the bals in SINGLE_BALS_CSV : ah-server list ${SINGLE_BALS_CSV} -c eip_id external_ip tags | grep -v testbal Instances tagged with loadtestbal or vcltestbal are safe to reboot, as they have no HA. Investigate the remaining singletons, as they may be secretly part of a \"cluster\"; failover EIPs where appropriate. Remove any instances that need to be manually rebooted from SINGLE_BALS_CSV , and reboot the rest. sv-taskrelaunch server -a ${REBOOT_OR_RELAUNCH} ${SINGLE_BALS_CSV} Non-Standard Balancers Non-standard balancer clusters have multiple EIPs which must be handled with care. How these clusters are handled depends on whether they have spare balancers to failover EIPs to. Identify the clusters, their balancers, and their EIPs: for i in ${NONSTANDARD_CLUSTERS[@]}; do echo \"bal_cluster_id: ${i}\" ah-server list ${NONSTANDARD_BALS_CSV} -w bal_cluster_id=${i} -c eip_id external_ip done If a cluster does not have any spare balancers, then there is nothing to failover the EIP to. You must reboot each cluster member one at a time; impact to the customer is unavoidable. sv-taskrelaunch server -a ${REBOOT_OR_RELAUNCH} -s 1 -m 1 ${one_bal_at_a_time} If a cluster has at least one spare, then you must rotate through each balancer one at a time. Starting with the spare bal: reboot the spare bal, failover an EIP to the spare, and reboot the new spare. Continue until all balancers in the cluster are done. For example, you may repeat the following for each balancer in the cluster: SPARE_BAL= # Any bal that DOES NOT have an EIP sv-taskrelaunch server -a ${REBOOT_OR_RELAUNCH} -s 1 -m 1 ${SPARE_BAL} EIP= # The EIP on the next server you need to reboot/relaunch ah-elastic-ip failover ${EIP}","title":"Balancer Mass Reboots / Relaunches"},{"location":"realm_management/procedures/balancer/#balancer-mass-reboots-relaunches","text":"","title":"Balancer Mass Reboots / Relaunches"},{"location":"realm_management/procedures/balancer/#general-information","text":"Balancer clusters may be in one of four different configurations: Type Balancers EIP/s \"Standard\" >=2 1 Singleton 1 1 or 0 Non-Standard >=2 >=2 \"Standard\": The standard setup for a cluster is two balancers with one EIP. Clusters with more than two balancers but only one EIP count as standard clusters for this runbook. Singleton: Singleton clusters are typically for test balancers and may or may not have an EIP. Watch out for snowflakes. Non-Standard: These are clusters with two or more associated EIPs. Clusters with spare balancers can failover their EIPs to maintain HA. Clusters without a spare balancer cannot be failed over.","title":"General Information"},{"location":"realm_management/procedures/balancer/#procedure","text":"Prepare lists of balancers Reboot / relaunch standard balancers Reboot / relaunch singleton balancers Reboot / relaunch non-standard balancers","title":"Procedure"},{"location":"realm_management/procedures/balancer/#important-notes","text":"Ensure you have initialized SERVERS , REGION , and OP per the main mass reboot runbook . Do not abort workflows! If you are unable to resolve a problem with a workflow, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership","title":"Important Notes"},{"location":"realm_management/procedures/balancer/#preparation","text":"List all balancers: REBOOT_OR_RELAUNCH= # valid values: reboot,relaunch BALS=( $(ah-server list % -w \"name IN ${SERVERS}\" typeINbal | sort -V) ) BALS_CSV=$(array-csv ${BALS[@]}) ALL_CLUSTERS_CSV=$(ah-server list $BALS_CSV -w status=0 bal_cluster_id!=0 \\ --no-name -c bal_cluster_id | sort | uniq | paste -sd,) List single balancer clusters: SINGLE_CLUSTERS=($(ah-server list % -w bal_cluster_idIN${ALL_CLUSTERS_CSV} \\ --no-name -c bal_cluster_id | sort | uniq -u)) SINGLE_CLUSTERS_CSV=$(array-csv ${SINGLE_CLUSTERS[@]}) SINGLE_BALS=($(ah-server list ${BALS_CSV} \\ -w bal_cluster_idIN${SINGLE_CLUSTERS_CSV} | sort -V)) SINGLE_BALS_CSV=$(array-csv ${SINGLE_BALS[@]}) List non-standard balancer clusters: NONSTANDARD_CLUSTERS=($(ah-server list bal% \\ -w status=0 bal_cluster_idIN${ALL_CLUSTERS_CSV} eip_id!=nil \\ --no-name -c bal_cluster_id |sort|uniq -d)) NONSTANDARD_CLUSTERS_CSV=$(array-csv ${NONSTANDARD_CLUSTERS[@]}) NONSTANDARD_BALS=($(ah-server list $BALS_CSV \\ -w bal_cluster_idIN${NONSTANDARD_CLUSTERS_CSV} | sort -V)) NONSTANDARD_BALS_CSV=$(array-csv ${NONSTANDARD_BALS[@]}) List standard balancers: declare -a STANDARD_BALS=() BOTH=( ${NONSTANDARD_BALS[@]} ${SINGLE_BALS[@]} ) if [[ -n ${BOTH} ]]; then for bal in ${BALS[@]}; do if ! contains ${bal} ${BOTH[@]}; then STANDARD_BALS+=(${bal}) fi done else STANDARD_BALS=( ${BALS[@]} ) fi STANDARD_BALS_CSV=$(array-csv ${STANDARD_BALS[@]}) Verify lists add up to the total count and paste them into the OP : echo \"{noformat:title=Balancers lists}\" \\ && echo \"Total balancers: ${#BALS[@]}\" \\ && echo \"Total single balancers: ${#SINGLE_BALS[@]}\" \\ && echo \"Total non-standard balancers: ${#NONSTANDARD_BALS[@]}\" \\ && echo \"Total standard balancers: ${#STANDARD_BALS[@]}\" \\ && echo \"{noformat}\" If you need to start at a specific time, calculate the UNIX_START_TIME variable: UNIX_START_TIME=$(date -d '2018/03/22 20:00 UTC' +\"%s\") add the following flag to your ah-bal-cluster relaunch command: --scheduled-time ${UNIX_START_TIME} If you want to resume a workflow task at a specific time, calculate UNIX_START_TIME as above, then schedule it to resume (you must do this after starting the workflow with ah-bal-cluster relaunch below): WORKFLOW_ID= ah-workflow schedule-resume ${WORKFLOW_ID} \\ --scheduled-time ${UNIX_START_TIME} To Find/Check scheduled maintenance information and status, Run scheduled_task=$(ah-workflow get ${WORKFLOW_ID} | grep -w \"scheduled_task_ids.0\"|cut -d: -f2) wf-scheduled or ah-scheduled-task get $scheduled_task To Cancel/Remove the scheduled task in case if your maintenance will be cancelled, Run ah-scheduled-task kill $scheduled_task Beware: Always check the last hrs update in your maintenance ticket for cancellation updates if any.","title":"Preparation"},{"location":"realm_management/procedures/balancer/#reboot-relaunch-balancers","text":"","title":"Reboot / Relaunch Balancers"},{"location":"realm_management/procedures/balancer/#standard-balancers","text":"Standard balancers may be restarted with a convenient, automated workflow. Disable monitoring # Copy the variables so that another terminal can be used to disable monitoring echo -e \"{code:title=servers to be rebooted or relaunched} STANDARD_BALS_CSV=${STANDARD_BALS_CSV} {code}\" # Copy above section of output in the JIRA ticket that you are working # In a separate terminal, re-populate the 'STANDARD_BALS_CSV' by copying it from the line above sv-mass-mondisable ${STANDARD_BALS_CSV} Reboot or Relaunch the standard balancers. # Generate reboot/relaunch workflow commands that can be run in parallel. # You can run upto 15 workflows in parallel ahops-workflow-batching -b 20 -t bal -m ${REBOOT_OR_RELAUNCH} -s ${STANDARD_BALS_CSV} Re-enable monitoring # Cancel the script that you ran in 'Disable monitoring' step above # Check that services are ok on all rebooted servers and fix any broken services on server/s # Re-enable monitoring on all servers # Repopulate 'STANDARD_BALS_CSV' by copying name and value for the variable from 'Disable monitoring' step above ah-server edit ${STANDARD_BALS_CSV} --no-config-tasks -s monitoring_status=2 If this is a scheduled workflow, use: ah-bal-cluster ${REBOOT_OR_RELAUNCH} --batch 10 ${STANDARD_BALS[@]} --scheduled-time ${UNIX_START_TIME} --send-notifications false Notes : * In order to receive workflow failure notifications --send-notications false flag can be avoided. * Edge balancers are included in the standard balancers and can be relaunched only using workflow during mass relaunch/reboot. * The ah-bal-cluster command option -V --vpc_id is ignored for edge clusters since it's elements can't be in different VPCs. * If you are changing tenancy for the balancers to dedicated or default use -e dedicated or -e default switch with the command. For more information, please go through link https://runbook.ops.acquia.com/master/kanban_tickets/dedicated_hypervisor/ Due to the way edge clusters are architected, sv-taskrelaunch ah-server suspend/launch shouldn't be used in production . Page edge in case the steps below are insufficient to fix the workflow failure for an edge cluster. Do not suspend bals in an edge cluster. * If the workflow stops or fails, investigate what caused it to fail. If the workflow failed... ...while rebooting: Identify why any bals failed to reboot. Reboot them manually, if necessary. ...occasionally a server reboot will take longer than 10 minutes to reboot. Either it will complete on its own or Atlas needs to be asked to check on the process. ...during EIP failover: Identify why any EIP failovers failed. Manually fail over EIPs, if necessary. Once you have resolved the problem, resume the workflow. Sometimes the workflow will forget to clean up the tags it left on the balancers. Identify the tag and remove it from any tagged servers.","title":"Standard Balancers"},{"location":"realm_management/procedures/balancer/#singleton-balancers","text":"Clusters with single balancers are usually provisioned for VCL or load testing. However, rarely, a balancer may belong to a site balancer pair in separate clusters. Review the bals in SINGLE_BALS_CSV : ah-server list ${SINGLE_BALS_CSV} -c eip_id external_ip tags | grep -v testbal Instances tagged with loadtestbal or vcltestbal are safe to reboot, as they have no HA. Investigate the remaining singletons, as they may be secretly part of a \"cluster\"; failover EIPs where appropriate. Remove any instances that need to be manually rebooted from SINGLE_BALS_CSV , and reboot the rest. sv-taskrelaunch server -a ${REBOOT_OR_RELAUNCH} ${SINGLE_BALS_CSV}","title":"Singleton Balancers"},{"location":"realm_management/procedures/balancer/#non-standard-balancers","text":"Non-standard balancer clusters have multiple EIPs which must be handled with care. How these clusters are handled depends on whether they have spare balancers to failover EIPs to. Identify the clusters, their balancers, and their EIPs: for i in ${NONSTANDARD_CLUSTERS[@]}; do echo \"bal_cluster_id: ${i}\" ah-server list ${NONSTANDARD_BALS_CSV} -w bal_cluster_id=${i} -c eip_id external_ip done If a cluster does not have any spare balancers, then there is nothing to failover the EIP to. You must reboot each cluster member one at a time; impact to the customer is unavoidable. sv-taskrelaunch server -a ${REBOOT_OR_RELAUNCH} -s 1 -m 1 ${one_bal_at_a_time} If a cluster has at least one spare, then you must rotate through each balancer one at a time. Starting with the spare bal: reboot the spare bal, failover an EIP to the spare, and reboot the new spare. Continue until all balancers in the cluster are done. For example, you may repeat the following for each balancer in the cluster: SPARE_BAL= # Any bal that DOES NOT have an EIP sv-taskrelaunch server -a ${REBOOT_OR_RELAUNCH} -s 1 -m 1 ${SPARE_BAL} EIP= # The EIP on the next server you need to reboot/relaunch ah-elastic-ip failover ${EIP}","title":"Non-Standard Balancers"},{"location":"realm_management/procedures/cplane/","text":"Control Plane Non-Customer-Impacting Hosts: dns , ossec , stats , log Rebooting or Relaunching DNS ( dns ) DNS=($(ah-server list % -w \"name IN ${SERVERS}\" typeINdns | sort -V)) ah-server bulk-${REBOOT_OR_RELAUNCH} --batch-size 64 ${DNS[@]} --send-notifications false Note : In order to receive workflow failure notifications --send-notications false flag can be avoided. Rebooting or Relaunching OSSEC ( ossec ) OSSEC=($(ah-server list % -w \"name IN ${SERVERS}\" typeINossec | sort -V)) ah-server bulk-${REBOOT_OR_RELAUNCH} --batch-size 64 ${OSSEC[@]} --send-notifications false Note : In order to receive workflow failure notifications --send-notications false flag can be avoided. Rebooting or Relaunching STATS ( stats ) STATS=($(ah-server list % -w \"name IN ${SERVERS}\" typeINstats | sort -V)) ah-server bulk-${REBOOT_OR_RELAUNCH} --batch-size 64 ${STATS[@]} --send-notifications false Note : In order to receive workflow failure notifications --send-notications false flag can be avoided. Rebooting or Relaunching LOG ( log ) Log servers operate in clusters of 3, so it is best to reboot them one at a time. LOG=($(ah-server list % -w \"name IN ${SERVERS}\" type=log | sort -V)) sv-taskrelaunch server -a ${REBOOT_OR_RELAUNCH} -s 1 -m 1 ${LOG[@]} Rebooting or Relaunching Monitoring Hosts ( mon , monui , sitemon ) Rebooting mon and sitemon hosts will impair the ability for incident response to maintain visibility. Please announce reboots of these hosts in the Operations chat room. MON=($(ah-server list % -w \"name IN ${SERVERS}\" typeINmon,monui | sort -V)) SITEMON=($(ah-server list % -w \"name IN ${SERVERS}\" typeINsitemon | sort -V)) ah-server bulk-${REBOOT_OR_RELAUNCH} --batch 1 ${MON[@]} --send-notifications false ah-server bulk-${REBOOT_OR_RELAUNCH} --batch 1 ${SITEMON[@]} --send-notifications false Note : In order to receive workflow failure notifications --send-notications false flag can be avoided. Customer-Impacting Hosts: svn Rebooting or Relaunching SVN Hosts ( svn ) svn hosts are customer-impacting because rebooting them will interrupt any commits or checkouts in flight. SVN=($(ah-server list % -w \"name IN ${SERVERS}\" typeINsvn | sort -V)) ah-server bulk-${REBOOT_OR_RELAUNCH} --batch-size 64 ${SVN[@]} --send-notifications false Note : In order to receive workflow failure notifications --send-notications false flag can be avoided.","title":"Control Plane"},{"location":"realm_management/procedures/cplane/#control-plane","text":"","title":"Control Plane"},{"location":"realm_management/procedures/cplane/#non-customer-impacting-hosts-dnsossecstats-log","text":"","title":"Non-Customer-Impacting Hosts: dns,ossec,stats, log"},{"location":"realm_management/procedures/cplane/#rebooting-or-relaunching-dns-dns","text":"DNS=($(ah-server list % -w \"name IN ${SERVERS}\" typeINdns | sort -V)) ah-server bulk-${REBOOT_OR_RELAUNCH} --batch-size 64 ${DNS[@]} --send-notifications false Note : In order to receive workflow failure notifications --send-notications false flag can be avoided.","title":"Rebooting or Relaunching DNS (dns)"},{"location":"realm_management/procedures/cplane/#rebooting-or-relaunching-ossec-ossec","text":"OSSEC=($(ah-server list % -w \"name IN ${SERVERS}\" typeINossec | sort -V)) ah-server bulk-${REBOOT_OR_RELAUNCH} --batch-size 64 ${OSSEC[@]} --send-notifications false Note : In order to receive workflow failure notifications --send-notications false flag can be avoided.","title":"Rebooting or Relaunching OSSEC (ossec)"},{"location":"realm_management/procedures/cplane/#rebooting-or-relaunching-stats-stats","text":"STATS=($(ah-server list % -w \"name IN ${SERVERS}\" typeINstats | sort -V)) ah-server bulk-${REBOOT_OR_RELAUNCH} --batch-size 64 ${STATS[@]} --send-notifications false Note : In order to receive workflow failure notifications --send-notications false flag can be avoided.","title":"Rebooting or Relaunching STATS (stats)"},{"location":"realm_management/procedures/cplane/#rebooting-or-relaunching-log-log","text":"Log servers operate in clusters of 3, so it is best to reboot them one at a time. LOG=($(ah-server list % -w \"name IN ${SERVERS}\" type=log | sort -V)) sv-taskrelaunch server -a ${REBOOT_OR_RELAUNCH} -s 1 -m 1 ${LOG[@]}","title":"Rebooting or Relaunching LOG (log)"},{"location":"realm_management/procedures/cplane/#rebooting-or-relaunching-monitoring-hosts-mon-monui-sitemon","text":"Rebooting mon and sitemon hosts will impair the ability for incident response to maintain visibility. Please announce reboots of these hosts in the Operations chat room. MON=($(ah-server list % -w \"name IN ${SERVERS}\" typeINmon,monui | sort -V)) SITEMON=($(ah-server list % -w \"name IN ${SERVERS}\" typeINsitemon | sort -V)) ah-server bulk-${REBOOT_OR_RELAUNCH} --batch 1 ${MON[@]} --send-notifications false ah-server bulk-${REBOOT_OR_RELAUNCH} --batch 1 ${SITEMON[@]} --send-notifications false Note : In order to receive workflow failure notifications --send-notications false flag can be avoided.","title":"Rebooting or Relaunching Monitoring Hosts (mon, monui, sitemon)"},{"location":"realm_management/procedures/cplane/#customer-impacting-hosts-svn","text":"","title":"Customer-Impacting Hosts: svn"},{"location":"realm_management/procedures/cplane/#rebooting-or-relaunching-svn-hosts-svn","text":"svn hosts are customer-impacting because rebooting them will interrupt any commits or checkouts in flight. SVN=($(ah-server list % -w \"name IN ${SERVERS}\" typeINsvn | sort -V)) ah-server bulk-${REBOOT_OR_RELAUNCH} --batch-size 64 ${SVN[@]} --send-notifications false Note : In order to receive workflow failure notifications --send-notications false flag can be avoided.","title":"Rebooting or Relaunching SVN Hosts (svn)"},{"location":"realm_management/procedures/custom_servers/","text":"Custom servers ( custom ) These only need special attention in case that the service that is installed is not able to start after reboot. Reboot all the custom servers. CUSTOM=($(ah-server list % -w \"name IN ${SERVERS}\" type=custom)) sv-taskrelaunch server -a reboot -s 64 -m 1 ${CUSTOM[@]} Please see the corresponding section in the docs if any service fails to start.","title":"Custom servers (`custom`)"},{"location":"realm_management/procedures/custom_servers/#custom-servers-custom","text":"These only need special attention in case that the service that is installed is not able to start after reboot. Reboot all the custom servers. CUSTOM=($(ah-server list % -w \"name IN ${SERVERS}\" type=custom)) sv-taskrelaunch server -a reboot -s 64 -m 1 ${CUSTOM[@]} Please see the corresponding section in the docs if any service fails to start.","title":"Custom servers (custom)"},{"location":"realm_management/procedures/databases/","text":"Database Mass Reboot/Relaunch General Information Rebooting databases en masse is a delicate process and should be handled with great care. In order to maintain SLA, this procedure attempts to ensure that: Only passive DB servers are rebooted DB clusters are locked while reboots are done Replication lag is nominal before any critical step is actioned Site file systems are available and stable throughout the process These are difficult things to do, but if done properly there should not be any customer downtime. It is your duty to mitigate them to the best of your ability. Be empathetic to the Ops hotseat by watching PagerDuty alerts and helping where you can. Procedure Preparation Reboot or Relaunch Database Clusters Cleanup and verify success Important Notes Ensure you have initialized SERVERS , REGION , and OP per the main mass reboot runbook . Do not abort workflows! If you are unable to resolve a problem with a workflow, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership Preparation Set this variable to appropriately reboot or relaunch the databases: REBOOT_OR_RELAUNCH= # valid values: reboot,relaunch Create a list of all the database servers and relevant FS nodes for the specified region: ALL_DBS=$(ah-server list % -w \"name IN ${SERVERS}\" typeINded,fsdb,dbmaster | paste -sd,) FS_CLUSTERS=$(ah-server list ${ALL_DBS} -w typeINded,fsdb --no-name -c fs_cluster_id | sort -V | uniq | paste -sd,) FS_NODES=$(ah-server list % -w status=0 \"fs_cluster_id IN ${FS_CLUSTERS}\" | paste -sd,) Check for locked DB clusters: sv-dbislocked ${ALL_DBS} Unlock any unintentionally locked DB clusters with ah-db-cluster unlock . If you find any DB clusters that should not be unlocked, remove them from ALL_DBS and update FS_NODES If you need to start at a specific time, calculate the UNIX_START_TIME variable: UNIX_START_TIME=$(date -d '2018/03/22 20:00 UTC' +\"%s\") add the following flag to your ah-server bulk-${REBOOT_OR_RELAUNCH} command: --scheduled-time ${UNIX_START_TIME} If you want to resume a workflow task at a specific time, calculate UNIX_START_TIME as above, then schedule it to resume (you must do this after starting the workflow with ah-server bulk-${REBOOT_OR_RELAUNCH} below): WORKFLOW_ID= ah-workflow schedule-resume ${WORKFLOW_ID} \\ --scheduled-time ${UNIX_START_TIME} To Find/Check scheduled maintenance information and status,Run scheduled_task=$(ah-workflow get ${WORKFLOW_ID} | grep -w \"scheduled_task_ids.0\"|cut -d: -f2) wf-scheduled or ah-scheduled-task get $scheduled_task To Cancel/Remove the scheduled task in case if your maintenance will be cancelled,run ah-scheduled-task kill $scheduled_task Beware: Always check the last hrs update in your maintenance ticket for cancellation updates if any. Reboot or Relaunch Database Clusters Reboot/Relaunch the database servers, each type must be initiated on individual workflows: DEDS=($(ah-server list % -w \"name IN ${ALL_DBS}\" typeINded)) DEDS_CSV=$(array-csv ${DEDS[@]}) FSDBS=($(ah-server list % -w \"name IN ${ALL_DBS}\" typeINfsdb)) FSDBS_CSV=$(array-csv ${FSDBS[@]}) DBMASTERS=($(ah-server list % -w \"name IN ${ALL_DBS}\" typeINdbmaster)) DBMASTERS_CSV=$(array-csv ${DBMASTERS[@]}) Reboot/Relaunch - DEDS # Disable monitoring # Copy the variables so that another terminal can be used to disable monitoring echo -e \"{code:title=servers to be rebooted or relaunched} DEDS_CSV=${DEDS_CSV} {code}\" # Copy above section of output in the JIRA ticket that you are working # In a separate terminal, re-populate the 'DEDS_CSV' by copying it from the line above sv-mass-mondisable ${DEDS_CSV} # Generate reboot/relaunch workflow commands that can be run in parallel. # You can run upto 15 workflows in parallel ahops-workflow-batching -b 20 -t ded -m ${REBOOT_OR_RELAUNCH} -s ${DEDS_CSV} # Use following if you need to upgrade OS as well ah-server bulk-${REBOOT_OR_RELAUNCH} ${UPGRADE_OS} --batch 32 ${DEDS[@]} --send-notifications false # Re-enable monitoring # Cancel the script that you ran in 'Disable monitoring' step above # Check that services are ok on all rebooted servers and fix any broken services on server/s # Re-enable monitoring on all servers # Repopulate 'DEDS_CSV' by copying name and value for the variable from 'Disable monitoring' step above ah-server edit ${DEDS_CSV} --no-config-tasks -s monitoring_status=2 Reboot/Relaunch - FSDBS # Disable monitoring # Copy the variables so that another terminal can be used to disable monitoring echo -e \"{code:title=servers to be rebooted or relaunched} FSDBS_CSV=${FSDBS_CSV} {code}\" # Copy above section of output in the JIRA ticket that you are working # In a separate terminal, re-populate the 'FSDBS_CSV' by copying it from the line above sv-mass-mondisable ${FSDBS_CSV} # Generate reboot/relaunch commands that can be run in parallel. # You can run upto 15 workflows in parallel ahops-workflow-batching -b 20 -t fsdb -m ${REBOOT_OR_RELAUNCH} -s ${FSDBS_CSV} # Use following if you need to upgrade OS as well ah-server bulk-${REBOOT_OR_RELAUNCH} ${UPGRADE_OS} --batch 32 ${FSDBS[@]} --send-notifications false # Re-enable monitoring # Cancel the script that you ran in 'Disable monitoring' step above # Check that services are ok on all rebooted servers and fix any broken services on server/s # Re-enable monitoring on all servers # Repopulate 'FSDBS_CSV' by copying name and value for the variable from 'Disable monitoring' step above # Re-enable monitoring on all servers ah-server edit ${FSDBS_CSV} --no-config-tasks -s monitoring_status=2 Relaunch/Reboot/OS-Upgrades - DBMASTERS # Disable monitoring # Copy the variables so that another terminal can be used to disable monitoring echo -e \"{code:title=servers to be rebooted or relaunched} DBMASTERS_CSV=${DBMASTERS_CSV} {code}\" # Copy above section of output in the JIRA ticket that you are working # In a separate terminal, re-populate the 'DBMASTERS_CSV' by copying it from the line above sv-mass-mondisable ${DBMASTERS_CSV} # Reboot/relaunch DBMASTERS ah-server bulk-${REBOOT_OR_RELAUNCH} ${UPGRADE_OS} --batch 32 ${DBMASTERS[@]} --send-notifications false # Re-enable monitoring # Cancel the script that you ran in 'Disable monitoring' step above # Check that services are ok on all rebooted servers and fix any broken services on server/s # Re-enable monitoring on all servers # Repopulate 'DBMASTERS_CSV' by copying name and value for the variable from 'Disable monitoring' step above # Re-enable monitoring on all servers ah-server edit ${DBMASTERS_CSV} --no-config-tasks -s monitoring_status=2 If this is a scheduled workflow then use: ah-server bulk-${REBOOT_OR_RELAUNCH} ${UPGRADE_OS} --batch 32 ${DEDS[@]} --scheduled-time ${UNIX_START_TIME} --send-notifications false ah-server bulk-${REBOOT_OR_RELAUNCH} ${UPGRADE_OS} --batch 32 ${FSDBS[@]} --scheduled-time ${UNIX_START_TIME} --send-notifications false ah-server bulk-${REBOOT_OR_RELAUNCH} ${UPGRADE_OS} --batch 32 ${DBMASTERS[@]} --scheduled-time ${UNIX_START_TIME} --send-notifications false Note : In order to receive workflow failure notifications --send-notications false flag can be avoided. Also, if you are relaunching the servers to change the tenancy, use -e dedicated or -e default to set the required tenancy. For more information, please go through link https://runbook.ops.acquia.com/master/kanban_tickets/dedicated_hypervisor/ For larger regions this may take some time. Monitor the progress of each workflow with: WORKFLOW_ID= watch -n 30 \"ah-workflow watch-queue ${WORKFLOW_ID}\" Cleanup Verify that replication lag is ok for all databases: fpdsh -l ${ALL_DBS} \\ -c \"sudo ruby -e 'require \\\"aq\\\"; s=Aq::Hosting::Server.from_local; \\ puts s.services.mysql.heartbeat_info.lag_max'\" | awk '$2>1' Please make sure to remount each fs node after the reboot/relaunch: sv-fsremount ${FS_NODES} |& grep -Ei 'fail|error|warn|status:[^0]$' Workflow Errors If bulk-relaunch workflow fails, please investigate the error using: ah-workflow get ${WORKFLOW_ID} --show-logs Check any failed tasks using: ah-task get ${TASK_ID} If you cannot fix it, escalate appropriately. Make sure to include all output from ah-workflow watch-queue in Jira. If any databases were removed from this procedure investigate them and manually reboot/relaunch them, if possible. If you cannot, escalate appropriately. Do not let them be forgotten! Go do something relaxing to calm your boiling hatred for the world. You and everyone else to whom this was handed off have earned it.","title":"Database Mass Reboot/Relaunch"},{"location":"realm_management/procedures/databases/#database-mass-rebootrelaunch","text":"","title":"Database Mass Reboot/Relaunch"},{"location":"realm_management/procedures/databases/#general-information","text":"Rebooting databases en masse is a delicate process and should be handled with great care. In order to maintain SLA, this procedure attempts to ensure that: Only passive DB servers are rebooted DB clusters are locked while reboots are done Replication lag is nominal before any critical step is actioned Site file systems are available and stable throughout the process These are difficult things to do, but if done properly there should not be any customer downtime. It is your duty to mitigate them to the best of your ability. Be empathetic to the Ops hotseat by watching PagerDuty alerts and helping where you can.","title":"General Information"},{"location":"realm_management/procedures/databases/#procedure","text":"Preparation Reboot or Relaunch Database Clusters Cleanup and verify success","title":"Procedure"},{"location":"realm_management/procedures/databases/#important-notes","text":"Ensure you have initialized SERVERS , REGION , and OP per the main mass reboot runbook . Do not abort workflows! If you are unable to resolve a problem with a workflow, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership","title":"Important Notes"},{"location":"realm_management/procedures/databases/#preparation","text":"Set this variable to appropriately reboot or relaunch the databases: REBOOT_OR_RELAUNCH= # valid values: reboot,relaunch Create a list of all the database servers and relevant FS nodes for the specified region: ALL_DBS=$(ah-server list % -w \"name IN ${SERVERS}\" typeINded,fsdb,dbmaster | paste -sd,) FS_CLUSTERS=$(ah-server list ${ALL_DBS} -w typeINded,fsdb --no-name -c fs_cluster_id | sort -V | uniq | paste -sd,) FS_NODES=$(ah-server list % -w status=0 \"fs_cluster_id IN ${FS_CLUSTERS}\" | paste -sd,) Check for locked DB clusters: sv-dbislocked ${ALL_DBS} Unlock any unintentionally locked DB clusters with ah-db-cluster unlock . If you find any DB clusters that should not be unlocked, remove them from ALL_DBS and update FS_NODES If you need to start at a specific time, calculate the UNIX_START_TIME variable: UNIX_START_TIME=$(date -d '2018/03/22 20:00 UTC' +\"%s\") add the following flag to your ah-server bulk-${REBOOT_OR_RELAUNCH} command: --scheduled-time ${UNIX_START_TIME} If you want to resume a workflow task at a specific time, calculate UNIX_START_TIME as above, then schedule it to resume (you must do this after starting the workflow with ah-server bulk-${REBOOT_OR_RELAUNCH} below): WORKFLOW_ID= ah-workflow schedule-resume ${WORKFLOW_ID} \\ --scheduled-time ${UNIX_START_TIME} To Find/Check scheduled maintenance information and status,Run scheduled_task=$(ah-workflow get ${WORKFLOW_ID} | grep -w \"scheduled_task_ids.0\"|cut -d: -f2) wf-scheduled or ah-scheduled-task get $scheduled_task To Cancel/Remove the scheduled task in case if your maintenance will be cancelled,run ah-scheduled-task kill $scheduled_task Beware: Always check the last hrs update in your maintenance ticket for cancellation updates if any.","title":"Preparation"},{"location":"realm_management/procedures/databases/#reboot-or-relaunch-database-clusters","text":"Reboot/Relaunch the database servers, each type must be initiated on individual workflows: DEDS=($(ah-server list % -w \"name IN ${ALL_DBS}\" typeINded)) DEDS_CSV=$(array-csv ${DEDS[@]}) FSDBS=($(ah-server list % -w \"name IN ${ALL_DBS}\" typeINfsdb)) FSDBS_CSV=$(array-csv ${FSDBS[@]}) DBMASTERS=($(ah-server list % -w \"name IN ${ALL_DBS}\" typeINdbmaster)) DBMASTERS_CSV=$(array-csv ${DBMASTERS[@]}) Reboot/Relaunch - DEDS # Disable monitoring # Copy the variables so that another terminal can be used to disable monitoring echo -e \"{code:title=servers to be rebooted or relaunched} DEDS_CSV=${DEDS_CSV} {code}\" # Copy above section of output in the JIRA ticket that you are working # In a separate terminal, re-populate the 'DEDS_CSV' by copying it from the line above sv-mass-mondisable ${DEDS_CSV} # Generate reboot/relaunch workflow commands that can be run in parallel. # You can run upto 15 workflows in parallel ahops-workflow-batching -b 20 -t ded -m ${REBOOT_OR_RELAUNCH} -s ${DEDS_CSV} # Use following if you need to upgrade OS as well ah-server bulk-${REBOOT_OR_RELAUNCH} ${UPGRADE_OS} --batch 32 ${DEDS[@]} --send-notifications false # Re-enable monitoring # Cancel the script that you ran in 'Disable monitoring' step above # Check that services are ok on all rebooted servers and fix any broken services on server/s # Re-enable monitoring on all servers # Repopulate 'DEDS_CSV' by copying name and value for the variable from 'Disable monitoring' step above ah-server edit ${DEDS_CSV} --no-config-tasks -s monitoring_status=2 Reboot/Relaunch - FSDBS # Disable monitoring # Copy the variables so that another terminal can be used to disable monitoring echo -e \"{code:title=servers to be rebooted or relaunched} FSDBS_CSV=${FSDBS_CSV} {code}\" # Copy above section of output in the JIRA ticket that you are working # In a separate terminal, re-populate the 'FSDBS_CSV' by copying it from the line above sv-mass-mondisable ${FSDBS_CSV} # Generate reboot/relaunch commands that can be run in parallel. # You can run upto 15 workflows in parallel ahops-workflow-batching -b 20 -t fsdb -m ${REBOOT_OR_RELAUNCH} -s ${FSDBS_CSV} # Use following if you need to upgrade OS as well ah-server bulk-${REBOOT_OR_RELAUNCH} ${UPGRADE_OS} --batch 32 ${FSDBS[@]} --send-notifications false # Re-enable monitoring # Cancel the script that you ran in 'Disable monitoring' step above # Check that services are ok on all rebooted servers and fix any broken services on server/s # Re-enable monitoring on all servers # Repopulate 'FSDBS_CSV' by copying name and value for the variable from 'Disable monitoring' step above # Re-enable monitoring on all servers ah-server edit ${FSDBS_CSV} --no-config-tasks -s monitoring_status=2 Relaunch/Reboot/OS-Upgrades - DBMASTERS # Disable monitoring # Copy the variables so that another terminal can be used to disable monitoring echo -e \"{code:title=servers to be rebooted or relaunched} DBMASTERS_CSV=${DBMASTERS_CSV} {code}\" # Copy above section of output in the JIRA ticket that you are working # In a separate terminal, re-populate the 'DBMASTERS_CSV' by copying it from the line above sv-mass-mondisable ${DBMASTERS_CSV} # Reboot/relaunch DBMASTERS ah-server bulk-${REBOOT_OR_RELAUNCH} ${UPGRADE_OS} --batch 32 ${DBMASTERS[@]} --send-notifications false # Re-enable monitoring # Cancel the script that you ran in 'Disable monitoring' step above # Check that services are ok on all rebooted servers and fix any broken services on server/s # Re-enable monitoring on all servers # Repopulate 'DBMASTERS_CSV' by copying name and value for the variable from 'Disable monitoring' step above # Re-enable monitoring on all servers ah-server edit ${DBMASTERS_CSV} --no-config-tasks -s monitoring_status=2 If this is a scheduled workflow then use: ah-server bulk-${REBOOT_OR_RELAUNCH} ${UPGRADE_OS} --batch 32 ${DEDS[@]} --scheduled-time ${UNIX_START_TIME} --send-notifications false ah-server bulk-${REBOOT_OR_RELAUNCH} ${UPGRADE_OS} --batch 32 ${FSDBS[@]} --scheduled-time ${UNIX_START_TIME} --send-notifications false ah-server bulk-${REBOOT_OR_RELAUNCH} ${UPGRADE_OS} --batch 32 ${DBMASTERS[@]} --scheduled-time ${UNIX_START_TIME} --send-notifications false Note : In order to receive workflow failure notifications --send-notications false flag can be avoided. Also, if you are relaunching the servers to change the tenancy, use -e dedicated or -e default to set the required tenancy. For more information, please go through link https://runbook.ops.acquia.com/master/kanban_tickets/dedicated_hypervisor/ For larger regions this may take some time. Monitor the progress of each workflow with: WORKFLOW_ID= watch -n 30 \"ah-workflow watch-queue ${WORKFLOW_ID}\"","title":"Reboot or Relaunch Database Clusters"},{"location":"realm_management/procedures/databases/#cleanup","text":"Verify that replication lag is ok for all databases: fpdsh -l ${ALL_DBS} \\ -c \"sudo ruby -e 'require \\\"aq\\\"; s=Aq::Hosting::Server.from_local; \\ puts s.services.mysql.heartbeat_info.lag_max'\" | awk '$2>1' Please make sure to remount each fs node after the reboot/relaunch: sv-fsremount ${FS_NODES} |& grep -Ei 'fail|error|warn|status:[^0]$'","title":"Cleanup"},{"location":"realm_management/procedures/databases/#workflow-errors","text":"If bulk-relaunch workflow fails, please investigate the error using: ah-workflow get ${WORKFLOW_ID} --show-logs Check any failed tasks using: ah-task get ${TASK_ID} If you cannot fix it, escalate appropriately. Make sure to include all output from ah-workflow watch-queue in Jira. If any databases were removed from this procedure investigate them and manually reboot/relaunch them, if possible. If you cannot, escalate appropriately. Do not let them be forgotten! Go do something relaxing to calm your boiling hatred for the world. You and everyone else to whom this was handed off have earned it.","title":"Workflow Errors"},{"location":"realm_management/procedures/fs/","text":"Filesystem Server Mass Reboot/Relaunch Gluster has no concept of active servers, so there is no failover to perform. However, filesystems for all nodes across the site MUST be remounted after each reboot/relaunch. Preparation Set this variable to appropriately reboot or relaunch the databases: REBOOT_OR_RELAUNCH= # valid values: reboot,relaunch List all FS servers, their cluster IDs, and all nodes linked to those clusters: FS_SERVERS=($(ah-server list % -w \"name IN ${SERVERS}\" typeINfs | sort -V)) FS_SERVERS_CSV=$(array-csv ${FS_SERVERS[@]}) FS_CLUSTERS=$(ah-server list ${FS_SERVERS_CSV} --no-name -c fs_cluster_id | paste -sd,) FS_NODES=$(ah-server list % -w status=0 \"fs_cluster_id IN ${FS_CLUSTERS}\" | paste -sd,) If you need to start at a specific time, calculate the UNIX_START_TIME variable: UNIX_START_TIME=$(date -d '2018/03/22 20:00 UTC' +\"%s\") add the following flag to your ah-server bulk-${REBOOT_OR_RELAUNCH} command: --scheduled-time ${UNIX_START_TIME} If you want to resume a workflow task at a specific time, calculate UNIX_START_TIME as above, then schedule it to resume (you must do this after starting the workflow with ah-server bulk-${REBOOT_OR_RELAUNCH} below): WORKFLOW_ID= ah-workflow schedule-resume ${WORKFLOW_ID} \\ --scheduled-time ${UNIX_START_TIME} To Check scheduled maintenance information and status, Run scheduled_task=$(ah-workflow get ${WORKFLOW_ID} | grep -w \"scheduled_task_ids.0\"|cut -d: -f2) wf-scheduled or ah-scheduled-task get $scheduled_task To Cancel/Remove the scheduled task in case if your maintenance will cancelled, Run ah-scheduled-task kill $scheduled_task Beware: Always check the last hrs update in your maintenance ticket for cancellation updates if any. Important Note Do not abort workflows! If you are unable to resolve a problem with a workflow, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership Ensure Gluster Mounts Ensure hosts and iptables configs are correct on all FS nodes, then remount gluster in case any of them are only connected to the servers you are about to reboot/relaunch: fpdsh -l ${FS_NODES} -c 'sudo ah-config-hosts; sudo ah-config-iptables' sv-fsremount ${FS_NODES} | egrep -i 'failed|error' Resolve all remount errors for every gluster node before continuing! Instances that fail to remount gluster will not have a stable file system and will cause alerts. For servers that do not remount cleanly, try a second remount. Otherwise, cron jobs or shell sessions may need to be killed. Refer to the Gluster alert runbook . ( TODO: Remounting Gluster should have its own runbook. ) Reboot/Relaunch FS Servers Reboot/Relaunch the FS servers: # Disable monitoring # Copy the variables so that another terminal can be used to disable monitoring echo -e \"{code:title=servers to be rebooted or relaunched} FS_SERVERS_CSV=${FS_SERVERS_CSV} {code}\" # Copy above section of output in the JIRA ticket that you are working # In a separate terminal, re-populate the 'FS_SERVERS_CSV' by copying it from the line above sv-mass-mondisable ${FS_SERVERS_CSV} # Reboot/Relaunch - FS # Generate reboot/relaunch commands that can be run in parallel. # You can run upto 15 workflows in parallel ahops-workflow-batching -b 20 -t fs -m ${REBOOT_OR_RELAUNCH} -s ${FS_SERVERS_CSV} # Use following if you need to upgrade OS as well ah-server bulk-${REBOOT_OR_RELAUNCH} ${UPGRADE_OS} --batch 64 ${FS_SERVERS[@]} --send-notifications false Note : In order to receive workflow failure notifications --send-notications false flag can be avoided. Also, if you are relaunching the servers to change the tenancy, use -e dedicated or -e default to set the required tenancy. For more information, please go through link https://runbook.ops.acquia.com/master/kanban_tickets/dedicated_hypervisor/ For larger regions this may take some time. Monitor the progress of each workflow with: WORKFLOW_ID= watch -n 30 \"ah-workflow watch-queue ${WORKFLOW_ID}\" Please make sure to remount each fs node after the reboot/relaunch: sv-fsremount ${FS_NODES} |& grep -Ei 'fail|error|warn|status:[^0]$' For servers that do not remount cleanly, try a second remount. Otherwise, cron jobs or shell sessions may need to be killed. Refer to the Gluster alert runbook . ( TODO: Remounting Gluster should have its own runbook. ) Enable Monitoring # Cancel the script that you ran in 'Disable monitoring' step above # Check that services are ok on all rebooted servers and fix any broken services on server/s # Re-enable monitoring on all servers # Repopulate 'FS_SERVERS_CSV' by copying name and value for the variable from 'Disable monitoring' step above ah-server edit ${FS_SERVERS_CSV} --no-config-tasks -s monitoring_status=2 Cleanup Verify that all affected servers can reach their gluster volumes: fpdsh -l ${FS_NODES} -c '(ls /mnt/gfs/home > /dev/null 2>&1 ) || echo \"Failed\"'; Remount gluster on any servers that fail. Workflow errors If ah-server bulk-relaunch workflow fails, please investigate the error using: ah-workflow get ${WORKFLOW_ID} --show-logs Check any failed tasks using: ah-task get ${TASK_ID} If you cannot fix it, escalate appropriately. Make sure to include all output from ah-workflow watch-queue in Jira.","title":"Filesystem Server Mass Reboot/Relaunch"},{"location":"realm_management/procedures/fs/#filesystem-server-mass-rebootrelaunch","text":"Gluster has no concept of active servers, so there is no failover to perform. However, filesystems for all nodes across the site MUST be remounted after each reboot/relaunch.","title":"Filesystem Server Mass Reboot/Relaunch"},{"location":"realm_management/procedures/fs/#preparation","text":"Set this variable to appropriately reboot or relaunch the databases: REBOOT_OR_RELAUNCH= # valid values: reboot,relaunch List all FS servers, their cluster IDs, and all nodes linked to those clusters: FS_SERVERS=($(ah-server list % -w \"name IN ${SERVERS}\" typeINfs | sort -V)) FS_SERVERS_CSV=$(array-csv ${FS_SERVERS[@]}) FS_CLUSTERS=$(ah-server list ${FS_SERVERS_CSV} --no-name -c fs_cluster_id | paste -sd,) FS_NODES=$(ah-server list % -w status=0 \"fs_cluster_id IN ${FS_CLUSTERS}\" | paste -sd,) If you need to start at a specific time, calculate the UNIX_START_TIME variable: UNIX_START_TIME=$(date -d '2018/03/22 20:00 UTC' +\"%s\") add the following flag to your ah-server bulk-${REBOOT_OR_RELAUNCH} command: --scheduled-time ${UNIX_START_TIME} If you want to resume a workflow task at a specific time, calculate UNIX_START_TIME as above, then schedule it to resume (you must do this after starting the workflow with ah-server bulk-${REBOOT_OR_RELAUNCH} below): WORKFLOW_ID= ah-workflow schedule-resume ${WORKFLOW_ID} \\ --scheduled-time ${UNIX_START_TIME} To Check scheduled maintenance information and status, Run scheduled_task=$(ah-workflow get ${WORKFLOW_ID} | grep -w \"scheduled_task_ids.0\"|cut -d: -f2) wf-scheduled or ah-scheduled-task get $scheduled_task To Cancel/Remove the scheduled task in case if your maintenance will cancelled, Run ah-scheduled-task kill $scheduled_task Beware: Always check the last hrs update in your maintenance ticket for cancellation updates if any.","title":"Preparation"},{"location":"realm_management/procedures/fs/#important-note","text":"Do not abort workflows! If you are unable to resolve a problem with a workflow, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership","title":"Important Note"},{"location":"realm_management/procedures/fs/#ensure-gluster-mounts","text":"Ensure hosts and iptables configs are correct on all FS nodes, then remount gluster in case any of them are only connected to the servers you are about to reboot/relaunch: fpdsh -l ${FS_NODES} -c 'sudo ah-config-hosts; sudo ah-config-iptables' sv-fsremount ${FS_NODES} | egrep -i 'failed|error' Resolve all remount errors for every gluster node before continuing! Instances that fail to remount gluster will not have a stable file system and will cause alerts. For servers that do not remount cleanly, try a second remount. Otherwise, cron jobs or shell sessions may need to be killed. Refer to the Gluster alert runbook . ( TODO: Remounting Gluster should have its own runbook. )","title":"Ensure Gluster Mounts"},{"location":"realm_management/procedures/fs/#rebootrelaunch-fs-servers","text":"Reboot/Relaunch the FS servers: # Disable monitoring # Copy the variables so that another terminal can be used to disable monitoring echo -e \"{code:title=servers to be rebooted or relaunched} FS_SERVERS_CSV=${FS_SERVERS_CSV} {code}\" # Copy above section of output in the JIRA ticket that you are working # In a separate terminal, re-populate the 'FS_SERVERS_CSV' by copying it from the line above sv-mass-mondisable ${FS_SERVERS_CSV} # Reboot/Relaunch - FS # Generate reboot/relaunch commands that can be run in parallel. # You can run upto 15 workflows in parallel ahops-workflow-batching -b 20 -t fs -m ${REBOOT_OR_RELAUNCH} -s ${FS_SERVERS_CSV} # Use following if you need to upgrade OS as well ah-server bulk-${REBOOT_OR_RELAUNCH} ${UPGRADE_OS} --batch 64 ${FS_SERVERS[@]} --send-notifications false Note : In order to receive workflow failure notifications --send-notications false flag can be avoided. Also, if you are relaunching the servers to change the tenancy, use -e dedicated or -e default to set the required tenancy. For more information, please go through link https://runbook.ops.acquia.com/master/kanban_tickets/dedicated_hypervisor/ For larger regions this may take some time. Monitor the progress of each workflow with: WORKFLOW_ID= watch -n 30 \"ah-workflow watch-queue ${WORKFLOW_ID}\" Please make sure to remount each fs node after the reboot/relaunch: sv-fsremount ${FS_NODES} |& grep -Ei 'fail|error|warn|status:[^0]$' For servers that do not remount cleanly, try a second remount. Otherwise, cron jobs or shell sessions may need to be killed. Refer to the Gluster alert runbook . ( TODO: Remounting Gluster should have its own runbook. ) Enable Monitoring # Cancel the script that you ran in 'Disable monitoring' step above # Check that services are ok on all rebooted servers and fix any broken services on server/s # Re-enable monitoring on all servers # Repopulate 'FS_SERVERS_CSV' by copying name and value for the variable from 'Disable monitoring' step above ah-server edit ${FS_SERVERS_CSV} --no-config-tasks -s monitoring_status=2","title":"Reboot/Relaunch FS Servers"},{"location":"realm_management/procedures/fs/#cleanup","text":"Verify that all affected servers can reach their gluster volumes: fpdsh -l ${FS_NODES} -c '(ls /mnt/gfs/home > /dev/null 2>&1 ) || echo \"Failed\"'; Remount gluster on any servers that fail.","title":"Cleanup"},{"location":"realm_management/procedures/fs/#workflow-errors","text":"If ah-server bulk-relaunch workflow fails, please investigate the error using: ah-workflow get ${WORKFLOW_ID} --show-logs Check any failed tasks using: ah-task get ${TASK_ID} If you cannot fix it, escalate appropriately. Make sure to include all output from ah-workflow watch-queue in Jira.","title":"Workflow errors"},{"location":"realm_management/procedures/manual_databases/","text":"Databases (dbmaster, ded, fsdb) Summary This document covers relaunching ded and fsdb hosts. For fsdbmesh and dbmesh hosts, please reference the Tungsten Database Servers doc. Only passive DB servers should be reboot or relaunched to reduce downtime, so this procedure involves checking replication, failing over, and locking failover. Create a list of all the database servers for the specified region. REGION= ah-server list % \\ -w status=0 typeINded,fsdb,dbmaster ec2_region=${REGION} \"name IN ${SERVERS}\" \\ | sort > ${OPSTMP}/all_dbs Check for replication lag. fpdsh -l $(paste -sd, < ${OPSTMP}/all_dbs) \\ -c \"sudo ruby -e 'require \\\"aq\\\"; \\ s=Aq::Hosting::Server.from_local(); \\ puts s.services.mysql.heartbeat_info.lag_max'\" If there is any replication lag (more than a few seconds), resolve it, or remove both servers in the lagging cluster from ${OPSTMP}/all_dbs . Find all the active and passive database servers after making sure nothing in your region is currently failed over to the passive. If any database clusters are failed over you will have to investigate as to why and either correct the situation or remove them from the list. REGION_DNS_SERVER=($(ah-server list dns-% -w ec2_region=$REGION)) dns-fix ${REGION_DNS_SERVER} eval $(sv-dbprisec $(paste -sd, ${OPSTMP}/all_dbs)) Create an active and passive file echo ${PRIMARY_DBS[@]} > ${OPSTMP}/active_dbs echo ${SECONDARY_DBS[@]} > ${OPSTMP}/passive_dbs Check for locked DB clusters. sv-dbislocked $(paste -sd, ${OPSTMP}/active_dbs) Unlock any unintentionally locked DB clusters with ah-db-cluster unlock . If any DB clusters are intentionally locked and should not be unlocked, remove them from your lists. Lock all the DB clusters. ah-db-cluster parallel-lock ${PRIMARY_DBS[@]} Reboot or Relaunch passive database servers. sv-taskrelaunch server -a ${REBOOT_OR_RELAUNCH} -s 32 \\ -m 1 $(paste -sd' ' $OPSTMP/passive_dbs) Remount Gluster. for i in $(cat ${OPSTMP}/active_dbs); do site-fsremount $(ah-site list on:$i | head -1) done Wait for replication on all the passive database servers to catch up. fpdsh -l $(paste -sd, < ${OPSTMP}/all_dbs) \\ -c \"sudo ruby -e 'require \\\"aq\\\"; \\ s=Aq::Hosting::Server.from_local(); \\ puts s.services.mysql.heartbeat_info.lag_max'\" Unlock the DB clusters you had previously locked. ah-db-cluster parallel-unlock ${PRIMARY_DBS[@]} Fail over all of the databases. ah-db-cluster parallel-failover-to --no-unlock --batch-size=64 ${SECONDARY_DBS[@]} Reboot the primary (failed-away-from) database servers. sv-taskrelaunch server -a ${REBOOT_OR_RELAUNCH} -s 32 \\ -m 1 $(paste -sd' ' ${OPSTMP}/active_dbs) Remount Gluster. for i in $(cat ${OPSTMP}/active_dbs); do site-fsremount $(ah-site list on:$i | head -1) done Wait for replication on all the passive database servers to catch up. fpdsh -l $(paste -sd, < ${OPSTMP}/all_dbs) \\ -c \"sudo ruby -e 'require \\\"aq\\\"; \\ s=Aq::Hosting::Server.from_local(); \\ puts s.services.mysql.heartbeat_info.lag_max'\" Unlock the DB clusters you had previously locked. ah-db-cluster parallel-unlock ${SECONDARY_DBS[@]} Fail the database cluster back to the primary database servers. ah-db-cluster parallel-failover-to -u --batch-size=64 ${PRIMARY_DBS[@]} Check that all database clusters are are unlocked and all database servers in your Region are on the master database server. Clean up any incorrect database clusters as needed. REGION_DNS_SERVER=($(ah-server list dns-% -w ec2_region=$REGION)) dns-fix ${REGION_DNS_SERVER} sv-dbislocked $(paste -sd, ${OPSTMP}/all_dbs)","title":"Databases (dbmaster, ded, fsdb)"},{"location":"realm_management/procedures/manual_databases/#databases-dbmaster-ded-fsdb","text":"","title":"Databases (dbmaster, ded, fsdb)"},{"location":"realm_management/procedures/manual_databases/#summary","text":"This document covers relaunching ded and fsdb hosts. For fsdbmesh and dbmesh hosts, please reference the Tungsten Database Servers doc. Only passive DB servers should be reboot or relaunched to reduce downtime, so this procedure involves checking replication, failing over, and locking failover. Create a list of all the database servers for the specified region. REGION= ah-server list % \\ -w status=0 typeINded,fsdb,dbmaster ec2_region=${REGION} \"name IN ${SERVERS}\" \\ | sort > ${OPSTMP}/all_dbs Check for replication lag. fpdsh -l $(paste -sd, < ${OPSTMP}/all_dbs) \\ -c \"sudo ruby -e 'require \\\"aq\\\"; \\ s=Aq::Hosting::Server.from_local(); \\ puts s.services.mysql.heartbeat_info.lag_max'\" If there is any replication lag (more than a few seconds), resolve it, or remove both servers in the lagging cluster from ${OPSTMP}/all_dbs . Find all the active and passive database servers after making sure nothing in your region is currently failed over to the passive. If any database clusters are failed over you will have to investigate as to why and either correct the situation or remove them from the list. REGION_DNS_SERVER=($(ah-server list dns-% -w ec2_region=$REGION)) dns-fix ${REGION_DNS_SERVER} eval $(sv-dbprisec $(paste -sd, ${OPSTMP}/all_dbs)) Create an active and passive file echo ${PRIMARY_DBS[@]} > ${OPSTMP}/active_dbs echo ${SECONDARY_DBS[@]} > ${OPSTMP}/passive_dbs Check for locked DB clusters. sv-dbislocked $(paste -sd, ${OPSTMP}/active_dbs) Unlock any unintentionally locked DB clusters with ah-db-cluster unlock . If any DB clusters are intentionally locked and should not be unlocked, remove them from your lists. Lock all the DB clusters. ah-db-cluster parallel-lock ${PRIMARY_DBS[@]} Reboot or Relaunch passive database servers. sv-taskrelaunch server -a ${REBOOT_OR_RELAUNCH} -s 32 \\ -m 1 $(paste -sd' ' $OPSTMP/passive_dbs) Remount Gluster. for i in $(cat ${OPSTMP}/active_dbs); do site-fsremount $(ah-site list on:$i | head -1) done Wait for replication on all the passive database servers to catch up. fpdsh -l $(paste -sd, < ${OPSTMP}/all_dbs) \\ -c \"sudo ruby -e 'require \\\"aq\\\"; \\ s=Aq::Hosting::Server.from_local(); \\ puts s.services.mysql.heartbeat_info.lag_max'\" Unlock the DB clusters you had previously locked. ah-db-cluster parallel-unlock ${PRIMARY_DBS[@]} Fail over all of the databases. ah-db-cluster parallel-failover-to --no-unlock --batch-size=64 ${SECONDARY_DBS[@]} Reboot the primary (failed-away-from) database servers. sv-taskrelaunch server -a ${REBOOT_OR_RELAUNCH} -s 32 \\ -m 1 $(paste -sd' ' ${OPSTMP}/active_dbs) Remount Gluster. for i in $(cat ${OPSTMP}/active_dbs); do site-fsremount $(ah-site list on:$i | head -1) done Wait for replication on all the passive database servers to catch up. fpdsh -l $(paste -sd, < ${OPSTMP}/all_dbs) \\ -c \"sudo ruby -e 'require \\\"aq\\\"; \\ s=Aq::Hosting::Server.from_local(); \\ puts s.services.mysql.heartbeat_info.lag_max'\" Unlock the DB clusters you had previously locked. ah-db-cluster parallel-unlock ${SECONDARY_DBS[@]} Fail the database cluster back to the primary database servers. ah-db-cluster parallel-failover-to -u --batch-size=64 ${PRIMARY_DBS[@]} Check that all database clusters are are unlocked and all database servers in your Region are on the master database server. Clean up any incorrect database clusters as needed. REGION_DNS_SERVER=($(ah-server list dns-% -w ec2_region=$REGION)) dns-fix ${REGION_DNS_SERVER} sv-dbislocked $(paste -sd, ${OPSTMP}/all_dbs)","title":"Summary"},{"location":"realm_management/procedures/manual_fs/","text":"Filesystem Server Mass Reboot/Relaunch - Manual Gluster has no concept of active servers, so there is no failover to perform. However, filesystems for all nodes across the site MUST be remounted after each reboot/relaunch. Preparation Set this variable to appropriately reboot or relaunch the databases: REBOOT_OR_RELAUNCH= # valid values: reboot,relaunch List all FS servers, their cluster IDs, and all nodes linked to those clusters: FS_SERVERS=($(ah-server list % -w \"name IN ${SERVERS}\" typeINfs | sort -V)) FS_SERVERS_CSV=$(array-csv ${FS_SERVERS[@]}) FS_CLUSTERS=$(ah-server list ${FS_SERVERS_CSV} --no-name -c fs_cluster_id | paste -sd,) FS_NODES=$(ah-server list % -w status=0 \"fs_cluster_id IN ${FS_CLUSTERS}\" | paste -sd,) Ensure Gluster Mounts Ensure hosts and iptables configs are correct on all FS nodes, then remount gluster in case any of them are only connected to the servers you are about to reboot/relaunch: fpdsh -l ${FS_SERVERS_CSV} -c 'sudo ah-config-hosts; sudo ah-config-iptables' sv-fsremount ${FS_SERVERS_CSV} | egrep -i 'failed|error' Resolve all remount errors for every gluster node before continuing! Instances that fail to remount gluster will not have a stable file system and will cause alerts. For servers that do not remount cleanly, try a second remount. Otherwise, cron jobs or shell sessions may need to be killed. Refer to the Gluster alert runbook . ( TODO: Remounting Gluster should have its own runbook. ) Reboot/Relaunch FS Servers Seperate into two groups so that we donot reboot or relaunch both nodes of a cluster at once. FS_ARRAY_A=$(for i in \"${!FS_SERVERS[@]}\"; do ((i%2==0)) && printf \"%s,\" \"${FS_SERVERS[i]}\"; done | sed 's/,$//g') FS_ARRAY_B=$(for i in \"${!FS_SERVERS[@]}\"; do ((i%2==1)) && printf \"%s,\" \"${FS_SERVERS[i]}\"; done | sed 's/,$//g') Relaunch the first group. sv-taskrelaunch server -a ${REBOOT_OR_RELAUNCH} ${FS_ARRAY_A} Remount Gluster across the site after the first group finishes relaunching. Ensure Gluster is mounted correctly across the impacted fs_clusters . If it throws errors, resolve those before continuing. fpdsh -l ${FS_ARRAY_A} -c 'sudo ah-config-hosts; sudo ah-config-iptables' sv-fsremount ${FS_NODES} |& grep -Ei 'fail|error|warn|status:[^0]$' For servers that do not remount cleanly, try a second remount. Otherwise, cron jobs or shell sessions may need to be killed. Refer to the Gluster alert runbook . Once all Gluster mounts have remounted successfully, proceed with relaunching the next group of hosts. sv-taskrelaunch server -a ${REBOOT_OR_RELAUNCH} ${FS_ARRAY_B} Remount Gluster across the site after the first group finishes relaunching. Ensure Gluster is mounted correctly across the impacted fs_clusters . If it throws errors, resolve those before continuing. fpdsh -l ${FS_ARRAY_B} -c 'sudo ah-config-hosts; sudo ah-config-iptables' sv-fsremount ${FS_NODES} |& grep -Ei 'fail|error|warn|status:[^0]$' For servers that do not remount cleanly, try a second remount. Otherwise, cron jobs or shell sessions may need to be killed. Refer to the Gluster alert runbook . Cleanup Verify that all affected servers can reach their gluster volumes: fpdsh -l ${FS_SERVERS_CSV} -c '(ls /mnt/gfs/home > /dev/null 2>&1 ) || echo \"Failed\"'; Remount gluster on any servers that fail.","title":"Filesystem Server Mass Reboot/Relaunch - Manual"},{"location":"realm_management/procedures/manual_fs/#filesystem-server-mass-rebootrelaunch-manual","text":"Gluster has no concept of active servers, so there is no failover to perform. However, filesystems for all nodes across the site MUST be remounted after each reboot/relaunch.","title":"Filesystem Server Mass Reboot/Relaunch - Manual"},{"location":"realm_management/procedures/manual_fs/#preparation","text":"Set this variable to appropriately reboot or relaunch the databases: REBOOT_OR_RELAUNCH= # valid values: reboot,relaunch List all FS servers, their cluster IDs, and all nodes linked to those clusters: FS_SERVERS=($(ah-server list % -w \"name IN ${SERVERS}\" typeINfs | sort -V)) FS_SERVERS_CSV=$(array-csv ${FS_SERVERS[@]}) FS_CLUSTERS=$(ah-server list ${FS_SERVERS_CSV} --no-name -c fs_cluster_id | paste -sd,) FS_NODES=$(ah-server list % -w status=0 \"fs_cluster_id IN ${FS_CLUSTERS}\" | paste -sd,)","title":"Preparation"},{"location":"realm_management/procedures/manual_fs/#ensure-gluster-mounts","text":"Ensure hosts and iptables configs are correct on all FS nodes, then remount gluster in case any of them are only connected to the servers you are about to reboot/relaunch: fpdsh -l ${FS_SERVERS_CSV} -c 'sudo ah-config-hosts; sudo ah-config-iptables' sv-fsremount ${FS_SERVERS_CSV} | egrep -i 'failed|error' Resolve all remount errors for every gluster node before continuing! Instances that fail to remount gluster will not have a stable file system and will cause alerts. For servers that do not remount cleanly, try a second remount. Otherwise, cron jobs or shell sessions may need to be killed. Refer to the Gluster alert runbook . ( TODO: Remounting Gluster should have its own runbook. )","title":"Ensure Gluster Mounts"},{"location":"realm_management/procedures/manual_fs/#rebootrelaunch-fs-servers","text":"Seperate into two groups so that we donot reboot or relaunch both nodes of a cluster at once. FS_ARRAY_A=$(for i in \"${!FS_SERVERS[@]}\"; do ((i%2==0)) && printf \"%s,\" \"${FS_SERVERS[i]}\"; done | sed 's/,$//g') FS_ARRAY_B=$(for i in \"${!FS_SERVERS[@]}\"; do ((i%2==1)) && printf \"%s,\" \"${FS_SERVERS[i]}\"; done | sed 's/,$//g') Relaunch the first group. sv-taskrelaunch server -a ${REBOOT_OR_RELAUNCH} ${FS_ARRAY_A} Remount Gluster across the site after the first group finishes relaunching. Ensure Gluster is mounted correctly across the impacted fs_clusters . If it throws errors, resolve those before continuing. fpdsh -l ${FS_ARRAY_A} -c 'sudo ah-config-hosts; sudo ah-config-iptables' sv-fsremount ${FS_NODES} |& grep -Ei 'fail|error|warn|status:[^0]$' For servers that do not remount cleanly, try a second remount. Otherwise, cron jobs or shell sessions may need to be killed. Refer to the Gluster alert runbook . Once all Gluster mounts have remounted successfully, proceed with relaunching the next group of hosts. sv-taskrelaunch server -a ${REBOOT_OR_RELAUNCH} ${FS_ARRAY_B} Remount Gluster across the site after the first group finishes relaunching. Ensure Gluster is mounted correctly across the impacted fs_clusters . If it throws errors, resolve those before continuing. fpdsh -l ${FS_ARRAY_B} -c 'sudo ah-config-hosts; sudo ah-config-iptables' sv-fsremount ${FS_NODES} |& grep -Ei 'fail|error|warn|status:[^0]$' For servers that do not remount cleanly, try a second remount. Otherwise, cron jobs or shell sessions may need to be killed. Refer to the Gluster alert runbook .","title":"Reboot/Relaunch FS Servers"},{"location":"realm_management/procedures/manual_fs/#cleanup","text":"Verify that all affected servers can reach their gluster volumes: fpdsh -l ${FS_SERVERS_CSV} -c '(ls /mnt/gfs/home > /dev/null 2>&1 ) || echo \"Failed\"'; Remount gluster on any servers that fail.","title":"Cleanup"},{"location":"realm_management/procedures/manual_webs/","text":"Manual Reboot or Relaunch Webs( api , web ) Reboot zone-by-zone. Procedure - Web Get the the list of zones on the region. REGION= AZS=$(aws ec2 describe-availability-zones --region ${REGION} \\ --output text | awk {'print $4'} | paste -sd' ') WEBS=$(ah-server list % -w status=0 \"name IN ${SERVERS}\" typeINweb,api | paste -sd,) Choose a zone and get the list for reboot. AZ=${REGION}-a,b,c,d,e WEB_BATCH=$(ah-server list % -w \"name IN ${WEBS}\" ec2_availability_zone=$AZ | paste -sd,) sv-taskrelaunch server -a ${REBOOT_OR_RELAUNCH} -m 1 -s 64 ${WEB_BATCH} Clean up sv-fsremount ${WEB_BATCH} fpdsh -l ${WEB_BATCH} -c 'sudo fields-config-web.php' Repeat over all AZs for a given ${REGION}.","title":"Manual Reboot or Relaunch Webs(`api`, `web`)"},{"location":"realm_management/procedures/manual_webs/#manual-reboot-or-relaunch-websapi-web","text":"Reboot zone-by-zone.","title":"Manual Reboot or Relaunch Webs(api, web)"},{"location":"realm_management/procedures/manual_webs/#procedure-web","text":"Get the the list of zones on the region. REGION= AZS=$(aws ec2 describe-availability-zones --region ${REGION} \\ --output text | awk {'print $4'} | paste -sd' ') WEBS=$(ah-server list % -w status=0 \"name IN ${SERVERS}\" typeINweb,api | paste -sd,) Choose a zone and get the list for reboot. AZ=${REGION}-a,b,c,d,e WEB_BATCH=$(ah-server list % -w \"name IN ${WEBS}\" ec2_availability_zone=$AZ | paste -sd,) sv-taskrelaunch server -a ${REBOOT_OR_RELAUNCH} -m 1 -s 64 ${WEB_BATCH} Clean up sv-fsremount ${WEB_BATCH} fpdsh -l ${WEB_BATCH} -c 'sudo fields-config-web.php' Repeat over all AZs for a given ${REGION}.","title":"Procedure - Web"},{"location":"realm_management/procedures/non_ha/","text":"Customer Non-HA Servers ( free , srv , staging , api ) Non-HA servers include free , srv , staging , and api instances and can be safely rebooted. We will treat api servers as Non-HA but force a batch size of 1 for uptime. Reboot or Relaunch 'free' servers FREE=($(ah-server list % -w \"name IN ${SERVERS}\" typeINfree | sort -V)) FREE_CSV=$(array-csv ${FREE[@]}) Disable monitoring and copy the variables so that another terminal can be used to disable monitoring echo -e \"{code:title=servers to be rebooted or relaunched} FREE_CSV=${FREE_CSV} {code}\" Copy above section of output in the JIRA ticket that you are working. In a separate terminal, re-populate the 'FREE_CSV' by copying it from the line above sv-mass-mondisable ${FREE_CSV} Start reboot/relaunch workflow ah-server bulk-${REBOOT_OR_RELAUNCH} --batch 64 ${FREE[@]} --send-notifications false Re-enable Monitoring : This to be done after all workflows above for 'free' servers have completed. Cancel the script that you ran in 'Disable monitoring' step above. Check that services are ok on all rebooted servers and fix any broken services on server/s. Re-enable monitoring on all servers. Repopulate 'FREE_CSV' by copying name and value for the variable from 'Disable monitoring' step above ah-server edit ${FREE_CSV} --no-config-tasks -s monitoring_status=2 Reboot or Relaunch 'srv' servers SRV=($(ah-server list % -w \"name IN ${SERVERS}\" typeINsrv | sort -V)) SRV_CSV=$(array-csv ${SRV[@]}) Disable monitoring and copy the variables so that another terminal can be used to disable monitoring echo -e \"{code:title=servers to be rebooted or relaunched} SRV_CSV=${SRV_CSV} {code}\" Copy above section of output in the JIRA ticket that you are working In a separate terminal, re-populate the 'SRV_CSV' by copying it from the line above sv-mass-mondisable ${SRV_CSV} Start reboot/relaunch workflow ah-server bulk-${REBOOT_OR_RELAUNCH} --batch 64 ${SRV[@]} --send-notifications false Re-enable Monitoring : This to be done after all workflows above for 'srv' servers have completed. Cancel the script that you ran in 'Disable monitoring' step above. Check that services are ok on all rebooted servers and fix any broken services on server/s. Re-enable monitoring on all servers. Repopulate 'SRV_CSV' by copying name and value for the variable from 'Disable monitoring' step above ah-server edit ${SRV_CSV} --no-config-tasks -s monitoring_status=2 Reboot or Relaunch 'api' servers API=($(ah-server list % -w \"name IN ${SERVERS}\" typeINapi | sort -V)) API_CSV=$(array-csv ${API[@]}) Disable monitoring and copy the variables so that another terminal can be used to disable monitoring echo -e \"{code:title=servers to be rebooted or relaunched} API_CSV=${API_CSV} {code}\" Copy above section of output in the JIRA ticket that you are working In a separate terminal, re-populate the 'API_CSV' by copying it from the line above sv-mass-mondisable ${API_CSV} Start reboot/relaunch wrofklow/s ah-server bulk-${REBOOT_OR_RELAUNCH} --batch 1 ${API[@]} --send-notifications false Re-enable Monitoring : This to be done after all workflows above for 'api' servers have completed Cancel the script that you ran in 'Disable monitoring' step above Check that services are ok on all rebooted servers and fix any broken services on server/s Re-enable monitoring on all servers Repopulate 'API_CSV' by copying name and value for the variable from 'Disable monitoring' step above ah-server edit ${API_CSV} --no-config-tasks -s monitoring_status=2 Reboot or Relaunch 'staging' servers STG=($(ah-server list % -w \"name IN ${SERVERS}\" typeINstaging | sort -V)) STG_CSV=$(array-csv ${STG[@]}) Disable Monitoring and copy the variables so that another terminal can be used to disable monitoring echo -e \"{code:title=servers to be rebooted or relaunched} STG_CSV=${STG_CSV} {code}\" Copy above section of output in the JIRA ticket that you are working In a separate terminal, re-populate the 'STG_CSV' by copying it from the line above sv-mass-mondisable ${STG_CSV} Generate reboot/relaunch commands that can be run in parallel. You can run upto 15 workflows in parallel ahops-workflow-batching -b 20 -t staging -m ${REBOOT_OR_RELAUNCH} -s ${STG_CSV} Re-enable Monitoring : This to be done after all workflows above for 'staging' servers have completed Cancel the script that you ran in 'Disable monitoring' step above Check that services are ok on all rebooted servers and fix any broken services on server/s Re-enable monitoring on all servers Repopulate 'STG_CSV' by copying name and value for the variable from 'Disable monitoring' step above ah-server edit ${STG_CSV} --no-config-tasks -s monitoring_status=2 Note : In order to receive workflow failure notifications --send-notications false flag can be avoided. Also, if you are relaunching the servers to change the tenancy, use -e dedicated or -e default to set the required tenancy. For more information, please go through link https://runbook.ops.acquia.com/master/kanban_tickets/dedicated_hypervisor/ Ensure Gluster FS volumes are mounted after reboot : for server in ${STG[@]}; do site-fsremount $(ah-site list on:$server | head -1); done Resolve any servers that fail to mount gluster.","title":"Customer Non-HA Servers (`free`, `srv`, `staging`, `api`)"},{"location":"realm_management/procedures/non_ha/#customer-non-ha-servers-free-srv-staging-api","text":"Non-HA servers include free , srv , staging , and api instances and can be safely rebooted. We will treat api servers as Non-HA but force a batch size of 1 for uptime.","title":"Customer Non-HA Servers (free, srv, staging, api)"},{"location":"realm_management/procedures/non_ha/#reboot-or-relaunch-free-servers","text":"FREE=($(ah-server list % -w \"name IN ${SERVERS}\" typeINfree | sort -V)) FREE_CSV=$(array-csv ${FREE[@]}) Disable monitoring and copy the variables so that another terminal can be used to disable monitoring echo -e \"{code:title=servers to be rebooted or relaunched} FREE_CSV=${FREE_CSV} {code}\" Copy above section of output in the JIRA ticket that you are working. In a separate terminal, re-populate the 'FREE_CSV' by copying it from the line above sv-mass-mondisable ${FREE_CSV} Start reboot/relaunch workflow ah-server bulk-${REBOOT_OR_RELAUNCH} --batch 64 ${FREE[@]} --send-notifications false Re-enable Monitoring : This to be done after all workflows above for 'free' servers have completed. Cancel the script that you ran in 'Disable monitoring' step above. Check that services are ok on all rebooted servers and fix any broken services on server/s. Re-enable monitoring on all servers. Repopulate 'FREE_CSV' by copying name and value for the variable from 'Disable monitoring' step above ah-server edit ${FREE_CSV} --no-config-tasks -s monitoring_status=2","title":"Reboot or Relaunch 'free' servers"},{"location":"realm_management/procedures/non_ha/#reboot-or-relaunch-srv-servers","text":"SRV=($(ah-server list % -w \"name IN ${SERVERS}\" typeINsrv | sort -V)) SRV_CSV=$(array-csv ${SRV[@]}) Disable monitoring and copy the variables so that another terminal can be used to disable monitoring echo -e \"{code:title=servers to be rebooted or relaunched} SRV_CSV=${SRV_CSV} {code}\" Copy above section of output in the JIRA ticket that you are working In a separate terminal, re-populate the 'SRV_CSV' by copying it from the line above sv-mass-mondisable ${SRV_CSV} Start reboot/relaunch workflow ah-server bulk-${REBOOT_OR_RELAUNCH} --batch 64 ${SRV[@]} --send-notifications false Re-enable Monitoring : This to be done after all workflows above for 'srv' servers have completed. Cancel the script that you ran in 'Disable monitoring' step above. Check that services are ok on all rebooted servers and fix any broken services on server/s. Re-enable monitoring on all servers. Repopulate 'SRV_CSV' by copying name and value for the variable from 'Disable monitoring' step above ah-server edit ${SRV_CSV} --no-config-tasks -s monitoring_status=2","title":"Reboot or Relaunch 'srv' servers"},{"location":"realm_management/procedures/non_ha/#reboot-or-relaunch-api-servers","text":"API=($(ah-server list % -w \"name IN ${SERVERS}\" typeINapi | sort -V)) API_CSV=$(array-csv ${API[@]}) Disable monitoring and copy the variables so that another terminal can be used to disable monitoring echo -e \"{code:title=servers to be rebooted or relaunched} API_CSV=${API_CSV} {code}\" Copy above section of output in the JIRA ticket that you are working In a separate terminal, re-populate the 'API_CSV' by copying it from the line above sv-mass-mondisable ${API_CSV} Start reboot/relaunch wrofklow/s ah-server bulk-${REBOOT_OR_RELAUNCH} --batch 1 ${API[@]} --send-notifications false Re-enable Monitoring : This to be done after all workflows above for 'api' servers have completed Cancel the script that you ran in 'Disable monitoring' step above Check that services are ok on all rebooted servers and fix any broken services on server/s Re-enable monitoring on all servers Repopulate 'API_CSV' by copying name and value for the variable from 'Disable monitoring' step above ah-server edit ${API_CSV} --no-config-tasks -s monitoring_status=2","title":"Reboot or Relaunch 'api' servers"},{"location":"realm_management/procedures/non_ha/#reboot-or-relaunch-staging-servers","text":"STG=($(ah-server list % -w \"name IN ${SERVERS}\" typeINstaging | sort -V)) STG_CSV=$(array-csv ${STG[@]}) Disable Monitoring and copy the variables so that another terminal can be used to disable monitoring echo -e \"{code:title=servers to be rebooted or relaunched} STG_CSV=${STG_CSV} {code}\" Copy above section of output in the JIRA ticket that you are working In a separate terminal, re-populate the 'STG_CSV' by copying it from the line above sv-mass-mondisable ${STG_CSV} Generate reboot/relaunch commands that can be run in parallel. You can run upto 15 workflows in parallel ahops-workflow-batching -b 20 -t staging -m ${REBOOT_OR_RELAUNCH} -s ${STG_CSV} Re-enable Monitoring : This to be done after all workflows above for 'staging' servers have completed Cancel the script that you ran in 'Disable monitoring' step above Check that services are ok on all rebooted servers and fix any broken services on server/s Re-enable monitoring on all servers Repopulate 'STG_CSV' by copying name and value for the variable from 'Disable monitoring' step above ah-server edit ${STG_CSV} --no-config-tasks -s monitoring_status=2 Note : In order to receive workflow failure notifications --send-notications false flag can be avoided. Also, if you are relaunching the servers to change the tenancy, use -e dedicated or -e default to set the required tenancy. For more information, please go through link https://runbook.ops.acquia.com/master/kanban_tickets/dedicated_hypervisor/ Ensure Gluster FS volumes are mounted after reboot : for server in ${STG[@]}; do site-fsremount $(ah-site list on:$server | head -1); done Resolve any servers that fail to mount gluster.","title":"Reboot or Relaunch 'staging' servers"},{"location":"realm_management/procedures/reboot_node_servers/","text":"Rebooting node/nodebal servers Reboot the node/nodebal servers is not yet automated through workflows so we need to use either a task based reboot or manual reboot. Node server reboot Since workflows are not supported yet, we need to reboot servers using ah-server command. While doing mass activity, reboot the servers AZ wise as Node.js service has HA architecture support. Reboot the servers by AZ using the following command: REGION= ## Should be in maintenance ticket N=0 for AZ in $(ah-server list % -w typeINnode status=0 ec2_region=$REGION -c ec2_availability_zone | awk '{print $2}' | sort | uniq);do declare -i N=$((N+1));echo \"Rebooting BATCH-$N: $AZ\";ah-server reboot-task $(ah-server list % -w typeINnode status=0 ec2_availability_zone=$AZ | paste -sd,);echo; done Verify all servers are up and running: fpdsh -l $SERVERS -c uptime sv-checkservices $SERVERS Perform the same activity for other batches one by one for each AZ. Nodebal reboot For nodebal reboots, we need to reboot passive nodebals i.e. without EIP and then perform failover and reboot the other ones Get the list of passive bals from a region: REGION= #Get the value from ticket PASSIVE_BALS=$(ah-server list % -w typeINnodebal ec2_region=$REGION status=0 eip_id=nil | paste -sd,) Reboot the servers: ah-server reboot-task $PASSIVE_BALS Verify all servers are up and running: fpdsh -l $PASSIVE_BALS -c uptime sv-checkservices $PASSIVE_BALS Once passive bals are rebooted, fetch the EIP's to failover using the following command: ah-server list % -w typeINnodebal ec2_region=$REGION status=0 eip_id=!nil -c external_ip | awk '{print $2}' | xargs -P 10 -n1 ah-elastic-ip failover Keep an eye on the EIP failover tasks and escalate to Cloud if any task fails. Once failover completes, reboot the now passive bals REGION= #Get the value from ticket PASSIVE_BALS=$(ah-server list % -w typeINnodebal ec2_region=$REGION status=0 eip_id=nil | paste -sd,) ah-server reboot-task $PASSIVE_BALS Verify all servers are up and running: fpdsh -l $PASSIVE_BALS -c uptime sv-checkservices $PASSIVE_BALS If you face any issue with rebooting node/nodebal servers - escalate to Node.js team using the ops-portal and select the component as Node.JS Hosting. For critical escalations take approval from Ops managers as per SOP.","title":"Rebooting node/nodebal servers"},{"location":"realm_management/procedures/reboot_node_servers/#rebooting-nodenodebal-servers","text":"Reboot the node/nodebal servers is not yet automated through workflows so we need to use either a task based reboot or manual reboot.","title":"Rebooting node/nodebal servers"},{"location":"realm_management/procedures/reboot_node_servers/#node-server-reboot","text":"Since workflows are not supported yet, we need to reboot servers using ah-server command. While doing mass activity, reboot the servers AZ wise as Node.js service has HA architecture support. Reboot the servers by AZ using the following command: REGION= ## Should be in maintenance ticket N=0 for AZ in $(ah-server list % -w typeINnode status=0 ec2_region=$REGION -c ec2_availability_zone | awk '{print $2}' | sort | uniq);do declare -i N=$((N+1));echo \"Rebooting BATCH-$N: $AZ\";ah-server reboot-task $(ah-server list % -w typeINnode status=0 ec2_availability_zone=$AZ | paste -sd,);echo; done Verify all servers are up and running: fpdsh -l $SERVERS -c uptime sv-checkservices $SERVERS Perform the same activity for other batches one by one for each AZ.","title":"Node server reboot"},{"location":"realm_management/procedures/reboot_node_servers/#nodebal-reboot","text":"For nodebal reboots, we need to reboot passive nodebals i.e. without EIP and then perform failover and reboot the other ones Get the list of passive bals from a region: REGION= #Get the value from ticket PASSIVE_BALS=$(ah-server list % -w typeINnodebal ec2_region=$REGION status=0 eip_id=nil | paste -sd,) Reboot the servers: ah-server reboot-task $PASSIVE_BALS Verify all servers are up and running: fpdsh -l $PASSIVE_BALS -c uptime sv-checkservices $PASSIVE_BALS Once passive bals are rebooted, fetch the EIP's to failover using the following command: ah-server list % -w typeINnodebal ec2_region=$REGION status=0 eip_id=!nil -c external_ip | awk '{print $2}' | xargs -P 10 -n1 ah-elastic-ip failover Keep an eye on the EIP failover tasks and escalate to Cloud if any task fails. Once failover completes, reboot the now passive bals REGION= #Get the value from ticket PASSIVE_BALS=$(ah-server list % -w typeINnodebal ec2_region=$REGION status=0 eip_id=nil | paste -sd,) ah-server reboot-task $PASSIVE_BALS Verify all servers are up and running: fpdsh -l $PASSIVE_BALS -c uptime sv-checkservices $PASSIVE_BALS If you face any issue with rebooting node/nodebal servers - escalate to Node.js team using the ops-portal and select the component as Node.JS Hosting. For critical escalations take approval from Ops managers as per SOP.","title":"Nodebal reboot"},{"location":"realm_management/procedures/relaunch_node_servers/","text":"Relaunching node/nodebal servers Relaunching the node/nodebal servers is not yet automated through workflows so we need to use either a task based relaunch or manual relaunch. If we have to perform mass relaunch activity such as upgrading OS versions - do not relaunch all servers at once as that will take down the service. Node server relaunch Since workflows are not supported yet, we need to relaunch servers using ah-server or sv-taskrelaunch . While doing mass activity, relaunch the servers AZ wise as Node.js service has HA architecture support. Create a batch using the command given below and make sure to run them one at a time REGION= ## Should be in maintenance ticket N=0 for AZ in $(ah-server list % -w typeINnode status=0 ec2_region=$REGION -c ec2_availability_zone | awk '{print $2}' | sort | uniq);do declare -i N=$((N+1));echo \"BATCH-$N: $AZ\";ah-server list % -w typeINnode status=0 ec2_availability_zone=$AZ | paste -sd,;echo; done Relaunch each batch one by one using the following command: SERVERS= #Set the value received from above command ah-server relaunch $SERVERS Verify all servers are up and running: fpdsh -l $SERVERS -c uptime sv-checkservices $SERVERS Perform the same activity one by one for each AZ. Nodebal relaunches For nodebal relaunches, we need to relaunch passive nodebals i.e. without EIP and then perform failover and relaunch the other ones Get the list of passive bals from a region: REGION= #Get the value from ticket PASSIVE_BALS=$(ah-server list % -w typeINnodebal ec2_region=$REGION status=0 eip_id=nil | paste -sd,) Relaunch the servers: ah-server relaunch $PASSIVE_BALS Verify all servers are up and running: fpdsh -l $PASSIVE_BALS -c uptime sv-checkservices $PASSIVE_BALS Once passive bals are relaunched, fetch the EIP's to failover using the following command: ah-server list % -w typeINnodebal ec2_region=$REGION status=0 eip_id=!nil -c external_ip | awk '{print $2}' | xargs -P 10 -n1 ah-elastic-ip failover Once failover completes, relaunch the now passive bals REGION= #Get the value from ticket PASSIVE_BALS=$(ah-server list % -w typeINnodebal ec2_region=$REGION status=0 eip_id=nil | paste -sd,) Verify all servers are up and running: fpdsh -l $PASSIVE_BALS -c uptime sv-checkservices $PASSIVE_BALS If you face any issue with relaunching node/nodebal servers - escalate to Node.js team using the ops-portal and select the component as Node.JS Hosting. For critical escalations take approval from Ops managers as per SOP.","title":"Relaunching node/nodebal servers"},{"location":"realm_management/procedures/relaunch_node_servers/#relaunching-nodenodebal-servers","text":"Relaunching the node/nodebal servers is not yet automated through workflows so we need to use either a task based relaunch or manual relaunch. If we have to perform mass relaunch activity such as upgrading OS versions - do not relaunch all servers at once as that will take down the service.","title":"Relaunching node/nodebal servers"},{"location":"realm_management/procedures/relaunch_node_servers/#node-server-relaunch","text":"Since workflows are not supported yet, we need to relaunch servers using ah-server or sv-taskrelaunch . While doing mass activity, relaunch the servers AZ wise as Node.js service has HA architecture support. Create a batch using the command given below and make sure to run them one at a time REGION= ## Should be in maintenance ticket N=0 for AZ in $(ah-server list % -w typeINnode status=0 ec2_region=$REGION -c ec2_availability_zone | awk '{print $2}' | sort | uniq);do declare -i N=$((N+1));echo \"BATCH-$N: $AZ\";ah-server list % -w typeINnode status=0 ec2_availability_zone=$AZ | paste -sd,;echo; done Relaunch each batch one by one using the following command: SERVERS= #Set the value received from above command ah-server relaunch $SERVERS Verify all servers are up and running: fpdsh -l $SERVERS -c uptime sv-checkservices $SERVERS Perform the same activity one by one for each AZ.","title":"Node server relaunch"},{"location":"realm_management/procedures/relaunch_node_servers/#nodebal-relaunches","text":"For nodebal relaunches, we need to relaunch passive nodebals i.e. without EIP and then perform failover and relaunch the other ones Get the list of passive bals from a region: REGION= #Get the value from ticket PASSIVE_BALS=$(ah-server list % -w typeINnodebal ec2_region=$REGION status=0 eip_id=nil | paste -sd,) Relaunch the servers: ah-server relaunch $PASSIVE_BALS Verify all servers are up and running: fpdsh -l $PASSIVE_BALS -c uptime sv-checkservices $PASSIVE_BALS Once passive bals are relaunched, fetch the EIP's to failover using the following command: ah-server list % -w typeINnodebal ec2_region=$REGION status=0 eip_id=!nil -c external_ip | awk '{print $2}' | xargs -P 10 -n1 ah-elastic-ip failover Once failover completes, relaunch the now passive bals REGION= #Get the value from ticket PASSIVE_BALS=$(ah-server list % -w typeINnodebal ec2_region=$REGION status=0 eip_id=nil | paste -sd,) Verify all servers are up and running: fpdsh -l $PASSIVE_BALS -c uptime sv-checkservices $PASSIVE_BALS If you face any issue with relaunching node/nodebal servers - escalate to Node.js team using the ops-portal and select the component as Node.JS Hosting. For critical escalations take approval from Ops managers as per SOP.","title":"Nodebal relaunches"},{"location":"realm_management/procedures/task/","text":"Task Servers Task servers must be handled with care so as not to break a customer's or other's initiated task. Caution and time must be taken to ensure that the task service is stopped and that all running tasks are allowed to complete first. Because of the impact to rebooting task servers we send customer facing notification to 1) hope that customers don't initiate tasks during the named window and 2) so we have recourse for the occasions where we must kill tasks and reboot servers. Prerequisites See preparation steps in parent . Procedure Task servers must be rebooted in a staged process. Set some variables: REBOOT_OR_RELAUNCH= # valid values: reboot,relaunch TASK_SERVERS=( $(ah-server list $SERVERS -w type=task status=0) ) TASK_SERVERS_CSV=$(array-csv ${TASK_SERVERS[@]}) Disable puppet, stop cron and the task service. fpdsh -l ${TASK_SERVERS_CSV} \\ -c \"sudo puppet agent --disable '${OP} ${USER} mass rebooting' \\ && sudo service cron stop \\ && sudo service ah-task-server stop\" OR in Masterless Puppet mode fpdsh -l ${TASK_SERVERS_CSV} \\ -c \"sudo ah-puppet-disable '${OP} ${USER} mass rebooting' \\ && sudo service cron stop \\ && sudo service ah-task-server stop\" Wait for all tasks/backups to finish. OUTPUT=\"yolo\" until [[ -z ${OUTPUT} ]]; do OUTPUT=$(fpdsh -l ${TASK_SERVERS_CSV} -c \"sudo ps aux | grep '[a]h-callback.task' || true\") done Task server reboots will be scheduled for a specific window. If you are still waiting for tasks to complete up to 60 minutes before the window closes then you must take drastic action, and kill the offending tasks. Diagnose where the task came from to assess its legitimacy: ah-task get ${ID} --full-body If the task is customer initiated create a support ticket notifying them that the their task is about to be killed. They were notified of this maintenance, so should have planned around it. Kill the offending task: ah-task kill ${ID} Re-run the until loop above to ensure that the tasks have been properly killed. Reboot/Relaunch the task servers: for t in ${TASK_SERVERS[@]}; do ah-server ${REBOOT_OR_RELAUNCH} ${t} done If you are upgrading to Ubuntu Xenial 16.04, you may upgrade the task servers by adding this to the above for loop: ah-server edit ${t} -s os=xenial Re-enable puppet, and execute a test run fpdsh -l ${TASK_SERVERS_CSV} -c \"sudo puppet agent --enable && sudo puppet agent -t\" OR in Masterless Puppet mode fpdsh -l ${TASK_SERVERS_CSV} -c \"sudo ah-puppet-enable && sudo run-puppet\"","title":"Task Servers"},{"location":"realm_management/procedures/task/#task-servers","text":"Task servers must be handled with care so as not to break a customer's or other's initiated task. Caution and time must be taken to ensure that the task service is stopped and that all running tasks are allowed to complete first. Because of the impact to rebooting task servers we send customer facing notification to 1) hope that customers don't initiate tasks during the named window and 2) so we have recourse for the occasions where we must kill tasks and reboot servers.","title":"Task Servers"},{"location":"realm_management/procedures/task/#prerequisites","text":"See preparation steps in parent .","title":"Prerequisites"},{"location":"realm_management/procedures/task/#procedure","text":"Task servers must be rebooted in a staged process. Set some variables: REBOOT_OR_RELAUNCH= # valid values: reboot,relaunch TASK_SERVERS=( $(ah-server list $SERVERS -w type=task status=0) ) TASK_SERVERS_CSV=$(array-csv ${TASK_SERVERS[@]}) Disable puppet, stop cron and the task service. fpdsh -l ${TASK_SERVERS_CSV} \\ -c \"sudo puppet agent --disable '${OP} ${USER} mass rebooting' \\ && sudo service cron stop \\ && sudo service ah-task-server stop\" OR in Masterless Puppet mode fpdsh -l ${TASK_SERVERS_CSV} \\ -c \"sudo ah-puppet-disable '${OP} ${USER} mass rebooting' \\ && sudo service cron stop \\ && sudo service ah-task-server stop\" Wait for all tasks/backups to finish. OUTPUT=\"yolo\" until [[ -z ${OUTPUT} ]]; do OUTPUT=$(fpdsh -l ${TASK_SERVERS_CSV} -c \"sudo ps aux | grep '[a]h-callback.task' || true\") done Task server reboots will be scheduled for a specific window. If you are still waiting for tasks to complete up to 60 minutes before the window closes then you must take drastic action, and kill the offending tasks. Diagnose where the task came from to assess its legitimacy: ah-task get ${ID} --full-body If the task is customer initiated create a support ticket notifying them that the their task is about to be killed. They were notified of this maintenance, so should have planned around it. Kill the offending task: ah-task kill ${ID} Re-run the until loop above to ensure that the tasks have been properly killed. Reboot/Relaunch the task servers: for t in ${TASK_SERVERS[@]}; do ah-server ${REBOOT_OR_RELAUNCH} ${t} done If you are upgrading to Ubuntu Xenial 16.04, you may upgrade the task servers by adding this to the above for loop: ah-server edit ${t} -s os=xenial Re-enable puppet, and execute a test run fpdsh -l ${TASK_SERVERS_CSV} -c \"sudo puppet agent --enable && sudo puppet agent -t\" OR in Masterless Puppet mode fpdsh -l ${TASK_SERVERS_CSV} -c \"sudo ah-puppet-enable && sudo run-puppet\"","title":"Procedure"},{"location":"realm_management/procedures/tungsten/","text":"Multiregion Database Mass Reboot/Relaunch Overview The procedure for mass rebooting multiregion databases is similar to that of standard databases, with some important caveats. Many of our current tools do not work correctly for multiregion databases, so many of these steps require extreme care before executing. Notably, it is more difficult to reliably distinguish between the primary and secondary databases. Additionally, it is important that only the active region databases are failed over during this procedure. Therefore, this runbook uses extra lists to keep track of these databases. TODO: Update this page to use ah-server bulk-relaunch/bulk-reboot when AUTO-1180 is released. Procedure Prepare lists of databases Reboot secondary DBs Failover to secondary DBs Reboot primary DBs Failover to primary DBs Cleanup and verify success Important Notes Ensure you have initialized SERVERS , REGION , and OP per the main mass reboot runbook . Ensure UPGRADE_OS is set only if you are relaunching to upgrade servers to Xenial, per the mass relaunch runbook ! If you use UPGRADE_OS , you must declare it as a full string. Otherwise, you can leave it undeclared or defined as the empty string to allow your relaunches to proceed without changing the OS. For example: UPGRADE_OS=\"\" UPGRADE_OS=\"-o xenial\" UPGRADE_OS will not work with reboot workflows! Do not abort workflows! If you are unable to resolve a problem with a workflow, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership Preparation Set this variable to appropriately reboot or relaunch the databases: REBOOT_OR_RELAUNCH= # valid values: reboot,relaunch Create a sorted list of all the database servers for the specified region: ah-server list % -w \"name IN ${SERVERS}\" typeINfsdbmesh,dbmesh | sort -V > ${OPSTMP}/all_mrdbs Check for replication lag: fpdsh -l $(paste -sd, ${OPSTMP}/all_mrdbs) \\ -c \"sudo ruby -e 'require \\\"aq\\\"; s=Aq::Hosting::Server.from_local; \\ puts s.services.mysql.heartbeat_info.lag_max'\" | awk '$2>1' If there is any replication lag (more than a few seconds), resolve it: MRDB= ah-db-cluster status ${MRDB} site-tungstatus $(ah-site list on:${MRDB}) site-tungstenslaveresync $(ah-site list on:${MRDB} If the lag cannot be resolved, remove all servers in the cluster from ${OPSTMP}/all_mrdbs and make a note in the OP that they will need special handholding. Split the server list into primary and secondary databases based on their ordering. It is important that ${OPSTMP}/all_mrdbs be sorted for this step to work correctly. awk 'NR % 2' ${OPSTMP}/all_mrdbs > ${OPSTMP}/all_pri_mrdbs awk 'NR % 2 == 0' ${OPSTMP}/all_mrdbs > ${OPSTMP}/all_sec_mrdbs Create some other server/site lists for later: for server in $(cat ${OPSTMP}/all_pri_mrdbs) ; do ah-site list on:${server} | head -1; done \\ | sort -u > ${OPSTMP}/all_mrdb_sites for site in $(cat ${OPSTMP}/all_mrdb_sites) ; do ah-server list site:${site} -w typeINdbmesh,fsdbmesh ; done \\ | sort -u > ${OPSTMP}/all_cluster_mrdbs List the true, active region primary and secondary databases: eval $(sv-dbprisec $(paste -sd, ${OPSTMP}/all_mrdbs)) printf \"%s\\n\" \"${PRIMARY_DBS[@]}\" > ${OPSTMP}/act_pri_mrdbs printf \"%s\\n\" \"${SECONDARY_DBS[@]}\" > ${OPSTMP}/act_sec_mrdbs NOTE: sv-dbprisec ignores databases in the passive region, but correctly identifies the primary databases in the active region. This runbook takes advantage of this feature in order to properly execute failovers. Verify that no active region databases are in the wrong list: comm -12 <(sort ${OPSTMP}/act_pri_mrdbs) <(sort ${OPSTMP}/all_sec_mrdbs) comm -12 <(sort ${OPSTMP}/act_sec_mrdbs) <(sort ${OPSTMP}/all_pri_mrdbs) WARNING: If there is any output, you should manually move the mis-listed database(s) from its current ${OPSTMP}/all_*_mrdbs file to the other. Failure to do so will cause downtime. Identify node servers that will need their gluster volumes to be remounted: MRFS_CLUSTERS=$(ah-server list $(paste -sd, ${OPSTMP}/all_pri_mrdbs) -w typeINfsdbmesh \\ --no-name -c fs_cluster_id | paste -sd,) ah-server list % -w status=0 \"fs_cluster_id IN ${MRFS_CLUSTERS}\" > ${OPSTMP}/mrfs_nodes Check for locked DB clusters: sv-dbislocked $(paste -sd, ${OPSTMP}/all_pri_mrdbs) Unlock any unintentionally locked DB clusters with ah-db-cluster unlock . If you find any DB clusters that should not be unlocked, remove them and their sites from your lists. Reboot Secondary Multiregion Databases Ensure hosts and iptables configs are correct on all FS nodes, then remount gluster in case any of them are only connected to the servers you are about to reboot/relaunch: fpdsh -l $(paste -sd, ${OPSTMP}/mrfs_nodes) -c 'sudo ah-config-hosts; sudo ah-config-iptables' for site in $(cat ${OPSTMP}/all_mrdb_sites); do site-fsremount $site | egrep -i 'failed|error'; done Resolve all remount errors for every gluster node before continuing! Instances that fail to remount gluster will not have a stable file system and will cause alerts. Lock all of the clusters to their primary DBs: < ${OPSTMP}/all_pri_mrdbs xargs -n1 -P20 -I{} ah-db-cluster lock {} Announce to the Ops hotseat in Operations chat that the secondary databases will be rebooted/relaunched. Downtime the MySQL Available alert for the primary DBs: < ${OPSTMP}/all_pri_mrdbs xargs -n1 -P20 \\ -I{} sv-downtimeservice {} 'Mysql Available' 60 \"${OP} - mass ${REBOOT_OR_RELAUNCH}\" Keep this command handy in case the process takes longer than 60 minutes to complete. Reboot/Relaunch the secondary database servers: Note: If you are upgrading to Xenial, ensure UPGRADE_OS=\"-o xenial\" and REBOOT_OR_RELAUNCH=relaunch . sv-taskrelaunch server -a ${REBOOT_OR_RELAUNCH} ${UPGRADE_OS} \\ -s 32 -m 1 $(paste -sd' ' ${OPSTMP}/all_sec_mrdbs) Failover to Secondary Multiregion Databases Remount gluster volumes: for site in $(cat ${OPSTMP}/all_mrdb_sites); do site-fsremount $site | egrep -i 'failed|error'; done Resolve all remount errors for every gluster node before continuing! Instances that fail to remount gluster will not have a stable file system and will cause alerts. Config iptables/hosts and run f-c-tungsten-peers: fpdsh -l $(paste -sd, ${OPSTMP}/all_cluster_mrdbs) \\ -c \"sudo ah-config-iptables; sudo ah-config-hosts\" fpdsh -l $(paste -sd, ${OPSTMP}/all_cluster_mrdbs) \\ -c \"sudo fields-config-tungsten-peers.php; sudo /etc/init.d/stunnel4 restart; sudo service treplicator restart\" Wait for replication to catch up: fpdsh -l $(paste -sd, ${OPSTMP}/all_mrdbs) \\ -c \"sudo ruby -e 'require \\\"aq\\\"; s=Aq::Hosting::Server.from_local; \\ puts s.services.mysql.heartbeat_info.lag_max'\" | awk '$2>1' If there are still errors, consult the instructions for missing peers . Unlock the clusters: < ${OPSTMP}/act_pri_mrdbs xargs -n1 -P20 -I{} ah-db-cluster unlock {} Downtime the MySQL Failover alert for the regional DNS server: DNS=$(ah-server list dns-% -w ec2_region=${REGION}) sv-downtimeservice ${DNS} 'MySQL Failover' 60 \"${OP} - mass ${REBOOT_OR_RELAUNCH}\" Keep this command handy. It may take longer than the allotted hour to complete all of the steps before you can unfailover the databases. Failover the active region clusters to the secondary DBs: sv-dbmultifailover $(paste -sd' ' ${OPSTMP}/act_sec_mrdbs) Reboot Primary Multiregion Databases Lock all of the clusters to their secondary DBs: < ${OPSTMP}/act_sec_mrdbs xargs -n1 -P20 -I{} ah-db-cluster lock {} Announce to the Ops hotseat in Operations chat that the primary databases will be rebooted/relaunched. Downtime the MySQL Available alert for the secondary DBs: < ${OPSTMP}/all_sec_mrdbs xargs -n1 -P20 \\ -I{} sv-downtimeservice {} 'Mysql Available' 60 \"${OP} - mass ${REBOOT_OR_RELAUNCH}\" Keep this command handy in case the process takes longer than 60 minutes to complete. Reboot/Relaunch the primary database servers: Note: If you are upgrading to Xenial, ensure UPGRADE_OS=\"-o xenial\" and REBOOT_OR_RELAUNCH=relaunch . sv-taskrelaunch server -a ${REBOOT_OR_RELAUNCH} ${UPGRADE_OS} \\ -s 32 -m 1 $(paste -sd' ' ${OPSTMP}/all_pri_mrdbs) Failover to Primary Multiregion Databases Remount gluster volumes: for site in $(cat ${OPSTMP}/all_mrdb_sites); do site-fsremount $site | egrep -i 'failed|error'; done Resolve all remount errors for every gluster node before continuing! Instances that fail to remount gluster will not have a stable file system and will cause alerts. Config iptables/hosts and run f-c-tungsten-peers: fpdsh -l $(paste -sd, ${OPSTMP}/all_cluster_mrdbs) \\ -c \"sudo ah-config-iptables; sudo ah-config-hosts\" fpdsh -l $(paste -sd, ${OPSTMP}/all_cluster_mrdbs) \\ -c \"sudo fields-config-tungsten-peers.php; sudo /etc/init.d/stunnel4 restart\" Wait for replication to catch up: fpdsh -l $(paste -sd, ${OPSTMP}/all_mrdbs) \\ -c \"sudo ruby -e 'require \\\"aq\\\"; s=Aq::Hosting::Server.from_local; \\ puts s.services.mysql.heartbeat_info.lag_max'\" | awk '$2>1' If there are still errors, consult the instructions for missing peers . Unlock the clusters: < ${OPSTMP}/all_sec_mrdbs xargs -n1 -P20 -I{} ah-db-cluster unlock {} Failover the active region clusters back to the primary databases: sv-dbmultifailover $(paste -sd' ' ${OPSTMP}/act_pri_mrdbs) Cleanup Verify that replication lag is ok for all databases: fpdsh -l $(paste -sd, ${OPSTMP}/all_mrdbs) \\ -c \"sudo ruby -e 'require \\\"aq\\\"; s=Aq::Hosting::Server.from_local; \\ puts s.services.mysql.heartbeat_info.lag_max'\" | awk '$2>1' Verify that all affected servers can reach their gluster volumes: fpdsh -l $(paste -sd, ${OPSTMP}/mrfs_nodes) -c '(ls /mnt/gfs/home > /dev/null 2>&1 ) || echo \"Failed\"' Remount gluster on any server that fails. If you suspect many of FS nodes failed to remount their gluster volumes, make a CSV list of the suspected nodes and remount their FS (try to be specific): NODES= sv-fsremount ${NODES} | egrep -i 'failed|error' If any databases were removed from this procedure, investigate why and manually reboot/relaunch them, if possible. If you cannot, escalate appropriately. Do not let them be forgotten!","title":"Multiregion Database Mass Reboot/Relaunch"},{"location":"realm_management/procedures/tungsten/#multiregion-database-mass-rebootrelaunch","text":"","title":"Multiregion Database Mass Reboot/Relaunch"},{"location":"realm_management/procedures/tungsten/#overview","text":"The procedure for mass rebooting multiregion databases is similar to that of standard databases, with some important caveats. Many of our current tools do not work correctly for multiregion databases, so many of these steps require extreme care before executing. Notably, it is more difficult to reliably distinguish between the primary and secondary databases. Additionally, it is important that only the active region databases are failed over during this procedure. Therefore, this runbook uses extra lists to keep track of these databases. TODO: Update this page to use ah-server bulk-relaunch/bulk-reboot when AUTO-1180 is released.","title":"Overview"},{"location":"realm_management/procedures/tungsten/#procedure","text":"Prepare lists of databases Reboot secondary DBs Failover to secondary DBs Reboot primary DBs Failover to primary DBs Cleanup and verify success","title":"Procedure"},{"location":"realm_management/procedures/tungsten/#important-notes","text":"Ensure you have initialized SERVERS , REGION , and OP per the main mass reboot runbook . Ensure UPGRADE_OS is set only if you are relaunching to upgrade servers to Xenial, per the mass relaunch runbook ! If you use UPGRADE_OS , you must declare it as a full string. Otherwise, you can leave it undeclared or defined as the empty string to allow your relaunches to proceed without changing the OS. For example: UPGRADE_OS=\"\" UPGRADE_OS=\"-o xenial\" UPGRADE_OS will not work with reboot workflows! Do not abort workflows! If you are unable to resolve a problem with a workflow, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership","title":"Important Notes"},{"location":"realm_management/procedures/tungsten/#preparation","text":"Set this variable to appropriately reboot or relaunch the databases: REBOOT_OR_RELAUNCH= # valid values: reboot,relaunch Create a sorted list of all the database servers for the specified region: ah-server list % -w \"name IN ${SERVERS}\" typeINfsdbmesh,dbmesh | sort -V > ${OPSTMP}/all_mrdbs Check for replication lag: fpdsh -l $(paste -sd, ${OPSTMP}/all_mrdbs) \\ -c \"sudo ruby -e 'require \\\"aq\\\"; s=Aq::Hosting::Server.from_local; \\ puts s.services.mysql.heartbeat_info.lag_max'\" | awk '$2>1' If there is any replication lag (more than a few seconds), resolve it: MRDB= ah-db-cluster status ${MRDB} site-tungstatus $(ah-site list on:${MRDB}) site-tungstenslaveresync $(ah-site list on:${MRDB} If the lag cannot be resolved, remove all servers in the cluster from ${OPSTMP}/all_mrdbs and make a note in the OP that they will need special handholding. Split the server list into primary and secondary databases based on their ordering. It is important that ${OPSTMP}/all_mrdbs be sorted for this step to work correctly. awk 'NR % 2' ${OPSTMP}/all_mrdbs > ${OPSTMP}/all_pri_mrdbs awk 'NR % 2 == 0' ${OPSTMP}/all_mrdbs > ${OPSTMP}/all_sec_mrdbs Create some other server/site lists for later: for server in $(cat ${OPSTMP}/all_pri_mrdbs) ; do ah-site list on:${server} | head -1; done \\ | sort -u > ${OPSTMP}/all_mrdb_sites for site in $(cat ${OPSTMP}/all_mrdb_sites) ; do ah-server list site:${site} -w typeINdbmesh,fsdbmesh ; done \\ | sort -u > ${OPSTMP}/all_cluster_mrdbs List the true, active region primary and secondary databases: eval $(sv-dbprisec $(paste -sd, ${OPSTMP}/all_mrdbs)) printf \"%s\\n\" \"${PRIMARY_DBS[@]}\" > ${OPSTMP}/act_pri_mrdbs printf \"%s\\n\" \"${SECONDARY_DBS[@]}\" > ${OPSTMP}/act_sec_mrdbs NOTE: sv-dbprisec ignores databases in the passive region, but correctly identifies the primary databases in the active region. This runbook takes advantage of this feature in order to properly execute failovers. Verify that no active region databases are in the wrong list: comm -12 <(sort ${OPSTMP}/act_pri_mrdbs) <(sort ${OPSTMP}/all_sec_mrdbs) comm -12 <(sort ${OPSTMP}/act_sec_mrdbs) <(sort ${OPSTMP}/all_pri_mrdbs) WARNING: If there is any output, you should manually move the mis-listed database(s) from its current ${OPSTMP}/all_*_mrdbs file to the other. Failure to do so will cause downtime. Identify node servers that will need their gluster volumes to be remounted: MRFS_CLUSTERS=$(ah-server list $(paste -sd, ${OPSTMP}/all_pri_mrdbs) -w typeINfsdbmesh \\ --no-name -c fs_cluster_id | paste -sd,) ah-server list % -w status=0 \"fs_cluster_id IN ${MRFS_CLUSTERS}\" > ${OPSTMP}/mrfs_nodes Check for locked DB clusters: sv-dbislocked $(paste -sd, ${OPSTMP}/all_pri_mrdbs) Unlock any unintentionally locked DB clusters with ah-db-cluster unlock . If you find any DB clusters that should not be unlocked, remove them and their sites from your lists.","title":"Preparation"},{"location":"realm_management/procedures/tungsten/#reboot-secondary-multiregion-databases","text":"Ensure hosts and iptables configs are correct on all FS nodes, then remount gluster in case any of them are only connected to the servers you are about to reboot/relaunch: fpdsh -l $(paste -sd, ${OPSTMP}/mrfs_nodes) -c 'sudo ah-config-hosts; sudo ah-config-iptables' for site in $(cat ${OPSTMP}/all_mrdb_sites); do site-fsremount $site | egrep -i 'failed|error'; done Resolve all remount errors for every gluster node before continuing! Instances that fail to remount gluster will not have a stable file system and will cause alerts. Lock all of the clusters to their primary DBs: < ${OPSTMP}/all_pri_mrdbs xargs -n1 -P20 -I{} ah-db-cluster lock {} Announce to the Ops hotseat in Operations chat that the secondary databases will be rebooted/relaunched. Downtime the MySQL Available alert for the primary DBs: < ${OPSTMP}/all_pri_mrdbs xargs -n1 -P20 \\ -I{} sv-downtimeservice {} 'Mysql Available' 60 \"${OP} - mass ${REBOOT_OR_RELAUNCH}\" Keep this command handy in case the process takes longer than 60 minutes to complete. Reboot/Relaunch the secondary database servers: Note: If you are upgrading to Xenial, ensure UPGRADE_OS=\"-o xenial\" and REBOOT_OR_RELAUNCH=relaunch . sv-taskrelaunch server -a ${REBOOT_OR_RELAUNCH} ${UPGRADE_OS} \\ -s 32 -m 1 $(paste -sd' ' ${OPSTMP}/all_sec_mrdbs)","title":"Reboot Secondary Multiregion Databases"},{"location":"realm_management/procedures/tungsten/#failover-to-secondary-multiregion-databases","text":"Remount gluster volumes: for site in $(cat ${OPSTMP}/all_mrdb_sites); do site-fsremount $site | egrep -i 'failed|error'; done Resolve all remount errors for every gluster node before continuing! Instances that fail to remount gluster will not have a stable file system and will cause alerts. Config iptables/hosts and run f-c-tungsten-peers: fpdsh -l $(paste -sd, ${OPSTMP}/all_cluster_mrdbs) \\ -c \"sudo ah-config-iptables; sudo ah-config-hosts\" fpdsh -l $(paste -sd, ${OPSTMP}/all_cluster_mrdbs) \\ -c \"sudo fields-config-tungsten-peers.php; sudo /etc/init.d/stunnel4 restart; sudo service treplicator restart\" Wait for replication to catch up: fpdsh -l $(paste -sd, ${OPSTMP}/all_mrdbs) \\ -c \"sudo ruby -e 'require \\\"aq\\\"; s=Aq::Hosting::Server.from_local; \\ puts s.services.mysql.heartbeat_info.lag_max'\" | awk '$2>1' If there are still errors, consult the instructions for missing peers . Unlock the clusters: < ${OPSTMP}/act_pri_mrdbs xargs -n1 -P20 -I{} ah-db-cluster unlock {} Downtime the MySQL Failover alert for the regional DNS server: DNS=$(ah-server list dns-% -w ec2_region=${REGION}) sv-downtimeservice ${DNS} 'MySQL Failover' 60 \"${OP} - mass ${REBOOT_OR_RELAUNCH}\" Keep this command handy. It may take longer than the allotted hour to complete all of the steps before you can unfailover the databases. Failover the active region clusters to the secondary DBs: sv-dbmultifailover $(paste -sd' ' ${OPSTMP}/act_sec_mrdbs)","title":"Failover to Secondary Multiregion Databases"},{"location":"realm_management/procedures/tungsten/#reboot-primary-multiregion-databases","text":"Lock all of the clusters to their secondary DBs: < ${OPSTMP}/act_sec_mrdbs xargs -n1 -P20 -I{} ah-db-cluster lock {} Announce to the Ops hotseat in Operations chat that the primary databases will be rebooted/relaunched. Downtime the MySQL Available alert for the secondary DBs: < ${OPSTMP}/all_sec_mrdbs xargs -n1 -P20 \\ -I{} sv-downtimeservice {} 'Mysql Available' 60 \"${OP} - mass ${REBOOT_OR_RELAUNCH}\" Keep this command handy in case the process takes longer than 60 minutes to complete. Reboot/Relaunch the primary database servers: Note: If you are upgrading to Xenial, ensure UPGRADE_OS=\"-o xenial\" and REBOOT_OR_RELAUNCH=relaunch . sv-taskrelaunch server -a ${REBOOT_OR_RELAUNCH} ${UPGRADE_OS} \\ -s 32 -m 1 $(paste -sd' ' ${OPSTMP}/all_pri_mrdbs)","title":"Reboot Primary Multiregion Databases"},{"location":"realm_management/procedures/tungsten/#failover-to-primary-multiregion-databases","text":"Remount gluster volumes: for site in $(cat ${OPSTMP}/all_mrdb_sites); do site-fsremount $site | egrep -i 'failed|error'; done Resolve all remount errors for every gluster node before continuing! Instances that fail to remount gluster will not have a stable file system and will cause alerts. Config iptables/hosts and run f-c-tungsten-peers: fpdsh -l $(paste -sd, ${OPSTMP}/all_cluster_mrdbs) \\ -c \"sudo ah-config-iptables; sudo ah-config-hosts\" fpdsh -l $(paste -sd, ${OPSTMP}/all_cluster_mrdbs) \\ -c \"sudo fields-config-tungsten-peers.php; sudo /etc/init.d/stunnel4 restart\" Wait for replication to catch up: fpdsh -l $(paste -sd, ${OPSTMP}/all_mrdbs) \\ -c \"sudo ruby -e 'require \\\"aq\\\"; s=Aq::Hosting::Server.from_local; \\ puts s.services.mysql.heartbeat_info.lag_max'\" | awk '$2>1' If there are still errors, consult the instructions for missing peers . Unlock the clusters: < ${OPSTMP}/all_sec_mrdbs xargs -n1 -P20 -I{} ah-db-cluster unlock {} Failover the active region clusters back to the primary databases: sv-dbmultifailover $(paste -sd' ' ${OPSTMP}/act_pri_mrdbs)","title":"Failover to Primary Multiregion Databases"},{"location":"realm_management/procedures/tungsten/#cleanup","text":"Verify that replication lag is ok for all databases: fpdsh -l $(paste -sd, ${OPSTMP}/all_mrdbs) \\ -c \"sudo ruby -e 'require \\\"aq\\\"; s=Aq::Hosting::Server.from_local; \\ puts s.services.mysql.heartbeat_info.lag_max'\" | awk '$2>1' Verify that all affected servers can reach their gluster volumes: fpdsh -l $(paste -sd, ${OPSTMP}/mrfs_nodes) -c '(ls /mnt/gfs/home > /dev/null 2>&1 ) || echo \"Failed\"' Remount gluster on any server that fails. If you suspect many of FS nodes failed to remount their gluster volumes, make a CSV list of the suspected nodes and remount their FS (try to be specific): NODES= sv-fsremount ${NODES} | egrep -i 'failed|error' If any databases were removed from this procedure, investigate why and manually reboot/relaunch them, if possible. If you cannot, escalate appropriately. Do not let them be forgotten!","title":"Cleanup"},{"location":"realm_management/procedures/webs/","text":"Webs ( web ) Rebooting web servers using cloning & replace method For reboot of web servers we are using cloning & replace method in which an existing web server will be replaced by its clone. Tags and settings of old server will be copied to new server. If elastic_ip is present on the existing server, it will get moved to new cloned server. Once new server is up and fine, old server will be terminated. Webs should be rebooted per Region, the bulk-${REBOOT_OR_RELAUNCH} workflow has built in logic to maintain site availability during the reboots as well as account for dedicated memcache HA. Here 'restart_web_servers_workflow' workflow will be called. Important Note Do not abort workflows! Set this variable to appropriately reboot the webs: REBOOT_OR_RELAUNCH= # valid values: reboot Gather the list of webs to reboot: NOTE Reboot one AZ at a time only WEBS=($(ah-server list % -w \"name IN ${SERVERS}\" typeINweb | sort -V)) WEB_SERVERS_CSV=$(array-csv ${WEBS[@]}) WEBS_AZS=$(ah-server list $WEB_SERVERS_CSV --no-name -c ec2_availability_zone|sort|uniq -c| awk '{print $2}') # Get list of webs per AZ for AZ in $WEBS_AZS;do echo $AZ;ah-server list $WEB_SERVERS_CSV -w ec2_availability_zone=$AZ|paste -sd,;echo ;done Reboot them: Populate WEBS_PER_AZ with webs from one AZ at a time echo -e \"{code:title=servers to be rebooted} WEBS_PER_AZ=${WEBS_PER_AZ} {code}\" # Copy above section of output in the JIRA ticket that you are working # Reboot - WEB # Generate reboot commands that can be run in parallel. # You can run upto 15 workflows in parallel ahops-workflow-batching -b 20 -t web -m ${REBOOT_OR_RELAUNCH} -s ${WEBS_PER_AZ} WF triggering command example- `ah-server bulk-reboot $SRV1 $SRV2 --batch-size n` Note : In order to reboot web servers via 'restart_server_workflow' (old WF) Include --no-replace-webs flag ah-server bulk-reboot $SRV1 $SRV2 --batch-size n --no-replace-webs Note : In order to receive workflow failure notifications --send-notications false flag can be avoided. NOTE Use the \u2014batch-size option when performing single site(logical stack). Batch size can be selected as per the table given below: Web count Batch size 1 1 2 1 3 1 4 1 5 1 6 1 7 1 8 2 9 2 10 2 11 2 12 3 13 3 14 3 15 3 16 4 Relanching webs Webs should be relaunched per Region, the bulk-${REBOOT_OR_RELAUNCH} workflow has built in logic to maintain site availability during the relaunch as well as account for dedicated memcache HA. If you are unable to resolve a problem with a workflow, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership Set this variable to appropriately relaunch the webs: REBOOT_OR_RELAUNCH= # valid values: relaunch Gather the list of webs to relaunch: NOTE Relaunch one AZ at a time only WEBS=($(ah-server list % -w \"name IN ${SERVERS}\" typeINweb | sort -V)) WEB_SERVERS_CSV=$(array-csv ${WEBS[@]}) WEBS_AZS=$(ah-server list $WEB_SERVERS_CSV --no-name -c ec2_availability_zone|sort|uniq -c| awk '{print $2}') # Get list of webs per AZ for AZ in $WEBS_AZS;do echo $AZ;ah-server list $WEB_SERVERS_CSV -w ec2_availability_zone=$AZ|paste -sd,;echo ;done Relaunch them: Populate WEBS_PER_AZ with webs from one AZ at a time # Disable monitoring # Copy the variables so that another terminal can be used to disable monitoring echo -e \"{code:title=servers to be relaunched} WEBS_PER_AZ=${WEBS_PER_AZ} {code}\" # Copy above section of output in the JIRA ticket that you are working # In a separate terminal, re-populate the 'WEBS_PER_AZ' by copying it from the line above sv-mass-mondisable ${WEBS_PER_AZ} # Relaunch - WEB # Generate relaunch commands that can be run in parallel. # You can run upto 15 workflows in parallel ahops-workflow-batching -b 20 -t web -m ${REBOOT_OR_RELAUNCH} -s ${WEBS_PER_AZ} # Re-enable monitoring # Cancel the script that you ran in 'Disable monitoring' step above # Check that services are ok on all relaunched servers and fix any broken services on server/s # Re-enable monitoring on all servers # Repopulate 'WEBS_PER_AZ' by copying name and value for the variable from 'Disable monitoring' step above ah-server edit ${WEBS_PER_AZ} --no-config-tasks -s monitoring_status=2 Note : In order to receive workflow failure notifications --send-notications false flag can be avoided. Also, if you are relaunching the servers to change the tenancy, use -e dedicated or -e default to set the required tenancy. For more information, please go through link https://runbook.ops.acquia.com/master/kanban_tickets/dedicated_hypervisor/ NOTE Use the \u2014batch-size option when performing single site(logical stack) relaunches(this does not apply to mass maintenances)due to a bug . Batch size can be selected as per the table given below: Web count Batch size 1 1 2 1 3 1 4 1 5 1 6 1 7 1 8 2 9 2 10 2 11 2 12 3 13 3 14 3 15 3 16 4 Remount all webs after relaunch: sv-fsremount ${WEB_SERVERS_CSV}","title":"Webs (`web`)"},{"location":"realm_management/procedures/webs/#webs-web","text":"","title":"Webs (web)"},{"location":"realm_management/procedures/webs/#rebooting-web-servers-using-cloning-replace-method","text":"For reboot of web servers we are using cloning & replace method in which an existing web server will be replaced by its clone. Tags and settings of old server will be copied to new server. If elastic_ip is present on the existing server, it will get moved to new cloned server. Once new server is up and fine, old server will be terminated. Webs should be rebooted per Region, the bulk-${REBOOT_OR_RELAUNCH} workflow has built in logic to maintain site availability during the reboots as well as account for dedicated memcache HA. Here 'restart_web_servers_workflow' workflow will be called.","title":"Rebooting web servers using cloning &amp; replace method"},{"location":"realm_management/procedures/webs/#important-note","text":"Do not abort workflows! Set this variable to appropriately reboot the webs: REBOOT_OR_RELAUNCH= # valid values: reboot Gather the list of webs to reboot: NOTE Reboot one AZ at a time only WEBS=($(ah-server list % -w \"name IN ${SERVERS}\" typeINweb | sort -V)) WEB_SERVERS_CSV=$(array-csv ${WEBS[@]}) WEBS_AZS=$(ah-server list $WEB_SERVERS_CSV --no-name -c ec2_availability_zone|sort|uniq -c| awk '{print $2}') # Get list of webs per AZ for AZ in $WEBS_AZS;do echo $AZ;ah-server list $WEB_SERVERS_CSV -w ec2_availability_zone=$AZ|paste -sd,;echo ;done Reboot them: Populate WEBS_PER_AZ with webs from one AZ at a time echo -e \"{code:title=servers to be rebooted} WEBS_PER_AZ=${WEBS_PER_AZ} {code}\" # Copy above section of output in the JIRA ticket that you are working # Reboot - WEB # Generate reboot commands that can be run in parallel. # You can run upto 15 workflows in parallel ahops-workflow-batching -b 20 -t web -m ${REBOOT_OR_RELAUNCH} -s ${WEBS_PER_AZ} WF triggering command example- `ah-server bulk-reboot $SRV1 $SRV2 --batch-size n` Note : In order to reboot web servers via 'restart_server_workflow' (old WF) Include --no-replace-webs flag ah-server bulk-reboot $SRV1 $SRV2 --batch-size n --no-replace-webs Note : In order to receive workflow failure notifications --send-notications false flag can be avoided. NOTE Use the \u2014batch-size option when performing single site(logical stack). Batch size can be selected as per the table given below: Web count Batch size 1 1 2 1 3 1 4 1 5 1 6 1 7 1 8 2 9 2 10 2 11 2 12 3 13 3 14 3 15 3 16 4","title":"Important Note"},{"location":"realm_management/procedures/webs/#relanching-webs","text":"Webs should be relaunched per Region, the bulk-${REBOOT_OR_RELAUNCH} workflow has built in logic to maintain site availability during the relaunch as well as account for dedicated memcache HA. If you are unable to resolve a problem with a workflow, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership Set this variable to appropriately relaunch the webs: REBOOT_OR_RELAUNCH= # valid values: relaunch Gather the list of webs to relaunch: NOTE Relaunch one AZ at a time only WEBS=($(ah-server list % -w \"name IN ${SERVERS}\" typeINweb | sort -V)) WEB_SERVERS_CSV=$(array-csv ${WEBS[@]}) WEBS_AZS=$(ah-server list $WEB_SERVERS_CSV --no-name -c ec2_availability_zone|sort|uniq -c| awk '{print $2}') # Get list of webs per AZ for AZ in $WEBS_AZS;do echo $AZ;ah-server list $WEB_SERVERS_CSV -w ec2_availability_zone=$AZ|paste -sd,;echo ;done Relaunch them: Populate WEBS_PER_AZ with webs from one AZ at a time # Disable monitoring # Copy the variables so that another terminal can be used to disable monitoring echo -e \"{code:title=servers to be relaunched} WEBS_PER_AZ=${WEBS_PER_AZ} {code}\" # Copy above section of output in the JIRA ticket that you are working # In a separate terminal, re-populate the 'WEBS_PER_AZ' by copying it from the line above sv-mass-mondisable ${WEBS_PER_AZ} # Relaunch - WEB # Generate relaunch commands that can be run in parallel. # You can run upto 15 workflows in parallel ahops-workflow-batching -b 20 -t web -m ${REBOOT_OR_RELAUNCH} -s ${WEBS_PER_AZ} # Re-enable monitoring # Cancel the script that you ran in 'Disable monitoring' step above # Check that services are ok on all relaunched servers and fix any broken services on server/s # Re-enable monitoring on all servers # Repopulate 'WEBS_PER_AZ' by copying name and value for the variable from 'Disable monitoring' step above ah-server edit ${WEBS_PER_AZ} --no-config-tasks -s monitoring_status=2 Note : In order to receive workflow failure notifications --send-notications false flag can be avoided. Also, if you are relaunching the servers to change the tenancy, use -e dedicated or -e default to set the required tenancy. For more information, please go through link https://runbook.ops.acquia.com/master/kanban_tickets/dedicated_hypervisor/ NOTE Use the \u2014batch-size option when performing single site(logical stack) relaunches(this does not apply to mass maintenances)due to a bug . Batch size can be selected as per the table given below: Web count Batch size 1 1 2 1 3 1 4 1 5 1 6 1 7 1 8 2 9 2 10 2 11 2 12 3 13 3 14 3 15 3 16 4 Remount all webs after relaunch: sv-fsremount ${WEB_SERVERS_CSV}","title":"Relanching webs"},{"location":"realm_management/procedures/workflow_errors/","text":"Dealing with Workflow errors If the bulk-relaunch workflow fails, investigate the error using: ah-workflow get ${WORKFLOW_ID} --show-logs Check any failed tasks using: ah-task get ${TASK_ID} If you cannot fix it, escalate appropriately. Make sure to include all output from ah-workflow watch-queue in Jira. Retry Workflow Review the steps the previous workflow took. Resolve the reason why the workflow failed and try resuming the workflow. If that does not work, start a new workflow. Make sure to exclude any servers that were successfully relaunched. If that also fails, relaunch any remaining servers manually. Aborting a workflow Important Note Do not abort workflows! If you are unable to resolve a problem with a workflow, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership If you are aborting any workflow due to some worklfow issues, you must be aware of the steps that you need to rollback or a list of services which need to be enabled which are disabled by workflow. First get the details of all the steps that a particular type of workflow is designed to execute. The output will list all the steps that are executed for ded,webs,fs,dbmaster servers. You have to figure out the steps as per your server. ah-workflow info ${WORKFLOW_ID} Then check on which step the workflow is aborted. ah-task get ${TASK_ID} For more details, you can use ah-workflow get ${WORKFLOW_ID} --show-logs Now you have to execute the leftover steps manually. For e.g. if you are executing a bulk-relaunch for a set of webs and your workflow got aborted at wait_on_processing_restart_tasks , then you have to remount the gluster and enable the web and memcache services on all the webs. Some Specific Workflow Fixes SSH Disconnect TODO: Remove when CL-16673 is fixed. Example: ERROR: Caught Net::SSH::Disconnect while while launching server: connection closed by remote host Fix with: ah-server suspend ${SERVER}+ ah-server launch ${SERVER} Proceed with the Workflow Gluster Failed Example: Caught RuntimeError while running workflow: Gluster healthy? check failed for servers Fix gluster then resume workflow Workflow Launch Task Times Out Example: [cloudservicesdev|hosting-prod:prod] ~/fields/1.99$ ah-workflow get 5555 --show-logs | less ... [2017-05-03 22:53:44] DEBUG: + retry: 3 secs left [2017-05-03 22:53:50] restart_standalone_servers_workflow workflow (5555): Step: restart_servers raised error Aq::RetryTimeoutException [2017-05-03 22:53:50] ERROR: Caught Aq::RetryTimeoutException while running workflow: timeout: 2400 [2017-05-03 22:53:50] ERROR: /usr/local/lib/ruby/gems/2.1.0/gems/aq-1.99.1493309416/lib/aq/retry.rb:87:in `run' ... Investigate the workflow and identify its sub-tasks: ah-workflow get ${WORKFLOW_ID} --show-logs TASK_CSV= ah-task list -w idIN${TASK_CSV} -c state body If some of the tasks are still in progress, you may have to wait for them to finish. If any of the tasks have errored, get their output and resolve the issue (sites not deploying, etc.) ah-task get ${TASK_ID} Restart the task: ah-task restart ${TASK_ID} Once all the task problems are resolved resume the workflow: ah-workflow resume ${WORKFLOW_ID} Workflow Hit Ruby Threading Bug Example: [2017-04-19 21:14:23] DEBUG: Failed to stat file /mnt/gfs/.GLUSTERHEALTHYTEST-fsdb-203 on web-205: Exit 66 with: (SSH Error: undefined method `update' for#OpenSSL::Cipher::Cipher:0x005602f92e33b0 (ahbot@web-205.network.hosting.acquia.com:40506) Resume the workflow ah-workflow resume ${WORKFLOW_ID} Workflow Hit Invalid VCS Path Incorrect VCS Path Runbook","title":"Dealing with Workflow errors"},{"location":"realm_management/procedures/workflow_errors/#dealing-with-workflow-errors","text":"If the bulk-relaunch workflow fails, investigate the error using: ah-workflow get ${WORKFLOW_ID} --show-logs Check any failed tasks using: ah-task get ${TASK_ID} If you cannot fix it, escalate appropriately. Make sure to include all output from ah-workflow watch-queue in Jira.","title":"Dealing with Workflow errors"},{"location":"realm_management/procedures/workflow_errors/#retry-workflow","text":"Review the steps the previous workflow took. Resolve the reason why the workflow failed and try resuming the workflow. If that does not work, start a new workflow. Make sure to exclude any servers that were successfully relaunched. If that also fails, relaunch any remaining servers manually.","title":"Retry Workflow"},{"location":"realm_management/procedures/workflow_errors/#aborting-a-workflow","text":"","title":"Aborting a workflow"},{"location":"realm_management/procedures/workflow_errors/#important-note","text":"Do not abort workflows! If you are unable to resolve a problem with a workflow, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership If you are aborting any workflow due to some worklfow issues, you must be aware of the steps that you need to rollback or a list of services which need to be enabled which are disabled by workflow. First get the details of all the steps that a particular type of workflow is designed to execute. The output will list all the steps that are executed for ded,webs,fs,dbmaster servers. You have to figure out the steps as per your server. ah-workflow info ${WORKFLOW_ID} Then check on which step the workflow is aborted. ah-task get ${TASK_ID} For more details, you can use ah-workflow get ${WORKFLOW_ID} --show-logs Now you have to execute the leftover steps manually. For e.g. if you are executing a bulk-relaunch for a set of webs and your workflow got aborted at wait_on_processing_restart_tasks , then you have to remount the gluster and enable the web and memcache services on all the webs.","title":"Important Note"},{"location":"realm_management/procedures/workflow_errors/#some-specific-workflow-fixes","text":"","title":"Some Specific Workflow Fixes"},{"location":"realm_management/procedures/workflow_errors/#ssh-disconnect","text":"TODO: Remove when CL-16673 is fixed. Example: ERROR: Caught Net::SSH::Disconnect while while launching server: connection closed by remote host Fix with: ah-server suspend ${SERVER}+ ah-server launch ${SERVER} Proceed with the Workflow","title":"SSH Disconnect"},{"location":"realm_management/procedures/workflow_errors/#gluster-failed","text":"Example: Caught RuntimeError while running workflow: Gluster healthy? check failed for servers Fix gluster then resume workflow","title":"Gluster Failed"},{"location":"realm_management/procedures/workflow_errors/#workflow-launch-task-times-out","text":"Example: [cloudservicesdev|hosting-prod:prod] ~/fields/1.99$ ah-workflow get 5555 --show-logs | less ... [2017-05-03 22:53:44] DEBUG: + retry: 3 secs left [2017-05-03 22:53:50] restart_standalone_servers_workflow workflow (5555): Step: restart_servers raised error Aq::RetryTimeoutException [2017-05-03 22:53:50] ERROR: Caught Aq::RetryTimeoutException while running workflow: timeout: 2400 [2017-05-03 22:53:50] ERROR: /usr/local/lib/ruby/gems/2.1.0/gems/aq-1.99.1493309416/lib/aq/retry.rb:87:in `run' ... Investigate the workflow and identify its sub-tasks: ah-workflow get ${WORKFLOW_ID} --show-logs TASK_CSV= ah-task list -w idIN${TASK_CSV} -c state body If some of the tasks are still in progress, you may have to wait for them to finish. If any of the tasks have errored, get their output and resolve the issue (sites not deploying, etc.) ah-task get ${TASK_ID} Restart the task: ah-task restart ${TASK_ID} Once all the task problems are resolved resume the workflow: ah-workflow resume ${WORKFLOW_ID}","title":"Workflow Launch Task Times Out"},{"location":"realm_management/procedures/workflow_errors/#workflow-hit-ruby-threading-bug","text":"Example: [2017-04-19 21:14:23] DEBUG: Failed to stat file /mnt/gfs/.GLUSTERHEALTHYTEST-fsdb-203 on web-205: Exit 66 with: (SSH Error: undefined method `update' for#OpenSSL::Cipher::Cipher:0x005602f92e33b0 (ahbot@web-205.network.hosting.acquia.com:40506) Resume the workflow ah-workflow resume ${WORKFLOW_ID}","title":"Workflow Hit Ruby Threading Bug"},{"location":"realm_management/procedures/workflow_errors/#workflow-hit-invalid-vcs-path","text":"Incorrect VCS Path Runbook","title":"Workflow Hit Invalid VCS Path"},{"location":"runbook_metadocs/","text":"Runbook Metadocs Contribution Welcome to Contributing to Ops Runbooks for Fields Guidelines Main Topics Contributing Workflow Local Development Setup (Automated) Setup (Manual) Reviewing Shortcutting Linting Labels Approved Style Guide Ops Runbook (Fields) Style Guide Install and Use Rules file The Standard Verbiage Headings Lists Ordered Unordered Code in lists Variables Standard Variables Common Reserved Variables Coding","title":"Runbook Metadocs"},{"location":"runbook_metadocs/#runbook-metadocs","text":"","title":"Runbook Metadocs"},{"location":"runbook_metadocs/#contribution","text":"Welcome to Contributing to Ops Runbooks for Fields Guidelines Main Topics Contributing Workflow Local Development Setup (Automated) Setup (Manual) Reviewing Shortcutting Linting Labels Approved","title":"Contribution"},{"location":"runbook_metadocs/#style-guide","text":"Ops Runbook (Fields) Style Guide Install and Use Rules file The Standard Verbiage Headings Lists Ordered Unordered Code in lists Variables Standard Variables Common Reserved Variables Coding","title":"Style Guide"},{"location":"runbook_metadocs/contribution/","text":"Welcome to Contributing to Ops Runbooks for Fields If you wish to contribute to this project please start by creating an OPE ticket and linking it to OPE-1021 to provide visibility for others working on documentation. Guidelines Main Topics Contributing Workflow Local Development Setup Reviewing Shortcutting Linting Labels Approved Guidelines Please view the style guide before contributing any content. Main Topics If you are unsure of where to create your page, please ask for assistance by sending an email to ops-forum@acquia.com Alerts : Procedures for incident response Bastion Database : Information pertaining to MySQL and Tungsten Gluster Instance Deprovision Instance Management Instance Provision Mass Maintenance : Reboots and relaunches for security patching and AWS maintenance Realm Management : Fields administration Search : Acquia Search Service Site Deprovision Site Management Site Provision TLS/SSL VPC : Acquia Shield Contributing This section details how we develop, test, commit and review changes. Please review this entire section before starting work. Workflow All work must be tied to a Jira ticket. Branch names are prefixed with the ticket - i.e. 'OP-1234_add-ace-reboot-procedure'. PRs Have the title of 'OP-1234 | Short description of change'. Are labelled 'needs-review'. Have links to generated pages on runbook.ops.acquia.com (LDAP creds). NOTE: update-mkdocs runs at */10. Have links to OpsWiki\u2122 pages where relevant. Show output of added/modified commands, where relevant. Merges Are done after at least two people have approved and >24 hours has passed since PR creation. Bypass the 24 hour rule if it's a bugfix. If the PR obsoletes an OpsWiki\u2122 page, update the page with a redirect of, for example: {{migrated|database/xtrabackup}} Local Development Setup (Automated) To set-up your local machine to view documentation locally and run the appropriate syntax and linting tests run ./setmeup.sh in the root of your repo's directory. Setup (Manual) Our method of reviewing a change is to view generated pages on runbook.ops.acquia.com because we auto-generate HTML from MarkDown. If you submit a PR for a fork, reviewers will not be able to properly review your work. Please go to https://github.acquia.com/ to request push access to this repo. git clone git@github.com:acquia/ops-runbook-fields.git cd ops-runbook-fields cp git_hooks/pre-commit .git/hooks/ bundle install sudo pip install virtualenv virtualenv .venv source .venv/bin/activate pip install mkdocs Reviewing source .venv/bin/activate mkdocs serve Then open http://localhost:8000 in your browser. The pages will automatically refresh as you save files. Shortcutting If your distro appends $HOME/bin to $PATH by default: $ cat > ~/bin/runbook <<EOF #!/usr/bin/env bash cd ~/dev/ops-runbook-fields source .venv/bin/activate mkdocs serve cd - EOF chmod 755 ~/bin/runbook Linting Markdownlint bundle install bundle exec mdl -s style.rb docs Labels We use several labels to organise our PRs. These are the most common ones: Approved Needs review Needs work Do not merge Bug fix Enhancement Approved Approved labels are coloured green, are per user, and are in the format of approved-$USER to make the labels sort properly. To create your own label: How to create a new Github label","title":"Welcome to Contributing to Ops Runbooks for Fields"},{"location":"runbook_metadocs/contribution/#welcome-to-contributing-to-ops-runbooks-for-fields","text":"If you wish to contribute to this project please start by creating an OPE ticket and linking it to OPE-1021 to provide visibility for others working on documentation. Guidelines Main Topics Contributing Workflow Local Development Setup Reviewing Shortcutting Linting Labels Approved","title":"Welcome to Contributing to Ops Runbooks for Fields"},{"location":"runbook_metadocs/contribution/#guidelines","text":"Please view the style guide before contributing any content.","title":"Guidelines"},{"location":"runbook_metadocs/contribution/#main-topics","text":"If you are unsure of where to create your page, please ask for assistance by sending an email to ops-forum@acquia.com Alerts : Procedures for incident response Bastion Database : Information pertaining to MySQL and Tungsten Gluster Instance Deprovision Instance Management Instance Provision Mass Maintenance : Reboots and relaunches for security patching and AWS maintenance Realm Management : Fields administration Search : Acquia Search Service Site Deprovision Site Management Site Provision TLS/SSL VPC : Acquia Shield","title":"Main Topics"},{"location":"runbook_metadocs/contribution/#contributing","text":"This section details how we develop, test, commit and review changes. Please review this entire section before starting work.","title":"Contributing"},{"location":"runbook_metadocs/contribution/#workflow","text":"All work must be tied to a Jira ticket. Branch names are prefixed with the ticket - i.e. 'OP-1234_add-ace-reboot-procedure'. PRs Have the title of 'OP-1234 | Short description of change'. Are labelled 'needs-review'. Have links to generated pages on runbook.ops.acquia.com (LDAP creds). NOTE: update-mkdocs runs at */10. Have links to OpsWiki\u2122 pages where relevant. Show output of added/modified commands, where relevant. Merges Are done after at least two people have approved and >24 hours has passed since PR creation. Bypass the 24 hour rule if it's a bugfix. If the PR obsoletes an OpsWiki\u2122 page, update the page with a redirect of, for example: {{migrated|database/xtrabackup}}","title":"Workflow"},{"location":"runbook_metadocs/contribution/#local-development","text":"","title":"Local Development"},{"location":"runbook_metadocs/contribution/#setup-automated","text":"To set-up your local machine to view documentation locally and run the appropriate syntax and linting tests run ./setmeup.sh in the root of your repo's directory.","title":"Setup (Automated)"},{"location":"runbook_metadocs/contribution/#setup-manual","text":"Our method of reviewing a change is to view generated pages on runbook.ops.acquia.com because we auto-generate HTML from MarkDown. If you submit a PR for a fork, reviewers will not be able to properly review your work. Please go to https://github.acquia.com/ to request push access to this repo. git clone git@github.com:acquia/ops-runbook-fields.git cd ops-runbook-fields cp git_hooks/pre-commit .git/hooks/ bundle install sudo pip install virtualenv virtualenv .venv source .venv/bin/activate pip install mkdocs","title":"Setup (Manual)"},{"location":"runbook_metadocs/contribution/#reviewing","text":"source .venv/bin/activate mkdocs serve Then open http://localhost:8000 in your browser. The pages will automatically refresh as you save files.","title":"Reviewing"},{"location":"runbook_metadocs/contribution/#shortcutting","text":"If your distro appends $HOME/bin to $PATH by default: $ cat > ~/bin/runbook <<EOF #!/usr/bin/env bash cd ~/dev/ops-runbook-fields source .venv/bin/activate mkdocs serve cd - EOF chmod 755 ~/bin/runbook","title":"Shortcutting"},{"location":"runbook_metadocs/contribution/#linting","text":"Markdownlint bundle install bundle exec mdl -s style.rb docs","title":"Linting"},{"location":"runbook_metadocs/contribution/#labels","text":"We use several labels to organise our PRs. These are the most common ones: Approved Needs review Needs work Do not merge Bug fix Enhancement","title":"Labels"},{"location":"runbook_metadocs/contribution/#approved","text":"Approved labels are coloured green, are per user, and are in the format of approved-$USER to make the labels sort properly. To create your own label: How to create a new Github label","title":"Approved"},{"location":"runbook_metadocs/style/","text":"Ops Runbook (Fields) Style Guide MarkDownLint ensures that all documents in this repository meet a minimum standard for formatting and style. Install and Use bundle install bundle exec mdl -s style.rb docs Rules file The current rules are defined in /style.rb . The Standard The goal of this guide is to ensure that all pages are as similar and easy to use as possible. The conventions laid out below have been chosen for cleanliness and best practice. There are other ways of writing markdown, but these ones are preferred. Verbiage Your content is worded definitely in the present tense. There is no ambiguity, and terminology is clinical. Procedures are numbered and tractable. Assumptions are also never made, with exception of some basics: ops-misc is properly configured. A person is in the relevant realm, i.e. they have already run aprod, adevcloud, etc. They are in ~/fields/$FIELDSVER/ , i.e. ./fields-provision.php and the ah-tools work. All needed credentials are in place for: ec2 aws ah-tools Commands that move a person from the fields directory are controlled with pushd and popd . Headings The ATX method of headings is used exclusively. The first line of every page is an H1 title. Headings must only ever increase by one, so H1 to H3 is illegal and you must have used H2 in between. There must only be one H1 (title) per page. # Heading 1 (Title) ## Heading 2 ### Heading 3 #### Heading 4 Lists Both ordered and unordered lists are indented by four spaces between levels. If extra paragraphs are needed they are simply indented by a further four spaces. Ordered 1. instruction one 1. sub-instruction one 1. sub-sub-instruction one 1. sub-instruction two 1. instruction two Second paragraph for instruction two 1. instruction three Unordered * item one * sub-item one Another paragraph for sub-item one * sub-sub-item one * sub-sub-item two * sub-item two * item two Code in lists Back ticks are preferable most of time, but when inside of a list you must use indentation of code blocks in order to not break the list count. Code must be indented by a further four spaces from the current next level of the list. I.e. eight spaces for level one and twelve spaces for level two. 1. instruction one # code block indented by 8 spaces dd if=/dev/urandom of=/dev/sda 1. instruction two with an extra note between instructions that doesn\u2019t break numbering 1. instruction three with an extra note between instructions, but this time with a code block # moar coad echo \u201c8 spaces is where is at\u201d 1. sub-instruction rm -rf --no-preserve-root / Variables Use them and have them automatically created where possible. Define as many variables as the procedure needs at the top of the document. Standard Variables INSTANCE=i-as12df34 SERVER=ded-1 SERVERS=ded-1,web-2,foo-3 SITENAME=fubarptyltddev SITEGROUP=fubarptyltd STAGE=dev REGION=us-east-1 AZ=us-east-1a AZS=(us-east-1a us-east-1b) SRC=ded-1 DST=fsdb-2 SIZE=100 NEW_VOL=vol-asdf1234 OLD_VOL=vol-1234asdf Common Reserved Variables FIELDS_STAGE EC2_ACCOUNT FIELDS_SERVER_DOMAIN FIELDS_MASTER_DOMAIN HOSTING_VERSION FIELDSVER OPSTMP OPSLOG Coding We use the Google shell standard for all code. Important notes: Always use $() instead of `` for readability and to avoid markdown rendering issues If a code block uses pipes then the pipe will be indented on the next line: echo \"foo bar\" \\ | grep foo \\ | sed 's/bar/baz/' When using commands with lots of options, please ensure that the command is easy to interpret and provides output in {noformat} tags for ticket comments. OUTPUT=$(fpdsh \\ -t site:mysite \\ -n web \\ -p 100 \\ -c \"sudo echo '#YOLO'\") -OR- echo \"{noformat}\" \\ && ah-server list bal-% --no-name \\ -w ec2_regionINus-east-1,ap-southeast-2,eu-west-1 eip_id=nil \\ -c ec2_id \\ | paste -sd, \\ && echo \"{noformat}\"","title":"Ops Runbook (Fields) Style Guide"},{"location":"runbook_metadocs/style/#ops-runbook-fields-style-guide","text":"MarkDownLint ensures that all documents in this repository meet a minimum standard for formatting and style.","title":"Ops Runbook (Fields) Style Guide"},{"location":"runbook_metadocs/style/#install-and-use","text":"bundle install bundle exec mdl -s style.rb docs","title":"Install and Use"},{"location":"runbook_metadocs/style/#rules-file","text":"The current rules are defined in /style.rb .","title":"Rules file"},{"location":"runbook_metadocs/style/#the-standard","text":"The goal of this guide is to ensure that all pages are as similar and easy to use as possible. The conventions laid out below have been chosen for cleanliness and best practice. There are other ways of writing markdown, but these ones are preferred.","title":"The Standard"},{"location":"runbook_metadocs/style/#verbiage","text":"Your content is worded definitely in the present tense. There is no ambiguity, and terminology is clinical. Procedures are numbered and tractable. Assumptions are also never made, with exception of some basics: ops-misc is properly configured. A person is in the relevant realm, i.e. they have already run aprod, adevcloud, etc. They are in ~/fields/$FIELDSVER/ , i.e. ./fields-provision.php and the ah-tools work. All needed credentials are in place for: ec2 aws ah-tools Commands that move a person from the fields directory are controlled with pushd and popd .","title":"Verbiage"},{"location":"runbook_metadocs/style/#headings","text":"The ATX method of headings is used exclusively. The first line of every page is an H1 title. Headings must only ever increase by one, so H1 to H3 is illegal and you must have used H2 in between. There must only be one H1 (title) per page. # Heading 1 (Title) ## Heading 2 ### Heading 3 #### Heading 4","title":"Headings"},{"location":"runbook_metadocs/style/#lists","text":"Both ordered and unordered lists are indented by four spaces between levels. If extra paragraphs are needed they are simply indented by a further four spaces.","title":"Lists"},{"location":"runbook_metadocs/style/#ordered","text":"1. instruction one 1. sub-instruction one 1. sub-sub-instruction one 1. sub-instruction two 1. instruction two Second paragraph for instruction two 1. instruction three","title":"Ordered"},{"location":"runbook_metadocs/style/#unordered","text":"* item one * sub-item one Another paragraph for sub-item one * sub-sub-item one * sub-sub-item two * sub-item two * item two","title":"Unordered"},{"location":"runbook_metadocs/style/#code-in-lists","text":"Back ticks are preferable most of time, but when inside of a list you must use indentation of code blocks in order to not break the list count. Code must be indented by a further four spaces from the current next level of the list. I.e. eight spaces for level one and twelve spaces for level two. 1. instruction one # code block indented by 8 spaces dd if=/dev/urandom of=/dev/sda 1. instruction two with an extra note between instructions that doesn\u2019t break numbering 1. instruction three with an extra note between instructions, but this time with a code block # moar coad echo \u201c8 spaces is where is at\u201d 1. sub-instruction rm -rf --no-preserve-root /","title":"Code in lists"},{"location":"runbook_metadocs/style/#variables","text":"Use them and have them automatically created where possible. Define as many variables as the procedure needs at the top of the document.","title":"Variables"},{"location":"runbook_metadocs/style/#standard-variables","text":"INSTANCE=i-as12df34 SERVER=ded-1 SERVERS=ded-1,web-2,foo-3 SITENAME=fubarptyltddev SITEGROUP=fubarptyltd STAGE=dev REGION=us-east-1 AZ=us-east-1a AZS=(us-east-1a us-east-1b) SRC=ded-1 DST=fsdb-2 SIZE=100 NEW_VOL=vol-asdf1234 OLD_VOL=vol-1234asdf","title":"Standard Variables"},{"location":"runbook_metadocs/style/#common-reserved-variables","text":"FIELDS_STAGE EC2_ACCOUNT FIELDS_SERVER_DOMAIN FIELDS_MASTER_DOMAIN HOSTING_VERSION FIELDSVER OPSTMP OPSLOG","title":"Common Reserved Variables"},{"location":"runbook_metadocs/style/#coding","text":"We use the Google shell standard for all code. Important notes: Always use $() instead of `` for readability and to avoid markdown rendering issues If a code block uses pipes then the pipe will be indented on the next line: echo \"foo bar\" \\ | grep foo \\ | sed 's/bar/baz/' When using commands with lots of options, please ensure that the command is easy to interpret and provides output in {noformat} tags for ticket comments. OUTPUT=$(fpdsh \\ -t site:mysite \\ -n web \\ -p 100 \\ -c \"sudo echo '#YOLO'\") -OR- echo \"{noformat}\" \\ && ah-server list bal-% --no-name \\ -w ec2_regionINus-east-1,ap-southeast-2,eu-west-1 eip_id=nil \\ -c ec2_id \\ | paste -sd, \\ && echo \"{noformat}\"","title":"Coding"},{"location":"secondary_response/","text":"Secondary Response CPU Wait Diagnosing CPU Wait problems Tools to Identify CPU Wait SignalFX vmstat ps iostat lsof strace Responses Balancers Webs FS DB DB Error: lock_wait_timeout MySQL lock_wait_timeout errors Background Optional: Verify how many processes are waiting Finding the long-running transaction Finding the PHP process Report to Support Disable ACP Sales Disable DevCloud Purchases Procedure Alternate Procedure Dump Restore: Tungsten - All Hosts Dump Restore All Tungsten Hosts Procedure Dump The DB Prepare Bad Hosts For The DR Restore The DB Restore Replication Dump Restore: Tungsten - Single Host Dump Restore A Single Tungsten Slave Procedure Dump The DB Restore The DB Restore Replication Dump Restore: MySQL (Workflow) MySQL Dump Restore Workflow Preparation Ensure there is no replication lag on either server Make sure there is enough space on the ephemeral volume Verify that replication is set up Starting the workflow Important Note Required parameter --method Optional parameter --path Standard workflow parameters Verify replication Trouble shooting Dump Restore: MySQL (Xtrabackup) Xtrabackup Dump Restore Pre Restoring MySQL data from dbmaster-A to dbmaster-B Prepare XtraBackup snapshot Copy snapshot and prepare passive master Restore replication Reset replication to restored passive master Verify replication Clean up Fencing * [Enable fence](./fencing.md#enable-fence) * [Enable on Single server](./fencing.md#enable-on-single-server) * [Enable on AZ](./fencing.md#enable-on-az) * [Disable fence](./fencing.md#disable-fence) * [Disable on Single server](./fencing.md#disable-on-single-server) * [Disable on AZ](./fencing.md#disable-on-az) Fix 1970 Timestamps Fix 1970 timestamps for files THIS IS FOR GLUSTER 3.0 ONLY Gather Information Remediation 1 Remediation 2 Remediation 3 Impaired Server Relaunch Relaunching impaired servers Pre-checks Web Servers FS Servers DB servers Balancers Search servers Diagnosing problems with relaunch and force relaunch MySQL Service Issue During Volume Resize Fix MySQL service issue occured during volume resize Important Note Setting up the variables Lock replication to the GOOD_DB_SERVER Attach last known/working DB volume on BAD_DB_SERVER Let's Sync the old data after mounting old DB volume on BAD_DB_SERVER Start MySQL Service Resume the Workflow Check replication Status Initiate Dump Restore Umount the old volume and remove the folder from $BAD_DB_SERVER Detach the volume from $BAD_DB_SERVER MySQL Startup Failures MySQL Startup Failure Troubleshooting InnoDB File unknown read returned OS error 71 Problem Description for File (unknown) error Fix for File (unknown) error You have to start mysqld with tc-heuristic-recover switch to commit or rollback pending transactions Problem Description for --tc-heuristic-recover error Fix for --tc-heuristic-recover error pt-kill Tool * [READ THIS FIRST](./pt-kill.md#read-this-first) * [Investigation](./pt-kill.md#investigation) * [Example pt-kill Command](./pt-kill.md#example-pt-kill-command) Reduce Site Factory MySQL Disk Usage Reduce Site Factory MySQL Disk Usage Warning Procedure Variables Prep Begin on Secondary Repeat on Primary Replacing Brick Volumes * [Initial Variables](./replacing-brick-volumes.md#initial-variables) * [Remove the old (corrupt) brick](./replacing-brick-volumes.md#remove-the-old-corrupt-brick) * [Relaunch the server to setup a new brick](./replacing-brick-volumes.md#relaunch-the-server-to-setup-a-new-brick) * [If all is fine delete the aws volume](./replacing-brick-volumes.md#if-all-is-fine-delete-the-aws-volume) Replacing Bricks Replacing Gluster Bricks THIS IS FOR GLUSTER 3.4 ONLY Stop Gluster and other services Remove the old (corrupt) brick directory Recover Volume ID Start Gluster Heal the brick Force-mounting the brick Verify success Start Gluster Client & Cron Search Disk Partitions Search Disk Partitions Alert Initialize Confirm that the indexes directory is filling its partition Remediation Move indexes that should not be deployed Determine if a customer is over their limit Move the largest index Emergency Upsize Split-Brain (GlusterFS) * [Init](./split-brain.md#init) * [Resolution](./split-brain.md#resolution) * [Heal and Check](./split-brain.md#heal-and-check) * [Clean up](./split-brain.md#clean-up) Tungsten Administration General Administration Check Consistency Check Status Dump Restore Missing Peers Properties Files Resetting Tungsten User Privileges Send Heartbeat State Overview Tungsten Slave Resync How To Use It Trim Log Files Binlogs Info Logs Total Wipe/Reinstallation Of Tungsten Verifying Replication With Checksumming","title":"Secondary Response"},{"location":"secondary_response/#secondary-response","text":"","title":"Secondary Response"},{"location":"secondary_response/#cpu-wait","text":"Diagnosing CPU Wait problems Tools to Identify CPU Wait SignalFX vmstat ps iostat lsof strace Responses Balancers Webs FS DB","title":"CPU Wait"},{"location":"secondary_response/#db-error-lock_wait_timeout","text":"MySQL lock_wait_timeout errors Background Optional: Verify how many processes are waiting Finding the long-running transaction Finding the PHP process Report to Support","title":"DB Error: lock_wait_timeout"},{"location":"secondary_response/#disable-acp-sales","text":"Disable DevCloud Purchases Procedure Alternate Procedure","title":"Disable ACP Sales"},{"location":"secondary_response/#dump-restore-tungsten-all-hosts","text":"Dump Restore All Tungsten Hosts Procedure Dump The DB Prepare Bad Hosts For The DR Restore The DB Restore Replication","title":"Dump Restore: Tungsten - All Hosts"},{"location":"secondary_response/#dump-restore-tungsten-single-host","text":"Dump Restore A Single Tungsten Slave Procedure Dump The DB Restore The DB Restore Replication","title":"Dump Restore: Tungsten - Single Host"},{"location":"secondary_response/#dump-restore-mysql-workflow","text":"MySQL Dump Restore Workflow Preparation Ensure there is no replication lag on either server Make sure there is enough space on the ephemeral volume Verify that replication is set up Starting the workflow Important Note Required parameter --method Optional parameter --path Standard workflow parameters Verify replication Trouble shooting","title":"Dump Restore: MySQL (Workflow)"},{"location":"secondary_response/#dump-restore-mysql-xtrabackup","text":"Xtrabackup Dump Restore Pre Restoring MySQL data from dbmaster-A to dbmaster-B Prepare XtraBackup snapshot Copy snapshot and prepare passive master Restore replication Reset replication to restored passive master Verify replication Clean up","title":"Dump Restore: MySQL (Xtrabackup)"},{"location":"secondary_response/#fencing","text":"* [Enable fence](./fencing.md#enable-fence) * [Enable on Single server](./fencing.md#enable-on-single-server) * [Enable on AZ](./fencing.md#enable-on-az) * [Disable fence](./fencing.md#disable-fence) * [Disable on Single server](./fencing.md#disable-on-single-server) * [Disable on AZ](./fencing.md#disable-on-az)","title":"Fencing"},{"location":"secondary_response/#fix-1970-timestamps","text":"Fix 1970 timestamps for files THIS IS FOR GLUSTER 3.0 ONLY Gather Information Remediation 1 Remediation 2 Remediation 3","title":"Fix 1970 Timestamps"},{"location":"secondary_response/#impaired-server-relaunch","text":"Relaunching impaired servers Pre-checks Web Servers FS Servers DB servers Balancers Search servers Diagnosing problems with relaunch and force relaunch","title":"Impaired Server Relaunch"},{"location":"secondary_response/#mysql-service-issue-during-volume-resize","text":"Fix MySQL service issue occured during volume resize Important Note Setting up the variables Lock replication to the GOOD_DB_SERVER Attach last known/working DB volume on BAD_DB_SERVER Let's Sync the old data after mounting old DB volume on BAD_DB_SERVER Start MySQL Service Resume the Workflow Check replication Status Initiate Dump Restore Umount the old volume and remove the folder from $BAD_DB_SERVER Detach the volume from $BAD_DB_SERVER","title":"MySQL Service Issue During Volume Resize"},{"location":"secondary_response/#mysql-startup-failures","text":"MySQL Startup Failure Troubleshooting InnoDB File unknown read returned OS error 71 Problem Description for File (unknown) error Fix for File (unknown) error You have to start mysqld with tc-heuristic-recover switch to commit or rollback pending transactions Problem Description for --tc-heuristic-recover error Fix for --tc-heuristic-recover error","title":"MySQL Startup Failures"},{"location":"secondary_response/#pt-kill-tool","text":"* [READ THIS FIRST](./pt-kill.md#read-this-first) * [Investigation](./pt-kill.md#investigation) * [Example pt-kill Command](./pt-kill.md#example-pt-kill-command)","title":"pt-kill Tool"},{"location":"secondary_response/#reduce-site-factory-mysql-disk-usage","text":"Reduce Site Factory MySQL Disk Usage Warning Procedure Variables Prep Begin on Secondary Repeat on Primary","title":"Reduce Site Factory MySQL Disk Usage"},{"location":"secondary_response/#replacing-brick-volumes","text":"* [Initial Variables](./replacing-brick-volumes.md#initial-variables) * [Remove the old (corrupt) brick](./replacing-brick-volumes.md#remove-the-old-corrupt-brick) * [Relaunch the server to setup a new brick](./replacing-brick-volumes.md#relaunch-the-server-to-setup-a-new-brick) * [If all is fine delete the aws volume](./replacing-brick-volumes.md#if-all-is-fine-delete-the-aws-volume)","title":"Replacing Brick Volumes"},{"location":"secondary_response/#replacing-bricks","text":"Replacing Gluster Bricks THIS IS FOR GLUSTER 3.4 ONLY Stop Gluster and other services Remove the old (corrupt) brick directory Recover Volume ID Start Gluster Heal the brick Force-mounting the brick Verify success Start Gluster Client & Cron","title":"Replacing Bricks"},{"location":"secondary_response/#search-disk-partitions","text":"Search Disk Partitions Alert Initialize Confirm that the indexes directory is filling its partition Remediation Move indexes that should not be deployed Determine if a customer is over their limit Move the largest index Emergency Upsize","title":"Search Disk Partitions"},{"location":"secondary_response/#split-brain-glusterfs","text":"* [Init](./split-brain.md#init) * [Resolution](./split-brain.md#resolution) * [Heal and Check](./split-brain.md#heal-and-check) * [Clean up](./split-brain.md#clean-up)","title":"Split-Brain (GlusterFS)"},{"location":"secondary_response/#tungsten-administration","text":"General Administration Check Consistency Check Status Dump Restore Missing Peers Properties Files Resetting Tungsten User Privileges Send Heartbeat State Overview Tungsten Slave Resync How To Use It Trim Log Files Binlogs Info Logs Total Wipe/Reinstallation Of Tungsten Verifying Replication With Checksumming","title":"Tungsten Administration"},{"location":"secondary_response/cpu_wait/","text":"Diagnosing CPU Wait problems When analyzing performance on a server, you may find that load is high even though actual CPU utilization is low. Such cases are commonly because some other resource, such as disk I/O, is over-utilized or unresponsive and causing processes to enter an uninterruptible sleep state while waiting for that resource to return data. This is sometimes known as CPU or I/O Wait and it can cause site outages that are difficult to diagnose. Usually, CPU Wait is short term, since most I/O resources will return data rather quickly. However, if a network socket or disk is over-utilized or unresponsive, the process will also become unresponsive, even to kill -9 . This can happen to any process that is performing I/O, but the process is not necessarily the cause of the problem! Tools to Identify CPU Wait The tools listed below are sorted from most general diagnostics to most specific. SignalFX We have various SFX dashboards for triaging site performance: Stack Glance : for quick triaging of CPU, memory, disk space, disk I/O, and network connections. Cluster Health : for an overview of a full site's traffic, PHP processes, cron processes, etc. vmstat If there are any processes currently in the uninterruptible sleep state vmstat -w will display how many under the b column. ps Use this to identify information about each process in CPU Wait. ps -elF | awk '$2~/D/' iostat If CPU Wait is caused by an over-utilized disk, this will help you diagnose which device is most utilized: iostat -xm 1 lsof This tool displays information about open files and what processes have them. This output is verbose and difficult to parse, but may reveal if a process has an unusual number of open files. You may specify a disk mountpoint (I.e. /mnt or /vol/ebs1 ) if CPU Wait is caused by disk I/O utilization: lsof ${MOUNTPOINT} If you want to know what files a process has open: lsof -p ${PID} If you want to check all TCP calls (this is what site-externalcalls uses for PHP, go read it in ops-misc ): lsof -a -iTCP -P strace This might give you a clue about what files a process is accessing: strace -yy -e trace=desc -p ${PID} If you want information regarding network system calls: strace -yy -e trace=network -p ${PID} See also the runbook on strace . Responses The appropriate response to resolve a problem caused by CPU Wait will be specific to the layer it's encountered in. Balancers In certain rare cases, balancers with sites serving large files will have Nginx cache those files to disk in /mnt/nginx/cache/proxy_temp and return a 206 Partial Content response to the requester. This isn't usually a problem, but it can be very difficult to diagnose when it is! You must dig into the balancer logs to find the root cause. The following command will read through the given Nginx log (I.e. /mnt/log/nginx/ssl-access.log ) and return the top five unique requests resulting in a Partial Content response (by size in bytes), and the site the request belongs to: LOG= grep -E 'status=206' ${LOG} \\ | awk -F\\\" 'match($0, /hosting_site=([^ ]+)/, s) && match($3, /[0-9]+ *([0-9]+)/, b) {sum_bytes[s[1]\" \"$2]+=b[1]}; \\ END {for (i in sum_bytes) {print sum_bytes[i], i}}' \\ | sort -n \\ | tail -n5 You can find the actual size of these files by searching for them on the customer's filesystem. With this information, coordinate with Support to find a solution. There is often no easy solution here. The customer may need to change how their files are cached, how large the file is, rate-limit requests for the file, or stop serving the file entirely. Webs CPU Wait most commonly affects processes on webs when PHP is hanging on external calls, a slow or unresponsive gluster mount, or slow MySQL queries. Once you resolve the root cause, you may need to restart PHP. FS Gluster commonly experiences CPU Wait due to high disk utilization on the brick volume. This is usually caused by customer code or a traffic spike thrashing the volume. However, in some cases, particularly on FS servers with magnetic volumes, Gluster performance problems may be due to high inode counts in a single directory. Run the following command to get a count of the directories with the most files: find /mnt/gfs -xdev -printf '%h\\n' | sort | uniq -c | sort -n | tail -n 10 Be patient, this command will take a long time to complete on large volumes. There is no hard limit for how large or small a directory must be to cause a problem, but problems have been identified for directories with inode counts of ~10,000. Communicate your findings with Support to work with the customer on a solution. The customer may need to clean up their directories or migrate their volumes to SSD if applicable. In extremely rare cases, a server may encounter disk I/O problems with the backup volume and cause access to the main FS volume to lock up when the backup rsync is running. DB MySQL usually only encounters CPU Wait problems when the database is suffering from slow queries and over-utilizing a cache table. If this is not the case, then something may be wrong with MySQL or the DB volume and the incident should be escalated to a DBA.","title":"Diagnosing CPU Wait problems"},{"location":"secondary_response/cpu_wait/#diagnosing-cpu-wait-problems","text":"When analyzing performance on a server, you may find that load is high even though actual CPU utilization is low. Such cases are commonly because some other resource, such as disk I/O, is over-utilized or unresponsive and causing processes to enter an uninterruptible sleep state while waiting for that resource to return data. This is sometimes known as CPU or I/O Wait and it can cause site outages that are difficult to diagnose. Usually, CPU Wait is short term, since most I/O resources will return data rather quickly. However, if a network socket or disk is over-utilized or unresponsive, the process will also become unresponsive, even to kill -9 . This can happen to any process that is performing I/O, but the process is not necessarily the cause of the problem!","title":"Diagnosing CPU Wait problems"},{"location":"secondary_response/cpu_wait/#tools-to-identify-cpu-wait","text":"The tools listed below are sorted from most general diagnostics to most specific.","title":"Tools to Identify CPU Wait"},{"location":"secondary_response/cpu_wait/#signalfx","text":"We have various SFX dashboards for triaging site performance: Stack Glance : for quick triaging of CPU, memory, disk space, disk I/O, and network connections. Cluster Health : for an overview of a full site's traffic, PHP processes, cron processes, etc.","title":"SignalFX"},{"location":"secondary_response/cpu_wait/#vmstat","text":"If there are any processes currently in the uninterruptible sleep state vmstat -w will display how many under the b column.","title":"vmstat"},{"location":"secondary_response/cpu_wait/#ps","text":"Use this to identify information about each process in CPU Wait. ps -elF | awk '$2~/D/'","title":"ps"},{"location":"secondary_response/cpu_wait/#iostat","text":"If CPU Wait is caused by an over-utilized disk, this will help you diagnose which device is most utilized: iostat -xm 1","title":"iostat"},{"location":"secondary_response/cpu_wait/#lsof","text":"This tool displays information about open files and what processes have them. This output is verbose and difficult to parse, but may reveal if a process has an unusual number of open files. You may specify a disk mountpoint (I.e. /mnt or /vol/ebs1 ) if CPU Wait is caused by disk I/O utilization: lsof ${MOUNTPOINT} If you want to know what files a process has open: lsof -p ${PID} If you want to check all TCP calls (this is what site-externalcalls uses for PHP, go read it in ops-misc ): lsof -a -iTCP -P","title":"lsof"},{"location":"secondary_response/cpu_wait/#strace","text":"This might give you a clue about what files a process is accessing: strace -yy -e trace=desc -p ${PID} If you want information regarding network system calls: strace -yy -e trace=network -p ${PID} See also the runbook on strace .","title":"strace"},{"location":"secondary_response/cpu_wait/#responses","text":"The appropriate response to resolve a problem caused by CPU Wait will be specific to the layer it's encountered in.","title":"Responses"},{"location":"secondary_response/cpu_wait/#balancers","text":"In certain rare cases, balancers with sites serving large files will have Nginx cache those files to disk in /mnt/nginx/cache/proxy_temp and return a 206 Partial Content response to the requester. This isn't usually a problem, but it can be very difficult to diagnose when it is! You must dig into the balancer logs to find the root cause. The following command will read through the given Nginx log (I.e. /mnt/log/nginx/ssl-access.log ) and return the top five unique requests resulting in a Partial Content response (by size in bytes), and the site the request belongs to: LOG= grep -E 'status=206' ${LOG} \\ | awk -F\\\" 'match($0, /hosting_site=([^ ]+)/, s) && match($3, /[0-9]+ *([0-9]+)/, b) {sum_bytes[s[1]\" \"$2]+=b[1]}; \\ END {for (i in sum_bytes) {print sum_bytes[i], i}}' \\ | sort -n \\ | tail -n5 You can find the actual size of these files by searching for them on the customer's filesystem. With this information, coordinate with Support to find a solution. There is often no easy solution here. The customer may need to change how their files are cached, how large the file is, rate-limit requests for the file, or stop serving the file entirely.","title":"Balancers"},{"location":"secondary_response/cpu_wait/#webs","text":"CPU Wait most commonly affects processes on webs when PHP is hanging on external calls, a slow or unresponsive gluster mount, or slow MySQL queries. Once you resolve the root cause, you may need to restart PHP.","title":"Webs"},{"location":"secondary_response/cpu_wait/#fs","text":"Gluster commonly experiences CPU Wait due to high disk utilization on the brick volume. This is usually caused by customer code or a traffic spike thrashing the volume. However, in some cases, particularly on FS servers with magnetic volumes, Gluster performance problems may be due to high inode counts in a single directory. Run the following command to get a count of the directories with the most files: find /mnt/gfs -xdev -printf '%h\\n' | sort | uniq -c | sort -n | tail -n 10 Be patient, this command will take a long time to complete on large volumes. There is no hard limit for how large or small a directory must be to cause a problem, but problems have been identified for directories with inode counts of ~10,000. Communicate your findings with Support to work with the customer on a solution. The customer may need to clean up their directories or migrate their volumes to SSD if applicable. In extremely rare cases, a server may encounter disk I/O problems with the backup volume and cause access to the main FS volume to lock up when the backup rsync is running.","title":"FS"},{"location":"secondary_response/cpu_wait/#db","text":"MySQL usually only encounters CPU Wait problems when the database is suffering from slow queries and over-utilizing a cache table. If this is not the case, then something may be wrong with MySQL or the DB volume and the incident should be escalated to a DBA.","title":"DB"},{"location":"secondary_response/db_error_lock_wait_timeout/","text":"MySQL lock_wait_timeout errors This runbook describes what to do if the application starts generating a lot of lock_wait_timeout errors and Support asks us to investigate. Background The lock_wait_timeout error occurs when a query on the database server has to wait for more than a certain amount of time before getting a lock that it requested. We use the MySQL default of 50 seconds for that timeout. This means that if a long-running transaction has locked some records for more than 50 seconds other transactions will be waiting for 50 seconds to get locks on the same records before timing out with the error above. It is important to note the difference between a query and a transaction at this point. A transaction can consist of multiple queries and any lock acquired by any query in the transaction will stay in place for the duration of the entire transaction. This is true even if the transaction does not appear to be doing anything in the MySQL process list, i.e. the state is sleeping. So the MySQL process list is not the first place to look for information on this. Instead we should start with the InnoDB engine status command. Optional: Verify how many processes are waiting Since waiting processes will time out after 50 seconds the number of processes is not going to be extremely high but it is a good measure of how many processes are actually being blocked. If it's a single process the impact is more limited than if there are 50 waiting processes. On active database server run the following command: mysql -NBe \"SELECT count(*) FROM information_schema.INNODB_TRX where trx_state = 'LOCK WAIT';\" Finding the long-running transaction To find out if there is a long-running transaction ssh to the database server and run the following command: sudo bash -c 'export dt=/mnt/tmp/$(date +%Y%m%d_%H%M%S)_mysql_proclist.txt;\\ mysql -r -e \"show full processlist; show engine innodb status;\" > ${dt};\\ less ${dt}' This will produce a long output which combines the MySQL process list at the top and the InnoDB status output at the bottom. The very last section lists all current transactions. The transactions are sorted by duration so the longest running one is all the way at the bottom. A typical output for a long-running transaction looks like this: ---TRANSACTION 99166651, ACTIVE 7377 sec 11 lock struct(s), heap size 1248, 6 row lock(s), undo log entries 5 MySQL thread id 51106318, OS thread handle 0x7fb39777c700, query id 4149696247 web-544.enterprise-g1.hosting Trx read view will not see trx with id >= 99166659, sees < 99165838 TABLE LOCK table \"ideaden20db86218\".\"commerce_order\" trx id 99166651 lock mode IX RECORD LOCKS space id 0 page no 694892 n bits 136 index \"PRIMARY\" of table \"ideaden20db86218\".\"commerce_order\" TABLE LOCK table \"ideaden20db86218\".\"commerce_order_revision\" trx id 99166651 lock mode IX RECORD LOCKS space id 0 page no 1237582 n bits 136 index \"PRIMARY\" of table \"ideaden20db86218\".\"commerce_order_ TABLE LOCK table \"ideaden20db86218\".\"variable\" trx id 99166651 lock mode IX RECORD LOCKS space id 0 page no 1197691 n bits 216 index \"PRIMARY\" of table \"ideaden20db86218\".\"variable\" trx id TABLE LOCK table \"ideaden20db86218\".\"sessions\" trx id 99166651 lock mode IX RECORD LOCKS space id 0 page no 408359 n bits 120 index \"PRIMARY\" of table \"ideaden20db86218\".\"sessions\" trx id RECORD LOCKS space id 0 page no 809856 n bits 144 index \"PRIMARY\" of table \"ideaden20db86218\".\"variable\" trx id TABLE LOCK table \"ideaden20db86218\".\"queue\" trx id 99166651 lock mode IX TOO MANY LOCKS PRINTED FOR THIS TRX: SUPPRESSING FURTHER PRINTS The first line shows that the transaction has been active for 7377 seconds which is over 2 hours. That makes it a suspect for causing locking issues. The second line shows how many locks and undo log entries the transaction has. The undo log entries are relevant in case this connection needs to be killed. The number indicates how much work needs to be rolled back. In this example there are only 5 undo log entries so killing this transaction will be quick. If the number of rollback entries is in the thousands it will take some time for the kill to complete, potentially even hours. A rollback cannot be interrupted. Even restarting MySQL or rebooting the server will not help. Failing over during a rollback will almost guarantee split-brain. The third row is the important one. It shows the MySQL thread that we can look up in the MySQL process list. In this case that is 51106318. If we search from the top of the file for that number we find: Id User Host db Command Time State Info 51106318 s306 web-544.enterprise-g1.hosting.acquia.com:49992 ideaden20db86218 Sleep 0 NULL The word Sleep indicates that the transaction is currently sleeping between queries. Since it's sleeping it also does not show a long time execution time and it won't show up in the slow query log. The information in this line is important because it gives us the web server and the port from which it is connecting to the database server. Finding the PHP process The next step is to ssh to web-544 and retrieve the process info by grepping lsof on the port number. [23:08:18] root@web-544.enterprise-g1:~# lsof | grep 49992 php-fpm 29251 ideaden2 9u IPv4 959291144 0t0 TCP web-544.enterprise-g1.hosting Now we know that the process in question is an fpm process. In case the process is an php-fpm process there is a good chance that this is an actual web request. It is unlikely that the user is still expecting a response after 2 hours so the best approach is to kill the process. kill 29251 In case the process is a regular php process it is likely a drush process. Drush process are batch jobs that can modify a lot of data and we need customer permission to kill it . Killing a drush process can also take a lot of time because all the changes have to be rolled back. Report to Support Since database transactions are customer code it is important that we provide feedback to the customer that their code runs for a long time and blocks other processes. This means that when this happens we have to create ZenDesk ticket with all the info for the transaction from the InnoDB status output command as well as the linux process id for searching the log files. It's up to the customer to determine from that output which code was running for so long.","title":"MySQL lock_wait_timeout errors"},{"location":"secondary_response/db_error_lock_wait_timeout/#mysql-lock_wait_timeout-errors","text":"This runbook describes what to do if the application starts generating a lot of lock_wait_timeout errors and Support asks us to investigate.","title":"MySQL lock_wait_timeout errors"},{"location":"secondary_response/db_error_lock_wait_timeout/#background","text":"The lock_wait_timeout error occurs when a query on the database server has to wait for more than a certain amount of time before getting a lock that it requested. We use the MySQL default of 50 seconds for that timeout. This means that if a long-running transaction has locked some records for more than 50 seconds other transactions will be waiting for 50 seconds to get locks on the same records before timing out with the error above. It is important to note the difference between a query and a transaction at this point. A transaction can consist of multiple queries and any lock acquired by any query in the transaction will stay in place for the duration of the entire transaction. This is true even if the transaction does not appear to be doing anything in the MySQL process list, i.e. the state is sleeping. So the MySQL process list is not the first place to look for information on this. Instead we should start with the InnoDB engine status command.","title":"Background"},{"location":"secondary_response/db_error_lock_wait_timeout/#optional-verify-how-many-processes-are-waiting","text":"Since waiting processes will time out after 50 seconds the number of processes is not going to be extremely high but it is a good measure of how many processes are actually being blocked. If it's a single process the impact is more limited than if there are 50 waiting processes. On active database server run the following command: mysql -NBe \"SELECT count(*) FROM information_schema.INNODB_TRX where trx_state = 'LOCK WAIT';\"","title":"Optional: Verify how many processes are waiting"},{"location":"secondary_response/db_error_lock_wait_timeout/#finding-the-long-running-transaction","text":"To find out if there is a long-running transaction ssh to the database server and run the following command: sudo bash -c 'export dt=/mnt/tmp/$(date +%Y%m%d_%H%M%S)_mysql_proclist.txt;\\ mysql -r -e \"show full processlist; show engine innodb status;\" > ${dt};\\ less ${dt}' This will produce a long output which combines the MySQL process list at the top and the InnoDB status output at the bottom. The very last section lists all current transactions. The transactions are sorted by duration so the longest running one is all the way at the bottom. A typical output for a long-running transaction looks like this: ---TRANSACTION 99166651, ACTIVE 7377 sec 11 lock struct(s), heap size 1248, 6 row lock(s), undo log entries 5 MySQL thread id 51106318, OS thread handle 0x7fb39777c700, query id 4149696247 web-544.enterprise-g1.hosting Trx read view will not see trx with id >= 99166659, sees < 99165838 TABLE LOCK table \"ideaden20db86218\".\"commerce_order\" trx id 99166651 lock mode IX RECORD LOCKS space id 0 page no 694892 n bits 136 index \"PRIMARY\" of table \"ideaden20db86218\".\"commerce_order\" TABLE LOCK table \"ideaden20db86218\".\"commerce_order_revision\" trx id 99166651 lock mode IX RECORD LOCKS space id 0 page no 1237582 n bits 136 index \"PRIMARY\" of table \"ideaden20db86218\".\"commerce_order_ TABLE LOCK table \"ideaden20db86218\".\"variable\" trx id 99166651 lock mode IX RECORD LOCKS space id 0 page no 1197691 n bits 216 index \"PRIMARY\" of table \"ideaden20db86218\".\"variable\" trx id TABLE LOCK table \"ideaden20db86218\".\"sessions\" trx id 99166651 lock mode IX RECORD LOCKS space id 0 page no 408359 n bits 120 index \"PRIMARY\" of table \"ideaden20db86218\".\"sessions\" trx id RECORD LOCKS space id 0 page no 809856 n bits 144 index \"PRIMARY\" of table \"ideaden20db86218\".\"variable\" trx id TABLE LOCK table \"ideaden20db86218\".\"queue\" trx id 99166651 lock mode IX TOO MANY LOCKS PRINTED FOR THIS TRX: SUPPRESSING FURTHER PRINTS The first line shows that the transaction has been active for 7377 seconds which is over 2 hours. That makes it a suspect for causing locking issues. The second line shows how many locks and undo log entries the transaction has. The undo log entries are relevant in case this connection needs to be killed. The number indicates how much work needs to be rolled back. In this example there are only 5 undo log entries so killing this transaction will be quick. If the number of rollback entries is in the thousands it will take some time for the kill to complete, potentially even hours. A rollback cannot be interrupted. Even restarting MySQL or rebooting the server will not help. Failing over during a rollback will almost guarantee split-brain. The third row is the important one. It shows the MySQL thread that we can look up in the MySQL process list. In this case that is 51106318. If we search from the top of the file for that number we find: Id User Host db Command Time State Info 51106318 s306 web-544.enterprise-g1.hosting.acquia.com:49992 ideaden20db86218 Sleep 0 NULL The word Sleep indicates that the transaction is currently sleeping between queries. Since it's sleeping it also does not show a long time execution time and it won't show up in the slow query log. The information in this line is important because it gives us the web server and the port from which it is connecting to the database server.","title":"Finding the long-running transaction"},{"location":"secondary_response/db_error_lock_wait_timeout/#finding-the-php-process","text":"The next step is to ssh to web-544 and retrieve the process info by grepping lsof on the port number. [23:08:18] root@web-544.enterprise-g1:~# lsof | grep 49992 php-fpm 29251 ideaden2 9u IPv4 959291144 0t0 TCP web-544.enterprise-g1.hosting Now we know that the process in question is an fpm process. In case the process is an php-fpm process there is a good chance that this is an actual web request. It is unlikely that the user is still expecting a response after 2 hours so the best approach is to kill the process. kill 29251 In case the process is a regular php process it is likely a drush process. Drush process are batch jobs that can modify a lot of data and we need customer permission to kill it . Killing a drush process can also take a lot of time because all the changes have to be rolled back.","title":"Finding the PHP process"},{"location":"secondary_response/db_error_lock_wait_timeout/#report-to-support","text":"Since database transactions are customer code it is important that we provide feedback to the customer that their code runs for a long time and blocks other processes. This means that when this happens we have to create ZenDesk ticket with all the info for the transaction from the InnoDB status output command as well as the linux process id for searching the log files. It's up to the customer to determine from that output which code was running for so long.","title":"Report to Support"},{"location":"secondary_response/disable_acp_sales/","text":"Disable DevCloud Purchases If launches are broken in ACP or free tier, disable automated provisioning and relaunching. Procedure Go to https://insight.acquia.com/admin/acquia/ecommerce Sign in with your network credentials Check the checkbox labelled \"Disable Dev Cloud purchases\" Click Add \"Journal entry\" and add the reason why it was disabled and the jira ticket number. Then click \"Save configuration\". Alternate Procedure If you are unable to disable DevCloud Purchases via the links presented above, please follow the below procedure: # ssh to ded-5.network cd /var/www/html/insight.prod/docroot/ drush vset -y acquia_ecommerce_disable_purchases 1 Once complete, open a BZ ticket that you cannot access the insight or network pages to disable DevCloud Purchases.","title":"Disable DevCloud Purchases"},{"location":"secondary_response/disable_acp_sales/#disable-devcloud-purchases","text":"If launches are broken in ACP or free tier, disable automated provisioning and relaunching.","title":"Disable DevCloud Purchases"},{"location":"secondary_response/disable_acp_sales/#procedure","text":"Go to https://insight.acquia.com/admin/acquia/ecommerce Sign in with your network credentials Check the checkbox labelled \"Disable Dev Cloud purchases\" Click Add \"Journal entry\" and add the reason why it was disabled and the jira ticket number. Then click \"Save configuration\".","title":"Procedure"},{"location":"secondary_response/disable_acp_sales/#alternate-procedure","text":"If you are unable to disable DevCloud Purchases via the links presented above, please follow the below procedure: # ssh to ded-5.network cd /var/www/html/insight.prod/docroot/ drush vset -y acquia_ecommerce_disable_purchases 1 Once complete, open a BZ ticket that you cannot access the insight or network pages to disable DevCloud Purchases.","title":"Alternate Procedure"},{"location":"secondary_response/dump_restore_all/","text":"Dump Restore All Tungsten Hosts Assume we have a 4 server cluster and all of the slave nodes are failing: Procedure Set Variables. The GOOD_HOST_SERVICE is the name internal to Tungsten that is simply the hostname with the hyphen stripped out. OP= GOOD_HOST= GOOD_HOST_SERVICE=$(echo ${GOOD_HOST} | sed -e 's/-//') REGION=$(ah-server list ${GOOD_HOST} --no-name -c ec2_region) SITE=$(ah-site list on:${GOOD_HOST} | head -1) ALL_HOSTS=($(ah-server list site:${SITE} \\ -w type=fsdbmesh status=0)) ALL_HOSTS_CSV=\"$(printf %s, ${ALL_HOSTS[@]})\" BAD_HOSTS=\"$(echo ${ALL_HOSTS[@]/$GOOD_HOST} | tr ',' ' ')\" BAD_HOSTS_CSV=\"$(printf %s, ${ALL_HOSTS[@]/$GOOD_HOST})\" BAD_HOSTS_SERVICES=($(echo ${ALL_HOSTS[@]/$GOOD_HOST} | tr -d '-')) ALL_HOSTS_SERVICES_CSV=\"$(echo ${GOOD_HOST_SERVICE} ${BAD_HOSTS_SERVICES[@]} | tr ' ' ',')\" echo \"{noformat:title=Variables}\" \\ && echo \"OP=${OP}\" \\ && echo \"GOOD_HOST=${GOOD_HOST}\" \\ && echo \"GOOD_HOST_SERVICE=${GOOD_HOST_SERVICE}\" \\ && echo \"REGION=${REGION}\" \\ && echo \"SITE=${SITE}\" \\ && echo \"ALL_HOSTS=(${ALL_HOSTS[@]})\" \\ && echo \"ALL_HOSTS_CSV=${ALL_HOSTS_CSV}\" \\ && echo \"ALL_HOSTS_SERVICES_CSV=${ALL_HOSTS_SERVICES_CSV}\" \\ && echo \"BAD_HOSTS=${BAD_HOSTS}\" \\ && echo \"BAD_HOSTS_CSV=${BAD_HOSTS_CSV}\" \\ && echo \"BAD_HOSTS_SERVICES=${BAD_HOSTS_SERVICES[@]}\" \\ && echo \"{noformat}\" Lock the database to the good host: ah-db-cluster lock ${GOOD_HOST} The pt-heartbeat service can conflict with restoring the database so it needs to be disabled for the duration along with cron . fpdsh -p 1 -l ${ALL_HOSTS_CSV} -c \"\\ sudo puppet agent --disable ${OP}; \\ sudo service pt-heartbeat stop; \\ sudo service cron stop\" OR in Masterless Puppet mode fpdsh -p 1 -l ${ALL_HOSTS_CSV} -c \"\\ sudo ah-puppet-disable ${OP}; \\ sudo service pt-heartbeat stop; \\ sudo service cron stop\" Unload Tungsten services from the Good host: for service in ${BAD_HOSTS_SERVICES[@]}; do fssh ${GOOD_HOST} \"\\ PATH=\\$PATH:/usr/local/tungsten-replicator/tungsten/tungsten-replicator/bin/; \\ sudo trepctl -service ${service} unload -y\" done Stop treplicator on the bad hosts. fpdsh -p 1 -l ${BAD_HOSTS_CSV} -c \"sudo service treplicator stop\" NOTE: At this point replication is completely broken. Purge the Tungsten logs for all bad servers from all hosts: for service in ${BAD_HOSTS_SERVICES[@]}; do fpdsh -p 1 -l ${ALL_HOSTS_CSV} -c \"\\ PATH=\\$PATH:/usr/local/tungsten-replicator/tungsten/tungsten-replicator/bin/; \\ sudo thl -service ${service} purge -y\" done Purge the Tungsten logs for the good host from all bad hosts: fpdsh -p 1 -l ${BAD_HOSTS_CSV} -c \"\\ PATH=\\$PATH:/usr/local/tungsten-replicator/tungsten/tungsten-replicator/bin/; \\ sudo thl -service ${GOOD_HOST_SERVICE} purge -y\" Drop the Tungsten databases on all hosts: for service in ${BAD_HOSTS_SERVICES[@]}; do fpdsh -p 1 -l ${ALL_HOSTS_CSV} -c \"sudo mysql -e 'drop database tungsten_${service}'\" done Dump The DB NOTE : We dump the DB to the ephemeral volume. Before continuing ensure there is enough free space available. A DB typically compresses with an approximate ratio of 1:10 compared to the size of the MySQL data directory (/vol/ebs1/mysql). If there is not clearly enough room, you will have to create and attach a temporary EBS volume. That is beyond the scope of this procedure. Dump the DB to ephemeral on the good host: fssh ${GOOD_HOST} \"sudo mysqldump \\ --complete-insert \\ --disable-keys \\ --single-transaction \\ --order-by-primary \\ --all-databases \\ --innodb-optimize-keys \\ --ignore-table mysql.user \\ | pv \\ | gzip > /mnt/tmp/restore$(date +%Y%m%d).sql.gz\" Log out of the good host. Prepare Bad Hosts For The DR Copy the DB to the bad server using fscp . Noting that using -3 provides no output or progress bar. FILE=\"restore$(date +%Y%m%d).sql.gz\" for bad_host in ${BAD_HOSTS[@]}; do echo \"Copying ${FILE} from ${GOOD_HOST} to ${bad_host}\" fscp ${GOOD_HOST}:/mnt/tmp/restore$(date +%Y%m%d).sql.gz \\ ${bad_host}:/mnt/tmp/ -3 done Clear old logs from the Bad hosts: fpdsh -l ${BAD_HOSTS_CSV} -c \"sudo rm -vrf /vol/ebs1/tungsten-replicator/thl/{${ALL_HOSTS_SERVICES_CSV}}\" Restore The DB Restore the DB. Depending on the size of the database this can take a long time. Since we're running the restores in parallel we can't use pv to show progress. Keep in mind that the restore takes place through fpdsh. Breaking off fpdsh does not stop the restore in case you run into a problem. You have to log into each server separately and kill the restore mysql thread to do that. fpdsh -t ${BAD_HOSTS_CSV} -c \"\\ sudo rm /mnt/tmp/nolog.sql; \\ echo 'SET sql_log_bin=0;' > /mnt/tmp/nolog.sql; \\ zcat -f /mnt/tmp/nolog.sql /mnt/tmp/${FILE} | sudo mysql\" Fix a possible permissions issue fpdsh -t ${BAD_HOSTS_CSV} -c \"sudo chown -R tungsten:tungsten /usr/local/tungsten-replicator/thl\" Restore Replication Start treplicator on the, formerly, bad servers: fpdsh -p 1 -l ${BAD_HOSTS_CSV} -c \"sudo service treplicator start\" Start the replication service on the good host: for service in ${BAD_HOSTS_SERVICES[@]}; do fpdsh -l ${GOOD_HOST} -c \"\\ PATH=\\$PATH:/usr/local/tungsten-replicator/tungsten/tungsten-replicator/bin/; \\ sudo trepctl -service ${service} load\" done Verify replication fpdsh -p 1 -l ${ALL_HOSTS_CSV} -c \"\\ sudo /usr/local/tungsten-replicator/current/tungsten-replicator/bin/trepctl services \\ | egrep 'serviceName|state'\" Clean up fpdsh -p 1 -l ${ALL_HOSTS_CSV} -c \"\\ sudo puppet agent --enable \\ && sudo puppet agent -t\" OR in Masterless Puppet mode fpdsh -p 1 -l ${ALL_HOSTS_CSV} -c \"\\ sudo ah-puppet-enable \\ && sudo run-puppet\"","title":"Dump Restore All Tungsten Hosts"},{"location":"secondary_response/dump_restore_all/#dump-restore-all-tungsten-hosts","text":"Assume we have a 4 server cluster and all of the slave nodes are failing:","title":"Dump Restore All Tungsten Hosts"},{"location":"secondary_response/dump_restore_all/#procedure","text":"Set Variables. The GOOD_HOST_SERVICE is the name internal to Tungsten that is simply the hostname with the hyphen stripped out. OP= GOOD_HOST= GOOD_HOST_SERVICE=$(echo ${GOOD_HOST} | sed -e 's/-//') REGION=$(ah-server list ${GOOD_HOST} --no-name -c ec2_region) SITE=$(ah-site list on:${GOOD_HOST} | head -1) ALL_HOSTS=($(ah-server list site:${SITE} \\ -w type=fsdbmesh status=0)) ALL_HOSTS_CSV=\"$(printf %s, ${ALL_HOSTS[@]})\" BAD_HOSTS=\"$(echo ${ALL_HOSTS[@]/$GOOD_HOST} | tr ',' ' ')\" BAD_HOSTS_CSV=\"$(printf %s, ${ALL_HOSTS[@]/$GOOD_HOST})\" BAD_HOSTS_SERVICES=($(echo ${ALL_HOSTS[@]/$GOOD_HOST} | tr -d '-')) ALL_HOSTS_SERVICES_CSV=\"$(echo ${GOOD_HOST_SERVICE} ${BAD_HOSTS_SERVICES[@]} | tr ' ' ',')\" echo \"{noformat:title=Variables}\" \\ && echo \"OP=${OP}\" \\ && echo \"GOOD_HOST=${GOOD_HOST}\" \\ && echo \"GOOD_HOST_SERVICE=${GOOD_HOST_SERVICE}\" \\ && echo \"REGION=${REGION}\" \\ && echo \"SITE=${SITE}\" \\ && echo \"ALL_HOSTS=(${ALL_HOSTS[@]})\" \\ && echo \"ALL_HOSTS_CSV=${ALL_HOSTS_CSV}\" \\ && echo \"ALL_HOSTS_SERVICES_CSV=${ALL_HOSTS_SERVICES_CSV}\" \\ && echo \"BAD_HOSTS=${BAD_HOSTS}\" \\ && echo \"BAD_HOSTS_CSV=${BAD_HOSTS_CSV}\" \\ && echo \"BAD_HOSTS_SERVICES=${BAD_HOSTS_SERVICES[@]}\" \\ && echo \"{noformat}\" Lock the database to the good host: ah-db-cluster lock ${GOOD_HOST} The pt-heartbeat service can conflict with restoring the database so it needs to be disabled for the duration along with cron . fpdsh -p 1 -l ${ALL_HOSTS_CSV} -c \"\\ sudo puppet agent --disable ${OP}; \\ sudo service pt-heartbeat stop; \\ sudo service cron stop\" OR in Masterless Puppet mode fpdsh -p 1 -l ${ALL_HOSTS_CSV} -c \"\\ sudo ah-puppet-disable ${OP}; \\ sudo service pt-heartbeat stop; \\ sudo service cron stop\" Unload Tungsten services from the Good host: for service in ${BAD_HOSTS_SERVICES[@]}; do fssh ${GOOD_HOST} \"\\ PATH=\\$PATH:/usr/local/tungsten-replicator/tungsten/tungsten-replicator/bin/; \\ sudo trepctl -service ${service} unload -y\" done Stop treplicator on the bad hosts. fpdsh -p 1 -l ${BAD_HOSTS_CSV} -c \"sudo service treplicator stop\" NOTE: At this point replication is completely broken. Purge the Tungsten logs for all bad servers from all hosts: for service in ${BAD_HOSTS_SERVICES[@]}; do fpdsh -p 1 -l ${ALL_HOSTS_CSV} -c \"\\ PATH=\\$PATH:/usr/local/tungsten-replicator/tungsten/tungsten-replicator/bin/; \\ sudo thl -service ${service} purge -y\" done Purge the Tungsten logs for the good host from all bad hosts: fpdsh -p 1 -l ${BAD_HOSTS_CSV} -c \"\\ PATH=\\$PATH:/usr/local/tungsten-replicator/tungsten/tungsten-replicator/bin/; \\ sudo thl -service ${GOOD_HOST_SERVICE} purge -y\" Drop the Tungsten databases on all hosts: for service in ${BAD_HOSTS_SERVICES[@]}; do fpdsh -p 1 -l ${ALL_HOSTS_CSV} -c \"sudo mysql -e 'drop database tungsten_${service}'\" done","title":"Procedure"},{"location":"secondary_response/dump_restore_all/#dump-the-db","text":"NOTE : We dump the DB to the ephemeral volume. Before continuing ensure there is enough free space available. A DB typically compresses with an approximate ratio of 1:10 compared to the size of the MySQL data directory (/vol/ebs1/mysql). If there is not clearly enough room, you will have to create and attach a temporary EBS volume. That is beyond the scope of this procedure. Dump the DB to ephemeral on the good host: fssh ${GOOD_HOST} \"sudo mysqldump \\ --complete-insert \\ --disable-keys \\ --single-transaction \\ --order-by-primary \\ --all-databases \\ --innodb-optimize-keys \\ --ignore-table mysql.user \\ | pv \\ | gzip > /mnt/tmp/restore$(date +%Y%m%d).sql.gz\" Log out of the good host.","title":"Dump The DB"},{"location":"secondary_response/dump_restore_all/#prepare-bad-hosts-for-the-dr","text":"Copy the DB to the bad server using fscp . Noting that using -3 provides no output or progress bar. FILE=\"restore$(date +%Y%m%d).sql.gz\" for bad_host in ${BAD_HOSTS[@]}; do echo \"Copying ${FILE} from ${GOOD_HOST} to ${bad_host}\" fscp ${GOOD_HOST}:/mnt/tmp/restore$(date +%Y%m%d).sql.gz \\ ${bad_host}:/mnt/tmp/ -3 done Clear old logs from the Bad hosts: fpdsh -l ${BAD_HOSTS_CSV} -c \"sudo rm -vrf /vol/ebs1/tungsten-replicator/thl/{${ALL_HOSTS_SERVICES_CSV}}\"","title":"Prepare Bad Hosts For The DR"},{"location":"secondary_response/dump_restore_all/#restore-the-db","text":"Restore the DB. Depending on the size of the database this can take a long time. Since we're running the restores in parallel we can't use pv to show progress. Keep in mind that the restore takes place through fpdsh. Breaking off fpdsh does not stop the restore in case you run into a problem. You have to log into each server separately and kill the restore mysql thread to do that. fpdsh -t ${BAD_HOSTS_CSV} -c \"\\ sudo rm /mnt/tmp/nolog.sql; \\ echo 'SET sql_log_bin=0;' > /mnt/tmp/nolog.sql; \\ zcat -f /mnt/tmp/nolog.sql /mnt/tmp/${FILE} | sudo mysql\" Fix a possible permissions issue fpdsh -t ${BAD_HOSTS_CSV} -c \"sudo chown -R tungsten:tungsten /usr/local/tungsten-replicator/thl\"","title":"Restore The DB"},{"location":"secondary_response/dump_restore_all/#restore-replication","text":"Start treplicator on the, formerly, bad servers: fpdsh -p 1 -l ${BAD_HOSTS_CSV} -c \"sudo service treplicator start\" Start the replication service on the good host: for service in ${BAD_HOSTS_SERVICES[@]}; do fpdsh -l ${GOOD_HOST} -c \"\\ PATH=\\$PATH:/usr/local/tungsten-replicator/tungsten/tungsten-replicator/bin/; \\ sudo trepctl -service ${service} load\" done Verify replication fpdsh -p 1 -l ${ALL_HOSTS_CSV} -c \"\\ sudo /usr/local/tungsten-replicator/current/tungsten-replicator/bin/trepctl services \\ | egrep 'serviceName|state'\" Clean up fpdsh -p 1 -l ${ALL_HOSTS_CSV} -c \"\\ sudo puppet agent --enable \\ && sudo puppet agent -t\" OR in Masterless Puppet mode fpdsh -p 1 -l ${ALL_HOSTS_CSV} -c \"\\ sudo ah-puppet-enable \\ && sudo run-puppet\"","title":"Restore Replication"},{"location":"secondary_response/dump_restore_single/","text":"Dump Restore A Single Tungsten Slave Assume we have a 4 server cluster with a single node (server D) offline: Procedure Set Variables. The BAD_HOST_SERVICE is the name internal to Tungsten that is simply the hostname with the hyphen stripped out. OP= BAD_HOST= BAD_HOST_SERVICE=$(echo ${BAD_HOST} | sed -e 's/-//') REGION=$(ah-server list ${BAD_HOST} --no-name -c ec2_region) SITE=$(ah-site list on:${BAD_HOST} | head -1) ALL_HOSTS=($(ah-server list site:${SITE} \\ -w type=fsdbmesh status=0)) ALL_HOSTS_CSV=\"$(printf %s, ${ALL_HOSTS[@]})\" GOOD_HOSTS_CSV=\"$(printf %s, ${ALL_HOSTS[@]/$BAD_HOST})\" echo \"{noformat:title=Variables}\" \\ && echo \"OP=${OP}\" \\ && echo \"BAD_HOST=${BAD_HOST}\" \\ && echo \"BAD_HOST_SERVICE=${BAD_HOST_SERVICE}\" \\ && echo \"REGION=${REGION}\" \\ && echo \"SITE=${SITE}\" \\ && echo \"ALL_HOSTS=(${ALL_HOSTS[@]})\" \\ && echo \"ALL_HOSTS_CSV=${ALL_HOSTS_CSV}\" \\ && echo \"GOOD_HOSTS_CSV=${GOOD_HOSTS_CSV}\" \\ && echo \"{noformat}\" The pt-heartbeat service can conflict with restoring the database so it needs to be disabled for the duration. fpdsh -l ${ALL_HOSTS_CSV} -c \"\\ sudo puppet agent --disable ${OP} \\ sudo service pt-heartbeat stop\" OR in Masterless mode fpdsh -l ${ALL_HOSTS_CSV} -c \"\\ sudo ah-puppet-disable ${OP} \\ sudo service pt-heartbeat stop\" Stop treplicator on the bad host. fssh ${BAD_HOST} \"sudo service treplicator stop\" On the good hosts stop the replication service for the bad host. fpdsh -l ${GOOD_HOSTS_CSV} -c \"\\ PATH=\\$PATH:/usr/local/tungsten-replicator/tungsten/tungsten-replicator/bin/;\\ sudo trepctl -service ${BAD_HOST_SERVICE} unload -y \\ && sudo thl -service ${BAD_HOST_SERVICE} purge -y\" On all servers drop the bad DB: fpdsh -l ${ALL_HOSTS_CSV} -c \"\\ sudo mysql -e 'drop database tungsten_${BAD_HOST_SERVICE}'\" Dump The DB For this section you need to be on the pair of the bad host. In this example that is Server C NOTE : We dump the DB to the ephemeral volume. Before continuing ensure there is enough free space available. A DB typically compresses with an approximate ratio of (TODO figure out a sane ratio). If there is not clearly enough room, you will have to create and attach a temporary EBS volume. That is beyond the scope of this procedure. SSH to the paired host: PAIRED_HOST=$(ah-server list ${GOOD_HOSTS_CSV} -w ec2_region=${REGION}) fssh ${PAIRED_HOST} Dump the DB to ephemeral. mysqldump \\ --single-transaction \\ --order-by-primary \\ --all-databases \\ --innodb-optimize-keys \\ --ignore-table mysql.user \\ | pv \\ | gzip > /mnt/tmp/restore$(date +%Y%m%d).sql.gz Copy the DB to the bad server. Provided there is enough room on /mnt/gfs : cp /mnt/tmp/restore$(date +%Y%m%d).sql.gz /mnt/gfs/ If you must directly scp the file to the bad server, use fscp from the bastion. Noting that using -3 provides no output or progress bar. fscp ${PAIRED_HOST}:/mnt/tmp/restore$(date +%Y%m%d).sql.gz \\ ${BAD_HOST}:/mnt/tmp/ -3 Restore The DB NOTE : As above you need to have enough space on ephemeral for this to succeed. SSH to the bad server. fssh ${BAD_SERVER} Move the dump file from Gluster, if applicable: mv /mnt/gfs/restore$(date +%Y%m%d).sql.gz /mnt/tmp/ Clean up the host before restoring the DB: WARNING : Be wary of UTC midnight as the date will have changed. rm -rf /var/log/tungsten/* rm -Rf /vol/ebs1/tungsten-replicator/thl/* echo \"SET sql_log_bin=0;\" > /mnt/tmp/nolog.sql zcat -f /mnt/tmp/nolog.sql /mnt/tmp/restore$(date +%Y%m%d).sql.gz \\ | pv \\ | mysql Restore Replication Start the replication service: fpdsh -l ${GOOD_HOSTS_CSV} -c \"\\ PATH=\\$PATH:/usr/local/tungsten-replicator/tungsten/tungsten-replicator/bin/;\\ sudo trepctl -service ${BAD_HOST_SERVICE} load\" Start treplicator on the, formally, bad server: fssh ${BAD_HOST} \"sudo service treplicator start\" Clean up fpdsh -l ${ALL_HOSTS_CSV} -c \"\\ sudo puppet agent --enable \\ && sudo service pt-heartbeat start \\ && sudo puppet agent -t\" OR in Masterless Puppet mode fpdsh -l ${ALL_HOSTS_CSV} -c \"\\ sudo ah-puppet-enable \\ && sudo service pt-heartbeat start \\ && sudo run-puppet\"","title":"Dump Restore A Single Tungsten Slave"},{"location":"secondary_response/dump_restore_single/#dump-restore-a-single-tungsten-slave","text":"Assume we have a 4 server cluster with a single node (server D) offline:","title":"Dump Restore A Single Tungsten Slave"},{"location":"secondary_response/dump_restore_single/#procedure","text":"Set Variables. The BAD_HOST_SERVICE is the name internal to Tungsten that is simply the hostname with the hyphen stripped out. OP= BAD_HOST= BAD_HOST_SERVICE=$(echo ${BAD_HOST} | sed -e 's/-//') REGION=$(ah-server list ${BAD_HOST} --no-name -c ec2_region) SITE=$(ah-site list on:${BAD_HOST} | head -1) ALL_HOSTS=($(ah-server list site:${SITE} \\ -w type=fsdbmesh status=0)) ALL_HOSTS_CSV=\"$(printf %s, ${ALL_HOSTS[@]})\" GOOD_HOSTS_CSV=\"$(printf %s, ${ALL_HOSTS[@]/$BAD_HOST})\" echo \"{noformat:title=Variables}\" \\ && echo \"OP=${OP}\" \\ && echo \"BAD_HOST=${BAD_HOST}\" \\ && echo \"BAD_HOST_SERVICE=${BAD_HOST_SERVICE}\" \\ && echo \"REGION=${REGION}\" \\ && echo \"SITE=${SITE}\" \\ && echo \"ALL_HOSTS=(${ALL_HOSTS[@]})\" \\ && echo \"ALL_HOSTS_CSV=${ALL_HOSTS_CSV}\" \\ && echo \"GOOD_HOSTS_CSV=${GOOD_HOSTS_CSV}\" \\ && echo \"{noformat}\" The pt-heartbeat service can conflict with restoring the database so it needs to be disabled for the duration. fpdsh -l ${ALL_HOSTS_CSV} -c \"\\ sudo puppet agent --disable ${OP} \\ sudo service pt-heartbeat stop\" OR in Masterless mode fpdsh -l ${ALL_HOSTS_CSV} -c \"\\ sudo ah-puppet-disable ${OP} \\ sudo service pt-heartbeat stop\" Stop treplicator on the bad host. fssh ${BAD_HOST} \"sudo service treplicator stop\" On the good hosts stop the replication service for the bad host. fpdsh -l ${GOOD_HOSTS_CSV} -c \"\\ PATH=\\$PATH:/usr/local/tungsten-replicator/tungsten/tungsten-replicator/bin/;\\ sudo trepctl -service ${BAD_HOST_SERVICE} unload -y \\ && sudo thl -service ${BAD_HOST_SERVICE} purge -y\" On all servers drop the bad DB: fpdsh -l ${ALL_HOSTS_CSV} -c \"\\ sudo mysql -e 'drop database tungsten_${BAD_HOST_SERVICE}'\"","title":"Procedure"},{"location":"secondary_response/dump_restore_single/#dump-the-db","text":"For this section you need to be on the pair of the bad host. In this example that is Server C NOTE : We dump the DB to the ephemeral volume. Before continuing ensure there is enough free space available. A DB typically compresses with an approximate ratio of (TODO figure out a sane ratio). If there is not clearly enough room, you will have to create and attach a temporary EBS volume. That is beyond the scope of this procedure. SSH to the paired host: PAIRED_HOST=$(ah-server list ${GOOD_HOSTS_CSV} -w ec2_region=${REGION}) fssh ${PAIRED_HOST} Dump the DB to ephemeral. mysqldump \\ --single-transaction \\ --order-by-primary \\ --all-databases \\ --innodb-optimize-keys \\ --ignore-table mysql.user \\ | pv \\ | gzip > /mnt/tmp/restore$(date +%Y%m%d).sql.gz Copy the DB to the bad server. Provided there is enough room on /mnt/gfs : cp /mnt/tmp/restore$(date +%Y%m%d).sql.gz /mnt/gfs/ If you must directly scp the file to the bad server, use fscp from the bastion. Noting that using -3 provides no output or progress bar. fscp ${PAIRED_HOST}:/mnt/tmp/restore$(date +%Y%m%d).sql.gz \\ ${BAD_HOST}:/mnt/tmp/ -3","title":"Dump The DB"},{"location":"secondary_response/dump_restore_single/#restore-the-db","text":"NOTE : As above you need to have enough space on ephemeral for this to succeed. SSH to the bad server. fssh ${BAD_SERVER} Move the dump file from Gluster, if applicable: mv /mnt/gfs/restore$(date +%Y%m%d).sql.gz /mnt/tmp/ Clean up the host before restoring the DB: WARNING : Be wary of UTC midnight as the date will have changed. rm -rf /var/log/tungsten/* rm -Rf /vol/ebs1/tungsten-replicator/thl/* echo \"SET sql_log_bin=0;\" > /mnt/tmp/nolog.sql zcat -f /mnt/tmp/nolog.sql /mnt/tmp/restore$(date +%Y%m%d).sql.gz \\ | pv \\ | mysql","title":"Restore The DB"},{"location":"secondary_response/dump_restore_single/#restore-replication","text":"Start the replication service: fpdsh -l ${GOOD_HOSTS_CSV} -c \"\\ PATH=\\$PATH:/usr/local/tungsten-replicator/tungsten/tungsten-replicator/bin/;\\ sudo trepctl -service ${BAD_HOST_SERVICE} load\" Start treplicator on the, formally, bad server: fssh ${BAD_HOST} \"sudo service treplicator start\" Clean up fpdsh -l ${ALL_HOSTS_CSV} -c \"\\ sudo puppet agent --enable \\ && sudo service pt-heartbeat start \\ && sudo puppet agent -t\" OR in Masterless Puppet mode fpdsh -l ${ALL_HOSTS_CSV} -c \"\\ sudo ah-puppet-enable \\ && sudo service pt-heartbeat start \\ && sudo run-puppet\"","title":"Restore Replication"},{"location":"secondary_response/dump_restore_workflow/","text":"MySQL Dump Restore Workflow WARNING : This only applies to Classic Cloud. This runbook describes how to use the dump-restore workflow to copy all databases from the active database master to the passive database master to restore replication. A dump-restore should be used to address certain replication issues. Split-brain Duplicate key errors in replication indicate split-brain. If it is a single set of errors on transient tables (semaphore, cache, etc.) a dump-restore may not be necessary. If the errors recur or other tables are involved a dump-restore is needed. Missing binary log files If a MySQL has been down long enough for the binary log files to be cleared up on the other master, the only way to restore replication is through a dump-restore. Replication not set up In certain cases replication is not set up correctly. The only way to fix this is with a dump-restore. This may require additional steps. See the preparation steps for more details on this scenario. The dump-restore workflow is modeled after the dump-restore procedure using mysqldump. The XtraBackup method is not yet implemented. This means that for large data sets the workflow will be slower than manually running XtraBackup. It is also important to note that the dump-restore workflow was released in 1.90 so it's fairly new tool. Please report any bugs you find. The dump-restore workflow can take hours to complete if the data directory for the database servers is very large. For an estimate of how long it will take you can look at the size of the MySQL data directory which is located in /vol/ebs1/mysql. Unfortunately the duration has many dependencies like processor speed, I/O speed, data set size, number of indexes, etc. which makes it almost impossible to predict. Very broadly speaking, a 10GB data directory will take over an hour. Preparation Ensure there is no replication lag on either server Before starting a dump-restore we need to be sure as much data has been replicated as possible. Most importantly, any data that is not replicated from the passive database server to the active database server will be lost during a dump-restore. To minimize data loss always make sure replication lag is 0 on both servers before starting the procedure. To do this, run mysql-slave-resync.pl multiple times on both database servers to make sure there is no lag and skip all data inconsistencies. That includes all inconsistencies on non-transient tables. It's necessary to run it multiple times because new inconsistencies may show up after a while. There is no fixed number of times to run this but a minimum of 3 is a good rule of thumb unless the third run still shows issues. Make sure there is enough space on the ephemeral volume The backup (mysqldump file) will be stored in /mnt/tmp so make sure there is enough space available on the ephemeral volume for the backup or the workflow will fail. It is hard to provide an accurate estimate for the necessary space but 10% of the total data directory is probably the easiest way to get some form of an estimate. echo \"Estimated space needed: $(du -d0 /vol/ebs1/mysql -B10G | cut -f1)G\" echo \"Space available on ephemeral: $(df /dev/xvdb -BG | tail -n1 | sed \"s/ \\+/\\t/g\" | cut -f4)\" If there is no way to make enough space available on the ephemeral volume you can use the --path parameter to specify an alternative location. Verify that replication is set up In certain cases replication is not set up correctly. This means that the host, username and/or password are not available on the replication slave or are wrong. If the information is missing the SHOW SLAVE STATUS command will show an empty result set on the slave. Otherwise it will show a connection error indicating the problem. mysql [(none)]> show slave status\\G Empty set (0.00 sec) Starting the workflow First set the active and passive masters. Be sure to verify which is the active master before running this. The workflow will not verify this and if you specify the passive master as the source a lot of data will be lost. ACTIVE= PASSIVE= Important Note Do not abort workflows! If you are unable to resolve a problem with a workflow, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership The command below kicks off the workflow ah-db-cluster dump-restore $ACTIVE $PASSIVE --method=mysqldump Required parameter --method This parameter specifies the method used for making the backup. Currently the only supported method is mysqldump. Optional parameter --path This parameter specifies the path where the dump file will be stored. This defaults to /mnt/tmp but can be specified to use another location if there is not enough space available. Standard workflow parameters The remaining parameters are all standard workflow parameters and not specific to this procedure. [--skip-task], [--no-skip-task] # Send a task to execute the workflow [--scheduled-time=SCHEDULED_TIME] # Send a scheduled task instead, with this start time (as epoch) [--pause-at-step=PAUSE_AT_STEP] # Create a queued workflow pause for this step name [--pause-description=PAUSE_DESCRIPTION] # The description for the queued workflow pause [--send-notifications], [--no-send-notifications] # Toggle notifications for this workflow, overriding default # behaviour set by the stage-wide variable. [--wait-for-task], [--no-wait-for-task] # Wait for any submitted tasks to be complete, and return the result. # Default: true [--debug], [--no-debug] # Set log level to Debug globally Verify replication After the workflow has completed, verify replication with ah-db-cluster status. Replication lag should be 0 on both servers. Trouble shooting Look at the workflow logs The workflow will get a workflow id. You can get the full logs for this workflow with the following command: ah-workflow get $ID --show-logs Why am I getting an error that I'm out of space when there is plenty of space? This happens because this error is not just triggered by being out of space. This is a known issue. It can occur for example if the customer is restoring a backup on the active master while mysqldump is running. The workflow stopped with an error This obviously depends on the type of error but if you can, fix the issue and resume the workflow. The most typical issue is for the ephemeral volume to fill up so in that case you can free up more space there and resume the workflow. If there is not enough space available start a new workflow and specify a different path. Duplicate entry error on mysql.innodb_index_stats table The error below is caused by an issue in Percona/MySQL 5.6. The mysql.innodb_index_stats table gets created and in the short amount of time between creation and locking it for insertion, it can have records inserted. There is an AUTO ticket for this: AUTO-1458 . [2017-01-01 16:55:20] ERROR: Caught Aq::System::NonZeroStatusError while running workflow: Command returned exit stdout was: stderr was: ERROR 1062 (23000) at line 460374: Duplicate entry 'g988821-themebuilder_assets-PRIMARY-n_diff_pfx01 In the mean time there is a workaround for this problem. After the failure, you can run the following commands on the target server. mysql -e \"SET GLOBAL innodb_stats_auto_recalc=0; SET GLOBAL innodb_stats_persistent=0;\" After that you can resume the workflow with the following command. This will restart the restore. ah-workflow resume <workflow id> After the workflow successfully completes go to the server that was restored again and reset the settings that we changed. mysql -e \"SET GLOBAL innodb_stats_auto_recalc=1; SET GLOBAL innodb_stats_persistent=1;\" Unexpected behavior Check with Team Auto and if necessary file an AUTO bug. Always add as much useful information as possible.","title":"MySQL Dump Restore Workflow"},{"location":"secondary_response/dump_restore_workflow/#mysql-dump-restore-workflow","text":"WARNING : This only applies to Classic Cloud. This runbook describes how to use the dump-restore workflow to copy all databases from the active database master to the passive database master to restore replication. A dump-restore should be used to address certain replication issues. Split-brain Duplicate key errors in replication indicate split-brain. If it is a single set of errors on transient tables (semaphore, cache, etc.) a dump-restore may not be necessary. If the errors recur or other tables are involved a dump-restore is needed. Missing binary log files If a MySQL has been down long enough for the binary log files to be cleared up on the other master, the only way to restore replication is through a dump-restore. Replication not set up In certain cases replication is not set up correctly. The only way to fix this is with a dump-restore. This may require additional steps. See the preparation steps for more details on this scenario. The dump-restore workflow is modeled after the dump-restore procedure using mysqldump. The XtraBackup method is not yet implemented. This means that for large data sets the workflow will be slower than manually running XtraBackup. It is also important to note that the dump-restore workflow was released in 1.90 so it's fairly new tool. Please report any bugs you find. The dump-restore workflow can take hours to complete if the data directory for the database servers is very large. For an estimate of how long it will take you can look at the size of the MySQL data directory which is located in /vol/ebs1/mysql. Unfortunately the duration has many dependencies like processor speed, I/O speed, data set size, number of indexes, etc. which makes it almost impossible to predict. Very broadly speaking, a 10GB data directory will take over an hour.","title":"MySQL Dump Restore Workflow"},{"location":"secondary_response/dump_restore_workflow/#preparation","text":"","title":"Preparation"},{"location":"secondary_response/dump_restore_workflow/#ensure-there-is-no-replication-lag-on-either-server","text":"Before starting a dump-restore we need to be sure as much data has been replicated as possible. Most importantly, any data that is not replicated from the passive database server to the active database server will be lost during a dump-restore. To minimize data loss always make sure replication lag is 0 on both servers before starting the procedure. To do this, run mysql-slave-resync.pl multiple times on both database servers to make sure there is no lag and skip all data inconsistencies. That includes all inconsistencies on non-transient tables. It's necessary to run it multiple times because new inconsistencies may show up after a while. There is no fixed number of times to run this but a minimum of 3 is a good rule of thumb unless the third run still shows issues.","title":"Ensure there is no replication lag on either server"},{"location":"secondary_response/dump_restore_workflow/#make-sure-there-is-enough-space-on-the-ephemeral-volume","text":"The backup (mysqldump file) will be stored in /mnt/tmp so make sure there is enough space available on the ephemeral volume for the backup or the workflow will fail. It is hard to provide an accurate estimate for the necessary space but 10% of the total data directory is probably the easiest way to get some form of an estimate. echo \"Estimated space needed: $(du -d0 /vol/ebs1/mysql -B10G | cut -f1)G\" echo \"Space available on ephemeral: $(df /dev/xvdb -BG | tail -n1 | sed \"s/ \\+/\\t/g\" | cut -f4)\" If there is no way to make enough space available on the ephemeral volume you can use the --path parameter to specify an alternative location.","title":"Make sure there is enough space on the ephemeral volume"},{"location":"secondary_response/dump_restore_workflow/#verify-that-replication-is-set-up","text":"In certain cases replication is not set up correctly. This means that the host, username and/or password are not available on the replication slave or are wrong. If the information is missing the SHOW SLAVE STATUS command will show an empty result set on the slave. Otherwise it will show a connection error indicating the problem. mysql [(none)]> show slave status\\G Empty set (0.00 sec)","title":"Verify that replication is set up"},{"location":"secondary_response/dump_restore_workflow/#starting-the-workflow","text":"First set the active and passive masters. Be sure to verify which is the active master before running this. The workflow will not verify this and if you specify the passive master as the source a lot of data will be lost. ACTIVE= PASSIVE=","title":"Starting the workflow"},{"location":"secondary_response/dump_restore_workflow/#important-note","text":"Do not abort workflows! If you are unable to resolve a problem with a workflow, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership The command below kicks off the workflow ah-db-cluster dump-restore $ACTIVE $PASSIVE --method=mysqldump","title":"Important Note"},{"location":"secondary_response/dump_restore_workflow/#required-parameter-method","text":"This parameter specifies the method used for making the backup. Currently the only supported method is mysqldump.","title":"Required parameter --method"},{"location":"secondary_response/dump_restore_workflow/#optional-parameter-path","text":"This parameter specifies the path where the dump file will be stored. This defaults to /mnt/tmp but can be specified to use another location if there is not enough space available.","title":"Optional parameter --path"},{"location":"secondary_response/dump_restore_workflow/#standard-workflow-parameters","text":"The remaining parameters are all standard workflow parameters and not specific to this procedure. [--skip-task], [--no-skip-task] # Send a task to execute the workflow [--scheduled-time=SCHEDULED_TIME] # Send a scheduled task instead, with this start time (as epoch) [--pause-at-step=PAUSE_AT_STEP] # Create a queued workflow pause for this step name [--pause-description=PAUSE_DESCRIPTION] # The description for the queued workflow pause [--send-notifications], [--no-send-notifications] # Toggle notifications for this workflow, overriding default # behaviour set by the stage-wide variable. [--wait-for-task], [--no-wait-for-task] # Wait for any submitted tasks to be complete, and return the result. # Default: true [--debug], [--no-debug] # Set log level to Debug globally","title":"Standard workflow parameters"},{"location":"secondary_response/dump_restore_workflow/#verify-replication","text":"After the workflow has completed, verify replication with ah-db-cluster status. Replication lag should be 0 on both servers.","title":"Verify replication"},{"location":"secondary_response/dump_restore_workflow/#trouble-shooting","text":"Look at the workflow logs The workflow will get a workflow id. You can get the full logs for this workflow with the following command: ah-workflow get $ID --show-logs Why am I getting an error that I'm out of space when there is plenty of space? This happens because this error is not just triggered by being out of space. This is a known issue. It can occur for example if the customer is restoring a backup on the active master while mysqldump is running. The workflow stopped with an error This obviously depends on the type of error but if you can, fix the issue and resume the workflow. The most typical issue is for the ephemeral volume to fill up so in that case you can free up more space there and resume the workflow. If there is not enough space available start a new workflow and specify a different path. Duplicate entry error on mysql.innodb_index_stats table The error below is caused by an issue in Percona/MySQL 5.6. The mysql.innodb_index_stats table gets created and in the short amount of time between creation and locking it for insertion, it can have records inserted. There is an AUTO ticket for this: AUTO-1458 . [2017-01-01 16:55:20] ERROR: Caught Aq::System::NonZeroStatusError while running workflow: Command returned exit stdout was: stderr was: ERROR 1062 (23000) at line 460374: Duplicate entry 'g988821-themebuilder_assets-PRIMARY-n_diff_pfx01 In the mean time there is a workaround for this problem. After the failure, you can run the following commands on the target server. mysql -e \"SET GLOBAL innodb_stats_auto_recalc=0; SET GLOBAL innodb_stats_persistent=0;\" After that you can resume the workflow with the following command. This will restart the restore. ah-workflow resume <workflow id> After the workflow successfully completes go to the server that was restored again and reset the settings that we changed. mysql -e \"SET GLOBAL innodb_stats_auto_recalc=1; SET GLOBAL innodb_stats_persistent=1;\" Unexpected behavior Check with Team Auto and if necessary file an AUTO bug. Always add as much useful information as possible.","title":"Trouble shooting"},{"location":"secondary_response/fencing/","text":"Fencing The fence mechanism can be enabled on a specific server or on an entire AZ. The fence works by creating iptables rules that rejects output on the Gluster ports where the destination is the specified server and rejects input on the Gluster ports where the source is the specified server these rules are applied to the file system peers and webs. Enable fence If a fs type server goes down due to the instance being impaired it is also great practice to put the Gluster fence in place. Enable on Single server FS_SERVER= ah-filesystem fencing server $FS_SERVER --fence --no-local Enable on AZ AZ= ah-filesystem fencing az $AZ --fence Disable fence Disable on Single server FS_SERVER= ah-filesystem fencing server $FS_SERVER --no-fence --no-local Disable on AZ AZ= ah-filesystem fencing az $AZ --no-fence","title":"Fencing"},{"location":"secondary_response/fencing/#fencing","text":"The fence mechanism can be enabled on a specific server or on an entire AZ. The fence works by creating iptables rules that rejects output on the Gluster ports where the destination is the specified server and rejects input on the Gluster ports where the source is the specified server these rules are applied to the file system peers and webs.","title":"Fencing"},{"location":"secondary_response/fencing/#enable-fence","text":"If a fs type server goes down due to the instance being impaired it is also great practice to put the Gluster fence in place.","title":"Enable fence"},{"location":"secondary_response/fencing/#enable-on-single-server","text":"FS_SERVER= ah-filesystem fencing server $FS_SERVER --fence --no-local","title":"Enable on Single server"},{"location":"secondary_response/fencing/#enable-on-az","text":"AZ= ah-filesystem fencing az $AZ --fence","title":"Enable on AZ"},{"location":"secondary_response/fencing/#disable-fence","text":"","title":"Disable fence"},{"location":"secondary_response/fencing/#disable-on-single-server","text":"FS_SERVER= ah-filesystem fencing server $FS_SERVER --no-fence --no-local","title":"Disable on Single server"},{"location":"secondary_response/fencing/#disable-on-az","text":"AZ= ah-filesystem fencing az $AZ --no-fence","title":"Disable on AZ"},{"location":"secondary_response/fix-1970-timestamps/","text":"Fix 1970 timestamps for files THIS IS FOR GLUSTER 3.0 ONLY From time to time, due to a gluster 3.0 bug, the files on the gluster mount on a web appear with Jan 1 1970 timestamp. This could cause issues based on what type of file gets corrupted. This runbook will provide steps to remediate the problem in a couple of ways. Most common issues would look like, DB backup files generated and located in /mnt/gfs/<site_name>/backups/ could appear with 1970 timestamp. This means that customer will not be able to see the backups generated in cloud UI. Any number of files under a single or multiple directories under the gluster mount for a customer could appear with 1970 timestamp. In this case, customer would report that they are seeing files with 1970 timestamp instead of their actual last modified timestamp. In case of backups, this runbook can help fix timestamps for only future backups but not for existing backups. From time to time, the files on both nodes might be corrupted and appear with 1970 timestamp. If a customer is experiencing any of the above mentioned issues, you can continue following the runbook to remediate the problem. Gather Information Get the customer site name SITE= JIRA_TICKET= Remediation 1 This remediation method was successfully executed and resolved issue for a customer . Remount gluster site-fsremount ${SITE} Verify gluster health site-checkgluster ${SITE} Verify the files after successful remount of gluster. If the issue is fixed, skip the next part of the runbook. Remediation 2 This method involves backing up of files or directories on the gluster brick and let them come back. For example, a file may appear corrupted with 1970 timestamp under the gluster mount ( /mnt/gfs ) but the same files may appear with correct timestamp under the gluster brick ( /mnt/brick* ). Identify fs type servers serving the site esl2 ${SITE} SSH to both of the fs servers and look for the corrupted files on the gluster brick. The file should be available under similar location as gluster mount. For example, gluster mount path for a file would look like: /mnt/gfs/cl28394/sites/default/files/vegan-chocolate.jpg gluster brick path would look like: /mnt/brick284813/cl28394/sites/default/files/vegan-chocolate.jpg After locating the corrupted file on the brick, move the bad file aside to /mnt/tmp and stat the file on the gluster mount: mkdir /mnt/tmp/${JIRA_TICKET} mv /mnt/brick284813/cl28394/sites/default/files/vegan-chocolate.jpg \\ /mnt/tmp/${JIRA_TICKET}/ ls -lah /mnt/gfs/cl28394/sites/default/files/vegan-chocolate.jpg Statting the file will cause gluster to heal the file properly in the background. This process shall be tried incrementally. If you are planning to do this process on multiple files, it is highly suggested that you do the remediation for a single file first and then go on. This process can be done on a directory as well. Remediation 3 This method involves manually modifying the timestamp for the files on one of the gluster clients and let gluster heal the file on the clients and bricks associated. For example, if a backup file appears with a 1970 timestamp lumc www-data 209M Jan 1 1970 prod-lumc-lumc-2020-04-22.sql.gz Before you do the remediation, take a backup of the file you would be modifying in /tmp. To modify the timestamp for this file, you can pick the date from the filename and the time based on the other backups in the directory. You can get a hint for the time based on other backups in the directory, a customer might have a cron to take backups everyday at 10:01 AM. If so, you can choose the time based on that and seconds doesn't really matter much. touch -t 202004221001.27 prod-lumc-lumc-2020-04-22.sql.gz In the above example, 202004221001.27 indicates year, month, date, hour, minute and seconds as below: [[CC]YY]MMDDhhmm [.SS] CC - The first two digits of the year YY - The second two digits of the year MM - The month of the year [01-12] DD - The day of the month [01-31] hh - The hour of the day [00-23] mm - The minute of the hour [00-59] SS - The second of the minute [00-61] Run this command only in the client directory /mnt/gfs. Once the timestamp is modified on the file in client directory, gluster will heal the file on the other clients and bricks associated. You can find a demonstration of the above process in this ticket . For non-backup files, use your best judgement to pick a timestamp based on the other files in the directory and perform the modification in an incremental manner if there are multiple files. If there are multiple files like this ticket , one way to improve on choosing an arbitrary date for the files would be to look through progressively older backups until you find one with a valid date for the files in question or find the one where they first appear (to determine an approximate date). If you find the problem is not resolved after trying all the remediation methods, you can escalate to the engineering team as per the escalation procedure.","title":"Fix 1970 timestamps for files"},{"location":"secondary_response/fix-1970-timestamps/#fix-1970-timestamps-for-files","text":"","title":"Fix 1970 timestamps for files"},{"location":"secondary_response/fix-1970-timestamps/#this-is-for-gluster-30-only","text":"From time to time, due to a gluster 3.0 bug, the files on the gluster mount on a web appear with Jan 1 1970 timestamp. This could cause issues based on what type of file gets corrupted. This runbook will provide steps to remediate the problem in a couple of ways. Most common issues would look like, DB backup files generated and located in /mnt/gfs/<site_name>/backups/ could appear with 1970 timestamp. This means that customer will not be able to see the backups generated in cloud UI. Any number of files under a single or multiple directories under the gluster mount for a customer could appear with 1970 timestamp. In this case, customer would report that they are seeing files with 1970 timestamp instead of their actual last modified timestamp. In case of backups, this runbook can help fix timestamps for only future backups but not for existing backups. From time to time, the files on both nodes might be corrupted and appear with 1970 timestamp. If a customer is experiencing any of the above mentioned issues, you can continue following the runbook to remediate the problem.","title":"THIS IS FOR GLUSTER 3.0 ONLY"},{"location":"secondary_response/fix-1970-timestamps/#gather-information","text":"Get the customer site name SITE= JIRA_TICKET=","title":"Gather Information"},{"location":"secondary_response/fix-1970-timestamps/#remediation-1","text":"This remediation method was successfully executed and resolved issue for a customer . Remount gluster site-fsremount ${SITE} Verify gluster health site-checkgluster ${SITE} Verify the files after successful remount of gluster. If the issue is fixed, skip the next part of the runbook.","title":"Remediation 1"},{"location":"secondary_response/fix-1970-timestamps/#remediation-2","text":"This method involves backing up of files or directories on the gluster brick and let them come back. For example, a file may appear corrupted with 1970 timestamp under the gluster mount ( /mnt/gfs ) but the same files may appear with correct timestamp under the gluster brick ( /mnt/brick* ). Identify fs type servers serving the site esl2 ${SITE} SSH to both of the fs servers and look for the corrupted files on the gluster brick. The file should be available under similar location as gluster mount. For example, gluster mount path for a file would look like: /mnt/gfs/cl28394/sites/default/files/vegan-chocolate.jpg gluster brick path would look like: /mnt/brick284813/cl28394/sites/default/files/vegan-chocolate.jpg After locating the corrupted file on the brick, move the bad file aside to /mnt/tmp and stat the file on the gluster mount: mkdir /mnt/tmp/${JIRA_TICKET} mv /mnt/brick284813/cl28394/sites/default/files/vegan-chocolate.jpg \\ /mnt/tmp/${JIRA_TICKET}/ ls -lah /mnt/gfs/cl28394/sites/default/files/vegan-chocolate.jpg Statting the file will cause gluster to heal the file properly in the background. This process shall be tried incrementally. If you are planning to do this process on multiple files, it is highly suggested that you do the remediation for a single file first and then go on. This process can be done on a directory as well.","title":"Remediation 2"},{"location":"secondary_response/fix-1970-timestamps/#remediation-3","text":"This method involves manually modifying the timestamp for the files on one of the gluster clients and let gluster heal the file on the clients and bricks associated. For example, if a backup file appears with a 1970 timestamp lumc www-data 209M Jan 1 1970 prod-lumc-lumc-2020-04-22.sql.gz Before you do the remediation, take a backup of the file you would be modifying in /tmp. To modify the timestamp for this file, you can pick the date from the filename and the time based on the other backups in the directory. You can get a hint for the time based on other backups in the directory, a customer might have a cron to take backups everyday at 10:01 AM. If so, you can choose the time based on that and seconds doesn't really matter much. touch -t 202004221001.27 prod-lumc-lumc-2020-04-22.sql.gz In the above example, 202004221001.27 indicates year, month, date, hour, minute and seconds as below: [[CC]YY]MMDDhhmm [.SS] CC - The first two digits of the year YY - The second two digits of the year MM - The month of the year [01-12] DD - The day of the month [01-31] hh - The hour of the day [00-23] mm - The minute of the hour [00-59] SS - The second of the minute [00-61] Run this command only in the client directory /mnt/gfs. Once the timestamp is modified on the file in client directory, gluster will heal the file on the other clients and bricks associated. You can find a demonstration of the above process in this ticket . For non-backup files, use your best judgement to pick a timestamp based on the other files in the directory and perform the modification in an incremental manner if there are multiple files. If there are multiple files like this ticket , one way to improve on choosing an arbitrary date for the files would be to look through progressively older backups until you find one with a valid date for the files in question or find the one where they first appear (to determine an approximate date). If you find the problem is not resolved after trying all the remediation methods, you can escalate to the engineering team as per the escalation procedure.","title":"Remediation 3"},{"location":"secondary_response/mysql_service_issue_during_volume_resize/","text":"Fix MySQL service issue occured during volume resize This procedure will help if the workflow is stuck at \"start_services\" because MySQL didn't shut down cleanly. Make sure the old volume is intact and is not deleted before proceeding. Important Note Do not abort workflows! Do not force stop/start MySQL! Ask DBA help before things get worse! Setting up the variables REGION= GOOD_DB_SERVER=(Input Active Server Name) BAD_DB_SERVER=(Set Problematic Server Name) BAD_INSTANCE_ID=$(ah-server list $BAD_DB_SERVER --no-name -c ec2_id) WORKFLOW_ID= Lock replication to the GOOD_DB_SERVER ah-db-cluster lock $GOOD_DB_SERVER Attach last known/working DB volume on BAD_DB_SERVER Note: Ops can get the old volume details(ebs_id) from the workflow logs. OLD_VOL_ID=(old working volume's ebs_id attached with BAD_DB_SERVER) aws ec2 attach-volume --volume-id $OLD_VOL_ID --instance-id $BAD_INSTANCE_ID --region $REGION --device /dev/xvdz Let's Sync the old data after mounting old DB volume on BAD_DB_SERVER fpdsh -l $BAD_DB_SERVER -c 'sudo mkdir /vol/old_ebs1' fpdsh -l $BAD_DB_SERVER -c 'sudo mount -t xfs -o nofail,nouuid,nodiratime,relatime,nobarrier,logbufs=8,logbsize=32k,allocsize=2M /dev/xvdz /vol/old_ebs1' fpdsh -l $BAD_DB_SERVER -c 'sudo rsync --archive --acls -H --compress --delete --verbose /vol/old_ebs1/ /vol/ebs1/ |tee -a /mnt/tmp/old-to-new.log' Start MySQL Service fpdsh -l $BAD_DB_SERVER -c 'sudo service mysql start' Resume the Workflow ah-workflow resume $WORKFLOW_ID Check replication Status ah-db-cluster status $GOOD_DB_SERVER Initiate Dump Restore ah-db-cluster dump-restore $GOOD_DB_SERVER $BAD_DB_SERVER --method=mysqldump Umount the old volume and remove the folder from $BAD_DB_SERVER fpdsh -l $BAD_DB_SERVER -c \"sudo umount /vol/old_ebs1\" fpdsh -l $BAD_DB_SERVER -c \"sudo rm -rf /vol/old_ebs1\" Detach the volume from $BAD_DB_SERVER aws ec2 detach-volume --volume-id $OLD_VOL_ID --region $REGION --force Note: Once lag fixed, then make sure the active Database should be the primary server.","title":"Fix MySQL service issue occured during volume resize"},{"location":"secondary_response/mysql_service_issue_during_volume_resize/#fix-mysql-service-issue-occured-during-volume-resize","text":"This procedure will help if the workflow is stuck at \"start_services\" because MySQL didn't shut down cleanly. Make sure the old volume is intact and is not deleted before proceeding.","title":"Fix MySQL service issue occured during volume resize"},{"location":"secondary_response/mysql_service_issue_during_volume_resize/#important-note","text":"Do not abort workflows! Do not force stop/start MySQL! Ask DBA help before things get worse!","title":"Important Note"},{"location":"secondary_response/mysql_service_issue_during_volume_resize/#setting-up-the-variables","text":"REGION= GOOD_DB_SERVER=(Input Active Server Name) BAD_DB_SERVER=(Set Problematic Server Name) BAD_INSTANCE_ID=$(ah-server list $BAD_DB_SERVER --no-name -c ec2_id) WORKFLOW_ID=","title":"Setting up the variables"},{"location":"secondary_response/mysql_service_issue_during_volume_resize/#lock-replication-to-the-good_db_server","text":"ah-db-cluster lock $GOOD_DB_SERVER","title":"Lock replication to the GOOD_DB_SERVER"},{"location":"secondary_response/mysql_service_issue_during_volume_resize/#attach-last-knownworking-db-volume-on-bad_db_server","text":"Note: Ops can get the old volume details(ebs_id) from the workflow logs. OLD_VOL_ID=(old working volume's ebs_id attached with BAD_DB_SERVER) aws ec2 attach-volume --volume-id $OLD_VOL_ID --instance-id $BAD_INSTANCE_ID --region $REGION --device /dev/xvdz","title":"Attach last known/working DB volume on BAD_DB_SERVER"},{"location":"secondary_response/mysql_service_issue_during_volume_resize/#lets-sync-the-old-data-after-mounting-old-db-volume-on-bad_db_server","text":"fpdsh -l $BAD_DB_SERVER -c 'sudo mkdir /vol/old_ebs1' fpdsh -l $BAD_DB_SERVER -c 'sudo mount -t xfs -o nofail,nouuid,nodiratime,relatime,nobarrier,logbufs=8,logbsize=32k,allocsize=2M /dev/xvdz /vol/old_ebs1' fpdsh -l $BAD_DB_SERVER -c 'sudo rsync --archive --acls -H --compress --delete --verbose /vol/old_ebs1/ /vol/ebs1/ |tee -a /mnt/tmp/old-to-new.log'","title":"Let's Sync the old data after mounting old DB volume on BAD_DB_SERVER"},{"location":"secondary_response/mysql_service_issue_during_volume_resize/#start-mysql-service","text":"fpdsh -l $BAD_DB_SERVER -c 'sudo service mysql start'","title":"Start MySQL Service"},{"location":"secondary_response/mysql_service_issue_during_volume_resize/#resume-the-workflow","text":"ah-workflow resume $WORKFLOW_ID","title":"Resume the Workflow"},{"location":"secondary_response/mysql_service_issue_during_volume_resize/#check-replication-status","text":"ah-db-cluster status $GOOD_DB_SERVER","title":"Check replication Status"},{"location":"secondary_response/mysql_service_issue_during_volume_resize/#initiate-dump-restore","text":"ah-db-cluster dump-restore $GOOD_DB_SERVER $BAD_DB_SERVER --method=mysqldump","title":"Initiate Dump Restore"},{"location":"secondary_response/mysql_service_issue_during_volume_resize/#umount-the-old-volume-and-remove-the-folder-from-bad_db_server","text":"fpdsh -l $BAD_DB_SERVER -c \"sudo umount /vol/old_ebs1\" fpdsh -l $BAD_DB_SERVER -c \"sudo rm -rf /vol/old_ebs1\"","title":"Umount the old volume and remove the folder from $BAD_DB_SERVER"},{"location":"secondary_response/mysql_service_issue_during_volume_resize/#detach-the-volume-from-bad_db_server","text":"aws ec2 detach-volume --volume-id $OLD_VOL_ID --region $REGION --force Note: Once lag fixed, then make sure the active Database should be the primary server.","title":"Detach the volume from $BAD_DB_SERVER"},{"location":"secondary_response/mysql_startup_failures/","text":"MySQL Startup Failure Troubleshooting This page describes different types of startup failures that MySQL can encounter and how to fix them (if possible). In some cases it is necessary to page a dba if MySQL fails to start but there are a number of common cases where following the instructions on this page can help. In all cases when MySQL won't start the first place to look is in the MySQL error log. This log file is located in /vol/ebs1/mysql/$(hostname).err . When reading this file pay close attention to the timestamps. It's easy to misread them and start looking at old errors. Always scroll to the bottom of the file for the latest messages. The contents of this page are listed per error message as they occur in the MySQL error log. InnoDB: File unknown read returned OS error 71 You have to start mysqld with tc-heuristic-recover switch to commit or rollback pending transactions InnoDB File unknown read returned OS error 71 Problem Description for File (unknown) error This problem is indicative of corruption in the InnoDB files and could point to problems with the underlying hardware (either volume or server). When this error occurs you will see the following messages in the MySQL error log. 2017-08-15 07:22:05 7f1e62a2c740 InnoDB: Operating system error number 2 in a file operation. InnoDB: The error means the system cannot find the path specified. InnoDB: If you are installing InnoDB, remember that you must create InnoDB: directories yourself, InnoDB does not create them. 2017-08-15 07:22:05 19934 [ERROR] InnoDB: File (unknown): 'read' returned OS error 71. Cannot continue operation This is immediately followed by the following message indicating that MySQL has stopped. 170815 07:22:06 mysqld_safe mysqld from pid file /var/run/mysqld/mysqld.pid ended The error indicates a problem reading a file from disk but since the the file is listed as unknown we don't know for certain which file caused the error. However, in all cases we encountered so far we could address this by replacing the InnoDB redo logs so it's very likely that those are the corrupted files. Replacing those files will result in data loss for the customer on non-clustered servers but at this point that is unavoidable. Fix for File (unknown) error If the server is the passive server in a cluster then the best approach is to perform an XtraBackup Dump Restore from the active to the passive. In that case you can skip the rest of this section. If the server is currently active or it's not part of cluster you have to get MySQL started again first. To start MySQL execute the following command to remove the redo logs: mv /vol/ebs1/mysql/ib_log* /mnt/tmp Now start MySQL again: systemctl start mysql Finally, check the MySQL error log again. If MySQL started you will most likely see a lot of the following errors: 2017-08-15 12:52:11 7f4a9a275700 InnoDB: Error: page 6 log sequence number 70940692378 InnoDB: is in the future! Current system log sequence number 68993429579. InnoDB: Your database may be corrupt or you may have copied the InnoDB InnoDB: tablespace but not the InnoDB log files. See InnoDB: http://dev.mysql.com/doc/refman/5.6/en/forcing-innodb-recovery.html InnoDB: for more information. These errors indicate there is a mismatch between the redo log files and the data files which is caused by removing the redo logs. As the log sequence numbers go up over time they should overtake the data page log numbers so the errors should stop at some point. For clustered servers this can be fixed with an XtraBackup Dump Restore . For non-clustered servers we should ideally rebuild the entire database directory by creating a backup of all databases, creating an empty database directory and reloading the backup. Unfortunately we do not have tooling for this and it will cause significant downtime so this is not normal procedure. If you want this to be done, finish up the normal work for the site and then place the OP in the dba escalation queue for follow-up. Since MySQL should be running at this point there is no need for paging. The dba's will decide in coordination with Support and the customer what the best approach is. You have to start mysqld with tc-heuristic-recover switch to commit or rollback pending transactions Problem Description for --tc-heuristic-recover error When you encounter the following messages in the MySQL error log while MySQL is refusing to start the problem is that MySQL was shut down in the middle of one or more writes and did not complete them. As MySQL starts it is detecting half-completed writes and does not know whether it should complete them or roll them back. 2017-08-15 06:53:14 7f3faff97740 InnoDB: 2 transactions in prepared state after recovery 2017-08-15 06:53:14 29668 [Note] Found 2 prepared transaction(s) in InnoDB 2017-08-15 06:53:14 29668 [ERROR] Found 2 prepared transactions! It means that mysqld was not shut down properly last time and critical recovery information (last binlog or tc.log file) was manually deleted after a crash. You have to start mysqld with --tc-heuristic-recover switch to commit or rollback pending transactions. 2017-08-15 06:53:14 29668 [ERROR] Aborting Fix for --tc-heuristic-recover error Fixing this issue is fairly straightforward and involves doing what the error message suggests. First modify the file /etc/mysql/my.cnf file to add the tc-heuristic-recover setting. sed -i \"s/\\[mysqld\\]/[mysqld]\\ntc-heuristic-recover=COMMIT/\" /etc/mysql/my.cnf Then restart MySQL. systemctl start mysql After performing the recovery MySQL will restart itself and fail because the tc-heuristic-recover setting only works if there is something to recover. Run puppet to remove the setting again. puppet agent -t OR in Masterless Puppet mode sudo run-puppet And finally start MySQL again. systemctl start mysql In the case of clustered servers it is possible at this point that replication is out of sync so keep an eye on replication conflicts. If replication conflicts occur apply the procedures for handling those.","title":"MySQL Startup Failure Troubleshooting"},{"location":"secondary_response/mysql_startup_failures/#mysql-startup-failure-troubleshooting","text":"This page describes different types of startup failures that MySQL can encounter and how to fix them (if possible). In some cases it is necessary to page a dba if MySQL fails to start but there are a number of common cases where following the instructions on this page can help. In all cases when MySQL won't start the first place to look is in the MySQL error log. This log file is located in /vol/ebs1/mysql/$(hostname).err . When reading this file pay close attention to the timestamps. It's easy to misread them and start looking at old errors. Always scroll to the bottom of the file for the latest messages. The contents of this page are listed per error message as they occur in the MySQL error log. InnoDB: File unknown read returned OS error 71 You have to start mysqld with tc-heuristic-recover switch to commit or rollback pending transactions","title":"MySQL Startup Failure Troubleshooting"},{"location":"secondary_response/mysql_startup_failures/#innodb-file-unknown-read-returned-os-error-71","text":"","title":"InnoDB File unknown read returned OS error 71"},{"location":"secondary_response/mysql_startup_failures/#problem-description-for-file-unknown-error","text":"This problem is indicative of corruption in the InnoDB files and could point to problems with the underlying hardware (either volume or server). When this error occurs you will see the following messages in the MySQL error log. 2017-08-15 07:22:05 7f1e62a2c740 InnoDB: Operating system error number 2 in a file operation. InnoDB: The error means the system cannot find the path specified. InnoDB: If you are installing InnoDB, remember that you must create InnoDB: directories yourself, InnoDB does not create them. 2017-08-15 07:22:05 19934 [ERROR] InnoDB: File (unknown): 'read' returned OS error 71. Cannot continue operation This is immediately followed by the following message indicating that MySQL has stopped. 170815 07:22:06 mysqld_safe mysqld from pid file /var/run/mysqld/mysqld.pid ended The error indicates a problem reading a file from disk but since the the file is listed as unknown we don't know for certain which file caused the error. However, in all cases we encountered so far we could address this by replacing the InnoDB redo logs so it's very likely that those are the corrupted files. Replacing those files will result in data loss for the customer on non-clustered servers but at this point that is unavoidable.","title":"Problem Description for File (unknown) error"},{"location":"secondary_response/mysql_startup_failures/#fix-for-file-unknown-error","text":"If the server is the passive server in a cluster then the best approach is to perform an XtraBackup Dump Restore from the active to the passive. In that case you can skip the rest of this section. If the server is currently active or it's not part of cluster you have to get MySQL started again first. To start MySQL execute the following command to remove the redo logs: mv /vol/ebs1/mysql/ib_log* /mnt/tmp Now start MySQL again: systemctl start mysql Finally, check the MySQL error log again. If MySQL started you will most likely see a lot of the following errors: 2017-08-15 12:52:11 7f4a9a275700 InnoDB: Error: page 6 log sequence number 70940692378 InnoDB: is in the future! Current system log sequence number 68993429579. InnoDB: Your database may be corrupt or you may have copied the InnoDB InnoDB: tablespace but not the InnoDB log files. See InnoDB: http://dev.mysql.com/doc/refman/5.6/en/forcing-innodb-recovery.html InnoDB: for more information. These errors indicate there is a mismatch between the redo log files and the data files which is caused by removing the redo logs. As the log sequence numbers go up over time they should overtake the data page log numbers so the errors should stop at some point. For clustered servers this can be fixed with an XtraBackup Dump Restore . For non-clustered servers we should ideally rebuild the entire database directory by creating a backup of all databases, creating an empty database directory and reloading the backup. Unfortunately we do not have tooling for this and it will cause significant downtime so this is not normal procedure. If you want this to be done, finish up the normal work for the site and then place the OP in the dba escalation queue for follow-up. Since MySQL should be running at this point there is no need for paging. The dba's will decide in coordination with Support and the customer what the best approach is.","title":"Fix for File (unknown) error"},{"location":"secondary_response/mysql_startup_failures/#you-have-to-start-mysqld-with-tc-heuristic-recover-switch-to-commit-or-rollback-pending-transactions","text":"","title":"You have to start mysqld with tc-heuristic-recover switch to commit or rollback pending transactions"},{"location":"secondary_response/mysql_startup_failures/#problem-description-for-tc-heuristic-recover-error","text":"When you encounter the following messages in the MySQL error log while MySQL is refusing to start the problem is that MySQL was shut down in the middle of one or more writes and did not complete them. As MySQL starts it is detecting half-completed writes and does not know whether it should complete them or roll them back. 2017-08-15 06:53:14 7f3faff97740 InnoDB: 2 transactions in prepared state after recovery 2017-08-15 06:53:14 29668 [Note] Found 2 prepared transaction(s) in InnoDB 2017-08-15 06:53:14 29668 [ERROR] Found 2 prepared transactions! It means that mysqld was not shut down properly last time and critical recovery information (last binlog or tc.log file) was manually deleted after a crash. You have to start mysqld with --tc-heuristic-recover switch to commit or rollback pending transactions. 2017-08-15 06:53:14 29668 [ERROR] Aborting","title":"Problem Description for --tc-heuristic-recover error"},{"location":"secondary_response/mysql_startup_failures/#fix-for-tc-heuristic-recover-error","text":"Fixing this issue is fairly straightforward and involves doing what the error message suggests. First modify the file /etc/mysql/my.cnf file to add the tc-heuristic-recover setting. sed -i \"s/\\[mysqld\\]/[mysqld]\\ntc-heuristic-recover=COMMIT/\" /etc/mysql/my.cnf Then restart MySQL. systemctl start mysql After performing the recovery MySQL will restart itself and fail because the tc-heuristic-recover setting only works if there is something to recover. Run puppet to remove the setting again. puppet agent -t OR in Masterless Puppet mode sudo run-puppet And finally start MySQL again. systemctl start mysql In the case of clustered servers it is possible at this point that replication is out of sync so keep an eye on replication conflicts. If replication conflicts occur apply the procedures for handling those.","title":"Fix for --tc-heuristic-recover error"},{"location":"secondary_response/pt-kill/","text":"pt-kill WARNING : This only applies to Classic Cloud. READ THIS FIRST We DO NOT support or offer this service to our customers. This is a measure taken when all other options run out and we need to keep a customer's site online with long-running SELECT statements that aren't easy to fix/optimize. The pt-kill tool is offered as part of the Percona Tools MySQL package that is deployed to every fields database server that Acquia manages. Official Percona pt-kill Documentation The pt-kill tool may ONLY be utilized under the following conditions: The number of running queries at any given time exceeds the running thread max of the server and appear to be running longer than 10 or 20 seconds per query. SELECT statements are the ONLY statements that may be killed. Support has indicated that the customer is unable to remediate the issue immediately, but mitigation is being worked on by the customer. Support has been notified AND the customer has given EXPLICIT permission to kill long-running queries. Queries other than SELECT statements may be killed ONLY after the customer has provided written approval to Support and they explicitly accept the risks of data loss or corruption. Investigation Prior to requesting approval from the customer via Support to kill queries, you should engage in DB-level investigation of performance issues. These methods are covered under alerts/perf-url-mon#db-layer-high-load . If the number of running queries at any given time exceeds the thread max of the server, and appear to be running longer than 10 or 20 seconds per query, this may be indicative of: Poor/unoptimized query structure (and therefore query performance) Large tables and/or full table-scans per query (discoverable using pt-query-digest or site-dbslowqueriesandlocks $SITE ) High traffic to a given URI/path on the website that is triggering slow queries (using site-logstream and site-goaccess ) Semaphore/table-lock/row-lock contention (sometimes aka \"Deadlocks\" ) If you are unfamiliar with how to diagnose any of the above, please escalate within Ops prior to killing any queries. Example pt-kill Command pt-kill --victims all --match-info \"[REGEX]\" --busy-time 20 --print --run-time 120 In the above example: --victims specifies which of the matching queries in each class will be killed. After classes have been matched/filtered, this option specifies which of the matching queries in each class will be killed (or printed, etc.). --match-info specifies to match only queries whose Info (query) matches this Perl regex. --busy-time specifies to match queries that have been running for longer than this time. The queries must be in Command=Query status. --print prints a KILL statement for matching queries; does not actually kill queries. --run-time How long to run before exiting. By default pt-kill runs forever, or until its process is killed or stopped by the creation of a sentinel file. If this option is specified, pt-kill runs for the specified amount of time and sleeps interval seconds between each check of the PROCESSLIST. This flag is REQUIRED . To complete the command (and thereby kill long-running queries), include the following flag: --kill terminates connections for matching queries.","title":"pt-kill"},{"location":"secondary_response/pt-kill/#pt-kill","text":"WARNING : This only applies to Classic Cloud.","title":"pt-kill"},{"location":"secondary_response/pt-kill/#read-this-first","text":"We DO NOT support or offer this service to our customers. This is a measure taken when all other options run out and we need to keep a customer's site online with long-running SELECT statements that aren't easy to fix/optimize. The pt-kill tool is offered as part of the Percona Tools MySQL package that is deployed to every fields database server that Acquia manages. Official Percona pt-kill Documentation The pt-kill tool may ONLY be utilized under the following conditions: The number of running queries at any given time exceeds the running thread max of the server and appear to be running longer than 10 or 20 seconds per query. SELECT statements are the ONLY statements that may be killed. Support has indicated that the customer is unable to remediate the issue immediately, but mitigation is being worked on by the customer. Support has been notified AND the customer has given EXPLICIT permission to kill long-running queries. Queries other than SELECT statements may be killed ONLY after the customer has provided written approval to Support and they explicitly accept the risks of data loss or corruption.","title":"READ THIS FIRST"},{"location":"secondary_response/pt-kill/#investigation","text":"Prior to requesting approval from the customer via Support to kill queries, you should engage in DB-level investigation of performance issues. These methods are covered under alerts/perf-url-mon#db-layer-high-load . If the number of running queries at any given time exceeds the thread max of the server, and appear to be running longer than 10 or 20 seconds per query, this may be indicative of: Poor/unoptimized query structure (and therefore query performance) Large tables and/or full table-scans per query (discoverable using pt-query-digest or site-dbslowqueriesandlocks $SITE ) High traffic to a given URI/path on the website that is triggering slow queries (using site-logstream and site-goaccess ) Semaphore/table-lock/row-lock contention (sometimes aka \"Deadlocks\" ) If you are unfamiliar with how to diagnose any of the above, please escalate within Ops prior to killing any queries.","title":"Investigation"},{"location":"secondary_response/pt-kill/#example-pt-kill-command","text":"pt-kill --victims all --match-info \"[REGEX]\" --busy-time 20 --print --run-time 120 In the above example: --victims specifies which of the matching queries in each class will be killed. After classes have been matched/filtered, this option specifies which of the matching queries in each class will be killed (or printed, etc.). --match-info specifies to match only queries whose Info (query) matches this Perl regex. --busy-time specifies to match queries that have been running for longer than this time. The queries must be in Command=Query status. --print prints a KILL statement for matching queries; does not actually kill queries. --run-time How long to run before exiting. By default pt-kill runs forever, or until its process is killed or stopped by the creation of a sentinel file. If this option is specified, pt-kill runs for the specified amount of time and sleeps interval seconds between each check of the PROCESSLIST. This flag is REQUIRED . To complete the command (and thereby kill long-running queries), include the following flag: --kill terminates connections for matching queries.","title":"Example pt-kill Command"},{"location":"secondary_response/reduce_sf_mysql_disk_usage/","text":"Reduce Site Factory MySQL Disk Usage Site Factory database clusters don't use the innodb_file_per_table MySQL setting, therefore all of the table data for all databases on the server is stored in /vol/ebs1/mysql/ibdata1 . The ibdata file can grow to be very large even if the data in the tables is deleted or tables are truncated due to InnoDB not returning empty tablespace back to the filesystem. This can lead to the volume becoming full even if the actual databases are rather small. To check true database size versus what's being used on disk use this SQL query. sudo mysqlanalyze -A sudo mysql -e 'SELECT Round(Sum(data_length + index_length) / 1024 / 1024, 1) \"DB Size in MB\" \\ FROM information_schema.TABLES;' If the number the query returns is significantly smaller than the size of /vol/ebs1/mysql/ibdata1 then proceed. If the numbers are similar the steps in this doc will be of little benefit and the volume will need to be upsized. Warning This procedure can lead to data loss if not performed correctly and should only be used if absolutely necessary. Please read these instructions: Volume upsize is recommended as the chances of failure is less and recovery is easier (as old volume could be mounted back to restore services). Do not perform these actions when you are on hotseat. This should preferably be handled in a maintenance window or regular ticket Consult with DBA or other Ops engineers (if DBA isn't available) even if there is slight confusion in the process. In case the ticket needs to be handed over, make sure the notes are clear with the instructions on which step is left. Ideally connect over zoom or Google meet to avoid any confusion. Procedure Begin with the secondary server, we can always restore from the primary if something goes wrong. Make sure there is no replication lag before starting. Variables OP= PRIMARY_DB= SECONDARY_DB= Prep Lock to primary server. ah-db-cluster lock $PRIMARY_DB Downtime both servers. sv-downtime $PRIMARY_DB 60 $OP \\ && sv-downtime $SECONDARY_DB 60 $OP Stop slave threads on both servers. fpdsh -l ${PRIMARY_DB},${SECONDARY_DB} -c 'sudo mysql -e \"stop slave;\"' Begin on Secondary NOTE As a pre-flight check run ah-db-cluster command or sv-dbprisec to verify the secondary and primary database server. Verify the variables are set and paste the output in the JIRA ticket: echo \"{noformat:title=Verifying the variables are set correctly}\" echo ${PRIMARY_DB} echo ${SECONDARY_DB} echo \"{noformat} SSH to secondary database server: fssh $SECONDARY_DB Before starting the process - start a screen session using screen command and mention the ID in ticket for handover purposes. Disable puppet and stop cron. sudo puppet agent --disable \\ && sudo systemctl stop cron OR in Masterless mode sudo ah-puppet-disable ${OP} | && sudo systemctl stop cron Stop mysql. sudo systemctl stop mysql Edit my.cnf to not start slave threads automatically. sudo sed -i 's/\\[mysqld\\]/\\[mysqld\\]\\nskip-slave-start/' /etc/mysql/my.cnf WARNING: This is the point of no return. Delete everything in the data directory. sudo bash -c 'rm -rf /vol/ebs1/mysql/*' Populate empty data directory with baseline config. sudo /usr/bin/mysql_install_db Start mysql. sudo systemctl start mysql Run mysql_secure_installation to set root password. Password can be found in /root/.my.cnf . sudo /usr/bin/mysql_secure_installation Press Enter for current password as there won't be one set. Use the password from /root/.my.cnf as the new password. Answer yes for all other questions. Some replication settings need to be restored, for that you'll need the FQDN of the master (the other server in the cluster) and the root password from the above step. You can use fqual on a bastion to get the FQDN. fqual $PRIMARY_DB Then on the server run this replacing FQDN and PASSWORD with the actual values. sudo mysql -e \"change master to master_host='FQDN', master_password='PASSWORD', master_user='root'\" Finally from a bastion perform dump/restore from the primary. ah-db-cluster dump-restore $PRIMARY_DB $SECONDARY_DB --method=mysqldump The workflow should enable replication again and restart services when it completes. Repeat on Primary Wait for replication to catch up and once it has failover and lock to $SECONDARY_DB . Repeat the above steps on $PRIMARY_DB in a screen session, of course doing the dump/restore from $SECONDARY_DB to $PRIMARY_DB . When the process is completed and replication is good, fail back to $PRIMARY_DB .","title":"Reduce Site Factory MySQL Disk Usage"},{"location":"secondary_response/reduce_sf_mysql_disk_usage/#reduce-site-factory-mysql-disk-usage","text":"Site Factory database clusters don't use the innodb_file_per_table MySQL setting, therefore all of the table data for all databases on the server is stored in /vol/ebs1/mysql/ibdata1 . The ibdata file can grow to be very large even if the data in the tables is deleted or tables are truncated due to InnoDB not returning empty tablespace back to the filesystem. This can lead to the volume becoming full even if the actual databases are rather small. To check true database size versus what's being used on disk use this SQL query. sudo mysqlanalyze -A sudo mysql -e 'SELECT Round(Sum(data_length + index_length) / 1024 / 1024, 1) \"DB Size in MB\" \\ FROM information_schema.TABLES;' If the number the query returns is significantly smaller than the size of /vol/ebs1/mysql/ibdata1 then proceed. If the numbers are similar the steps in this doc will be of little benefit and the volume will need to be upsized.","title":"Reduce Site Factory MySQL Disk Usage"},{"location":"secondary_response/reduce_sf_mysql_disk_usage/#warning","text":"This procedure can lead to data loss if not performed correctly and should only be used if absolutely necessary. Please read these instructions: Volume upsize is recommended as the chances of failure is less and recovery is easier (as old volume could be mounted back to restore services). Do not perform these actions when you are on hotseat. This should preferably be handled in a maintenance window or regular ticket Consult with DBA or other Ops engineers (if DBA isn't available) even if there is slight confusion in the process. In case the ticket needs to be handed over, make sure the notes are clear with the instructions on which step is left. Ideally connect over zoom or Google meet to avoid any confusion.","title":"Warning"},{"location":"secondary_response/reduce_sf_mysql_disk_usage/#procedure","text":"Begin with the secondary server, we can always restore from the primary if something goes wrong. Make sure there is no replication lag before starting.","title":"Procedure"},{"location":"secondary_response/reduce_sf_mysql_disk_usage/#variables","text":"OP= PRIMARY_DB= SECONDARY_DB=","title":"Variables"},{"location":"secondary_response/reduce_sf_mysql_disk_usage/#prep","text":"Lock to primary server. ah-db-cluster lock $PRIMARY_DB Downtime both servers. sv-downtime $PRIMARY_DB 60 $OP \\ && sv-downtime $SECONDARY_DB 60 $OP Stop slave threads on both servers. fpdsh -l ${PRIMARY_DB},${SECONDARY_DB} -c 'sudo mysql -e \"stop slave;\"'","title":"Prep"},{"location":"secondary_response/reduce_sf_mysql_disk_usage/#begin-on-secondary","text":"NOTE As a pre-flight check run ah-db-cluster command or sv-dbprisec to verify the secondary and primary database server. Verify the variables are set and paste the output in the JIRA ticket: echo \"{noformat:title=Verifying the variables are set correctly}\" echo ${PRIMARY_DB} echo ${SECONDARY_DB} echo \"{noformat} SSH to secondary database server: fssh $SECONDARY_DB Before starting the process - start a screen session using screen command and mention the ID in ticket for handover purposes. Disable puppet and stop cron. sudo puppet agent --disable \\ && sudo systemctl stop cron OR in Masterless mode sudo ah-puppet-disable ${OP} | && sudo systemctl stop cron Stop mysql. sudo systemctl stop mysql Edit my.cnf to not start slave threads automatically. sudo sed -i 's/\\[mysqld\\]/\\[mysqld\\]\\nskip-slave-start/' /etc/mysql/my.cnf WARNING: This is the point of no return. Delete everything in the data directory. sudo bash -c 'rm -rf /vol/ebs1/mysql/*' Populate empty data directory with baseline config. sudo /usr/bin/mysql_install_db Start mysql. sudo systemctl start mysql Run mysql_secure_installation to set root password. Password can be found in /root/.my.cnf . sudo /usr/bin/mysql_secure_installation Press Enter for current password as there won't be one set. Use the password from /root/.my.cnf as the new password. Answer yes for all other questions. Some replication settings need to be restored, for that you'll need the FQDN of the master (the other server in the cluster) and the root password from the above step. You can use fqual on a bastion to get the FQDN. fqual $PRIMARY_DB Then on the server run this replacing FQDN and PASSWORD with the actual values. sudo mysql -e \"change master to master_host='FQDN', master_password='PASSWORD', master_user='root'\" Finally from a bastion perform dump/restore from the primary. ah-db-cluster dump-restore $PRIMARY_DB $SECONDARY_DB --method=mysqldump The workflow should enable replication again and restart services when it completes.","title":"Begin on Secondary"},{"location":"secondary_response/reduce_sf_mysql_disk_usage/#repeat-on-primary","text":"Wait for replication to catch up and once it has failover and lock to $SECONDARY_DB . Repeat the above steps on $PRIMARY_DB in a screen session, of course doing the dump/restore from $SECONDARY_DB to $PRIMARY_DB . When the process is completed and replication is good, fail back to $PRIMARY_DB .","title":"Repeat on Primary"},{"location":"secondary_response/replacing-brick-volumes/","text":"Replacing Brick Volumes It may be necessary to replace a gluster 3.4 brick if the brick becomes corrupted by automated means or due to user error. Typically, this will result in the glusterfsd process refusing to start on the fs server with the corrupted brick. The process to replace the brick volume, which will result in Gluster automatically including the new brick in the cluster and auto-healing is outlined below. Initial Variables JIRA_TICKET= USER= SERVER= SITE= Gather volume volume information from sv-vollist ${SERVER} REGION= BRICKID= VOLUME= SIZE= DEVICE=/dev/xvdo or old /dev/sdo Remove the old (corrupt) brick Set the brick to create ah-volume edit ${BRICKID} --set=ebs_id=create Relaunch the server to setup a new brick Relaunch ah-server relaunch ${SERVER} Remount gluster site-fsremount ${SITE} Do a gluster heal screen -S heal find /mnt/gfs -noleaf -print0 | xargs -0 --null stat >/dev/null Check brick size and files df -hT /mnt/gfs /dev/xvdo ls /mnt/brick*/ If all is fine delete the aws volume Delete the old volume aws ec2 delete-volume --region ${REGION} --volume-id ${VOLUME}","title":"Replacing Brick Volumes"},{"location":"secondary_response/replacing-brick-volumes/#replacing-brick-volumes","text":"It may be necessary to replace a gluster 3.4 brick if the brick becomes corrupted by automated means or due to user error. Typically, this will result in the glusterfsd process refusing to start on the fs server with the corrupted brick. The process to replace the brick volume, which will result in Gluster automatically including the new brick in the cluster and auto-healing is outlined below.","title":"Replacing Brick Volumes"},{"location":"secondary_response/replacing-brick-volumes/#initial-variables","text":"JIRA_TICKET= USER= SERVER= SITE= Gather volume volume information from sv-vollist ${SERVER} REGION= BRICKID= VOLUME= SIZE= DEVICE=/dev/xvdo or old /dev/sdo","title":"Initial Variables"},{"location":"secondary_response/replacing-brick-volumes/#remove-the-old-corrupt-brick","text":"Set the brick to create ah-volume edit ${BRICKID} --set=ebs_id=create","title":"Remove the old (corrupt) brick"},{"location":"secondary_response/replacing-brick-volumes/#relaunch-the-server-to-setup-a-new-brick","text":"Relaunch ah-server relaunch ${SERVER} Remount gluster site-fsremount ${SITE} Do a gluster heal screen -S heal find /mnt/gfs -noleaf -print0 | xargs -0 --null stat >/dev/null Check brick size and files df -hT /mnt/gfs /dev/xvdo ls /mnt/brick*/","title":"Relaunch the server to setup a new brick"},{"location":"secondary_response/replacing-brick-volumes/#if-all-is-fine-delete-the-aws-volume","text":"Delete the old volume aws ec2 delete-volume --region ${REGION} --volume-id ${VOLUME}","title":"If all is fine delete the aws volume"},{"location":"secondary_response/replacing-bricks/","text":"Replacing Gluster Bricks THIS IS FOR GLUSTER 3.4 ONLY It may be necessary to replace a gluster 3.4 brick directory if the brick contents become corrupted by automated means or due to user error. Typically, this will result in I/O errors accessing files (on the client /mnt/gfs) or errors during healing (evidenced in logs). The process to replace the brick directory and initiate auto-healing is outlined below. Stop Gluster and other services Disable puppet and stop cron puppet agent --disable \"$OP | replacing gluster brick\" service cron stop Unmount /mnt/gfs on the glusterfs server umount /mnt/gfs Stop the glusterfs server service glusterfs-server stop Remove the old (corrupt) brick directory Remove the bad brick directory rm -fr /mnt/brick1234/brick Re-create the brick directory mkdir /mnt/brick1234/brick Recover Volume ID Gluster 3.4 will not start with a blank volume; it needs the trusted.glusterfs.volume-id parameter set. See the archive , the blog post , and comments beginning on OP-87993 for more information. Locate the volume ID from the good server getfattr -n trusted.glusterfs.volume-id -e hex /mnt/brick5678/brick/ Set the volume ID on the newly replaced brick directory setfattr -n trusted.glusterfs.volume-id -v VOLUMEIDHERE /mnt/brick1234/brick Start Gluster Start the glusterfs-server server service glusterfs-server start Heal the brick Get the gluster volume name gluster volume list Initiate a brick heal gluster volume heal VOLNAME full If the brick fails with \"Launching Heal operation on volume VOLNAME has been unsuccessful,\" you may need to force-mount the brick: Force-mounting the brick If the heal fails immediately, it may be that the brick is offline. You can verify with gluster volume status . If it shows 'N' for online, you can bring it online with gluster volume start VOLNAME force . This may be necessary after recovering volume ID in some situations. Verify success Verify the files were healed gluster volume heal VOLNAME info healed Grep for a null brick error (ignore errors from previous actions - note the timestamps) grep \"removing brick (null)\" /var/log/glusterfs/etc-glusterfs-glusterd.vol.log If no entries are found, proceed to [[#Start Gluster Client]]. If entries are found, proceed to [[#Recovering Volume ID]]. Start Gluster Client & Cron Mount /mnt/gfs on the glusterfs server mount /mnt/gfs Verify the contents of /mnt/gfs ls /mnt/gfs find /mnt/gfs Start cron service cron start","title":"Replacing Gluster Bricks"},{"location":"secondary_response/replacing-bricks/#replacing-gluster-bricks","text":"","title":"Replacing Gluster Bricks"},{"location":"secondary_response/replacing-bricks/#this-is-for-gluster-34-only","text":"It may be necessary to replace a gluster 3.4 brick directory if the brick contents become corrupted by automated means or due to user error. Typically, this will result in I/O errors accessing files (on the client /mnt/gfs) or errors during healing (evidenced in logs). The process to replace the brick directory and initiate auto-healing is outlined below.","title":"THIS IS FOR GLUSTER 3.4 ONLY"},{"location":"secondary_response/replacing-bricks/#stop-gluster-and-other-services","text":"Disable puppet and stop cron puppet agent --disable \"$OP | replacing gluster brick\" service cron stop Unmount /mnt/gfs on the glusterfs server umount /mnt/gfs Stop the glusterfs server service glusterfs-server stop","title":"Stop Gluster and other services"},{"location":"secondary_response/replacing-bricks/#remove-the-old-corrupt-brick-directory","text":"Remove the bad brick directory rm -fr /mnt/brick1234/brick Re-create the brick directory mkdir /mnt/brick1234/brick","title":"Remove the old (corrupt) brick directory"},{"location":"secondary_response/replacing-bricks/#recover-volume-id","text":"Gluster 3.4 will not start with a blank volume; it needs the trusted.glusterfs.volume-id parameter set. See the archive , the blog post , and comments beginning on OP-87993 for more information. Locate the volume ID from the good server getfattr -n trusted.glusterfs.volume-id -e hex /mnt/brick5678/brick/ Set the volume ID on the newly replaced brick directory setfattr -n trusted.glusterfs.volume-id -v VOLUMEIDHERE /mnt/brick1234/brick","title":"Recover Volume ID"},{"location":"secondary_response/replacing-bricks/#start-gluster","text":"Start the glusterfs-server server service glusterfs-server start","title":"Start Gluster"},{"location":"secondary_response/replacing-bricks/#heal-the-brick","text":"Get the gluster volume name gluster volume list Initiate a brick heal gluster volume heal VOLNAME full If the brick fails with \"Launching Heal operation on volume VOLNAME has been unsuccessful,\" you may need to force-mount the brick:","title":"Heal the brick"},{"location":"secondary_response/replacing-bricks/#force-mounting-the-brick","text":"If the heal fails immediately, it may be that the brick is offline. You can verify with gluster volume status . If it shows 'N' for online, you can bring it online with gluster volume start VOLNAME force . This may be necessary after recovering volume ID in some situations.","title":"Force-mounting the brick"},{"location":"secondary_response/replacing-bricks/#verify-success","text":"Verify the files were healed gluster volume heal VOLNAME info healed Grep for a null brick error (ignore errors from previous actions - note the timestamps) grep \"removing brick (null)\" /var/log/glusterfs/etc-glusterfs-glusterd.vol.log If no entries are found, proceed to [[#Start Gluster Client]]. If entries are found, proceed to [[#Recovering Volume ID]].","title":"Verify success"},{"location":"secondary_response/replacing-bricks/#start-gluster-client-cron","text":"Mount /mnt/gfs on the glusterfs server mount /mnt/gfs Verify the contents of /mnt/gfs ls /mnt/gfs find /mnt/gfs Start cron service cron start","title":"Start Gluster Client &amp; Cron"},{"location":"secondary_response/search_disk_partitions/","text":"Search Disk Partitions Alert Note: To login Search jumpboxes, follow these instructions We have different remediation strategies for resolving a disk alert on a javasrv if and only if the alert is due to the ebs volume filling due to search indexes. If another volume is alerting or if the ebs volume is full for some other reason, then this runbook will not help. Initialize JAVASRV= FARMDIR=$(fssh $JAVASRV 'find /vol/ebs1/gfs -maxdepth 1 -mindepth 1 -type d ! -name home') && echo $FARMDIR FARM=$(basename $FARMDIR | sed 's/m$//') Confirm that the indexes directory is filling its partition Compare the output of the following command to the output of df : fssh $JAVASRV \"sudo du -mad 0 $FARMDIR/files/indexes\" If the bulk of the usage is due to indexes, then proceed with the remediation strategies below, in order. Otherwise, file a Search ticket indicating that we can't address the alert for this reason. Remediation For the following strategies, you will want to consider only the largest indexes: INDEXES=$(fssh $JAVASRV \"sudo du -mad 1 $FARMDIR/files/indexes\" \\ | sort -nrk 1 | awk '{ print $2 }' | head -n30 | xargs -n 1 basename \\ | grep -v indexes | sort) && echo \"$INDEXES\" Move indexes that should not be deployed You will need the governor cli in your path. Find the indexes that are on the disk but not listed by governor: comm -23 <(echo \"$INDEXES\") \\ <(governor farm:indexes $FARM | grep \\\" \\ | sed 's/^ *\"\\([^\"]*\\)\".*$/\\1/' | sort) Move listed indexes to /mnt/tmp until the volume stops alerting. Paste the list of indexes you moved in a Search ticket and link to the OP Determine if a customer is over their limit For the indexes in $INDEXES , check CCI and compare the subscription limit to the actual disk usage. If any of them are exceeding their limit, then file an AM ticket to this effect for each offending index. If a customer is using more than 10GB, upsize them to tier 1 dedicated search. Index files sharing the same base pattern '^[A-Z]+-[0-9]+' are for the same customer. Move the largest index If the disk is still alerting after attempting the above then move indexes to another server, starting with the largest, using this procedure . Repeat as necessary to bring the disk space usage under the alert threshold. Emergency Upsize If the disk is at risk of filling and none of the above remediation strategies were applicable or helpful, then the instance must be emergency upsized to prevent a sev0.","title":"Search Disk Partitions Alert"},{"location":"secondary_response/search_disk_partitions/#search-disk-partitions-alert","text":"Note: To login Search jumpboxes, follow these instructions We have different remediation strategies for resolving a disk alert on a javasrv if and only if the alert is due to the ebs volume filling due to search indexes. If another volume is alerting or if the ebs volume is full for some other reason, then this runbook will not help.","title":"Search Disk Partitions Alert"},{"location":"secondary_response/search_disk_partitions/#initialize","text":"JAVASRV= FARMDIR=$(fssh $JAVASRV 'find /vol/ebs1/gfs -maxdepth 1 -mindepth 1 -type d ! -name home') && echo $FARMDIR FARM=$(basename $FARMDIR | sed 's/m$//')","title":"Initialize"},{"location":"secondary_response/search_disk_partitions/#confirm-that-the-indexes-directory-is-filling-its-partition","text":"Compare the output of the following command to the output of df : fssh $JAVASRV \"sudo du -mad 0 $FARMDIR/files/indexes\" If the bulk of the usage is due to indexes, then proceed with the remediation strategies below, in order. Otherwise, file a Search ticket indicating that we can't address the alert for this reason.","title":"Confirm that the indexes directory is filling its partition"},{"location":"secondary_response/search_disk_partitions/#remediation","text":"For the following strategies, you will want to consider only the largest indexes: INDEXES=$(fssh $JAVASRV \"sudo du -mad 1 $FARMDIR/files/indexes\" \\ | sort -nrk 1 | awk '{ print $2 }' | head -n30 | xargs -n 1 basename \\ | grep -v indexes | sort) && echo \"$INDEXES\"","title":"Remediation"},{"location":"secondary_response/search_disk_partitions/#move-indexes-that-should-not-be-deployed","text":"You will need the governor cli in your path. Find the indexes that are on the disk but not listed by governor: comm -23 <(echo \"$INDEXES\") \\ <(governor farm:indexes $FARM | grep \\\" \\ | sed 's/^ *\"\\([^\"]*\\)\".*$/\\1/' | sort) Move listed indexes to /mnt/tmp until the volume stops alerting. Paste the list of indexes you moved in a Search ticket and link to the OP","title":"Move indexes that should not be deployed"},{"location":"secondary_response/search_disk_partitions/#determine-if-a-customer-is-over-their-limit","text":"For the indexes in $INDEXES , check CCI and compare the subscription limit to the actual disk usage. If any of them are exceeding their limit, then file an AM ticket to this effect for each offending index. If a customer is using more than 10GB, upsize them to tier 1 dedicated search. Index files sharing the same base pattern '^[A-Z]+-[0-9]+' are for the same customer.","title":"Determine if a customer is over their limit"},{"location":"secondary_response/search_disk_partitions/#move-the-largest-index","text":"If the disk is still alerting after attempting the above then move indexes to another server, starting with the largest, using this procedure . Repeat as necessary to bring the disk space usage under the alert threshold.","title":"Move the largest index"},{"location":"secondary_response/search_disk_partitions/#emergency-upsize","text":"If the disk is at risk of filling and none of the above remediation strategies were applicable or helpful, then the instance must be emergency upsized to prevent a sev0.","title":"Emergency Upsize"},{"location":"secondary_response/split-brain/","text":"Split-brain A gluster split-brain occurs when the clients and servers are partitioned such that no client can connect to both servers, but each server has some clients writing to it. We will only notice a split-brain when the partition is either fully resolved so that all nodes can communicate or the partition is bridged by one or more clients. We are often notified of a split-brain because of a failing rsync job that the customer attempted in the Insight UI. Since other problems often occur in concert with split-brain, you should run through the not split-brain runbook Init OP= SERVER= SERVER can be any server in the fs_cluster . Resolution You may wish to run ls -l on all files in the gluster mount so that each split-brained file gets a log entry. We have no way of detecting split-brain except after a split-brained file is accessed. You might skip this if the ticket was filed due to an rsync job failing, because that will have caused reads on all files, though of course the problem may have gotten worse since the ticket was filed. fssh $SERVER \"sudo ls -lahR /mnt/gfs\" &> $OPSTMP/${OP}_gluster_find.out NOTE: You may not see an Input/Output error for every file in split-brain. If gluster doesn't have a metadata split-brain, then the information it needs to satisfy ls may be consistent, so ls may show no error. Gather data, determine the list of files to delete from one server. DATA=$(sv-glustersplitbrainfiles $SERVER \\ | awk '!($(NF-1) ~ /0x0*$/ && $NF ~ /0x0*$/) \\ { total=( $(NF-2) + $(NF-3) ); $NF=$(NF-1)=$(NF-2)=$(NF-3)=\"\"; print $0, total }') read LOSER WINNER <<< $(echo \"$DATA\" | awk '{ a[$1] += $NF } END { for (i in a) { print i, a[i] } }' \\ | sort -snk 2,2 | awk '{ print $1 }') NODES=$(ah-server list % -w fs_cluster_id=$(ah-server list $LOSER -c fs_cluster_id --no-name)) NODES_CSV=$(array-csv ${NODES[@]}) LOSER_CLIENTS=( $(echo ${NODES[@]} | xargs -n1 | grep -v $LOSER) ) echo \"$DATA\" echo $LOSER PATHS=\"$(echo \"$DATA\" | awk -v loser=$LOSER '$1 == loser { $3=$2$3; $1=$2=$NF=\"\"; print }' | sed 's/^ *\\([^ ]*\\) *$/\\1/')\" echo \"$PATHS\" Fence off the server whose brick will get files deleted (called \"the loser\" from here forward): GLUSTER_PORT_RANGES_CSV=1000:1023,6996,24007,24008,49152:49200 fpdsh -l $NODES_CSV -c \"sudo su -c 'rm -f /var/acquia/no-config-iptables ah-config-iptables touch /var/acquia/no-config-iptables'\" fpdsh -l $(array-csv ${LOSER_CLIENTS[@]}) -c \"sudo iptables --insert OUTPUT -p tcp \\ -d $LOSER -m multiport \\ --dports $GLUSTER_PORT_RANGES_CSV -j REJECT --reject-with tcp-reset\" Turn things off on the loser: fssh $LOSER <<EOF sudo su -c 'service cron stop puppet agent --disable $OP service glusterfs-server stop pkill gluster' EOF Back up the brick files we plan to delete from the loser: NOTE: this backup strategy does not preserve hard links in gfs as such. Attempting to restore the brick from the backup may break things. For this reason, it is best to allow support to help the client update gfs using the backed up files manually as necessary. echo \"${PATHS}\" | fssh $LOSER \"sudo su -c 'cat - | xargs -I FILE tar -rvf /mnt/tmp/${OP}_$(date +%s).tar \\\"FILE\\\"'\" Delete the brick files from the loser: echo \"${PATHS}\" | fssh $LOSER \"sudo bash -xc 'cat - | xargs -I FILE rm -rvf \\\"FILE\\\"; if (2>/dev/null ls -d /mnt/brick*/brick/.glusterfs); then find /mnt/brick*/brick/.glusterfs -type l -not -exec test -e {} \\; -print | xargs -I LINK bash -c \\\"( &>/dev/null readlink -e LINK ) || echo LINK\\\" | xargs rm -v; find /mnt/brick*/brick/.glusterfs -type f | egrep -v \\\"(indices|landfill)\\\" | xargs -L 1 stat -c \\\"%h %n\\\" | awk \\\"\\\\\\$1 == 1 { print \\\\\\$2 }\\\" | xargs rm -v; fi'\" Heal and Check Note that this step can down the cluster. Both gluster server nodes need to be able to connect to each other in order to heal, and in the case of a ded pair with no webs, that means all traffic can hit the healing brick and fail and take a long time to do it as the heal locks whole directories. fssh $WINNER \"sudo su -c 'rm -f /var/acquia/no-config-iptables; ah-config-iptables'\" < /dev/null sv-fsremount $LOSER,$WINNER echo ${PATHS[@]} | sed 's/\\/mnt\\/brick[0-9]*\\/\\(brick\\/\\)*/\\/mnt\\/gfs\\//g' \\ | fssh $WINNER \"xargs -I FILE sudo ls -l \\\"FILE\\\"\" echo ${PATHS[@]} | sed 's/\\/mnt\\/brick[0-9]*\\/\\(brick\\/\\)*/\\/mnt\\/gfs\\//g' \\ | fssh $LOSER \"xargs -I FILE sudo ls -l \\\"FILE\\\"\" sv-glustersplitbrainfiles $SERVER If the output of sv-glustersplitbrainfiles now shows all 0's for the afr changelogs and showed no errors, proceed. If any afr changelogs are not all 0's, then files are still split-brained. Review the output to check for any errors. Address them and try again. If you have errors from the last run of sv-glustersplitbrainfiles , verify that the two servers can connect to each other and gluster is running properly on both. Because our strategy requires picking a whole brick arbitrarily, you may have deleted a file from the only brick it was ever on. If so, you will be alerted by the above commands that some paths don't exist, and you will need to see if they are in your backup. If they're not, then you didn't delete them, so no worries. If they are, then copy them to the gluster mount at the correct path. If the ls of the gfs mount on the winner still shows input/output errors but the files on the brick don't show split-brain, try the ls command again and/or try it on the other nodes. It can take some time for the loser to get its copies updated, and that will be exacerbated by large files and/or large numbers of files. Clean up Turn things back on for everybody in the cluster fpdsh -l $NODES_CSV -c \"sudo su -c 'rm -f /var/acquia/no-config-iptables; ah-config-iptables; service cron start; puppet agent --enable'\" Now that we've healed the loser brick, confirm that all the clients can access the files without error for NODE in ${NODES[@]}; do echo \"${PATHS[@]}\" | sed 's/\\/mnt\\/brick[0-9]*\\/\\(brick\\/\\)*/\\/mnt\\/gfs\\//g' \\ | fssh $NODE \"cat - | xargs -I FILE sudo ls -l 'FILE'\" done If you get errors, you may need to remount gluster on the offending servers and try again. If you still get errors, escalate to cloud. Call out the location of the backup in the ticket so that support can find it if necessary.","title":"Split-brain"},{"location":"secondary_response/split-brain/#split-brain","text":"A gluster split-brain occurs when the clients and servers are partitioned such that no client can connect to both servers, but each server has some clients writing to it. We will only notice a split-brain when the partition is either fully resolved so that all nodes can communicate or the partition is bridged by one or more clients. We are often notified of a split-brain because of a failing rsync job that the customer attempted in the Insight UI. Since other problems often occur in concert with split-brain, you should run through the not split-brain runbook","title":"Split-brain"},{"location":"secondary_response/split-brain/#init","text":"OP= SERVER= SERVER can be any server in the fs_cluster .","title":"Init"},{"location":"secondary_response/split-brain/#resolution","text":"You may wish to run ls -l on all files in the gluster mount so that each split-brained file gets a log entry. We have no way of detecting split-brain except after a split-brained file is accessed. You might skip this if the ticket was filed due to an rsync job failing, because that will have caused reads on all files, though of course the problem may have gotten worse since the ticket was filed. fssh $SERVER \"sudo ls -lahR /mnt/gfs\" &> $OPSTMP/${OP}_gluster_find.out NOTE: You may not see an Input/Output error for every file in split-brain. If gluster doesn't have a metadata split-brain, then the information it needs to satisfy ls may be consistent, so ls may show no error. Gather data, determine the list of files to delete from one server. DATA=$(sv-glustersplitbrainfiles $SERVER \\ | awk '!($(NF-1) ~ /0x0*$/ && $NF ~ /0x0*$/) \\ { total=( $(NF-2) + $(NF-3) ); $NF=$(NF-1)=$(NF-2)=$(NF-3)=\"\"; print $0, total }') read LOSER WINNER <<< $(echo \"$DATA\" | awk '{ a[$1] += $NF } END { for (i in a) { print i, a[i] } }' \\ | sort -snk 2,2 | awk '{ print $1 }') NODES=$(ah-server list % -w fs_cluster_id=$(ah-server list $LOSER -c fs_cluster_id --no-name)) NODES_CSV=$(array-csv ${NODES[@]}) LOSER_CLIENTS=( $(echo ${NODES[@]} | xargs -n1 | grep -v $LOSER) ) echo \"$DATA\" echo $LOSER PATHS=\"$(echo \"$DATA\" | awk -v loser=$LOSER '$1 == loser { $3=$2$3; $1=$2=$NF=\"\"; print }' | sed 's/^ *\\([^ ]*\\) *$/\\1/')\" echo \"$PATHS\" Fence off the server whose brick will get files deleted (called \"the loser\" from here forward): GLUSTER_PORT_RANGES_CSV=1000:1023,6996,24007,24008,49152:49200 fpdsh -l $NODES_CSV -c \"sudo su -c 'rm -f /var/acquia/no-config-iptables ah-config-iptables touch /var/acquia/no-config-iptables'\" fpdsh -l $(array-csv ${LOSER_CLIENTS[@]}) -c \"sudo iptables --insert OUTPUT -p tcp \\ -d $LOSER -m multiport \\ --dports $GLUSTER_PORT_RANGES_CSV -j REJECT --reject-with tcp-reset\" Turn things off on the loser: fssh $LOSER <<EOF sudo su -c 'service cron stop puppet agent --disable $OP service glusterfs-server stop pkill gluster' EOF Back up the brick files we plan to delete from the loser: NOTE: this backup strategy does not preserve hard links in gfs as such. Attempting to restore the brick from the backup may break things. For this reason, it is best to allow support to help the client update gfs using the backed up files manually as necessary. echo \"${PATHS}\" | fssh $LOSER \"sudo su -c 'cat - | xargs -I FILE tar -rvf /mnt/tmp/${OP}_$(date +%s).tar \\\"FILE\\\"'\" Delete the brick files from the loser: echo \"${PATHS}\" | fssh $LOSER \"sudo bash -xc 'cat - | xargs -I FILE rm -rvf \\\"FILE\\\"; if (2>/dev/null ls -d /mnt/brick*/brick/.glusterfs); then find /mnt/brick*/brick/.glusterfs -type l -not -exec test -e {} \\; -print | xargs -I LINK bash -c \\\"( &>/dev/null readlink -e LINK ) || echo LINK\\\" | xargs rm -v; find /mnt/brick*/brick/.glusterfs -type f | egrep -v \\\"(indices|landfill)\\\" | xargs -L 1 stat -c \\\"%h %n\\\" | awk \\\"\\\\\\$1 == 1 { print \\\\\\$2 }\\\" | xargs rm -v; fi'\"","title":"Resolution"},{"location":"secondary_response/split-brain/#heal-and-check","text":"Note that this step can down the cluster. Both gluster server nodes need to be able to connect to each other in order to heal, and in the case of a ded pair with no webs, that means all traffic can hit the healing brick and fail and take a long time to do it as the heal locks whole directories. fssh $WINNER \"sudo su -c 'rm -f /var/acquia/no-config-iptables; ah-config-iptables'\" < /dev/null sv-fsremount $LOSER,$WINNER echo ${PATHS[@]} | sed 's/\\/mnt\\/brick[0-9]*\\/\\(brick\\/\\)*/\\/mnt\\/gfs\\//g' \\ | fssh $WINNER \"xargs -I FILE sudo ls -l \\\"FILE\\\"\" echo ${PATHS[@]} | sed 's/\\/mnt\\/brick[0-9]*\\/\\(brick\\/\\)*/\\/mnt\\/gfs\\//g' \\ | fssh $LOSER \"xargs -I FILE sudo ls -l \\\"FILE\\\"\" sv-glustersplitbrainfiles $SERVER If the output of sv-glustersplitbrainfiles now shows all 0's for the afr changelogs and showed no errors, proceed. If any afr changelogs are not all 0's, then files are still split-brained. Review the output to check for any errors. Address them and try again. If you have errors from the last run of sv-glustersplitbrainfiles , verify that the two servers can connect to each other and gluster is running properly on both. Because our strategy requires picking a whole brick arbitrarily, you may have deleted a file from the only brick it was ever on. If so, you will be alerted by the above commands that some paths don't exist, and you will need to see if they are in your backup. If they're not, then you didn't delete them, so no worries. If they are, then copy them to the gluster mount at the correct path. If the ls of the gfs mount on the winner still shows input/output errors but the files on the brick don't show split-brain, try the ls command again and/or try it on the other nodes. It can take some time for the loser to get its copies updated, and that will be exacerbated by large files and/or large numbers of files.","title":"Heal and Check"},{"location":"secondary_response/split-brain/#clean-up","text":"Turn things back on for everybody in the cluster fpdsh -l $NODES_CSV -c \"sudo su -c 'rm -f /var/acquia/no-config-iptables; ah-config-iptables; service cron start; puppet agent --enable'\" Now that we've healed the loser brick, confirm that all the clients can access the files without error for NODE in ${NODES[@]}; do echo \"${PATHS[@]}\" | sed 's/\\/mnt\\/brick[0-9]*\\/\\(brick\\/\\)*/\\/mnt\\/gfs\\//g' \\ | fssh $NODE \"cat - | xargs -I FILE sudo ls -l 'FILE'\" done If you get errors, you may need to remount gluster on the offending servers and try again. If you still get errors, escalate to cloud. Call out the location of the backup in the ticket so that support can find it if necessary.","title":"Clean up"},{"location":"secondary_response/tungsten_administration/","text":"General Administration Check Consistency Check Status Dump Restore Missing Peers Properties Files Resetting Tungsten User Privileges Send Heartbeat State Overview Trim Log Files Total Wipe/Reinstallation Of Tungsten Tungsten Slave Resync Verifying Replication With Checksumming Tungsten Cheat Sheet Check Consistency Tungsten has built-in support for performing a consistency check per table. The logic behind it is similar to what pt-table-checksum does in that the number of rows and the checksum of the data is compared on the master and the slave. The check needs to be performed on a master service and will replicate down to each of the slave nodes. The biggest downside of the way that errors are reported is that it stops replication on the slave and the error shows that it was because of an inconsistency. Starting replication will make replication continue without a problem. This is a downside because it means that one small inconsistency will require manual intervention to make sure replication does not fall behind. We have not automated this check and because of the manual intervention we currently won't do that either. If you do want to run this check to verify that all is good make sure you are monitoring the replication on the slave nodes and be ready to restart them when an inconsistency is reported. The command to check the consistency for a single table is: trepctl -service <service name> check <database>.<table> To run the check for all tables you can run the following one-liner: HOST=$(hostname -s | tr -d \"-\") TABLES=($(mysql -NBe \"select concat(table_schema, '.', table_name) \\ from information_schema.tables \\ where table_schema not in ('acquia','mysql','information_schema','performance_schema')\")) for t in ${TABLES[@]}; do echo \"[$(date)] $t\" trepctl -service $host check $t done Please note that running this check will go over all of the data in all databases which will create both CPU load and disk I/O. Do not run this when the customer's site is busy. Check Status SITENAME= TUNGSTEN_BIN=\"/usr/local/tungsten-replicator/current/tungsten-replicator/bin\" fpdsh -t site:${SITENAME} \\ -n fsdbmesh \\ -c \"sudo ${TUNGSTEN_BIN}/trepctl services\" \\ | dshbak Dump Restore DR a single node DR all passive nodes Missing Peers Check trepctl services. If peers are missing, i.e. there are less than four peers descipher which server/s is/are missing. Check /usr/local/tungsten-replicator/peers.txt on all servers in the cluster. Make sure this is the same between all servers. If this file isn\u2019t valid, missing a peer, or malformed, then this is the first piece of the puzzle. Re-run fields-config-tungsten-peers.php - this should properly generate peers.txt and the /etc/stunnel/stunnel-client.conf files. Restart stunnel on all nodes where these updates were applied. sudo service stunnel4 restart Restart treplicator on all nodes. sudo service treplicator restart Properties Files [10:15:32] root@fsdbmesh-4057.prod:~# ls -la /vol/ebs1/tungsten-replicator/tungsten/tungsten-replicator/conf/ total 168 drwxr-xr-x 2 tungsten tungsten 4096 2013-02-28 22:33 . drwxr-xr-x 10 tungsten tungsten 109 2013-02-01 21:27 .. -rw-r--r-- 1 tungsten tungsten 1467 2013-02-01 21:27 development.log4j.properties -rw-r--r-- 1 tungsten tungsten 3730 2013-02-01 21:27 log4j.properties -rw-r--r-- 1 tungsten tungsten 4339 2013-02-01 21:27 replication-svc-wrapper.conf -rw-r--r-- 1 tungsten tungsten 420 2013-02-01 21:27 replicator.service.properties -rw-r--r-- 1 tungsten tungsten 1630 2013-02-01 21:27 services.properties -rw-r--r-- 1 tungsten tungsten 896 2013-02-01 21:27 shard.list -rw-r--r-- 1 tungsten tungsten 30796 2013-02-01 21:30 static-fsdbmesh4056.properties -rw-r--r-- 1 tungsten tungsten 30783 2013-02-01 21:27 static-fsdbmesh4057.properties -rw-r--r-- 1 tungsten tungsten 30796 2013-02-01 21:30 static-fsdbmesh4058.properties -rw-r--r-- 1 tungsten tungsten 30796 2013-02-01 21:30 static-fsdbmesh4059.properties -rw-r--r-- 1 tungsten tungsten 5673 2013-02-01 21:27 wrapper.conf Resetting Tungsten User Privileges In the current set of instructions, you will blow out the local tungsten user when you import the dump into the slaves. To reset: SERVER= fssh $SERVER sudo su - PASSWORD=$(grep -m1 password /root/.my.cnf|sed 's/password\\=//') mysql -e \"\\ SET sql_log_bin = 0; \\ grant all privileges on *.* to 'tungsten'@'$(hostname)' identified by '${PASSWORD}' with grant option; \\ grant super on *.* to 'tungsten'@'$(hostname)'; \\ flush privileges; \\ SET sql_log_bin = 1;\" Send Heartbeat Occasionally, if a cluster has replication lag, it needs to have a heartbeat sent. Run trepctl services If: The passive region reports as completely in sync. The active region reports the passive region as either -1 or a very high latency. Then do the following. fsdbmeshaaaa is the server that is reporting the lag and fsdbmesh-cccc is the server that is lagging. NOTE : In tungsten land the service is the hostname sans hyphen fssh fsdbmesh-cccc sudo su - trepctl -service fsdbmeshaaaa heartbeat State Overview There a couple of states that a replication service can be in: ONLINE This is the normal state and indicates that the replication service is running normally. One thing to note is that when a service is started but there is nothing to replicate the sequence number may be -1 and the latency may be -1.0. This does NOT indicate an error, just the fact that no statement has been replicated yet. This can be addressed by executing any type of update on the master service. GOING-ONLINE:SYNCHRONIZING This state should be temporary and indicates that the the service is going from offline to online. OFFLINE:NORMAL This state indicates that the service has been manually brought offline rather than by an error. OFFLINE:ERROR This state indicates that the service encountered an error and could not continue. unknown This indicates that the service has been stopped and nothing is currently known about the state. Tungsten Slave Resync The script tungsten-slave-resync is in root's $PATH on a tungsten host. It can only be run by root. How To Use It Find broken replication with trepctl services Run tungsten-slave-resync on server displaying broken replication services. NOTE: Always sync up non-active masters first! Examine the queries that are being skipped, cache/sessions queries should automatically skip, others should be examined and understood before skipping. Once tungsten-slave-resync is finished running, check services with trepctl services Check replication consistency by verifying replication with checksumming If checksums do not match up, or there are unsafe queries being skipped, follow the procedure to Dump Restore a single node . Trim Log Files There are 2 types of logs that Tungsten will fill up during \"normal\" operation. The first is the replication binlog, the second is the spurious normal, human readable log file filled with info level messages. Binlogs Sources: * OP-8421 * OP-36071 With tungsten the active mesh server can have logs that in time fill root. This procedure may need to be replicated on all mesh servers, but you should only need to purge the logs on the active. Given the example below we are ssh'd in to fsdbmesh-1153 which is the primary active. for i in 1154 1155 1156; do trepctl -service fsdbmesh$i unload -y thl -service fsdbmesh$i purge -y trepctl -service fsdbmesh$i load done NOTE : Only ever purge servers that are NOT the primary active!!! Using the above example, For: fsdbmesh-1154 only purge 1155 and 1156 fsdbmesh-1155 only purge 1154 and 1156 fsdbmesh-1156 only purge 1154 and 1155 Info Logs Tungsten logs to /usr instead of /var/log/. If you see a full / it could be caused by a number of things. Here's a du command that will highlight all the things: du --exclude={proc,dev,sys,vol,mnt} -sh /* If /usr is kind of large, keep reading. The path of the tungsten logs is /usr/local/tungsten-replicator/tungsten-replicator-2.0.3/tungsten-replicator/log . On the affected server cd to the log dir. If du -sh . reveals 5+G of data, you're in the right place. tar zcf oldlogs-$(date +%F).tgz trepsvc.log.* rm -f trepsvc.log.* Total Wipe/Reinstallation Of Tungsten WARNING: This is obviously a bad idea if you are considering running this on ANY in-production servers/sites. You must have the blessing of a DBA before using this procedure. This is a drastic clean slate \"fix\". THESE INSTRUCTIONS HAVE NOT BEEN IN ANY WAY TESTED. USE AT YOUR OWN RISK!! Set Vars: SITE= SERVERS=($(ah-server list site:${SITE} -w type=fsdbmesh)) SERVICES=($(echo ${SERVERS[@]} | tr -d '-')) Disable Puppet fpdsh -t site:${SITE} -n fsdbmesh -c \"sudo puppet agent --disable\" OR in Masterless Puppet mode fpdsh -t site:${SITE} -n fsdbmesh -c \"sudo ah-puppet-disable ${OP}\" Stop the replicator service fpdsh -t site:${SITE} -n fsdbmesh -c \"sudo servicetreplicator stop\" Verify that it is stopped fpdsh -t site:${SITE} -n fsdbmesh -c \"ps auxww | grep [t]ungsten\" Drop all the databases. SERVICES is an array of Tungsten service names, which are the server's hostname sans hyphen. fpdsh -t site:${SITE} -n fsdbmesh -c \"sudo mysql -e 'drop database tungsten_${SERVICES[0]}'\" fpdsh -t site:${SITE} -n fsdbmesh -c \"sudo mysql -e 'drop database tungsten_${SERVICES[1]}'\" fpdsh -t site:${SITE} -n fsdbmesh -c \"sudo mysql -e 'drop database tungsten_${SERVICES[2]}'\" fpdsh -t site:${SITE} -n fsdbmesh -c \"sudo mysql -e 'drop database tungsten_${SERVICES[3]}'\" fpdsh -t site:${SITE} -n fsdbmesh -c \"sudo mysql -e 'show databases'\" Delete the install directory and source tarball fpdsh -t site:${SITE} -n fsdbmesh -c \"sudo rm -vrf /root/tungsten-replicator-2.0.6-677.tar.gz\" fpdsh -t site:${SITE} -n fsdbmesh -c \"sudo rm -vrf /root/tungsten-replicator-2.0.6-677\" fpdsh -t site:${SITE} -n fsdbmesh -c \"sudo rm -vrf /vol/ebs1/tungsten-replicator\" Run puppet. For some reason I had to set the CWD to root for puppet to work. This is very very curious. fpdsh -t site:${SITE} -n fsdbmesh -c \"sudo puppet agent --enable\" fpdsh -t site:${SITE} -n fsdbmesh -c \"sudo puppet agent -t\" OR in Masterless Puppet mode fpdsh -t site:${SITE} -n fsdbmesh -c \"sudo ah-puppet-enable\" fpdsh -t site:${SITE} -n fsdbmesh -c \"sudo run-puppet\" Verify the fresh tungsten install is in place fpdsh -t site:${SITE} -n fsdbmesh -c \"ls -al /vol/ebs1/tungsten-replicator/release/tools/tungsten-installer\" On each server, rotate all binlogs and purge up to it fpdsh -t site:${SITE} -n fsdbmesh -c \"sudo mysql -e 'flush logs; purge binary logs to \\\"binlog.latest\\\"'\" Issue the task to set up the replication services and confirm success ah-task submit tungsten-setup --body=\"{\\\"server\\\" : \\\"${SERVERS[0]}\\\"}\" Check your work fpdsh -t site:${SITE} -n fsdbmesh -c \"\\ sudo /usr/local/tungsten-replicator/tungsten/tungsten-replicator/bin/trepctl services\" Verifying Replication With Checksumming On server A: pt-table-checksum --replicate acquia.checksum --create-replicate-table --empty-replicate-table \\ --chunk-size 5000 --sleep-coef 2 $(hostname -s) On servers B,C,D: pt-table-checksum --replicate-check 1 --replicate acquia.checksum localhost","title":"General Administration"},{"location":"secondary_response/tungsten_administration/#general-administration","text":"Check Consistency Check Status Dump Restore Missing Peers Properties Files Resetting Tungsten User Privileges Send Heartbeat State Overview Trim Log Files Total Wipe/Reinstallation Of Tungsten Tungsten Slave Resync Verifying Replication With Checksumming Tungsten Cheat Sheet","title":"General Administration"},{"location":"secondary_response/tungsten_administration/#check-consistency","text":"Tungsten has built-in support for performing a consistency check per table. The logic behind it is similar to what pt-table-checksum does in that the number of rows and the checksum of the data is compared on the master and the slave. The check needs to be performed on a master service and will replicate down to each of the slave nodes. The biggest downside of the way that errors are reported is that it stops replication on the slave and the error shows that it was because of an inconsistency. Starting replication will make replication continue without a problem. This is a downside because it means that one small inconsistency will require manual intervention to make sure replication does not fall behind. We have not automated this check and because of the manual intervention we currently won't do that either. If you do want to run this check to verify that all is good make sure you are monitoring the replication on the slave nodes and be ready to restart them when an inconsistency is reported. The command to check the consistency for a single table is: trepctl -service <service name> check <database>.<table> To run the check for all tables you can run the following one-liner: HOST=$(hostname -s | tr -d \"-\") TABLES=($(mysql -NBe \"select concat(table_schema, '.', table_name) \\ from information_schema.tables \\ where table_schema not in ('acquia','mysql','information_schema','performance_schema')\")) for t in ${TABLES[@]}; do echo \"[$(date)] $t\" trepctl -service $host check $t done Please note that running this check will go over all of the data in all databases which will create both CPU load and disk I/O. Do not run this when the customer's site is busy.","title":"Check Consistency"},{"location":"secondary_response/tungsten_administration/#check-status","text":"SITENAME= TUNGSTEN_BIN=\"/usr/local/tungsten-replicator/current/tungsten-replicator/bin\" fpdsh -t site:${SITENAME} \\ -n fsdbmesh \\ -c \"sudo ${TUNGSTEN_BIN}/trepctl services\" \\ | dshbak","title":"Check Status"},{"location":"secondary_response/tungsten_administration/#dump-restore","text":"DR a single node DR all passive nodes","title":"Dump Restore"},{"location":"secondary_response/tungsten_administration/#missing-peers","text":"Check trepctl services. If peers are missing, i.e. there are less than four peers descipher which server/s is/are missing. Check /usr/local/tungsten-replicator/peers.txt on all servers in the cluster. Make sure this is the same between all servers. If this file isn\u2019t valid, missing a peer, or malformed, then this is the first piece of the puzzle. Re-run fields-config-tungsten-peers.php - this should properly generate peers.txt and the /etc/stunnel/stunnel-client.conf files. Restart stunnel on all nodes where these updates were applied. sudo service stunnel4 restart Restart treplicator on all nodes. sudo service treplicator restart","title":"Missing Peers"},{"location":"secondary_response/tungsten_administration/#properties-files","text":"[10:15:32] root@fsdbmesh-4057.prod:~# ls -la /vol/ebs1/tungsten-replicator/tungsten/tungsten-replicator/conf/ total 168 drwxr-xr-x 2 tungsten tungsten 4096 2013-02-28 22:33 . drwxr-xr-x 10 tungsten tungsten 109 2013-02-01 21:27 .. -rw-r--r-- 1 tungsten tungsten 1467 2013-02-01 21:27 development.log4j.properties -rw-r--r-- 1 tungsten tungsten 3730 2013-02-01 21:27 log4j.properties -rw-r--r-- 1 tungsten tungsten 4339 2013-02-01 21:27 replication-svc-wrapper.conf -rw-r--r-- 1 tungsten tungsten 420 2013-02-01 21:27 replicator.service.properties -rw-r--r-- 1 tungsten tungsten 1630 2013-02-01 21:27 services.properties -rw-r--r-- 1 tungsten tungsten 896 2013-02-01 21:27 shard.list -rw-r--r-- 1 tungsten tungsten 30796 2013-02-01 21:30 static-fsdbmesh4056.properties -rw-r--r-- 1 tungsten tungsten 30783 2013-02-01 21:27 static-fsdbmesh4057.properties -rw-r--r-- 1 tungsten tungsten 30796 2013-02-01 21:30 static-fsdbmesh4058.properties -rw-r--r-- 1 tungsten tungsten 30796 2013-02-01 21:30 static-fsdbmesh4059.properties -rw-r--r-- 1 tungsten tungsten 5673 2013-02-01 21:27 wrapper.conf","title":"Properties Files"},{"location":"secondary_response/tungsten_administration/#resetting-tungsten-user-privileges","text":"In the current set of instructions, you will blow out the local tungsten user when you import the dump into the slaves. To reset: SERVER= fssh $SERVER sudo su - PASSWORD=$(grep -m1 password /root/.my.cnf|sed 's/password\\=//') mysql -e \"\\ SET sql_log_bin = 0; \\ grant all privileges on *.* to 'tungsten'@'$(hostname)' identified by '${PASSWORD}' with grant option; \\ grant super on *.* to 'tungsten'@'$(hostname)'; \\ flush privileges; \\ SET sql_log_bin = 1;\"","title":"Resetting Tungsten User Privileges"},{"location":"secondary_response/tungsten_administration/#send-heartbeat","text":"Occasionally, if a cluster has replication lag, it needs to have a heartbeat sent. Run trepctl services If: The passive region reports as completely in sync. The active region reports the passive region as either -1 or a very high latency. Then do the following. fsdbmeshaaaa is the server that is reporting the lag and fsdbmesh-cccc is the server that is lagging. NOTE : In tungsten land the service is the hostname sans hyphen fssh fsdbmesh-cccc sudo su - trepctl -service fsdbmeshaaaa heartbeat","title":"Send Heartbeat"},{"location":"secondary_response/tungsten_administration/#state-overview","text":"There a couple of states that a replication service can be in: ONLINE This is the normal state and indicates that the replication service is running normally. One thing to note is that when a service is started but there is nothing to replicate the sequence number may be -1 and the latency may be -1.0. This does NOT indicate an error, just the fact that no statement has been replicated yet. This can be addressed by executing any type of update on the master service. GOING-ONLINE:SYNCHRONIZING This state should be temporary and indicates that the the service is going from offline to online. OFFLINE:NORMAL This state indicates that the service has been manually brought offline rather than by an error. OFFLINE:ERROR This state indicates that the service encountered an error and could not continue. unknown This indicates that the service has been stopped and nothing is currently known about the state.","title":"State Overview"},{"location":"secondary_response/tungsten_administration/#tungsten-slave-resync","text":"The script tungsten-slave-resync is in root's $PATH on a tungsten host. It can only be run by root.","title":"Tungsten Slave Resync"},{"location":"secondary_response/tungsten_administration/#how-to-use-it","text":"Find broken replication with trepctl services Run tungsten-slave-resync on server displaying broken replication services. NOTE: Always sync up non-active masters first! Examine the queries that are being skipped, cache/sessions queries should automatically skip, others should be examined and understood before skipping. Once tungsten-slave-resync is finished running, check services with trepctl services Check replication consistency by verifying replication with checksumming If checksums do not match up, or there are unsafe queries being skipped, follow the procedure to Dump Restore a single node .","title":"How To Use It"},{"location":"secondary_response/tungsten_administration/#trim-log-files","text":"There are 2 types of logs that Tungsten will fill up during \"normal\" operation. The first is the replication binlog, the second is the spurious normal, human readable log file filled with info level messages.","title":"Trim Log Files"},{"location":"secondary_response/tungsten_administration/#binlogs","text":"Sources: * OP-8421 * OP-36071 With tungsten the active mesh server can have logs that in time fill root. This procedure may need to be replicated on all mesh servers, but you should only need to purge the logs on the active. Given the example below we are ssh'd in to fsdbmesh-1153 which is the primary active. for i in 1154 1155 1156; do trepctl -service fsdbmesh$i unload -y thl -service fsdbmesh$i purge -y trepctl -service fsdbmesh$i load done NOTE : Only ever purge servers that are NOT the primary active!!! Using the above example, For: fsdbmesh-1154 only purge 1155 and 1156 fsdbmesh-1155 only purge 1154 and 1156 fsdbmesh-1156 only purge 1154 and 1155","title":"Binlogs"},{"location":"secondary_response/tungsten_administration/#info-logs","text":"Tungsten logs to /usr instead of /var/log/. If you see a full / it could be caused by a number of things. Here's a du command that will highlight all the things: du --exclude={proc,dev,sys,vol,mnt} -sh /* If /usr is kind of large, keep reading. The path of the tungsten logs is /usr/local/tungsten-replicator/tungsten-replicator-2.0.3/tungsten-replicator/log . On the affected server cd to the log dir. If du -sh . reveals 5+G of data, you're in the right place. tar zcf oldlogs-$(date +%F).tgz trepsvc.log.* rm -f trepsvc.log.*","title":"Info Logs"},{"location":"secondary_response/tungsten_administration/#total-wipereinstallation-of-tungsten","text":"WARNING: This is obviously a bad idea if you are considering running this on ANY in-production servers/sites. You must have the blessing of a DBA before using this procedure. This is a drastic clean slate \"fix\". THESE INSTRUCTIONS HAVE NOT BEEN IN ANY WAY TESTED. USE AT YOUR OWN RISK!! Set Vars: SITE= SERVERS=($(ah-server list site:${SITE} -w type=fsdbmesh)) SERVICES=($(echo ${SERVERS[@]} | tr -d '-')) Disable Puppet fpdsh -t site:${SITE} -n fsdbmesh -c \"sudo puppet agent --disable\" OR in Masterless Puppet mode fpdsh -t site:${SITE} -n fsdbmesh -c \"sudo ah-puppet-disable ${OP}\" Stop the replicator service fpdsh -t site:${SITE} -n fsdbmesh -c \"sudo servicetreplicator stop\" Verify that it is stopped fpdsh -t site:${SITE} -n fsdbmesh -c \"ps auxww | grep [t]ungsten\" Drop all the databases. SERVICES is an array of Tungsten service names, which are the server's hostname sans hyphen. fpdsh -t site:${SITE} -n fsdbmesh -c \"sudo mysql -e 'drop database tungsten_${SERVICES[0]}'\" fpdsh -t site:${SITE} -n fsdbmesh -c \"sudo mysql -e 'drop database tungsten_${SERVICES[1]}'\" fpdsh -t site:${SITE} -n fsdbmesh -c \"sudo mysql -e 'drop database tungsten_${SERVICES[2]}'\" fpdsh -t site:${SITE} -n fsdbmesh -c \"sudo mysql -e 'drop database tungsten_${SERVICES[3]}'\" fpdsh -t site:${SITE} -n fsdbmesh -c \"sudo mysql -e 'show databases'\" Delete the install directory and source tarball fpdsh -t site:${SITE} -n fsdbmesh -c \"sudo rm -vrf /root/tungsten-replicator-2.0.6-677.tar.gz\" fpdsh -t site:${SITE} -n fsdbmesh -c \"sudo rm -vrf /root/tungsten-replicator-2.0.6-677\" fpdsh -t site:${SITE} -n fsdbmesh -c \"sudo rm -vrf /vol/ebs1/tungsten-replicator\" Run puppet. For some reason I had to set the CWD to root for puppet to work. This is very very curious. fpdsh -t site:${SITE} -n fsdbmesh -c \"sudo puppet agent --enable\" fpdsh -t site:${SITE} -n fsdbmesh -c \"sudo puppet agent -t\" OR in Masterless Puppet mode fpdsh -t site:${SITE} -n fsdbmesh -c \"sudo ah-puppet-enable\" fpdsh -t site:${SITE} -n fsdbmesh -c \"sudo run-puppet\" Verify the fresh tungsten install is in place fpdsh -t site:${SITE} -n fsdbmesh -c \"ls -al /vol/ebs1/tungsten-replicator/release/tools/tungsten-installer\" On each server, rotate all binlogs and purge up to it fpdsh -t site:${SITE} -n fsdbmesh -c \"sudo mysql -e 'flush logs; purge binary logs to \\\"binlog.latest\\\"'\" Issue the task to set up the replication services and confirm success ah-task submit tungsten-setup --body=\"{\\\"server\\\" : \\\"${SERVERS[0]}\\\"}\" Check your work fpdsh -t site:${SITE} -n fsdbmesh -c \"\\ sudo /usr/local/tungsten-replicator/tungsten/tungsten-replicator/bin/trepctl services\"","title":"Total Wipe/Reinstallation Of Tungsten"},{"location":"secondary_response/tungsten_administration/#verifying-replication-with-checksumming","text":"On server A: pt-table-checksum --replicate acquia.checksum --create-replicate-table --empty-replicate-table \\ --chunk-size 5000 --sleep-coef 2 $(hostname -s) On servers B,C,D: pt-table-checksum --replicate-check 1 --replicate acquia.checksum localhost","title":"Verifying Replication With Checksumming"},{"location":"secondary_response/xtrabackup/","text":"Xtrabackup Dump Restore This procedure restores replication by effectively copying the database files from the healthy, known good, active database to a corrupt/broken passive one. It is critically important that when a database has broken replication, or is split brained, you ensure the db is locked to the active server!! ah-db-cluster status $DBMASTER ah-db-cluster lock $DBMASTER Pre Two terminal sessions are required for this procedure. You will be logged in to the primary db in one and the secondary db in the other. If your terminal times out you MUST re-set the ENV vars! Ensure MySQL versions match between servers. This should only be a consideration if one of the DBAs is rolling updates, but if this is the case they will have given ample notice. Ensure there is enough free disk space on the ephemeral partition (/mnt) on the source server to dump the contents of /var/lib/mysql/. Xtrabackup effectively dumps all databases inclusive of binlogs to /mnt/tmp. If there is not enough space you will need to create and attach a new volume; this is beyond the scope of this procedure. Do NOT use xtrabackup on any ACSF realms! Doing so causes rolling outages and has other impacts. For ACSF realms, the mysqldump procedure should be followed. Because the DR process can take many hours, depending on volume usage plus database load, we use screen. If you don't use it consider yourself warned! There are many other safety reasons too; power outage, network interruption, etc. Use screen! Restoring MySQL data from dbmaster-A to dbmaster-B DBMASTER_A: active server being restored from. DBMASTER_B: failed/corrupt server being restored to. Set these variables on both servers . OPS_USER is your $USER , and FIELDS_STAGE is prod for ACE, devcloud for ACP etc. Variables must be exported for use inside of screen. FIELDS_SERVER_DOMAIN' does not exist on servers, so it must be set by hand. If you are performing this task in the hosting-dev environment, then you must set the value of FIELDS_SERVER_DOMAIN to srvs.ahdev.co Otherwise, use the variable assignment provided below. export OPS_USER= export DBMASTER_A= export DBMASTER_B= export FIELDS_STAGE= export FIELDS_SERVER_DOMAIN=hosting.acquia.com screen -S Xtrabackup Prepare XtraBackup snapshot Stop mysqld and puppet on DBMASTER_B puppet agent --disable \"$OPS_USER - Xtrabackup from $DBMASTER_A to $DBMASTER_B\" ah-runbook \"$OPS_USER - Xtrabackup from $DBMASTER_A to $DBMASTER_B\" service cron stop service mysql stop OR in Masterless Puppet mode sudo ah-puppet-disable \"$OPS_USER - Xtrabackup from $DBMASTER_A to $DBMASTER_B\" ah-runbook \"$OPS_USER - Xtrabackup from $DBMASTER_A to $DBMASTER_B\" service cron stop service mysql stop Stop Slave on DBMASTER_A. This part of the procedure locks tables for reading, so may cause some short term outages. There is no avoiding this as it's a necessary evil for a long term gain. The ulimit is set to greater than the number of files to scan/copy. mysql -e \"stop slave; set global wait_timeout=6000;\" mkdir -p /mnt/tmp/master-backup ulimit -n $(($(find /var/lib/mysql/ | wc -l)+1024)) PASSWORD=$(grep -m1 password /root/.my.cnf|sed 's/password\\=//') innobackupex \\ --defaults-file=/etc/mysql/my.cnf \\ --user=root \\ --password=$PASSWORD \\ --slave-info /mnt/tmp/master-backup/ 2>&1 \\ | tee /mnt/tmp/master-backup.log Apply innodb logs on DBMASTER_A TIME_STAMP=$(ls -t /mnt/tmp/master-backup | head -1) innobackupex \\ --defaults-file=/etc/mysql/my.cnf \\ --user=root \\ --password=$PASSWORD \\ --slave-info \\ --apply-log /mnt/tmp/master-backup/$TIME_STAMP 2>&1 \\ | tee /mnt/tmp/master-backup-apply.log Copy snapshot and prepare passive master If you, for any reason, want to keep the corrupt data you will need to either create an EBS snapshot of the volume or copy the data to another volume first. That is beyond the scope of this procedure. This is the Point of No Return (PNR). Delete the old MySQL data directory on DBMASTER_B . rm -rf /var/lib/mysql/* touch /var/lib/mysql/.install.first.lock From the bastion, copy the prepared Xtrabackup files from DBMASTER_A to DBMASTER_B . sv-rsyncfile -o avP ${DBMASTER_A}:/mnt/tmp/master-backup/${TIME_STAMP}/ ${DBMASTER_B}:/var/lib/mysql Fix ownership and start MySQL on DBMASTER_B . Note : you can't chown a symlink. Ignore the error about the debian-sys-maint user: sed -i 's/\\[mysqld\\]/\\[mysqld\\]\\nskip-slave-start/' /etc/mysql/my.cnf chown -R mysql:mysql /vol/ebs1/mysql/ \\ && /etc/init.d/mysql start \\ && reset-debian-password.sh Restore replication Update DBMASTER_A with the current binlog position of the passive master: From the bastion, get the MASTER_LOG_FILE and MASTER_LOG_POS of DBMASTER_B . MASTER_STATUS=($(fssh ${DBMASTER_B} \"sudo mysql -BNe 'show master status'\")) echo \"MASTER_LOG_FILE=${MASTER_STATUS[0]}\" echo \"MASTER_LOG_POS=${MASTER_STATUS[1]}\" Set the echoed variables on DBMASTER_A . Update MySQL: mysql -e \"change master to master_log_file='$MASTER_LOG_FILE', master_log_pos=$MASTER_LOG_POS; start slave;\" Reset replication to restored passive master Update DBMASTER_B with the data from the active xtrabckup_binlog_info Set variables; PASSWORD=$(grep -m1 password /root/.my.cnf|sed 's/password\\=//') MASTER_STATUS=($(cat /var/lib/mysql/xtrabackup_binlog_info)) echo \"${MASTER_STATUS[@]}\" MASTER_LOG_FILE=${MASTER_STATUS[0]} MASTER_LOG_POS=${MASTER_STATUS[1]} Update MySQL mysql -e \"change master to master_log_file='$MASTER_LOG_FILE', master_log_pos=$MASTER_LOG_POS, master_user='root', master_host='$DBMASTER_A.$FIELDS_STAGE.$FIELDS_SERVER_DOMAIN', master_password='$PASSWORD'; start slave;\" Verify replication Run on both hosts: mysqladmin flush-privileges stat mysql-slave-resync.pl mysql -e 'show slave status\\G' Clean up DBMASTER_A ah-config-iptables DBMASTER_B puppet agent --enable puppet agent -t OR in Masterless Puppet mode sudo ah-puppet-enable sudo run-puppet Provided that there are zero seconds of slave lag both ways, unlock the db. ah-db-cluster unlock $DBMASTER_A","title":"Xtrabackup Dump Restore"},{"location":"secondary_response/xtrabackup/#xtrabackup-dump-restore","text":"This procedure restores replication by effectively copying the database files from the healthy, known good, active database to a corrupt/broken passive one. It is critically important that when a database has broken replication, or is split brained, you ensure the db is locked to the active server!! ah-db-cluster status $DBMASTER ah-db-cluster lock $DBMASTER","title":"Xtrabackup Dump Restore"},{"location":"secondary_response/xtrabackup/#pre","text":"Two terminal sessions are required for this procedure. You will be logged in to the primary db in one and the secondary db in the other. If your terminal times out you MUST re-set the ENV vars! Ensure MySQL versions match between servers. This should only be a consideration if one of the DBAs is rolling updates, but if this is the case they will have given ample notice. Ensure there is enough free disk space on the ephemeral partition (/mnt) on the source server to dump the contents of /var/lib/mysql/. Xtrabackup effectively dumps all databases inclusive of binlogs to /mnt/tmp. If there is not enough space you will need to create and attach a new volume; this is beyond the scope of this procedure. Do NOT use xtrabackup on any ACSF realms! Doing so causes rolling outages and has other impacts. For ACSF realms, the mysqldump procedure should be followed. Because the DR process can take many hours, depending on volume usage plus database load, we use screen. If you don't use it consider yourself warned! There are many other safety reasons too; power outage, network interruption, etc. Use screen!","title":"Pre"},{"location":"secondary_response/xtrabackup/#restoring-mysql-data-from-dbmaster-a-to-dbmaster-b","text":"DBMASTER_A: active server being restored from. DBMASTER_B: failed/corrupt server being restored to. Set these variables on both servers . OPS_USER is your $USER , and FIELDS_STAGE is prod for ACE, devcloud for ACP etc. Variables must be exported for use inside of screen. FIELDS_SERVER_DOMAIN' does not exist on servers, so it must be set by hand. If you are performing this task in the hosting-dev environment, then you must set the value of FIELDS_SERVER_DOMAIN to srvs.ahdev.co Otherwise, use the variable assignment provided below. export OPS_USER= export DBMASTER_A= export DBMASTER_B= export FIELDS_STAGE= export FIELDS_SERVER_DOMAIN=hosting.acquia.com screen -S Xtrabackup","title":"Restoring MySQL data from dbmaster-A to dbmaster-B"},{"location":"secondary_response/xtrabackup/#prepare-xtrabackup-snapshot","text":"Stop mysqld and puppet on DBMASTER_B puppet agent --disable \"$OPS_USER - Xtrabackup from $DBMASTER_A to $DBMASTER_B\" ah-runbook \"$OPS_USER - Xtrabackup from $DBMASTER_A to $DBMASTER_B\" service cron stop service mysql stop OR in Masterless Puppet mode sudo ah-puppet-disable \"$OPS_USER - Xtrabackup from $DBMASTER_A to $DBMASTER_B\" ah-runbook \"$OPS_USER - Xtrabackup from $DBMASTER_A to $DBMASTER_B\" service cron stop service mysql stop Stop Slave on DBMASTER_A. This part of the procedure locks tables for reading, so may cause some short term outages. There is no avoiding this as it's a necessary evil for a long term gain. The ulimit is set to greater than the number of files to scan/copy. mysql -e \"stop slave; set global wait_timeout=6000;\" mkdir -p /mnt/tmp/master-backup ulimit -n $(($(find /var/lib/mysql/ | wc -l)+1024)) PASSWORD=$(grep -m1 password /root/.my.cnf|sed 's/password\\=//') innobackupex \\ --defaults-file=/etc/mysql/my.cnf \\ --user=root \\ --password=$PASSWORD \\ --slave-info /mnt/tmp/master-backup/ 2>&1 \\ | tee /mnt/tmp/master-backup.log Apply innodb logs on DBMASTER_A TIME_STAMP=$(ls -t /mnt/tmp/master-backup | head -1) innobackupex \\ --defaults-file=/etc/mysql/my.cnf \\ --user=root \\ --password=$PASSWORD \\ --slave-info \\ --apply-log /mnt/tmp/master-backup/$TIME_STAMP 2>&1 \\ | tee /mnt/tmp/master-backup-apply.log","title":"Prepare XtraBackup snapshot"},{"location":"secondary_response/xtrabackup/#copy-snapshot-and-prepare-passive-master","text":"If you, for any reason, want to keep the corrupt data you will need to either create an EBS snapshot of the volume or copy the data to another volume first. That is beyond the scope of this procedure. This is the Point of No Return (PNR). Delete the old MySQL data directory on DBMASTER_B . rm -rf /var/lib/mysql/* touch /var/lib/mysql/.install.first.lock From the bastion, copy the prepared Xtrabackup files from DBMASTER_A to DBMASTER_B . sv-rsyncfile -o avP ${DBMASTER_A}:/mnt/tmp/master-backup/${TIME_STAMP}/ ${DBMASTER_B}:/var/lib/mysql Fix ownership and start MySQL on DBMASTER_B . Note : you can't chown a symlink. Ignore the error about the debian-sys-maint user: sed -i 's/\\[mysqld\\]/\\[mysqld\\]\\nskip-slave-start/' /etc/mysql/my.cnf chown -R mysql:mysql /vol/ebs1/mysql/ \\ && /etc/init.d/mysql start \\ && reset-debian-password.sh","title":"Copy snapshot and prepare passive master"},{"location":"secondary_response/xtrabackup/#restore-replication","text":"Update DBMASTER_A with the current binlog position of the passive master: From the bastion, get the MASTER_LOG_FILE and MASTER_LOG_POS of DBMASTER_B . MASTER_STATUS=($(fssh ${DBMASTER_B} \"sudo mysql -BNe 'show master status'\")) echo \"MASTER_LOG_FILE=${MASTER_STATUS[0]}\" echo \"MASTER_LOG_POS=${MASTER_STATUS[1]}\" Set the echoed variables on DBMASTER_A . Update MySQL: mysql -e \"change master to master_log_file='$MASTER_LOG_FILE', master_log_pos=$MASTER_LOG_POS; start slave;\"","title":"Restore replication"},{"location":"secondary_response/xtrabackup/#reset-replication-to-restored-passive-master","text":"Update DBMASTER_B with the data from the active xtrabckup_binlog_info Set variables; PASSWORD=$(grep -m1 password /root/.my.cnf|sed 's/password\\=//') MASTER_STATUS=($(cat /var/lib/mysql/xtrabackup_binlog_info)) echo \"${MASTER_STATUS[@]}\" MASTER_LOG_FILE=${MASTER_STATUS[0]} MASTER_LOG_POS=${MASTER_STATUS[1]} Update MySQL mysql -e \"change master to master_log_file='$MASTER_LOG_FILE', master_log_pos=$MASTER_LOG_POS, master_user='root', master_host='$DBMASTER_A.$FIELDS_STAGE.$FIELDS_SERVER_DOMAIN', master_password='$PASSWORD'; start slave;\"","title":"Reset replication to restored passive master"},{"location":"secondary_response/xtrabackup/#verify-replication","text":"Run on both hosts: mysqladmin flush-privileges stat mysql-slave-resync.pl mysql -e 'show slave status\\G'","title":"Verify replication"},{"location":"secondary_response/xtrabackup/#clean-up","text":"DBMASTER_A ah-config-iptables DBMASTER_B puppet agent --enable puppet agent -t OR in Masterless Puppet mode sudo ah-puppet-enable sudo run-puppet Provided that there are zero seconds of slave lag both ways, unlock the db. ah-db-cluster unlock $DBMASTER_A","title":"Clean up"},{"location":"standard_maintenance/","text":"Standard Maintenance AZ Migration AZ Migration Preparatory Work Variables (prep) Procedure (prep) Important Note Monitor Snapshot Progress Maintenance Window Procedure for Servers without Volumes (web) Important Note Procedure for Servers with Volumes Confirm ELB AZ Configuration is Correct when migrating Bals Monitor Snapshot Progress AZ Migration (manual) Manual AZ Migration Preparatory Work Variables (prep) Procedure (prep) Wait for completion Maintenance Window Procedure for Servers without Volumes (web) Procedure for Servers with Volumes AZ Migration: Volume M (manual) AZ Migration (xvdm) Variables Maintenance Window Procedure Post Launch AZ Migration: Volume MN (manual) AZ Migration (xvdm xvdn) Variables Maintenance Window Procedure Post Launch AZ Migration: Volume MNO (manual) AZ Migration (xvdm xvdn xvdo) Variables Maintenance Window Procedure Post Launch AZ Migration: Volume NO (manual) AZ Migration (xvdn xvdo) Variables Maintenance Window Procedure Post Launch Fedramp Relaunch Relaunching into FedRAMP compliance VPC Site Factory site layout Prep Maintenance Validate Maintenance Relaunch Into VPC FIPS 140-2 FIPS 140-2 compliant instance management Reporting issues References FIPS Check Check whether a server is already FIPS compliant Check kernel release Check package pin Check mysql version on DB servers FIPS Disable Disable FIPS Disable FIPS on a server Bulk disable FIPS on servers FIPS Enable Enable FIPS Enable FIPS on a server Bulk enable FIPS on servers Bulk relaunch servers FIPS Migrate DB Enable FIPS on DB servers FIPS MySQL Upgrade Upgrading mysql tier to be FIPS 140-2 compliant Pre-requisites (must be known before you begin) Gathering a list of servers Create lists of database servers for the customer Verify the MySQL Versions before starting Find all active and passive database servers Upgrade database servers to use FIPS compliant mysql version Verification step Suspend, Enable FIPS, Relaunch to New VPC FIPS Provision FIPS 140-2 compliant server provisioning Provisioning a Fedramp Site (With Acquia Shield) Moving a FedRAMP Site with Acquia Cloud Shield Requirements VPC Site Factory site layout Provisioning New Hardware Preparation Procedure Important Note Syncing Data Prior to Downtime Variables Home directory copy commands Site Move Verification IPv6 Support TLSv1.2 Support Network Boundaries Site Factory post-steps Recovery Provisioning a Fedramp Site (Without Acquia Shield) Moving a FedRAMP Site without Acquia Cloud Shield Requirements VPC Site Factory site layout Provisioning New Hardware Preparation Procedure Important Note Syncing Data Prior to Downtime Varriables Migrating EIP of dedicated bals - PLEASE READ THIS CAREFULLY Home directory copy commands Site Move Create an ELB Verification IPv6 Support TLSv1.2 Support Site Factory post-steps Recovery Relaunch Bastion Relaunching Rebooting Pre-Flight Check Suspending Launching Post Relaunch Setup Fields Ops-misc Ops-API (Otto) Ahrabot Ahopsbot AHT AWS CLI ops-incidents Restore the crontab Unison Sync Cleanup Notification Replace Volumes Replacing a Bad Volume Manually Diagnosing a Bad Volume Repairing the File System Replacing the Volume with a Snapshot Resize Volumes Resize volumes Emergency upsize guidelines (ACE & ACSF only) Gluster Prep Dumps Preparatory steps Create and attach the new volume Copy data: rsync method Important Note Copy data: XFS dump-restore method Important Note No data copy: no_data_migration method Maintenance window steps Volume and service specifics MySQL volumes (xvdm) Backup (xvdn) Gluster (xvdo) Mntfs (xvdb) Livedev-enabled sites Troubleshooting Reset XFS dump-restore Gluster 3.4 ID Volume Cleanup Resize Volumes Manual Resize volumes manually Emergency upsize guidelines (ACE & ACSF only) Gluster Prep Dumps Preparatory steps Create and attach the new volume Format and mount the new volume Copy data: rsync method Copy data: XFS dump-restore method Maintenance window steps Volume and service specifics MySQL volumes (sdm) Backup (sdn) Gluster (sdo) Troubleshooting Reset XFS dump-restore Gluster 3.4 ID Deleting a volume Volume Cleanup","title":"Standard Maintenance"},{"location":"standard_maintenance/#standard-maintenance","text":"","title":"Standard Maintenance"},{"location":"standard_maintenance/#az-migration","text":"AZ Migration Preparatory Work Variables (prep) Procedure (prep) Important Note Monitor Snapshot Progress Maintenance Window Procedure for Servers without Volumes (web) Important Note Procedure for Servers with Volumes Confirm ELB AZ Configuration is Correct when migrating Bals Monitor Snapshot Progress","title":"AZ Migration"},{"location":"standard_maintenance/#az-migration-manual","text":"Manual AZ Migration Preparatory Work Variables (prep) Procedure (prep) Wait for completion Maintenance Window Procedure for Servers without Volumes (web) Procedure for Servers with Volumes","title":"AZ Migration (manual)"},{"location":"standard_maintenance/#az-migration-volume-m-manual","text":"AZ Migration (xvdm) Variables Maintenance Window Procedure Post Launch","title":"AZ Migration: Volume M (manual)"},{"location":"standard_maintenance/#az-migration-volume-mn-manual","text":"AZ Migration (xvdm xvdn) Variables Maintenance Window Procedure Post Launch","title":"AZ Migration: Volume MN (manual)"},{"location":"standard_maintenance/#az-migration-volume-mno-manual","text":"AZ Migration (xvdm xvdn xvdo) Variables Maintenance Window Procedure Post Launch","title":"AZ Migration: Volume MNO (manual)"},{"location":"standard_maintenance/#az-migration-volume-no-manual","text":"AZ Migration (xvdn xvdo) Variables Maintenance Window Procedure Post Launch","title":"AZ Migration: Volume NO (manual)"},{"location":"standard_maintenance/#fedramp-relaunch","text":"Relaunching into FedRAMP compliance VPC Site Factory site layout Prep Maintenance Validate Maintenance Relaunch Into VPC","title":"Fedramp Relaunch"},{"location":"standard_maintenance/#fips-140-2","text":"FIPS 140-2 compliant instance management Reporting issues References","title":"FIPS 140-2"},{"location":"standard_maintenance/#fips-check","text":"Check whether a server is already FIPS compliant Check kernel release Check package pin Check mysql version on DB servers","title":"FIPS Check"},{"location":"standard_maintenance/#fips-disable","text":"Disable FIPS Disable FIPS on a server Bulk disable FIPS on servers","title":"FIPS Disable"},{"location":"standard_maintenance/#fips-enable","text":"Enable FIPS Enable FIPS on a server Bulk enable FIPS on servers Bulk relaunch servers","title":"FIPS Enable"},{"location":"standard_maintenance/#fips-migrate-db","text":"Enable FIPS on DB servers","title":"FIPS Migrate DB"},{"location":"standard_maintenance/#fips-mysql-upgrade","text":"Upgrading mysql tier to be FIPS 140-2 compliant Pre-requisites (must be known before you begin) Gathering a list of servers Create lists of database servers for the customer Verify the MySQL Versions before starting Find all active and passive database servers Upgrade database servers to use FIPS compliant mysql version Verification step Suspend, Enable FIPS, Relaunch to New VPC","title":"FIPS MySQL Upgrade"},{"location":"standard_maintenance/#fips-provision","text":"FIPS 140-2 compliant server provisioning","title":"FIPS Provision"},{"location":"standard_maintenance/#provisioning-a-fedramp-site-with-acquia-shield","text":"Moving a FedRAMP Site with Acquia Cloud Shield Requirements VPC Site Factory site layout Provisioning New Hardware Preparation Procedure Important Note Syncing Data Prior to Downtime Variables Home directory copy commands Site Move Verification IPv6 Support TLSv1.2 Support Network Boundaries Site Factory post-steps Recovery","title":"Provisioning a Fedramp Site (With Acquia Shield)"},{"location":"standard_maintenance/#provisioning-a-fedramp-site-without-acquia-shield","text":"Moving a FedRAMP Site without Acquia Cloud Shield Requirements VPC Site Factory site layout Provisioning New Hardware Preparation Procedure Important Note Syncing Data Prior to Downtime Varriables Migrating EIP of dedicated bals - PLEASE READ THIS CAREFULLY Home directory copy commands Site Move Create an ELB Verification IPv6 Support TLSv1.2 Support Site Factory post-steps Recovery","title":"Provisioning a Fedramp Site (Without Acquia Shield)"},{"location":"standard_maintenance/#relaunch-bastion","text":"Relaunching Rebooting Pre-Flight Check Suspending Launching Post Relaunch Setup Fields Ops-misc Ops-API (Otto) Ahrabot Ahopsbot AHT AWS CLI ops-incidents Restore the crontab Unison Sync Cleanup Notification","title":"Relaunch Bastion"},{"location":"standard_maintenance/#replace-volumes","text":"Replacing a Bad Volume Manually Diagnosing a Bad Volume Repairing the File System Replacing the Volume with a Snapshot","title":"Replace Volumes"},{"location":"standard_maintenance/#resize-volumes","text":"Resize volumes Emergency upsize guidelines (ACE & ACSF only) Gluster Prep Dumps Preparatory steps Create and attach the new volume Copy data: rsync method Important Note Copy data: XFS dump-restore method Important Note No data copy: no_data_migration method Maintenance window steps Volume and service specifics MySQL volumes (xvdm) Backup (xvdn) Gluster (xvdo) Mntfs (xvdb) Livedev-enabled sites Troubleshooting Reset XFS dump-restore Gluster 3.4 ID Volume Cleanup","title":"Resize Volumes"},{"location":"standard_maintenance/#resize-volumes-manual","text":"Resize volumes manually Emergency upsize guidelines (ACE & ACSF only) Gluster Prep Dumps Preparatory steps Create and attach the new volume Format and mount the new volume Copy data: rsync method Copy data: XFS dump-restore method Maintenance window steps Volume and service specifics MySQL volumes (sdm) Backup (sdn) Gluster (sdo) Troubleshooting Reset XFS dump-restore Gluster 3.4 ID Deleting a volume Volume Cleanup","title":"Resize Volumes Manual"},{"location":"standard_maintenance/audit_shared_bal_pairs/","text":"Audit Shared Bal Pairs We need to audit the shared bal pairs for number of reasons. Please follow the below instructions : For each VPC this tool will list shared bal pairs running with less than or equal to 25 sites. This tool will list all the active bal pairs for each VPC irrespective of number of sites on them for guidance If any active legacy bal pair running very high number of sites, add a new active bal pair. If the bal pair has low number of prod sites like less than 3 and not active in the region, create an AM ticket to request the customer to move their sites to active bal pair in the same region. E.g AM-4661802 Check for pairs running with high hardware size but has low number of prod and non-prod sites. Audit the bal pair for downsizing the hardware and add your findings in the ticket. If a pair has low number of RA sites like less than 10 and the pair is not active RA add the same in the ticket. After adding all the audit result in the ticket ask Senior Engineer or Operations team lead and Ops Manager to review your findings. Once you get all the approvals, proceed accordingly. Do not terminate any bal pair until it has no site running on it. Output of this tool is according to table format compatible with JIRA to get a better view of the result. We have a tool available with us which will do all the data matching and gives the output with all the bal pairs running with low number of prod, non-prod and ra sites and not tagged as active in the VPC. audit_sharedbals Important Note Do not downsize any hardware or move any site from one bal pair to another without proper approvals.","title":"Audit Shared Bal Pairs"},{"location":"standard_maintenance/audit_shared_bal_pairs/#audit-shared-bal-pairs","text":"We need to audit the shared bal pairs for number of reasons. Please follow the below instructions : For each VPC this tool will list shared bal pairs running with less than or equal to 25 sites. This tool will list all the active bal pairs for each VPC irrespective of number of sites on them for guidance If any active legacy bal pair running very high number of sites, add a new active bal pair. If the bal pair has low number of prod sites like less than 3 and not active in the region, create an AM ticket to request the customer to move their sites to active bal pair in the same region. E.g AM-4661802 Check for pairs running with high hardware size but has low number of prod and non-prod sites. Audit the bal pair for downsizing the hardware and add your findings in the ticket. If a pair has low number of RA sites like less than 10 and the pair is not active RA add the same in the ticket. After adding all the audit result in the ticket ask Senior Engineer or Operations team lead and Ops Manager to review your findings. Once you get all the approvals, proceed accordingly. Do not terminate any bal pair until it has no site running on it. Output of this tool is according to table format compatible with JIRA to get a better view of the result. We have a tool available with us which will do all the data matching and gives the output with all the bal pairs running with low number of prod, non-prod and ra sites and not tagged as active in the VPC. audit_sharedbals","title":"Audit Shared Bal Pairs"},{"location":"standard_maintenance/audit_shared_bal_pairs/#important-note","text":"Do not downsize any hardware or move any site from one bal pair to another without proper approvals.","title":"Important Note"},{"location":"standard_maintenance/az_migration/","text":"AZ Migration You may need to migrate a server to another AZ for any number of reasons, such as an instance type or any given AWS feature being available in the current availability zone the server is currently in. If a server has meaningful customer data on its EBS volumes, then we must create new volumes and migrate the data. If not, we simply need to relaunch the server in a different AZ. The steps below utilize an automated workflow. There is a manual AZ migration page in case you need it. Preparatory Work If the server has customer data on its EBS volumes, then take snapshots of all the volumes and paste the output in the OP. Variables (prep) export SERVER= export OP= export NEW_AZ= Procedure (prep) If the server being moved has volumes that need to be migrated, follow this prep work to begin the workflow and take snapshots. Start the workflow, and set pause-at-step to pause the workflow after it finishes the snapshots but before the server suspends. If you are migrating a server with a database (ded,dbmaster,etc.), you must ensure that it is locked and not the active master (failed over if it is the primary db): ah-db-cluster status $SERVER # If necessary: # dns-update $CLUSTER_ID $SECONDARY_DB ah-db-cluster lock $SERVER You can add -a ${NEW_AMI_TYPE} if you need to change the AMI type in the same relaunch. ah-server migrate-az ${SERVER} \\ -z ${NEW_AZ} \\ --pause-at-step suspend_server \\ --pause-description \"${OP} - ${USER}\" Important Note Do not abort workflows! If you are unable to resolve a problem with a workflow, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership Monitor Snapshot Progress Run this command until all snapshots are 100% complete. Be sure NEW_AZ and WORKFLOW_ID variables are populated when running the commands below. NEW_AZ= WORKFLOW_ID= REGION=${NEW_AZ::-1} unset snaps_array declare -A snaps_array eval $(ah-workflow get $WORKFLOW_ID --show-logs|grep -i \"Created snapshot\"| \\ sed -n 's/.*\\(snap-[0-9a-z]\\+\\).*\\(primary\\|secondary\\|brick\\)/\\2 \\1/p'| \\ awk '{print \"snaps_array[\"$1\"]=\"$2}') watch -n 30 aws ec2 describe-snapshots \\ --snapshot-ids ${snaps_array[@]} \\ --region $REGION \\ --query \"Snapshots[*].{SnapshotId:SnapshotId,VolumeID:VolumeId,StartTime:StartTime,Progress:Progress}\" Maintenance Window If you are resizing a pair of servers, it is recommended that you relaunch the server not being migrated first to avoid complexity at the end of the procedure. If you are migrating a DB class server, downtime all of the DB servers in the cluster for the duration of the maintenance window out of kindness for the Ops hotseat DURATION= SITE=$(ah-site list on:${SERVER} | head -1) ah-server list site:${SITE} \\ -w typeINded,fsdb,fsdbmesh,dbmaster \\ | xargs -n1 -I{} sv-downtimeservice {} 'Mysql Available' ${DURATION} \"${OP} - AZ Migration\" Notify the Ops hotseat that you are working on these DB servers, as they still receive an unavoidable alert for 'MySQL Failover' from the DNS server. OpsBot: alerts who Procedure for Servers without Volumes (web) Use the ah-server migrate-az workflow to relaunch. You can change the AMI type, if needed, by adding -a ${NEW_AMI_TYPE} to the following command. ah-server migrate-az ${SERVER} -z ${NEW_AZ} Important Note Do not abort workflows! If you are unable to resolve a problem with a workflow, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership Procedure for Servers with Volumes WARNING: If you are performing this procedure on a DB class server you must ensure the server you are moving is locked and not the active master. ah-db-cluster status ${SERVER} If there was a prep work ticket, simply resume the workflow. WORKFLOW= ah-workflow resume ${WORKFLOW} If there was no prep work, begin the workflow, performing any necessary prepatory failovers that you would for an ordinary relaunch . ah-server migrate-az ${SERVER} -z ${NEW_AZ} Confirm ELB AZ Configuration is Correct when migrating Bals SITES=($(ah-site list on:${SERVER} -w stage!=ra | paste -sd' ')) for site in ${SITES[@]}; do ELB=$(ruby -e \"require 'aq'; site = Aq::Hosting::Site.from_query(name: '${site}'); puts \\ Aq::Hosting::SiteElb.fromQuery('site_id' => site['id']).record['elb_name']\") AZS=($(ah-server list site:${site} -w type=bal -c ec2_availability_zone --no-name | paste -sd' ')) REGION=($(ah-server list site:${site} -w type=bal -c ec2_region --no-name | uniq)) aws elb enable-availability-zones-for-load-balancer \\ --region $REGION \\ --load-balancer-name $ELB \\ --availability-zones $AZS done Monitor Snapshot Progress","title":"AZ Migration"},{"location":"standard_maintenance/az_migration/#az-migration","text":"You may need to migrate a server to another AZ for any number of reasons, such as an instance type or any given AWS feature being available in the current availability zone the server is currently in. If a server has meaningful customer data on its EBS volumes, then we must create new volumes and migrate the data. If not, we simply need to relaunch the server in a different AZ. The steps below utilize an automated workflow. There is a manual AZ migration page in case you need it.","title":"AZ Migration"},{"location":"standard_maintenance/az_migration/#preparatory-work","text":"If the server has customer data on its EBS volumes, then take snapshots of all the volumes and paste the output in the OP.","title":"Preparatory Work"},{"location":"standard_maintenance/az_migration/#variables-prep","text":"export SERVER= export OP= export NEW_AZ=","title":"Variables (prep)"},{"location":"standard_maintenance/az_migration/#procedure-prep","text":"If the server being moved has volumes that need to be migrated, follow this prep work to begin the workflow and take snapshots. Start the workflow, and set pause-at-step to pause the workflow after it finishes the snapshots but before the server suspends. If you are migrating a server with a database (ded,dbmaster,etc.), you must ensure that it is locked and not the active master (failed over if it is the primary db): ah-db-cluster status $SERVER # If necessary: # dns-update $CLUSTER_ID $SECONDARY_DB ah-db-cluster lock $SERVER You can add -a ${NEW_AMI_TYPE} if you need to change the AMI type in the same relaunch. ah-server migrate-az ${SERVER} \\ -z ${NEW_AZ} \\ --pause-at-step suspend_server \\ --pause-description \"${OP} - ${USER}\"","title":"Procedure (prep)"},{"location":"standard_maintenance/az_migration/#important-note","text":"Do not abort workflows! If you are unable to resolve a problem with a workflow, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership","title":"Important Note"},{"location":"standard_maintenance/az_migration/#monitor-snapshot-progress","text":"Run this command until all snapshots are 100% complete. Be sure NEW_AZ and WORKFLOW_ID variables are populated when running the commands below. NEW_AZ= WORKFLOW_ID= REGION=${NEW_AZ::-1} unset snaps_array declare -A snaps_array eval $(ah-workflow get $WORKFLOW_ID --show-logs|grep -i \"Created snapshot\"| \\ sed -n 's/.*\\(snap-[0-9a-z]\\+\\).*\\(primary\\|secondary\\|brick\\)/\\2 \\1/p'| \\ awk '{print \"snaps_array[\"$1\"]=\"$2}') watch -n 30 aws ec2 describe-snapshots \\ --snapshot-ids ${snaps_array[@]} \\ --region $REGION \\ --query \"Snapshots[*].{SnapshotId:SnapshotId,VolumeID:VolumeId,StartTime:StartTime,Progress:Progress}\"","title":"Monitor Snapshot Progress"},{"location":"standard_maintenance/az_migration/#maintenance-window","text":"If you are resizing a pair of servers, it is recommended that you relaunch the server not being migrated first to avoid complexity at the end of the procedure. If you are migrating a DB class server, downtime all of the DB servers in the cluster for the duration of the maintenance window out of kindness for the Ops hotseat DURATION= SITE=$(ah-site list on:${SERVER} | head -1) ah-server list site:${SITE} \\ -w typeINded,fsdb,fsdbmesh,dbmaster \\ | xargs -n1 -I{} sv-downtimeservice {} 'Mysql Available' ${DURATION} \"${OP} - AZ Migration\" Notify the Ops hotseat that you are working on these DB servers, as they still receive an unavoidable alert for 'MySQL Failover' from the DNS server. OpsBot: alerts who","title":"Maintenance Window"},{"location":"standard_maintenance/az_migration/#procedure-for-servers-without-volumes-web","text":"Use the ah-server migrate-az workflow to relaunch. You can change the AMI type, if needed, by adding -a ${NEW_AMI_TYPE} to the following command. ah-server migrate-az ${SERVER} -z ${NEW_AZ}","title":"Procedure for Servers without Volumes (web)"},{"location":"standard_maintenance/az_migration/#important-note_1","text":"Do not abort workflows! If you are unable to resolve a problem with a workflow, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership","title":"Important  Note"},{"location":"standard_maintenance/az_migration/#procedure-for-servers-with-volumes","text":"WARNING: If you are performing this procedure on a DB class server you must ensure the server you are moving is locked and not the active master. ah-db-cluster status ${SERVER} If there was a prep work ticket, simply resume the workflow. WORKFLOW= ah-workflow resume ${WORKFLOW} If there was no prep work, begin the workflow, performing any necessary prepatory failovers that you would for an ordinary relaunch . ah-server migrate-az ${SERVER} -z ${NEW_AZ}","title":"Procedure for Servers with Volumes"},{"location":"standard_maintenance/az_migration/#confirm-elb-az-configuration-is-correct-when-migrating-bals","text":"SITES=($(ah-site list on:${SERVER} -w stage!=ra | paste -sd' ')) for site in ${SITES[@]}; do ELB=$(ruby -e \"require 'aq'; site = Aq::Hosting::Site.from_query(name: '${site}'); puts \\ Aq::Hosting::SiteElb.fromQuery('site_id' => site['id']).record['elb_name']\") AZS=($(ah-server list site:${site} -w type=bal -c ec2_availability_zone --no-name | paste -sd' ')) REGION=($(ah-server list site:${site} -w type=bal -c ec2_region --no-name | uniq)) aws elb enable-availability-zones-for-load-balancer \\ --region $REGION \\ --load-balancer-name $ELB \\ --availability-zones $AZS done","title":"Confirm ELB AZ Configuration is Correct when migrating Bals"},{"location":"standard_maintenance/az_migration/#monitor-snapshot-progress_1","text":"","title":"Monitor Snapshot Progress"},{"location":"standard_maintenance/az_migration_manual/","text":"Manual AZ Migration You may need to migrate a server to another AZ for any number of reasons, such as an instance type or any given AWS feature being available in the current availability zone the server is currently in. If a server has meaningful customer data on its EBS volumes, then we must create new volumes and migrate the data. If not, we simply need to relaunch the server in a different AZ. Preparatory Work If the server has customer data on its EBS volumes, then take snapshots of all the volumes and paste the output in the OP. Variables (prep) export SERVER= export OP= Procedure (prep) This C&P creates a snapshot for each volume attached to a server and outputs Jira friendly text. VOL_IDS=($(ruby -e \"require 'aq'; \\ puts Aq::Hosting::Server.from_query({'name' => '${SERVER}'}).record['volumes'].keys\")) REGION=$(ruby -e \"require 'aq'; \\ puts Aq::Hosting::Server.from_query({'name' => '${SERVER}'}).record['ec2_region']\") declare -A SNAPS echo \"{noformat:title=${SERVER} volume snapshots}\" \\ && for vol_id in ${VOL_IDS[@]}; do vol=($(ah-volume get ${vol_id} \\ | grep -E '^(device|ebs_id):' \\ | awk '{print $2}')) snap=$(aws ec2 create-snapshot \\ --volume-id ${vol[1]} \\ --description $OP \\ --region ${REGION} \\ --query SnapshotId \\ --output text) echo \"mount: ${vol[0]}\" echo \" ebs_id: ${vol[1]}\" echo \" ec2_region: ${REGION}\" echo \" snapshot: $snap\" SNAPS[$vol_id]=$snap done \\ && echo \"{noformat}\" Wait for completion Run this command until all snapshots are 100% complete. watch -n 10 aws ec2 describe-snapshots \\ --snapshot-ids ${SNAPS[@]} \\ --region=${REGION} \\ --query 'Snapshots[*].{SnapshotID:SnapshotId,Progress:Progress}' \\ --output text Maintenance Window You will need to suspend the server, migrate any customer data, edit server attributes, launch the server in its new AZ, and put it back in rotation. If you are not required to change the AMI_TYPE , then simply set the AMI_TYPE variable to the current existing value. If you are resizing a pair of servers, it is recommended that you relaunch the server not being migrated first to avoid complexity at the end of the procedure. Ensure that you perform the post launch steps relative to the procedure you need Post Launch: dbmaster Post Launch: bal free srv Post Launch: ded fsdb fsdbmesh staging Post Launch: fs Downtime the dbservers for the duration of the maintenance window as to not cause pain for the oncall: SITE=$(ah-site list on:${SERVER} | head -1) DURATION=windowdurationinminutes TICKET=ticketid ah-server list site:${SITE} \\ -w typeINded,fsdb,fsdbmesh,dbmaster | \\ xargs -n1 -I{} sv-downtime {} $DURATION \"$USER $TICKET\" Notify the on alerts person OpsBot: alerts whom Procedure for Servers without Volumes (web) Follow the relaunch guide , but change the ec2_availability_zone while the server is suspended: AZ= ah-server edit ${SERVER} -s ec2_availability_zone=${AZ} Procedure for Servers with Volumes WARNING If performing this procedure on a DB class server you must ensure the server you are moving is not the active master. ah-db-cluster status ${SERVER} dbmaster bal free srv ded fsdb fsdbmesh staging fs","title":"Manual AZ Migration"},{"location":"standard_maintenance/az_migration_manual/#manual-az-migration","text":"You may need to migrate a server to another AZ for any number of reasons, such as an instance type or any given AWS feature being available in the current availability zone the server is currently in. If a server has meaningful customer data on its EBS volumes, then we must create new volumes and migrate the data. If not, we simply need to relaunch the server in a different AZ.","title":"Manual AZ Migration"},{"location":"standard_maintenance/az_migration_manual/#preparatory-work","text":"If the server has customer data on its EBS volumes, then take snapshots of all the volumes and paste the output in the OP.","title":"Preparatory Work"},{"location":"standard_maintenance/az_migration_manual/#variables-prep","text":"export SERVER= export OP=","title":"Variables (prep)"},{"location":"standard_maintenance/az_migration_manual/#procedure-prep","text":"This C&P creates a snapshot for each volume attached to a server and outputs Jira friendly text. VOL_IDS=($(ruby -e \"require 'aq'; \\ puts Aq::Hosting::Server.from_query({'name' => '${SERVER}'}).record['volumes'].keys\")) REGION=$(ruby -e \"require 'aq'; \\ puts Aq::Hosting::Server.from_query({'name' => '${SERVER}'}).record['ec2_region']\") declare -A SNAPS echo \"{noformat:title=${SERVER} volume snapshots}\" \\ && for vol_id in ${VOL_IDS[@]}; do vol=($(ah-volume get ${vol_id} \\ | grep -E '^(device|ebs_id):' \\ | awk '{print $2}')) snap=$(aws ec2 create-snapshot \\ --volume-id ${vol[1]} \\ --description $OP \\ --region ${REGION} \\ --query SnapshotId \\ --output text) echo \"mount: ${vol[0]}\" echo \" ebs_id: ${vol[1]}\" echo \" ec2_region: ${REGION}\" echo \" snapshot: $snap\" SNAPS[$vol_id]=$snap done \\ && echo \"{noformat}\"","title":"Procedure (prep)"},{"location":"standard_maintenance/az_migration_manual/#wait-for-completion","text":"Run this command until all snapshots are 100% complete. watch -n 10 aws ec2 describe-snapshots \\ --snapshot-ids ${SNAPS[@]} \\ --region=${REGION} \\ --query 'Snapshots[*].{SnapshotID:SnapshotId,Progress:Progress}' \\ --output text","title":"Wait for completion"},{"location":"standard_maintenance/az_migration_manual/#maintenance-window","text":"You will need to suspend the server, migrate any customer data, edit server attributes, launch the server in its new AZ, and put it back in rotation. If you are not required to change the AMI_TYPE , then simply set the AMI_TYPE variable to the current existing value. If you are resizing a pair of servers, it is recommended that you relaunch the server not being migrated first to avoid complexity at the end of the procedure. Ensure that you perform the post launch steps relative to the procedure you need Post Launch: dbmaster Post Launch: bal free srv Post Launch: ded fsdb fsdbmesh staging Post Launch: fs Downtime the dbservers for the duration of the maintenance window as to not cause pain for the oncall: SITE=$(ah-site list on:${SERVER} | head -1) DURATION=windowdurationinminutes TICKET=ticketid ah-server list site:${SITE} \\ -w typeINded,fsdb,fsdbmesh,dbmaster | \\ xargs -n1 -I{} sv-downtime {} $DURATION \"$USER $TICKET\" Notify the on alerts person OpsBot: alerts whom","title":"Maintenance Window"},{"location":"standard_maintenance/az_migration_manual/#procedure-for-servers-without-volumes-web","text":"Follow the relaunch guide , but change the ec2_availability_zone while the server is suspended: AZ= ah-server edit ${SERVER} -s ec2_availability_zone=${AZ}","title":"Procedure for Servers without Volumes (web)"},{"location":"standard_maintenance/az_migration_manual/#procedure-for-servers-with-volumes","text":"WARNING If performing this procedure on a DB class server you must ensure the server you are moving is not the active master. ah-db-cluster status ${SERVER} dbmaster bal free srv ded fsdb fsdbmesh staging fs","title":"Procedure for Servers with Volumes"},{"location":"standard_maintenance/az_migration_manual_volume_m/","text":"AZ Migration (xvdm) You will suspend the server, migrate the volumes, edit, and launch the server in its new AZ. Variables If you are not required to change the AMI_TYPE , then simply set AMI_TYPE to the current existing value. NEW_AZ is the full name of the AZ; for example us-east-1e . export SERVER= # set what will be the active mysql server OTHER_SERVER= export NEW_AZ= export AMI_TYPE= export OP= echo \"{noformat:title=Global Variables}\" \\ && echo \"export SERVER=${SERVER}\" \\ && echo \"export OTHER_SERVER=${OTHER_SERVER}\" \\ && echo \"export NEW_AZ=${NEW_AZ}\" \\ && echo \"export AMI_TYPE=${AMI_TYPE}\" \\ && echo \"export OP=${OP}\" \\ && echo \"{noformat}\" Maintenance Window Procedure Before you suspend the server gather the existing volume information and put it in to your JIRA ticket. WARNING : verify that the pre-maintenance volume snapshots are complete prior to commencing this procedure. Gather volume information: echo \"{noformat:title=${SERVER} Volume List (pre)}\" \\ && sv-vollist ${SERVER} \\ && echo \"{noformat}\" Set more variables. declare -A VOL_ID VOL_SIZE REGION=$(ah-server list ${SERVER} -c ec2_region --no-name) XVDM_ID=$(ah-server get ${SERVER} | grep \"[/]vol/ebs1\" | grep -Po \"\\d\\d+\") VOL_ID[xvdm]=$(ah-volume get ${XVDM_ID} | grep ebs_id | awk '{print $2}') VOL_SIZE[xvdm]=$(ah-volume get ${XVDM_ID} | grep size | awk '{print $2}') echo \"{noformat:title=${SERVER} Variables}\" \\ && echo \"declare -A VOL_ID VOL_SIZE\" \\ && echo \"REGION=${REGION}\" \\ && echo \"XVDM_ID=${XVDM_ID}\" \\ && echo \"VOL_ID[xvdm]=${VOL_ID[xvdm]}\" \\ && echo \"VOL_SIZE[xvdm]=${VOL_SIZE[xvdm]}\" \\ && echo \"{noformat}\" Suspend the server. sv-downtime ${SERVER} 30 \"${OP} - az migration\" sv-downtimeservice ${OTHER_SERVER} 'Mysql Available' 30 \"${OP} - az migration\" ah-server suspend ${SERVER} Create final snapshots for each volume in order: declare -A SNAP_ID for device in xvdm; do SNAP_ID[$device]=$(aws ec2 create-snapshot \\ --volume-id ${VOL_ID[$device]} \\ --description ${OP} \\ --region ${REGION} \\ --query SnapshotId \\ --output text) done echo \"{noformat:title=${SERVER} Volume Snapshots}\" \\ && echo \"declare -A SNAP_ID\" \\ && echo \"SNAP_ID[xvdm]=${SNAP_ID[xvdm]}\" \\ && echo \"{noformat}\" Run this command until all snapshots are 100% complete watch -n 10 aws ec2 describe-snapshots \\ --snapshot-ids ${SNAP_ID[xvdm]} \\ --region=${REGION} \\ --query 'Snapshots[*].{SnapshotID:SnapshotId,Progress:Progress}' \\ --output text Update the fields server record: echo \"{noformat:title=Edit /dev/xvdm & /dev/xvdn}\" \\ && ah-server edit ${SERVER} -s \\ ebs_id=${SNAP_ID[xvdm]} \\ ebs2_id= \\ ec2_availability_zone=${NEW_AZ} \\ ami_type=${AMI_TYPE} \\ && echo \"{noformat}\" Launch the server with --debug and tail -f the output file. When you launch a server volume and instance tags are automatically set for you. Note : Debug output is advised given that manual volume moves in this operation are prone to issues and you may need this extra output. ah-server launch ${SERVER} --debug Post Launch Verify DB and re-enable monitoring: ah-db-cluster status ${SERVER} sv-monenable $(ah-server list site:${SITE} \\ -w typeINded,fsdb,fsdbmesh,dbmaster \\ | paste -sd,) Delete the maintenance window snapshots. for device in xvdm; do aws ec2 delete-snapshot \\ --region ${REGION} \\ --snapshot-id ${SNAP_ID[$device]} done Delete the old volumes in the previous AZ. for vol in ${VOL_ID[@]} ; do aws ec2 delete-tags \\ --region ${REGION} \\ --resources $vol \\ --tags Key=title Key=active aws ec2 create-tags \\ --region $REGION \\ --resources $vol \\ --tags Key=ops_replaced_in,Value=$OP \\ Key=ah_resize_info,Value=${vol}/$(date +%Y%m%d%H%M -d \"+7 days\") done Delete snapshots from maintenance window prep work. PRE_OP is the OP ticket of the volume snapshot prep work. PRE_OP= PRE_SNAPSHOTS=($(aws ec2 describe-snapshots \\ --region ${REGION} \\ --filters \"Name=description,Values=${PRE_OP}\" \\ --query 'Snapshots[*].{SnapshotId:SnapshotId}' \\ --output text)) for SNAPSHOT in ${PRE_SNAPSHOTS[@]}; do aws ec2 delete-snapshot \\ --region ${REGION} \\ --snapshot-id ${SNAPSHOT} done Update the JIRA ticket with the output from esl and sv-vollist . For example: echo \"{noformat:title=esl}\" \\ && esl ${SERVER} \\ && echo \"{noformat}\" echo \"{noformat:title=${SERVER} Volume List (post)}\" \\ && sv-vollist ${SERVER} \\ && echo \"{noformat}\"","title":"AZ Migration (xvdm)"},{"location":"standard_maintenance/az_migration_manual_volume_m/#az-migration-xvdm","text":"You will suspend the server, migrate the volumes, edit, and launch the server in its new AZ.","title":"AZ Migration (xvdm)"},{"location":"standard_maintenance/az_migration_manual_volume_m/#variables","text":"If you are not required to change the AMI_TYPE , then simply set AMI_TYPE to the current existing value. NEW_AZ is the full name of the AZ; for example us-east-1e . export SERVER= # set what will be the active mysql server OTHER_SERVER= export NEW_AZ= export AMI_TYPE= export OP= echo \"{noformat:title=Global Variables}\" \\ && echo \"export SERVER=${SERVER}\" \\ && echo \"export OTHER_SERVER=${OTHER_SERVER}\" \\ && echo \"export NEW_AZ=${NEW_AZ}\" \\ && echo \"export AMI_TYPE=${AMI_TYPE}\" \\ && echo \"export OP=${OP}\" \\ && echo \"{noformat}\"","title":"Variables"},{"location":"standard_maintenance/az_migration_manual_volume_m/#maintenance-window-procedure","text":"Before you suspend the server gather the existing volume information and put it in to your JIRA ticket. WARNING : verify that the pre-maintenance volume snapshots are complete prior to commencing this procedure. Gather volume information: echo \"{noformat:title=${SERVER} Volume List (pre)}\" \\ && sv-vollist ${SERVER} \\ && echo \"{noformat}\" Set more variables. declare -A VOL_ID VOL_SIZE REGION=$(ah-server list ${SERVER} -c ec2_region --no-name) XVDM_ID=$(ah-server get ${SERVER} | grep \"[/]vol/ebs1\" | grep -Po \"\\d\\d+\") VOL_ID[xvdm]=$(ah-volume get ${XVDM_ID} | grep ebs_id | awk '{print $2}') VOL_SIZE[xvdm]=$(ah-volume get ${XVDM_ID} | grep size | awk '{print $2}') echo \"{noformat:title=${SERVER} Variables}\" \\ && echo \"declare -A VOL_ID VOL_SIZE\" \\ && echo \"REGION=${REGION}\" \\ && echo \"XVDM_ID=${XVDM_ID}\" \\ && echo \"VOL_ID[xvdm]=${VOL_ID[xvdm]}\" \\ && echo \"VOL_SIZE[xvdm]=${VOL_SIZE[xvdm]}\" \\ && echo \"{noformat}\" Suspend the server. sv-downtime ${SERVER} 30 \"${OP} - az migration\" sv-downtimeservice ${OTHER_SERVER} 'Mysql Available' 30 \"${OP} - az migration\" ah-server suspend ${SERVER} Create final snapshots for each volume in order: declare -A SNAP_ID for device in xvdm; do SNAP_ID[$device]=$(aws ec2 create-snapshot \\ --volume-id ${VOL_ID[$device]} \\ --description ${OP} \\ --region ${REGION} \\ --query SnapshotId \\ --output text) done echo \"{noformat:title=${SERVER} Volume Snapshots}\" \\ && echo \"declare -A SNAP_ID\" \\ && echo \"SNAP_ID[xvdm]=${SNAP_ID[xvdm]}\" \\ && echo \"{noformat}\" Run this command until all snapshots are 100% complete watch -n 10 aws ec2 describe-snapshots \\ --snapshot-ids ${SNAP_ID[xvdm]} \\ --region=${REGION} \\ --query 'Snapshots[*].{SnapshotID:SnapshotId,Progress:Progress}' \\ --output text Update the fields server record: echo \"{noformat:title=Edit /dev/xvdm & /dev/xvdn}\" \\ && ah-server edit ${SERVER} -s \\ ebs_id=${SNAP_ID[xvdm]} \\ ebs2_id= \\ ec2_availability_zone=${NEW_AZ} \\ ami_type=${AMI_TYPE} \\ && echo \"{noformat}\" Launch the server with --debug and tail -f the output file. When you launch a server volume and instance tags are automatically set for you. Note : Debug output is advised given that manual volume moves in this operation are prone to issues and you may need this extra output. ah-server launch ${SERVER} --debug","title":"Maintenance Window Procedure"},{"location":"standard_maintenance/az_migration_manual_volume_m/#post-launch","text":"Verify DB and re-enable monitoring: ah-db-cluster status ${SERVER} sv-monenable $(ah-server list site:${SITE} \\ -w typeINded,fsdb,fsdbmesh,dbmaster \\ | paste -sd,) Delete the maintenance window snapshots. for device in xvdm; do aws ec2 delete-snapshot \\ --region ${REGION} \\ --snapshot-id ${SNAP_ID[$device]} done Delete the old volumes in the previous AZ. for vol in ${VOL_ID[@]} ; do aws ec2 delete-tags \\ --region ${REGION} \\ --resources $vol \\ --tags Key=title Key=active aws ec2 create-tags \\ --region $REGION \\ --resources $vol \\ --tags Key=ops_replaced_in,Value=$OP \\ Key=ah_resize_info,Value=${vol}/$(date +%Y%m%d%H%M -d \"+7 days\") done Delete snapshots from maintenance window prep work. PRE_OP is the OP ticket of the volume snapshot prep work. PRE_OP= PRE_SNAPSHOTS=($(aws ec2 describe-snapshots \\ --region ${REGION} \\ --filters \"Name=description,Values=${PRE_OP}\" \\ --query 'Snapshots[*].{SnapshotId:SnapshotId}' \\ --output text)) for SNAPSHOT in ${PRE_SNAPSHOTS[@]}; do aws ec2 delete-snapshot \\ --region ${REGION} \\ --snapshot-id ${SNAPSHOT} done Update the JIRA ticket with the output from esl and sv-vollist . For example: echo \"{noformat:title=esl}\" \\ && esl ${SERVER} \\ && echo \"{noformat}\" echo \"{noformat:title=${SERVER} Volume List (post)}\" \\ && sv-vollist ${SERVER} \\ && echo \"{noformat}\"","title":"Post Launch"},{"location":"standard_maintenance/az_migration_manual_volume_mn/","text":"AZ Migration (xvdm xvdn) You will suspend the server, migrate the volumes, edit, and launch the server in its new AZ. Variables If you are not required to change the AMI_TYPE , then simply set AMI_TYPE to the current existing value. NEW_AZ is the full name of the AZ; for example us-east-1e . export SERVER= export NEW_AZ= export AMI_TYPE= export OP= echo \"{noformat:title=Global Variables}\" \\ && echo \"export SERVER=${SERVER}\" \\ && echo \"export NEW_AZ=${NEW_AZ}\" \\ && echo \"export AMI_TYPE=${AMI_TYPE}\" \\ && echo \"export OP=${OP}\" \\ && echo \"{noformat}\" Maintenance Window Procedure Before you suspend the server gather the existing volume information and put it in to your JIRA ticket. WARNING : verify that the pre-maintenance volume snapshots are complete prior to commencing this procedure. Gather volume information: echo \"{noformat:title=${SERVER} Volume List (pre)}\" \\ && sv-vollist ${SERVER} \\ && echo \"{noformat}\" Set more variables. declare -A VOL_ID VOL_SIZE REGION=$(ah-server list ${SERVER} -c ec2_region --no-name) XVDM_ID=$(ah-server get ${SERVER} | grep \"[/]vol/ebs1\" | grep -Po \"\\d\\d+\") XVDN_ID=$(ah-server get ${SERVER} | grep \"[/]vol/backup-ebs\" \\ | grep -Po \"\\d+\") VOL_ID[xvdm]=$(ah-volume get ${XVDM_ID} | grep ebs_id | awk '{print $2}') VOL_ID[xvdn]=$(ah-volume get ${XVDN_ID} | grep ebs_id | awk '{print $2}') VOL_SIZE[xvdm]=$(ah-volume get ${XVDM_ID} | grep size | awk '{print $2}') VOL_SIZE[xvdn]=$(ah-volume get ${XVDN_ID} | grep size | awk '{print $2}') echo \"{noformat:title=${SERVER} Variables}\" \\ && echo \"declare -A VOL_ID VOL_SIZE\" \\ && echo \"REGION=${REGION}\" \\ && echo \"XVDM_ID=${XVDM_ID}\" \\ && echo \"VOL_ID[xvdm]=${VOL_ID[xvdm]}\" \\ && echo \"VOL_SIZE[xvdm]=${VOL_SIZE[xvdm]}\" \\ && echo \"XVDN_ID=${XVDN_ID}\" \\ && echo \"VOL_ID[xvdn]=${VOL_ID[xvdn]}\" \\ && echo \"VOL_SIZE[xvdn]=${VOL_SIZE[xvdn]}\" \\ && echo \"{noformat}\" Suspend the server. sv-downtime ${SERVER} 30 \"${OP} - az migration\" ah-server suspend ${SERVER} Create final snapshots for each volume in order: declare -A SNAP_ID for device in xvdm xvdn; do SNAP_ID[$device]=$(aws ec2 create-snapshot \\ --volume-id ${VOL_ID[$device]} \\ --description ${OP} \\ --region ${REGION} \\ --query SnapshotId \\ --output text) echo ${SNAP_ID[$device]} done echo \"{noformat:title=${SERVER} Volume Snapshots}\" \\ && echo \"declare -A SNAP_ID\" \\ && echo \"SNAP_ID[xvdm]=${SNAP_ID[xvdm]}\" \\ && echo \"SNAP_ID[xvdn]=${SNAP_ID[xvdn]}\" \\ && echo \"{noformat}\" Run this command until all snapshots are 100% complete watch -n 10 aws ec2 describe-snapshots \\ --snapshot-ids ${SNAP_ID[xvdm]} ${SNAP_ID[xvdn]} \\ --region=${REGION} \\ --query 'Snapshots[*].{SnapshotID:SnapshotId,Progress:Progress}' \\ --output text Update the fields server record: echo \"{noformat:title=Edit /dev/xvdm & /dev/xvdn}\" \\ && ah-server edit ${SERVER} -s \\ ebs_id=${SNAP_ID[xvdm]} \\ ebs2_id=${SNAP_ID[xvdn]} \\ ec2_availability_zone=${NEW_AZ} \\ ami_type=${AMI_TYPE} \\ && echo \"{noformat}\" Launch the server with --debug and tail -f the output file. When you launch a server volume and instance tags are automatically set for you. Note : Debug output is advised given that manual volume moves in this operation are prone to issues and you may need this extra output. ah-server launch ${SERVER} --debug Post Launch Delete the maintenance window snapshots. for device in xvdm xvdn; do aws ec2 delete-snapshot \\ --region ${REGION} \\ --snapshot-id ${SNAP_ID[$device]} done Delete the old volumes in the previous AZ. for vol in ${VOL_ID[@]} ; do aws ec2 delete-tags \\ --region ${REGION} \\ --resources $vol \\ --tags Key=title Key=active aws ec2 create-tags \\ --region $REGION \\ --resources $vol \\ --tags Key=ops_replaced_in,Value=$OP \\ Key=ah_resize_info,Value=${vol}/$(date +%Y%m%d%H%M -d \"+7 days\") done Delete snapshots from maintenance window prep work. PRE_OP is the OP ticket of the volume snapshot prep work. PRE_OP= PRE_SNAPSHOTS=($(aws ec2 describe-snapshots \\ --region ${REGION} \\ --filters \"Name=description,Values=${PRE_OP}\" \\ --query 'Snapshots[*].{SnapshotId:SnapshotId}' \\ --output text)) for SNAPSHOT in ${PRE_SNAPSHOTS[@]}; do aws ec2 delete-snapshot \\ --region ${REGION} \\ --snapshot-id ${SNAPSHOT} done Update the JIRA ticket with the output from esl and sv-vollist . For example: echo \"{noformat:title=esl}\" \\ && esl ${SERVER} \\ && echo \"{noformat}\" echo \"{noformat:title=${SERVER} Volume List (post)}\" \\ && sv-vollist ${SERVER} \\ && echo \"{noformat}\"","title":"AZ Migration (xvdm xvdn)"},{"location":"standard_maintenance/az_migration_manual_volume_mn/#az-migration-xvdm-xvdn","text":"You will suspend the server, migrate the volumes, edit, and launch the server in its new AZ.","title":"AZ Migration (xvdm xvdn)"},{"location":"standard_maintenance/az_migration_manual_volume_mn/#variables","text":"If you are not required to change the AMI_TYPE , then simply set AMI_TYPE to the current existing value. NEW_AZ is the full name of the AZ; for example us-east-1e . export SERVER= export NEW_AZ= export AMI_TYPE= export OP= echo \"{noformat:title=Global Variables}\" \\ && echo \"export SERVER=${SERVER}\" \\ && echo \"export NEW_AZ=${NEW_AZ}\" \\ && echo \"export AMI_TYPE=${AMI_TYPE}\" \\ && echo \"export OP=${OP}\" \\ && echo \"{noformat}\"","title":"Variables"},{"location":"standard_maintenance/az_migration_manual_volume_mn/#maintenance-window-procedure","text":"Before you suspend the server gather the existing volume information and put it in to your JIRA ticket. WARNING : verify that the pre-maintenance volume snapshots are complete prior to commencing this procedure. Gather volume information: echo \"{noformat:title=${SERVER} Volume List (pre)}\" \\ && sv-vollist ${SERVER} \\ && echo \"{noformat}\" Set more variables. declare -A VOL_ID VOL_SIZE REGION=$(ah-server list ${SERVER} -c ec2_region --no-name) XVDM_ID=$(ah-server get ${SERVER} | grep \"[/]vol/ebs1\" | grep -Po \"\\d\\d+\") XVDN_ID=$(ah-server get ${SERVER} | grep \"[/]vol/backup-ebs\" \\ | grep -Po \"\\d+\") VOL_ID[xvdm]=$(ah-volume get ${XVDM_ID} | grep ebs_id | awk '{print $2}') VOL_ID[xvdn]=$(ah-volume get ${XVDN_ID} | grep ebs_id | awk '{print $2}') VOL_SIZE[xvdm]=$(ah-volume get ${XVDM_ID} | grep size | awk '{print $2}') VOL_SIZE[xvdn]=$(ah-volume get ${XVDN_ID} | grep size | awk '{print $2}') echo \"{noformat:title=${SERVER} Variables}\" \\ && echo \"declare -A VOL_ID VOL_SIZE\" \\ && echo \"REGION=${REGION}\" \\ && echo \"XVDM_ID=${XVDM_ID}\" \\ && echo \"VOL_ID[xvdm]=${VOL_ID[xvdm]}\" \\ && echo \"VOL_SIZE[xvdm]=${VOL_SIZE[xvdm]}\" \\ && echo \"XVDN_ID=${XVDN_ID}\" \\ && echo \"VOL_ID[xvdn]=${VOL_ID[xvdn]}\" \\ && echo \"VOL_SIZE[xvdn]=${VOL_SIZE[xvdn]}\" \\ && echo \"{noformat}\" Suspend the server. sv-downtime ${SERVER} 30 \"${OP} - az migration\" ah-server suspend ${SERVER} Create final snapshots for each volume in order: declare -A SNAP_ID for device in xvdm xvdn; do SNAP_ID[$device]=$(aws ec2 create-snapshot \\ --volume-id ${VOL_ID[$device]} \\ --description ${OP} \\ --region ${REGION} \\ --query SnapshotId \\ --output text) echo ${SNAP_ID[$device]} done echo \"{noformat:title=${SERVER} Volume Snapshots}\" \\ && echo \"declare -A SNAP_ID\" \\ && echo \"SNAP_ID[xvdm]=${SNAP_ID[xvdm]}\" \\ && echo \"SNAP_ID[xvdn]=${SNAP_ID[xvdn]}\" \\ && echo \"{noformat}\" Run this command until all snapshots are 100% complete watch -n 10 aws ec2 describe-snapshots \\ --snapshot-ids ${SNAP_ID[xvdm]} ${SNAP_ID[xvdn]} \\ --region=${REGION} \\ --query 'Snapshots[*].{SnapshotID:SnapshotId,Progress:Progress}' \\ --output text Update the fields server record: echo \"{noformat:title=Edit /dev/xvdm & /dev/xvdn}\" \\ && ah-server edit ${SERVER} -s \\ ebs_id=${SNAP_ID[xvdm]} \\ ebs2_id=${SNAP_ID[xvdn]} \\ ec2_availability_zone=${NEW_AZ} \\ ami_type=${AMI_TYPE} \\ && echo \"{noformat}\" Launch the server with --debug and tail -f the output file. When you launch a server volume and instance tags are automatically set for you. Note : Debug output is advised given that manual volume moves in this operation are prone to issues and you may need this extra output. ah-server launch ${SERVER} --debug","title":"Maintenance Window Procedure"},{"location":"standard_maintenance/az_migration_manual_volume_mn/#post-launch","text":"Delete the maintenance window snapshots. for device in xvdm xvdn; do aws ec2 delete-snapshot \\ --region ${REGION} \\ --snapshot-id ${SNAP_ID[$device]} done Delete the old volumes in the previous AZ. for vol in ${VOL_ID[@]} ; do aws ec2 delete-tags \\ --region ${REGION} \\ --resources $vol \\ --tags Key=title Key=active aws ec2 create-tags \\ --region $REGION \\ --resources $vol \\ --tags Key=ops_replaced_in,Value=$OP \\ Key=ah_resize_info,Value=${vol}/$(date +%Y%m%d%H%M -d \"+7 days\") done Delete snapshots from maintenance window prep work. PRE_OP is the OP ticket of the volume snapshot prep work. PRE_OP= PRE_SNAPSHOTS=($(aws ec2 describe-snapshots \\ --region ${REGION} \\ --filters \"Name=description,Values=${PRE_OP}\" \\ --query 'Snapshots[*].{SnapshotId:SnapshotId}' \\ --output text)) for SNAPSHOT in ${PRE_SNAPSHOTS[@]}; do aws ec2 delete-snapshot \\ --region ${REGION} \\ --snapshot-id ${SNAPSHOT} done Update the JIRA ticket with the output from esl and sv-vollist . For example: echo \"{noformat:title=esl}\" \\ && esl ${SERVER} \\ && echo \"{noformat}\" echo \"{noformat:title=${SERVER} Volume List (post)}\" \\ && sv-vollist ${SERVER} \\ && echo \"{noformat}\"","title":"Post Launch"},{"location":"standard_maintenance/az_migration_manual_volume_mno/","text":"AZ Migration (xvdm xvdn xvdo) You will suspend the server, migrate the volumes, edit, and launch the server in its new AZ. Variables If you are not required to change the AMI_TYPE , then simply set AMI_TYPE to the current existing value. NEW_AZ is the full name of the AZ; for example us-east-1e . export SERVER= # set what will be the active mysql server OTHER_SERVER= export NEW_AZ= export AMI_TYPE= export OP= echo \"{noformat:title=Global Variables}\" \\ && echo \"export SERVER=${SERVER}\" \\ && echo \"export OTHER_SERVER=${OTHER_SERVER}\" \\ && echo \"export NEW_AZ=${NEW_AZ}\" \\ && echo \"export AMI_TYPE=${AMI_TYPE}\" \\ && echo \"export OP=${OP}\" \\ && echo \"{noformat}\" Maintenance Window Procedure Before you suspend the server gather the existing volume information and put it in to your JIRA ticket. WARNING : verify that the pre-maintenance volume snapshots are complete prior to commencing this procedure. Gather volume information: echo \"{noformat:title=${SERVER} Volume List (pre)}\" \\ && sv-vollist ${SERVER} \\ && echo \"{noformat}\" Set more variables. declare -A VOL_ID VOL_SIZE REGION=$(ah-server list ${SERVER} -c ec2_region --no-name) XVDM_ID=$(ah-server get ${SERVER} | grep \"[/]vol/ebs1\" | grep -Po \"\\d\\d+\") XVDN_ID=$(ah-server get ${SERVER} | grep \"[/]vol/backup-ebs\" \\ | grep -Po \"\\d+\") XVDO_ID=$(ah-server get ${SERVER} | grep brick$ | grep -Po \"\\d+\") VOL_ID[xvdm]=$(ah-volume get ${XVDM_ID} | grep ebs_id | awk '{print $2}') VOL_ID[xvdn]=$(ah-volume get ${XVDN_ID} | grep ebs_id | awk '{print $2}') VOL_ID[xvdo]=$(ah-volume get ${XVDO_ID} | grep ebs_id | awk '{print $2}') VOL_SIZE[xvdm]=$(ah-volume get ${XVDM_ID} | grep size | awk '{print $2}') VOL_SIZE[xvdn]=$(ah-volume get ${XVDN_ID} | grep size | awk '{print $2}') VOL_SIZE[xvdo]=$(ah-volume get ${XVDO_ID} | grep size | awk '{print $2}') echo \"{noformat:title=${SERVER} Variables}\" \\ && echo \"declare -A VOL_ID VOL_SIZE\" \\ && echo \"REGION=${REGION}\" \\ && echo \"XVDM_ID=${XVDM_ID}\" \\ && echo \"VOL_ID[xvdm]=${VOL_ID[xvdm]}\" \\ && echo \"VOL_SIZE[xvdm]=${VOL_SIZE[xvdm]}\" \\ && echo \"XVDN_ID=${XVDN_ID}\" \\ && echo \"VOL_ID[xvdn]=${VOL_ID[xvdn]}\" \\ && echo \"VOL_SIZE[xvdn]=${VOL_SIZE[xvdn]}\" \\ && echo \"XVDO_ID=${XVDO_ID}\" \\ && echo \"VOL_ID[xvdo]=${VOL_ID[xvdo]}\" \\ && echo \"VOL_SIZE[xvdo]=${VOL_SIZE[xvdo]}\" \\ && echo \"{noformat}\" Suspend the server. sv-downtime ${SERVER} 30 \"${OP} - az migration\" sv-downtimeservice ${OTHER_SERVER} 'Mysql Available' 30 \"${OP} - az migration\" ah-server suspend ${SERVER} Create final snapshots for each volume in order: declare -A SNAP_ID for device in xvdm xvdn xvdo; do SNAP_ID[$device]=$(aws ec2 create-snapshot \\ --volume-id ${VOL_ID[$device]} \\ --description ${OP} \\ --region ${REGION} \\ --query SnapshotId \\ --output text) done echo \"{noformat:title=${SERVER} Volume Snapshots}\" \\ && echo \"declare -A SNAP_ID\" \\ && echo \"SNAP_ID[xvdm]=${SNAP_ID[xvdm]}\" \\ && echo \"SNAP_ID[xvdn]=${SNAP_ID[xvdn]}\" \\ && echo \"SNAP_ID[xvdo]=${SNAP_ID[xvdo]}\" \\ && echo \"{noformat}\" Run this command until all snapshots are 100% complete watch -n 10 aws ec2 describe-snapshots \\ --snapshot-ids ${SNAP_ID[xvdm]} ${SNAP_ID[xvdn]} ${SNAP_ID[xvdo]} \\ --region=${REGION} \\ --query 'Snapshots[*].{SnapshotID:SnapshotId,Progress:Progress}' \\ --output text Update the fields server record: echo \"{noformat:title=Edit /dev/xvdm & /dev/xvdn}\" \\ && ah-server edit ${SERVER} -s \\ ebs_id=${SNAP_ID[xvdm]} \\ ebs2_id=${SNAP_ID[xvdn]} \\ ec2_availability_zone=${NEW_AZ} \\ ami_type=${AMI_TYPE} \\ && echo \"{noformat}\" Update the brick volume record: echo \"{noformat:title=Edit /dev/xvdo}\" \\ && ah-volume edit ${XVDO_ID} -s \\ ec2_availability_zone=${NEW_AZ} \\ ebs_id=${SNAP_ID[xvdo]} \\ && echo \"{noformat}\" Launch the server with --debug and tail -f the output file. When you launch a server volume and instance tags are automatically set for you. Note : Debug output is advised given that manual volume moves in this operation are prone to issues and you may need this extra output. ah-server launch ${SERVER} --debug Post Launch Remount gluster: SITE=$(ah-site list on:${SERVER} | head -1) site-fsremount ${SITE} For fsdbmesh hosts only. fpdsh -t site:${SITE} -n fsdbmesh \\ -c 'sudo ah-config-hosts; sudo ah-config-iptables; \\ sudo fields-config-tungsten-peers.php; sudo service stunnel4 restart' Verify DB and re-enable monitoring: ah-db-cluster status ${SERVER} sv-monenable $(ah-server list site:${SITE} \\ -w typeINded,fsdb,fsdbmesh,dbmaster \\ | paste -sd,) Delete the maintenance window snapshots. for device in xvdm xvdn xvdo; do aws ec2 delete-snapshot \\ --region ${REGION} \\ --snapshot-id ${SNAP_ID[$device]} done Delete the old volumes in the previous AZ. for vol in ${VOL_ID[@]} ; do aws ec2 delete-tags \\ --region ${REGION} \\ --resources $vol \\ --tags Key=title Key=active aws ec2 create-tags \\ --region $REGION \\ --resources $vol \\ --tags Key=ops_replaced_in,Value=$OP \\ Key=ah_resize_info,Value=${vol}/$(date +%Y%m%d%H%M -d \"+7 days\") done Delete snapshots from maintenance window prep work. PRE_OP is the OP ticket of the volume snapshot prep work. PRE_OP= PRE_SNAPSHOTS=($(aws ec2 describe-snapshots \\ --region ${REGION} \\ --filters \"Name=description,Values=${PRE_OP}\" \\ --query 'Snapshots[*].{SnapshotId:SnapshotId}' \\ --output text)) for SNAPSHOT in ${PRE_SNAPSHOTS[@]}; do aws ec2 delete-snapshot \\ --region ${REGION} \\ --snapshot-id ${SNAPSHOT} done Update the JIRA ticket with the output from esl and sv-vollist . For example: echo \"{noformat:title=esl}\" \\ && esl ${SERVER} \\ && echo \"{noformat}\" echo \"{noformat:title=${SERVER} Volume List (post)}\" \\ && sv-vollist ${SERVER} \\ && echo \"{noformat}\"","title":"AZ Migration (xvdm xvdn xvdo)"},{"location":"standard_maintenance/az_migration_manual_volume_mno/#az-migration-xvdm-xvdn-xvdo","text":"You will suspend the server, migrate the volumes, edit, and launch the server in its new AZ.","title":"AZ Migration (xvdm xvdn xvdo)"},{"location":"standard_maintenance/az_migration_manual_volume_mno/#variables","text":"If you are not required to change the AMI_TYPE , then simply set AMI_TYPE to the current existing value. NEW_AZ is the full name of the AZ; for example us-east-1e . export SERVER= # set what will be the active mysql server OTHER_SERVER= export NEW_AZ= export AMI_TYPE= export OP= echo \"{noformat:title=Global Variables}\" \\ && echo \"export SERVER=${SERVER}\" \\ && echo \"export OTHER_SERVER=${OTHER_SERVER}\" \\ && echo \"export NEW_AZ=${NEW_AZ}\" \\ && echo \"export AMI_TYPE=${AMI_TYPE}\" \\ && echo \"export OP=${OP}\" \\ && echo \"{noformat}\"","title":"Variables"},{"location":"standard_maintenance/az_migration_manual_volume_mno/#maintenance-window-procedure","text":"Before you suspend the server gather the existing volume information and put it in to your JIRA ticket. WARNING : verify that the pre-maintenance volume snapshots are complete prior to commencing this procedure. Gather volume information: echo \"{noformat:title=${SERVER} Volume List (pre)}\" \\ && sv-vollist ${SERVER} \\ && echo \"{noformat}\" Set more variables. declare -A VOL_ID VOL_SIZE REGION=$(ah-server list ${SERVER} -c ec2_region --no-name) XVDM_ID=$(ah-server get ${SERVER} | grep \"[/]vol/ebs1\" | grep -Po \"\\d\\d+\") XVDN_ID=$(ah-server get ${SERVER} | grep \"[/]vol/backup-ebs\" \\ | grep -Po \"\\d+\") XVDO_ID=$(ah-server get ${SERVER} | grep brick$ | grep -Po \"\\d+\") VOL_ID[xvdm]=$(ah-volume get ${XVDM_ID} | grep ebs_id | awk '{print $2}') VOL_ID[xvdn]=$(ah-volume get ${XVDN_ID} | grep ebs_id | awk '{print $2}') VOL_ID[xvdo]=$(ah-volume get ${XVDO_ID} | grep ebs_id | awk '{print $2}') VOL_SIZE[xvdm]=$(ah-volume get ${XVDM_ID} | grep size | awk '{print $2}') VOL_SIZE[xvdn]=$(ah-volume get ${XVDN_ID} | grep size | awk '{print $2}') VOL_SIZE[xvdo]=$(ah-volume get ${XVDO_ID} | grep size | awk '{print $2}') echo \"{noformat:title=${SERVER} Variables}\" \\ && echo \"declare -A VOL_ID VOL_SIZE\" \\ && echo \"REGION=${REGION}\" \\ && echo \"XVDM_ID=${XVDM_ID}\" \\ && echo \"VOL_ID[xvdm]=${VOL_ID[xvdm]}\" \\ && echo \"VOL_SIZE[xvdm]=${VOL_SIZE[xvdm]}\" \\ && echo \"XVDN_ID=${XVDN_ID}\" \\ && echo \"VOL_ID[xvdn]=${VOL_ID[xvdn]}\" \\ && echo \"VOL_SIZE[xvdn]=${VOL_SIZE[xvdn]}\" \\ && echo \"XVDO_ID=${XVDO_ID}\" \\ && echo \"VOL_ID[xvdo]=${VOL_ID[xvdo]}\" \\ && echo \"VOL_SIZE[xvdo]=${VOL_SIZE[xvdo]}\" \\ && echo \"{noformat}\" Suspend the server. sv-downtime ${SERVER} 30 \"${OP} - az migration\" sv-downtimeservice ${OTHER_SERVER} 'Mysql Available' 30 \"${OP} - az migration\" ah-server suspend ${SERVER} Create final snapshots for each volume in order: declare -A SNAP_ID for device in xvdm xvdn xvdo; do SNAP_ID[$device]=$(aws ec2 create-snapshot \\ --volume-id ${VOL_ID[$device]} \\ --description ${OP} \\ --region ${REGION} \\ --query SnapshotId \\ --output text) done echo \"{noformat:title=${SERVER} Volume Snapshots}\" \\ && echo \"declare -A SNAP_ID\" \\ && echo \"SNAP_ID[xvdm]=${SNAP_ID[xvdm]}\" \\ && echo \"SNAP_ID[xvdn]=${SNAP_ID[xvdn]}\" \\ && echo \"SNAP_ID[xvdo]=${SNAP_ID[xvdo]}\" \\ && echo \"{noformat}\" Run this command until all snapshots are 100% complete watch -n 10 aws ec2 describe-snapshots \\ --snapshot-ids ${SNAP_ID[xvdm]} ${SNAP_ID[xvdn]} ${SNAP_ID[xvdo]} \\ --region=${REGION} \\ --query 'Snapshots[*].{SnapshotID:SnapshotId,Progress:Progress}' \\ --output text Update the fields server record: echo \"{noformat:title=Edit /dev/xvdm & /dev/xvdn}\" \\ && ah-server edit ${SERVER} -s \\ ebs_id=${SNAP_ID[xvdm]} \\ ebs2_id=${SNAP_ID[xvdn]} \\ ec2_availability_zone=${NEW_AZ} \\ ami_type=${AMI_TYPE} \\ && echo \"{noformat}\" Update the brick volume record: echo \"{noformat:title=Edit /dev/xvdo}\" \\ && ah-volume edit ${XVDO_ID} -s \\ ec2_availability_zone=${NEW_AZ} \\ ebs_id=${SNAP_ID[xvdo]} \\ && echo \"{noformat}\" Launch the server with --debug and tail -f the output file. When you launch a server volume and instance tags are automatically set for you. Note : Debug output is advised given that manual volume moves in this operation are prone to issues and you may need this extra output. ah-server launch ${SERVER} --debug","title":"Maintenance Window Procedure"},{"location":"standard_maintenance/az_migration_manual_volume_mno/#post-launch","text":"Remount gluster: SITE=$(ah-site list on:${SERVER} | head -1) site-fsremount ${SITE} For fsdbmesh hosts only. fpdsh -t site:${SITE} -n fsdbmesh \\ -c 'sudo ah-config-hosts; sudo ah-config-iptables; \\ sudo fields-config-tungsten-peers.php; sudo service stunnel4 restart' Verify DB and re-enable monitoring: ah-db-cluster status ${SERVER} sv-monenable $(ah-server list site:${SITE} \\ -w typeINded,fsdb,fsdbmesh,dbmaster \\ | paste -sd,) Delete the maintenance window snapshots. for device in xvdm xvdn xvdo; do aws ec2 delete-snapshot \\ --region ${REGION} \\ --snapshot-id ${SNAP_ID[$device]} done Delete the old volumes in the previous AZ. for vol in ${VOL_ID[@]} ; do aws ec2 delete-tags \\ --region ${REGION} \\ --resources $vol \\ --tags Key=title Key=active aws ec2 create-tags \\ --region $REGION \\ --resources $vol \\ --tags Key=ops_replaced_in,Value=$OP \\ Key=ah_resize_info,Value=${vol}/$(date +%Y%m%d%H%M -d \"+7 days\") done Delete snapshots from maintenance window prep work. PRE_OP is the OP ticket of the volume snapshot prep work. PRE_OP= PRE_SNAPSHOTS=($(aws ec2 describe-snapshots \\ --region ${REGION} \\ --filters \"Name=description,Values=${PRE_OP}\" \\ --query 'Snapshots[*].{SnapshotId:SnapshotId}' \\ --output text)) for SNAPSHOT in ${PRE_SNAPSHOTS[@]}; do aws ec2 delete-snapshot \\ --region ${REGION} \\ --snapshot-id ${SNAPSHOT} done Update the JIRA ticket with the output from esl and sv-vollist . For example: echo \"{noformat:title=esl}\" \\ && esl ${SERVER} \\ && echo \"{noformat}\" echo \"{noformat:title=${SERVER} Volume List (post)}\" \\ && sv-vollist ${SERVER} \\ && echo \"{noformat}\"","title":"Post Launch"},{"location":"standard_maintenance/az_migration_manual_volume_no/","text":"AZ Migration (xvdn xvdo) You will suspend the server, migrate the volumes, edit, and launch the server in its new AZ. Variables If you are not required to change the AMI_TYPE , then simply set AMI_TYPE to the current existing value. NEW_AZ is the full name of the AZ; for example us-east-1e . export SERVER= export NEW_AZ= export AMI_TYPE= export OP= echo \"{noformat:title=Global Variables}\" \\ && echo \"export SERVER=${SERVER}\" \\ && echo \"export NEW_AZ=${NEW_AZ}\" \\ && echo \"export AMI_TYPE=${AMI_TYPE}\" \\ && echo \"export OP=${OP}\" \\ && echo \"{noformat}\" Maintenance Window Procedure Before you suspend the server gather the existing volume information and put it in to your JIRA ticket. WARNING : verify that the pre-maintenance volume snapshots are complete prior to commencing this procedure. Gather volume information: echo \"{noformat:title=${SERVER} Volume List (pre)}\" \\ && sv-vollist ${SERVER} \\ && echo \"{noformat}\" Set more variables. declare -A VOL_ID VOL_SIZE REGION=$(ah-server list ${SERVER} -c ec2_region --no-name) XVDN_ID=$(ah-server get ${SERVER} | grep \"[/]vol/backup-ebs\" \\ | grep -Po \"\\d+\") XVDO_ID=$(ah-server get ${SERVER} | grep brick$ | grep -Po \"\\d+\") VOL_ID[xvdn]=$(ah-volume get ${XVDN_ID} | grep ebs_id | awk '{print $2}') VOL_ID[xvdo]=$(ah-volume get ${XVDO_ID} | grep ebs_id | awk '{print $2}') VOL_SIZE[xvdn]=$(ah-volume get ${XVDN_ID} | grep size | awk '{print $2}') VOL_SIZE[xvdo]=$(ah-volume get ${XVDO_ID} | grep size | awk '{print $2}') echo \"{noformat:title=${SERVER} Variables}\" \\ && echo \"declare -A VOL_ID VOL_SIZE\" \\ && echo \"REGION=${REGION}\" \\ && echo \"XVDN_ID=${XVDN_ID}\" \\ && echo \"VOL_ID[xvdn]=${VOL_ID[xvdn]}\" \\ && echo \"VOL_SIZE[xvdn]=${VOL_SIZE[xvdn]}\" \\ && echo \"XVDO_ID=${XVDO_ID}\" \\ && echo \"VOL_ID[xvdo]=${VOL_ID[xvdo]}\" \\ && echo \"VOL_SIZE[xvdo]=${VOL_SIZE[xvdo]}\" \\ && echo \"{noformat}\" Suspend the server. sv-downtime ${SERVER} 30 \"${OP} - az migration\" ah-server suspend ${SERVER} Create final snapshots for each volume in order: declare -A SNAP_ID for device in xvdn xvdo; do SNAP_ID[$device]=$(aws ec2 create-snapshot \\ --volume-id ${VOL_ID[$device]} \\ --description ${OP} \\ --region ${REGION} \\ --query SnapshotId \\ --output text) echo ${SNAP_ID[$device]} done echo \"{noformat:title=${SERVER} Volume Snapshots}\" \\ && echo \"declare -A SNAP_ID\" \\ && echo \"SNAP_ID[xvdn]=${SNAP_ID[xvdn]}\" \\ && echo \"SNAP_ID[xvdo]=${SNAP_ID[xvdo]}\" \\ && echo \"{noformat}\" Run this command until all snapshots are 100% complete watch -n 10 aws ec2 describe-snapshots \\ --snapshot-ids ${SNAP_ID[xvdn]} ${SNAP_ID[xvdo]} \\ --region=${REGION} \\ --query 'Snapshots[*].{SnapshotID:SnapshotId,Progress:Progress}' \\ --output text Update the fields server record: echo \"{noformat:title=Edit /dev/xvdn}\" \\ && ah-server edit ${SERVER} -s \\ ebs2_id=${SNAP_ID[xvdn]} \\ ec2_availability_zone=${NEW_AZ} \\ ami_type=${AMI_TYPE} \\ && echo \"{noformat}\" Update the brick volume record: echo \"{noformat:title=Edit /dev/xvdo}\" \\ && ah-volume edit ${XVDO_ID} -s \\ ec2_availability_zone=${NEW_AZ} \\ ebs_id=${SNAP_ID[xvdo]} \\ && echo \"{noformat}\" Launch the server with --debug and tail -f the output file. When you launch a server volume and instance tags are automatically set for you. Note : Debug output is advised given that manual volume moves in this operation are prone to issues and you may need this extra output. ah-server launch ${SERVER} --debug Post Launch Remount gluster: SITE=$(ah-site list on:${SERVER} | head -1) site-fsremount ${SITE} Re-enable monitoring: sv-monenable $(ah-server list site:${SITE} \\ -w typeINded,fsdb,fsdbmesh,dbmaster \\ | paste -sd,) Delete the maintenance window snapshots. for device in xvdm xvdn xvdo; do aws ec2 delete-snapshot \\ --region ${REGION} \\ --snapshot-id ${SNAP_ID[$device]} done Delete the old volumes in the previous AZ. for vol in ${VOL_ID[@]}} ; do aws ec2 delete-tags \\ --region ${REGION} \\ --resources $vol \\ --tags Key=title Key=active aws ec2 create-tags \\ --region $REGION \\ --resources $vol \\ --tags Key=ops_replaced_in,Value=$OP \\ Key=ah_resize_info,Value=${vol}/$(date +%Y%m%d%H%M -d \"+7 days\") done Delete snapshots from maintenance window prep work. PRE_OP is the OP ticket of the volume snapshot prep work. PRE_OP= PRE_SNAPSHOTS=($(aws ec2 describe-snapshots \\ --region ${REGION} \\ --filters \"Name=description,Values=${PRE_OP}\" \\ --query 'Snapshots[*].{SnapshotId:SnapshotId}' \\ --output text)) for SNAPSHOT in ${PRE_SNAPSHOTS[@]}; do aws ec2 delete-snapshot \\ --region ${REGION} \\ --snapshot-id ${SNAPSHOT} done Update the JIRA ticket with the output from esl and sv-vollist . For example: echo \"{noformat:title=esl}\" \\ && esl ${SERVER} \\ && echo \"{noformat}\" echo \"{noformat:title=${SERVER} Volume List (post)}\" \\ && sv-vollist ${SERVER} \\ && echo \"{noformat}\"","title":"AZ Migration (xvdn xvdo)"},{"location":"standard_maintenance/az_migration_manual_volume_no/#az-migration-xvdn-xvdo","text":"You will suspend the server, migrate the volumes, edit, and launch the server in its new AZ.","title":"AZ Migration (xvdn xvdo)"},{"location":"standard_maintenance/az_migration_manual_volume_no/#variables","text":"If you are not required to change the AMI_TYPE , then simply set AMI_TYPE to the current existing value. NEW_AZ is the full name of the AZ; for example us-east-1e . export SERVER= export NEW_AZ= export AMI_TYPE= export OP= echo \"{noformat:title=Global Variables}\" \\ && echo \"export SERVER=${SERVER}\" \\ && echo \"export NEW_AZ=${NEW_AZ}\" \\ && echo \"export AMI_TYPE=${AMI_TYPE}\" \\ && echo \"export OP=${OP}\" \\ && echo \"{noformat}\"","title":"Variables"},{"location":"standard_maintenance/az_migration_manual_volume_no/#maintenance-window-procedure","text":"Before you suspend the server gather the existing volume information and put it in to your JIRA ticket. WARNING : verify that the pre-maintenance volume snapshots are complete prior to commencing this procedure. Gather volume information: echo \"{noformat:title=${SERVER} Volume List (pre)}\" \\ && sv-vollist ${SERVER} \\ && echo \"{noformat}\" Set more variables. declare -A VOL_ID VOL_SIZE REGION=$(ah-server list ${SERVER} -c ec2_region --no-name) XVDN_ID=$(ah-server get ${SERVER} | grep \"[/]vol/backup-ebs\" \\ | grep -Po \"\\d+\") XVDO_ID=$(ah-server get ${SERVER} | grep brick$ | grep -Po \"\\d+\") VOL_ID[xvdn]=$(ah-volume get ${XVDN_ID} | grep ebs_id | awk '{print $2}') VOL_ID[xvdo]=$(ah-volume get ${XVDO_ID} | grep ebs_id | awk '{print $2}') VOL_SIZE[xvdn]=$(ah-volume get ${XVDN_ID} | grep size | awk '{print $2}') VOL_SIZE[xvdo]=$(ah-volume get ${XVDO_ID} | grep size | awk '{print $2}') echo \"{noformat:title=${SERVER} Variables}\" \\ && echo \"declare -A VOL_ID VOL_SIZE\" \\ && echo \"REGION=${REGION}\" \\ && echo \"XVDN_ID=${XVDN_ID}\" \\ && echo \"VOL_ID[xvdn]=${VOL_ID[xvdn]}\" \\ && echo \"VOL_SIZE[xvdn]=${VOL_SIZE[xvdn]}\" \\ && echo \"XVDO_ID=${XVDO_ID}\" \\ && echo \"VOL_ID[xvdo]=${VOL_ID[xvdo]}\" \\ && echo \"VOL_SIZE[xvdo]=${VOL_SIZE[xvdo]}\" \\ && echo \"{noformat}\" Suspend the server. sv-downtime ${SERVER} 30 \"${OP} - az migration\" ah-server suspend ${SERVER} Create final snapshots for each volume in order: declare -A SNAP_ID for device in xvdn xvdo; do SNAP_ID[$device]=$(aws ec2 create-snapshot \\ --volume-id ${VOL_ID[$device]} \\ --description ${OP} \\ --region ${REGION} \\ --query SnapshotId \\ --output text) echo ${SNAP_ID[$device]} done echo \"{noformat:title=${SERVER} Volume Snapshots}\" \\ && echo \"declare -A SNAP_ID\" \\ && echo \"SNAP_ID[xvdn]=${SNAP_ID[xvdn]}\" \\ && echo \"SNAP_ID[xvdo]=${SNAP_ID[xvdo]}\" \\ && echo \"{noformat}\" Run this command until all snapshots are 100% complete watch -n 10 aws ec2 describe-snapshots \\ --snapshot-ids ${SNAP_ID[xvdn]} ${SNAP_ID[xvdo]} \\ --region=${REGION} \\ --query 'Snapshots[*].{SnapshotID:SnapshotId,Progress:Progress}' \\ --output text Update the fields server record: echo \"{noformat:title=Edit /dev/xvdn}\" \\ && ah-server edit ${SERVER} -s \\ ebs2_id=${SNAP_ID[xvdn]} \\ ec2_availability_zone=${NEW_AZ} \\ ami_type=${AMI_TYPE} \\ && echo \"{noformat}\" Update the brick volume record: echo \"{noformat:title=Edit /dev/xvdo}\" \\ && ah-volume edit ${XVDO_ID} -s \\ ec2_availability_zone=${NEW_AZ} \\ ebs_id=${SNAP_ID[xvdo]} \\ && echo \"{noformat}\" Launch the server with --debug and tail -f the output file. When you launch a server volume and instance tags are automatically set for you. Note : Debug output is advised given that manual volume moves in this operation are prone to issues and you may need this extra output. ah-server launch ${SERVER} --debug","title":"Maintenance Window Procedure"},{"location":"standard_maintenance/az_migration_manual_volume_no/#post-launch","text":"Remount gluster: SITE=$(ah-site list on:${SERVER} | head -1) site-fsremount ${SITE} Re-enable monitoring: sv-monenable $(ah-server list site:${SITE} \\ -w typeINded,fsdb,fsdbmesh,dbmaster \\ | paste -sd,) Delete the maintenance window snapshots. for device in xvdm xvdn xvdo; do aws ec2 delete-snapshot \\ --region ${REGION} \\ --snapshot-id ${SNAP_ID[$device]} done Delete the old volumes in the previous AZ. for vol in ${VOL_ID[@]}} ; do aws ec2 delete-tags \\ --region ${REGION} \\ --resources $vol \\ --tags Key=title Key=active aws ec2 create-tags \\ --region $REGION \\ --resources $vol \\ --tags Key=ops_replaced_in,Value=$OP \\ Key=ah_resize_info,Value=${vol}/$(date +%Y%m%d%H%M -d \"+7 days\") done Delete snapshots from maintenance window prep work. PRE_OP is the OP ticket of the volume snapshot prep work. PRE_OP= PRE_SNAPSHOTS=($(aws ec2 describe-snapshots \\ --region ${REGION} \\ --filters \"Name=description,Values=${PRE_OP}\" \\ --query 'Snapshots[*].{SnapshotId:SnapshotId}' \\ --output text)) for SNAPSHOT in ${PRE_SNAPSHOTS[@]}; do aws ec2 delete-snapshot \\ --region ${REGION} \\ --snapshot-id ${SNAPSHOT} done Update the JIRA ticket with the output from esl and sv-vollist . For example: echo \"{noformat:title=esl}\" \\ && esl ${SERVER} \\ && echo \"{noformat}\" echo \"{noformat:title=${SERVER} Volume List (post)}\" \\ && sv-vollist ${SERVER} \\ && echo \"{noformat}\"","title":"Post Launch"},{"location":"standard_maintenance/fedramp_relaunch/","text":"Relaunching into FedRAMP compliance VPC If a customer site is running on dedicated hardware we can relaunch them into VPC directly faster, more reliably,and with less downtime than a site move. Preparation steps Maintenance window Site Factory site layout Site Factory relaunches, such as in the enterprise-g1 realm, have some noteworthy differences from site moves in ACE: Site Factory sites are comprised of several sitegroups which cannot be moved independently of one another Since it is required to move all sites in a Site Factory, it is helpful to understand the sitegroup/sites on a typical site factory: esl ${CUSTOMERNAME}% Each Site Factory has three sitegroups, ${CUSTOMERNAME} , ${CUSTOMERNAME}sf , and ${CUSTOMERNAME}theme . These sitegroups are often on separate stacks, so spend time tracking down all of the hardware. Within those sitegroups you will see sitenames such as ${CUSTOMERNAME}01live , ${CUSTOMERNAME}01update , ${CUSTOMERNAME}01theme , etc. Note some older site factories may add an underscore, i.e. ${CUSTOMERNAME}_sf . Identify all sitegroups, sites, and hardware before beginning the relaunch. Prep For any FedRAMP maintenance, you should be given a customer sitegroup to migrate (potentially a list of sitegroups if the customer has multiple sitegroups). Find all sites and hardware: SITEGROUP= SITES=( $(ah-site list sitegroup:${SITEGROUP} -w stage!=ra) ) SERVERS=( $(ah-server list $(printf 'site:%s\\n' ${SITES[@]} | \\ paste -sd,) -w type!=svn status=0) ) SERVERS_CSV=$(array-csv ${SERVERS[@]}) Identify any shared hardware by checking tags and other sites: ah-server list ${SERVERS_CSV} -c tags site-list -s ${SERVERS_CSV} If any sites are sharing hardware with a site that is not part of your maintenance, then that site must be migrated to FedRAMP VPC via a site move ! If a site is not sharing any hardware, then its servers may be relaunched directly into VPC. In order to do this, the databases must be upgraded to MySQL 5.6.41 beforehand by following this runbook . Maintenance Validate Maintenance First build lists and verify information for the maintenance. Verify that all prep steps above were done and setup variables in your terminal. Modify your lists appropriately so that shared hardware is not included in your work! SITES=( ) SERVERS=( ) SERVERS_CSV=$(array-csv ${SERVERS[@]}) Gather information about the current server configuration: ah-server list ${SERVERS_CSV} -c ec2_availability_zone vpc_id ami_type \\ puppet:mysql_version puppet:fips_enabled Validate MySQL by running: ah-server list ${SERVERS_CSV} \\ -w typeINstaging,ded,fsdb,dbmaster,fsdbmesh,dbmesh -c puppet:mysql_version As of this writing, all database servers must be running MySQL 5.6.41 in order to be FIPS compliant. Make note of any sites which currently have an ELB: for site in ${SITES[@]}; do site-elbdescribe ${site} done If they do, we need to provision new ELBs for each site and communicate the new ELB FQDN to the customer for DNS. Validate the target VPC: VPC_ID= VPC_NAME=$(ah-vpc list % -w id=${VPC_ID}) ah-vpc get ${VPC_NAME} The target VPC must be tagged with fedramp and must match the region of the servers you are migrating. Validate the volume encryption: sv-vollist ${SERVERS_CSV}|egrep 'brick|mnt|ebs1|backup' Note:Update the non encrypted volumes to encrypted volume(brick/ebs1/backup)before the relaunch using resize workflow. Ops can use below command to update (mnt) volume or choose another method given in Relaunch section to save time. ah-volume upsize-mntfs --server-name=${SERVER_NAME} --target-size=${TARGET_SIZE} Relaunch Into VPC If there is nothing blocking a safe relaunch, proceed to suspend them so we can FIPS-enable them. Please note that this will incur hard downtime for the customer, but is a faster and less painful process than site moves. Check the AMI type of all servers: ah-server list ${SERVERS_CSV} -c ami_type For simplicity's sake, this runbook includes commands to convert server AMI types from 5-series to 4-series. If the customer currently has any non-5-series servers, you must edit the ami_type manually! Additionally, only c4 and m4 server AMI types can be FIPS-enabled, and all servers in the stack must be FIPS-enabled for the maintenance to succeed. Suspend all servers at the same time: ah-server suspend ${SERVERS_CSV} Note: Update /mnt volume encryption status to (1) after suspending the servers for non encrypted mnt volumes.. VOL_ID=$(sv-vollist ${SERVERS_CSV}|egrep 'mnt$'|awk -F',' {'print $2'}) for volume in $VOL_ID; do ah-volume edit ${volume} -s encrypted=1 done Edit the servers to enable them for FIPS in the new VPC: for server in ${SERVERS[@]}; do NEW_AMI_TYPE=$(ah-server list ${server} \\ --no-name -c ami_type | tr '5' '4') ah-server edit ${server} -s ami_type=${NEW_AMI_TYPE} ah-server edit ${server} -c puppet:fips_enabled=1 -s vpc_id=${VPC_ID} done Launch them: ah-server launch ${SERVERS[@]} If the site has any ELBs, recreate them. Repeat the following step for each of the ELB/s a site (ACE) or relted group of sites (ACSF) may have Variables SITE=[ SITENAME ] REGION=$(ah-site get ${SITE}|egrep '^region:'|awk '{print $2}') ELB_FQDN=\"$(site-elbdescribe $SITE|egrep elb.amazonaws.com)\" ELB_NAME=$(echo ${ELB_FQDN} | \\ egrep elb.amazonaws.com | \\ awk -F. '{print $1}' | \\ awk -F- 'BEGIN{OFS=\"-\"} {NF--; print}') ELB_CERT_ARN=$(aws elb describe-load-balancers \\ --load-balancer-names ${ELB_NAME} --region $REGION \\ --query \\ \"LoadBalancerDescriptions[?LoadBalancerName==\\`${ELB_NAME}\\`]\" \\ | egrep SSLCertificateId|awk -F\\\" '{print $4}') ELB_CERT_TYPE=$(echo ${ELB_CERT_ARN} | cut -d: -f3) if [ ${ELB_CERT_TYPE} == \"acm\" ] ;then CERT_TYPE=\"ACM Managed Certificate\" elif [ ${ELB_CERT_TYPE} == \"iam\" ] ;then CERT_TYPE=\"IAM Server Certificate\" fi site-elbdescribe ${SITE} echo -e \"{code:title=ELB Details - Before Fedramp Migration} Site: $SITE Region: $REGION ELB before migration: $ELB_NAME ELB FQDN before migration: $ELB_FQDN elb_cert_arn: $ELB_CERT_ARN ELB Cert Type: $CERT_TYPE {code}\" If ELB Cert Type from the above output is IAM Server Certificate **Re-creation of ELB after moving hardware to FedRamp VPC** FEDRAMP_VPC=[NAME OF THE FEDRAMP VPC] ah-site ssl tech-refresh-vpc-migrate-elb ${SITE} ${FEDRAMP_VPC} # Make note of 'New ELB Name' from the output of the above # command and set following variable with it's value NEW_ELB_NAME=[New ELB Name] # Set existing certificate for the old elb to the new elb # that was created in the step above aws elb set-load-balancer-listener-ssl-certificate \\ --load-balancer-name ${NEW_ELB_NAME} --ssl-certificate-id \\ ${ELB_CERT_ARN} --load-balancer-port 443 --region ${REGION **Delete the old ELB in AWS (hapi now already has new ELB in VPC)** aws elb delete-load-balancer \\ --load-balancer-name ${ELB_NAME} --region $REGION If ELB Cert Type from the above output is ACM Managed Certificate (ACM certs are common in ACSF) **Re-creation of ELB after moving hardware to FedRamp VPC Manually** FEDRAMP_VPC=[NAME OF THE FEDRAMP VPC] # Delete the old elb ah-site ssl deprovision-elb ${SITE} # Create new ELB with self signed certs KEY=${OPSTMP}/$SITE.key CERT=${OPSTMP}/$SITE.pem DOMAIN=\"www.${SITE}.acsitefactory.com\" openssl req -nodes -sha256 -newkey rsa:2048 -keyout ${KEY} -out ${OPSTMP}/${SITE}.csr \\ -subj \"/C=US/ST=Massachusetts/L=Boston/O=Acquia Inc./OU=Acquia/CN=${DOMAIN}\" openssl x509 -req -days 365 -in ${OPSTMP}/${SITE}.csr -signkey ${KEY} -out ${CERT} ah-site ssl create-elb ${SITE} --ca ${CERT} --cert ${CERT} --key ${KEY} # Make note of 'New ELB Name' from the output of the above # command and set following variable with it's value NEW_ELB_NAME=[New ELB Name] aws elb set-load-balancer-listener-ssl-certificate --load-balancer-name ${NEW_ELB_NAME} \\ --load-balancer-port 443 --ssl-certificate-id ${ELB_CERT_ARN} --region ${REGION} Update all the domains pointing OLD ELB to the NEW ELB # Get the new ELB FQDN after recreating it NEW_ELB_FQDN=\"$(site-elbdescribe $SITE|egrep elb.amazonaws.com)\" # Store all domains which are pointing to old ELB in an array DOMAINS=( $(site-domainshost ${CUSTOMERNAME}% | grep \"is an alias for ${ELB_FQDN}\" | awk '{print $1}') ) # Update all the domains to point to the new ELB for DOMAIN in ${DOMAINS[@]}; do ah-dns set -t CNAME -v ${NEW_ELB_FQDN} -h ${DOMAIN} done Note: Double check to make sure that you have re-pointed all the domains to new ELB that were pointed to old ELB, specifically in case of enterprise-g1 where multiple sites are linked with ELB. After creating the ELB, you must configure the ELB to support TLSv1.2 only. Until this is supported by the platform, it must be done manually in the AWS UI. Login to the AWS console. Select EC2 under services. Select Load Balancers on the left menu. Search for the customer's ELB in the search bar. For example \"mc-12555\". Click the Listeners tab at the bottom, then Cipher . Click \"Custom Security Policy\", and then ensure that only Protocol-TLSv1.2 is selected on the right under SSL Protocols. Save. Route53 Verification Finally, verify if the customer has a route 53 address. If the customer has a route 53 address point the customer's route 53 alias to the new ELBs using the steps below. Verify if the customer has a route 53 alias: site_displayalias $sitename Update the new route 53 alias site_updateroute53alias $sitename $new_elbfqdn If all launches are successful, refer to this section to verify that all sites work and post-maintenance configuration is done.","title":"Relaunching into FedRAMP compliance VPC"},{"location":"standard_maintenance/fedramp_relaunch/#relaunching-into-fedramp-compliance-vpc","text":"If a customer site is running on dedicated hardware we can relaunch them into VPC directly faster, more reliably,and with less downtime than a site move. Preparation steps Maintenance window","title":"Relaunching into FedRAMP compliance VPC"},{"location":"standard_maintenance/fedramp_relaunch/#site-factory-site-layout","text":"Site Factory relaunches, such as in the enterprise-g1 realm, have some noteworthy differences from site moves in ACE: Site Factory sites are comprised of several sitegroups which cannot be moved independently of one another Since it is required to move all sites in a Site Factory, it is helpful to understand the sitegroup/sites on a typical site factory: esl ${CUSTOMERNAME}% Each Site Factory has three sitegroups, ${CUSTOMERNAME} , ${CUSTOMERNAME}sf , and ${CUSTOMERNAME}theme . These sitegroups are often on separate stacks, so spend time tracking down all of the hardware. Within those sitegroups you will see sitenames such as ${CUSTOMERNAME}01live , ${CUSTOMERNAME}01update , ${CUSTOMERNAME}01theme , etc. Note some older site factories may add an underscore, i.e. ${CUSTOMERNAME}_sf . Identify all sitegroups, sites, and hardware before beginning the relaunch.","title":"Site Factory site layout"},{"location":"standard_maintenance/fedramp_relaunch/#prep","text":"For any FedRAMP maintenance, you should be given a customer sitegroup to migrate (potentially a list of sitegroups if the customer has multiple sitegroups). Find all sites and hardware: SITEGROUP= SITES=( $(ah-site list sitegroup:${SITEGROUP} -w stage!=ra) ) SERVERS=( $(ah-server list $(printf 'site:%s\\n' ${SITES[@]} | \\ paste -sd,) -w type!=svn status=0) ) SERVERS_CSV=$(array-csv ${SERVERS[@]}) Identify any shared hardware by checking tags and other sites: ah-server list ${SERVERS_CSV} -c tags site-list -s ${SERVERS_CSV} If any sites are sharing hardware with a site that is not part of your maintenance, then that site must be migrated to FedRAMP VPC via a site move ! If a site is not sharing any hardware, then its servers may be relaunched directly into VPC. In order to do this, the databases must be upgraded to MySQL 5.6.41 beforehand by following this runbook .","title":"Prep"},{"location":"standard_maintenance/fedramp_relaunch/#maintenance","text":"","title":"Maintenance"},{"location":"standard_maintenance/fedramp_relaunch/#validate-maintenance","text":"First build lists and verify information for the maintenance. Verify that all prep steps above were done and setup variables in your terminal. Modify your lists appropriately so that shared hardware is not included in your work! SITES=( ) SERVERS=( ) SERVERS_CSV=$(array-csv ${SERVERS[@]}) Gather information about the current server configuration: ah-server list ${SERVERS_CSV} -c ec2_availability_zone vpc_id ami_type \\ puppet:mysql_version puppet:fips_enabled Validate MySQL by running: ah-server list ${SERVERS_CSV} \\ -w typeINstaging,ded,fsdb,dbmaster,fsdbmesh,dbmesh -c puppet:mysql_version As of this writing, all database servers must be running MySQL 5.6.41 in order to be FIPS compliant. Make note of any sites which currently have an ELB: for site in ${SITES[@]}; do site-elbdescribe ${site} done If they do, we need to provision new ELBs for each site and communicate the new ELB FQDN to the customer for DNS. Validate the target VPC: VPC_ID= VPC_NAME=$(ah-vpc list % -w id=${VPC_ID}) ah-vpc get ${VPC_NAME} The target VPC must be tagged with fedramp and must match the region of the servers you are migrating. Validate the volume encryption: sv-vollist ${SERVERS_CSV}|egrep 'brick|mnt|ebs1|backup' Note:Update the non encrypted volumes to encrypted volume(brick/ebs1/backup)before the relaunch using resize workflow. Ops can use below command to update (mnt) volume or choose another method given in Relaunch section to save time. ah-volume upsize-mntfs --server-name=${SERVER_NAME} --target-size=${TARGET_SIZE}","title":"Validate Maintenance"},{"location":"standard_maintenance/fedramp_relaunch/#relaunch-into-vpc","text":"If there is nothing blocking a safe relaunch, proceed to suspend them so we can FIPS-enable them. Please note that this will incur hard downtime for the customer, but is a faster and less painful process than site moves. Check the AMI type of all servers: ah-server list ${SERVERS_CSV} -c ami_type For simplicity's sake, this runbook includes commands to convert server AMI types from 5-series to 4-series. If the customer currently has any non-5-series servers, you must edit the ami_type manually! Additionally, only c4 and m4 server AMI types can be FIPS-enabled, and all servers in the stack must be FIPS-enabled for the maintenance to succeed. Suspend all servers at the same time: ah-server suspend ${SERVERS_CSV} Note: Update /mnt volume encryption status to (1) after suspending the servers for non encrypted mnt volumes.. VOL_ID=$(sv-vollist ${SERVERS_CSV}|egrep 'mnt$'|awk -F',' {'print $2'}) for volume in $VOL_ID; do ah-volume edit ${volume} -s encrypted=1 done Edit the servers to enable them for FIPS in the new VPC: for server in ${SERVERS[@]}; do NEW_AMI_TYPE=$(ah-server list ${server} \\ --no-name -c ami_type | tr '5' '4') ah-server edit ${server} -s ami_type=${NEW_AMI_TYPE} ah-server edit ${server} -c puppet:fips_enabled=1 -s vpc_id=${VPC_ID} done Launch them: ah-server launch ${SERVERS[@]} If the site has any ELBs, recreate them. Repeat the following step for each of the ELB/s a site (ACE) or relted group of sites (ACSF) may have Variables SITE=[ SITENAME ] REGION=$(ah-site get ${SITE}|egrep '^region:'|awk '{print $2}') ELB_FQDN=\"$(site-elbdescribe $SITE|egrep elb.amazonaws.com)\" ELB_NAME=$(echo ${ELB_FQDN} | \\ egrep elb.amazonaws.com | \\ awk -F. '{print $1}' | \\ awk -F- 'BEGIN{OFS=\"-\"} {NF--; print}') ELB_CERT_ARN=$(aws elb describe-load-balancers \\ --load-balancer-names ${ELB_NAME} --region $REGION \\ --query \\ \"LoadBalancerDescriptions[?LoadBalancerName==\\`${ELB_NAME}\\`]\" \\ | egrep SSLCertificateId|awk -F\\\" '{print $4}') ELB_CERT_TYPE=$(echo ${ELB_CERT_ARN} | cut -d: -f3) if [ ${ELB_CERT_TYPE} == \"acm\" ] ;then CERT_TYPE=\"ACM Managed Certificate\" elif [ ${ELB_CERT_TYPE} == \"iam\" ] ;then CERT_TYPE=\"IAM Server Certificate\" fi site-elbdescribe ${SITE} echo -e \"{code:title=ELB Details - Before Fedramp Migration} Site: $SITE Region: $REGION ELB before migration: $ELB_NAME ELB FQDN before migration: $ELB_FQDN elb_cert_arn: $ELB_CERT_ARN ELB Cert Type: $CERT_TYPE {code}\" If ELB Cert Type from the above output is IAM Server Certificate **Re-creation of ELB after moving hardware to FedRamp VPC** FEDRAMP_VPC=[NAME OF THE FEDRAMP VPC] ah-site ssl tech-refresh-vpc-migrate-elb ${SITE} ${FEDRAMP_VPC} # Make note of 'New ELB Name' from the output of the above # command and set following variable with it's value NEW_ELB_NAME=[New ELB Name] # Set existing certificate for the old elb to the new elb # that was created in the step above aws elb set-load-balancer-listener-ssl-certificate \\ --load-balancer-name ${NEW_ELB_NAME} --ssl-certificate-id \\ ${ELB_CERT_ARN} --load-balancer-port 443 --region ${REGION **Delete the old ELB in AWS (hapi now already has new ELB in VPC)** aws elb delete-load-balancer \\ --load-balancer-name ${ELB_NAME} --region $REGION If ELB Cert Type from the above output is ACM Managed Certificate (ACM certs are common in ACSF) **Re-creation of ELB after moving hardware to FedRamp VPC Manually** FEDRAMP_VPC=[NAME OF THE FEDRAMP VPC] # Delete the old elb ah-site ssl deprovision-elb ${SITE} # Create new ELB with self signed certs KEY=${OPSTMP}/$SITE.key CERT=${OPSTMP}/$SITE.pem DOMAIN=\"www.${SITE}.acsitefactory.com\" openssl req -nodes -sha256 -newkey rsa:2048 -keyout ${KEY} -out ${OPSTMP}/${SITE}.csr \\ -subj \"/C=US/ST=Massachusetts/L=Boston/O=Acquia Inc./OU=Acquia/CN=${DOMAIN}\" openssl x509 -req -days 365 -in ${OPSTMP}/${SITE}.csr -signkey ${KEY} -out ${CERT} ah-site ssl create-elb ${SITE} --ca ${CERT} --cert ${CERT} --key ${KEY} # Make note of 'New ELB Name' from the output of the above # command and set following variable with it's value NEW_ELB_NAME=[New ELB Name] aws elb set-load-balancer-listener-ssl-certificate --load-balancer-name ${NEW_ELB_NAME} \\ --load-balancer-port 443 --ssl-certificate-id ${ELB_CERT_ARN} --region ${REGION} Update all the domains pointing OLD ELB to the NEW ELB # Get the new ELB FQDN after recreating it NEW_ELB_FQDN=\"$(site-elbdescribe $SITE|egrep elb.amazonaws.com)\" # Store all domains which are pointing to old ELB in an array DOMAINS=( $(site-domainshost ${CUSTOMERNAME}% | grep \"is an alias for ${ELB_FQDN}\" | awk '{print $1}') ) # Update all the domains to point to the new ELB for DOMAIN in ${DOMAINS[@]}; do ah-dns set -t CNAME -v ${NEW_ELB_FQDN} -h ${DOMAIN} done Note: Double check to make sure that you have re-pointed all the domains to new ELB that were pointed to old ELB, specifically in case of enterprise-g1 where multiple sites are linked with ELB. After creating the ELB, you must configure the ELB to support TLSv1.2 only. Until this is supported by the platform, it must be done manually in the AWS UI. Login to the AWS console. Select EC2 under services. Select Load Balancers on the left menu. Search for the customer's ELB in the search bar. For example \"mc-12555\". Click the Listeners tab at the bottom, then Cipher . Click \"Custom Security Policy\", and then ensure that only Protocol-TLSv1.2 is selected on the right under SSL Protocols. Save. Route53 Verification Finally, verify if the customer has a route 53 address. If the customer has a route 53 address point the customer's route 53 alias to the new ELBs using the steps below. Verify if the customer has a route 53 alias: site_displayalias $sitename Update the new route 53 alias site_updateroute53alias $sitename $new_elbfqdn If all launches are successful, refer to this section to verify that all sites work and post-maintenance configuration is done.","title":"Relaunch Into VPC"},{"location":"standard_maintenance/fips-140-2/","text":"FIPS 140-2 compliant instance management FIPS 140-2 compliancy is controlled by fips_enabled server config setting. Because the compliancy requires to launch servers on a different kernel, the flag can only be set in allocated state. The current implementation denies changing this config setting on launched server. Use the following runbooks in order to activate / deactivate the feature on servers: Provision new FIPS server Enable FIPS on (non-DB) servers Disable FIPS on (non-DB) servers Migrate DB clusters to FIPS aka Enable/ Disable FIPS on DB servers Check FIPS compliancy on servers Reporting issues If you experience FIPS related instance management issues reach out Cloud Platform team in a CL Jira ticket. Additionally you can get help in #cloud_eng_platform slack channel. References SCNG research page FIPS 140-2 Checklist Fields sshd config doc with list of strict sshd algorithms","title":"FIPS 140-2 compliant instance management"},{"location":"standard_maintenance/fips-140-2/#fips-140-2-compliant-instance-management","text":"FIPS 140-2 compliancy is controlled by fips_enabled server config setting. Because the compliancy requires to launch servers on a different kernel, the flag can only be set in allocated state. The current implementation denies changing this config setting on launched server. Use the following runbooks in order to activate / deactivate the feature on servers: Provision new FIPS server Enable FIPS on (non-DB) servers Disable FIPS on (non-DB) servers Migrate DB clusters to FIPS aka Enable/ Disable FIPS on DB servers Check FIPS compliancy on servers","title":"FIPS 140-2 compliant instance management"},{"location":"standard_maintenance/fips-140-2/#reporting-issues","text":"If you experience FIPS related instance management issues reach out Cloud Platform team in a CL Jira ticket. Additionally you can get help in #cloud_eng_platform slack channel.","title":"Reporting issues"},{"location":"standard_maintenance/fips-140-2/#references","text":"SCNG research page FIPS 140-2 Checklist Fields sshd config doc with list of strict sshd algorithms","title":"References"},{"location":"standard_maintenance/moving_a_fedramp_site_with_acquia_shield/","text":"Moving a FedRAMP Site with Acquia Cloud Shield This procedure guides you through moving a site from one stack of servers to another. Requirements In order for FedRAMP customer sites to meet all of the latest requirements, the following things are all necessary: The site must be in a dedicated VPC for customers with Acquia Cloud Shield. All instances must be 4-series hardware. All servers must have FIPS mode enabled. Note: while webs, bals, and fs-only servers can have FIPS mode enabled during a relaunch, database servers cannot. A site move is mandatory to move onto new database servers that are launched with FIPS mode from the very start. Check if the hardware is already FIPS enabled with this runbook . If the customer has an ELB, the ELB's back-end instances must have IPv6 addresses. See the Verification section to check this. If the customer does not have an ELB, one must be added. The customer must have dedicated balancers. Balancers must be configured to use TLSv1.2 only. See the Verification section to check this. Shield Access Control needs to be enabled. See the Verification section to check this under \u201cNetwork Boundaries\u201d. VPC FedRAMP customers must be in a dedicated VPC. The customer should fill out the VPC questionnaire to provide you with the information that you need to provision their dedicated VPC. Follow the VPC provision instructions . Site Factory site layout Site Factory site moves, such as in the enterprise-g1 realm, have some noteworthy differences from site moves in ACE: Site Factory sites are comprised of several sitegroups which cannot be moved independently of one another ELBs in Site Factory have extra requirements Create a DG ticket after the site move is completed. Since it is required to move all sites in a Site Factory, it is helpful to understand the sitegroup/sites on a typical site factory: https://ops.acquia.com/doc/index.php/Procedures/Provision_%26_Deprovision/Provisioning_Gardens . esl ${CUSTOMERNAME}% Each Site Factory has three sitegroups, ${CUSTOMERNAME} , ${CUSTOMERNAME}sf , and ${CUSTOMERNAME}theme . These sitegroups are often on separate stacks, so spend time tracking down all of the hardware. Within those sitegroups you will see sitenames such as ${CUSTOMERNAME}01live , ${CUSTOMERNAME}01update , ${CUSTOMERNAME}01theme , etc. Note some older site factories may add an underscore, i.e. ${CUSTOMERNAME}_sf . Identify all sitegroups, sites, and hardware before beginning the site move. Provisioning New Hardware In order to be FIPS compliant, all servers must be on series 4 hardware. If you are not provided with an existing list of ami types for the new hardware, find equivalent series 4 ami's: https://ec2instances.info/?filter=c4|m4 . Follow the FIPS server provisioning runbook to provision FIPS-mode servers to move the site to. Preparation The following prep work should be completed before the site move is executed: Verify that the site and destination servers are in the same region. If the regions differ, then balancers and VCS repos must move to the new region as well. SRC_SITE= DST_FS_SERVER= DST_DB_SERVER= SRC_SRV=$(ah-server list site:${SRC_SITE} -w type!=svn| tail -1) ah-server list ${SRC_SRV},${DST_FS_SERVER} -c ec2_region --no-name | paste -s \\ | awk '$1 != $2 { exit 1; }' && echo \"Regions match\" || echo \"WARNING: Regions do not match\" Verify that the destination server has enough disk space to accommodate the new site. This is a hard stop point if this check does not pass. site-movevolusage ${SRC_SITE} ${DST_FS_SERVER} ${DST_DB_SERVER} Additionally, if the destination hardware does not exist yet, run the above as follows (with destination sizes): site-movevolusage ${SRC_SITE} ${DST_FS_SIZE} [e.g. 10G or 10240M] ${DST_DB_SIZE} [e.g. 10G or 10240M] If the site is moving to servers in a different region and it has an ELB then verify that the key and cert are on the gluster volume at SITE= SITE_ENV= SITEGROUP=$(ah-site list ${SITE} --no-name -c sitegroup) /home/${SITEGROUP}/${SITE_ENV}/ssl If they are not, assign the ticket to the reporter, set to Waiting for Feedback, and ask that the files be provided at that path. EIPs cannot move between regions, so the customer needs to whitelist any new webnode EIPs before the site move can go forward. Procedure Use the site move workflow to move the site to the new hardware. There is now a pre-sync step to minimize downtime. Important Note Do not abort workflows! If you are unable to resolve a problem with a workflow, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership Syncing Data Prior to Downtime The site move workflow can be used in such a way that the majority of a site's data can be rsynced onto the new hardware before the site is actually transferred. This \"pre-rsync\" does not require downtime and can shorten the total required downtime for switching hardware. To do this, simply pause the workflow at the step update_site_location_within_the_hosting_api . --pause-at-step=update_site_location_within_the_hosting_api The step which executes the pre-rsync is called pre_migrate_site_files . Variables Set variables for the SITE to be moved, the lowest-numbered destination DB server, space-separated lists of destination WEBS and BALS , and the OP ticket. SITE= DB= WEBS=() BALS=() OP= WEBS_CSV=$(array-csv ${WEBS[@]}) BALS_CSV=$(array-csv ${BALS[@]}) Home directory copy commands These commands are generated now but executed later after site-move for moving customer's home directory contents. Copy these to the OP ticket to be run after the site-move is done while true; do SRC=$(ah-server list site:${SITE} -w typeINded,fs,fsdb,fsdbmesh,staging | head -1) DST_FS_CLUSTER_ID=$(ah-server list ${WEBS_CSV} --no-name -c fs_cluster_id | head -1) DST=$(ah-server list % -w typeINded,fs,fsdb,fsdbmesh,staging fs_cluster_id=${DST_FS_CLUSTER_ID} | head -1) SITEGROUP=$(ah-site list ${SITE} --no-name -c sitegroup) SITEGROUP_UID=$(ah-sitegroup list ${SITEGROUP} --no-name -c unix_uid) echo \"{code:title= Move $SITE home directory content from $SRC to $DST}\" echo \"fssh ${DST} 'sudo mkdir -m755 /mnt/gfs/home'\" echo \"sv-rsyncfile -o avPu ${SRC}:/mnt/gfs/home/${SITEGROUP}/ ${WEBS[0]}:/mnt/gfs/home/${SITEGROUP}/\" echo \"fssh ${DST} 'sudo chown -Rh ${SITEGROUP_UID}:${SITEGROUP_UID} /mnt/gfs/home/${SITEGROUP}'\" echo \"{code}\" echo echo 'COPY THE ABOVE OUTPUT TO JIRA TICKET AND EXECUTE THEM LATER AFTER THE SITE MOVE AS LAST STEP' break done Site Move Start the workflow to move the site. Omit any parameters which are not being changed (i.e. if the site is keeping its current balancers). Add a pause if desired. ah-site move ${SITE} --webs ${WEBS[@]} --bals ${BALS[@]} --db ${DB} --force Once the workflow is completed, if the old webs or deds have EIPs, move them to the new webs/deds. ah-server help migrate-eip Usage: ah-server migrate-eip --destination-server-name=DESTINATION_SERVER_NAME --source-server-name=SOURCE_SERVER_NAME # Note. Classic Elastic IPs need to be allocated 24 hours before moving them which is a hard AWS restriction. If the site has an ELB, work with support and the customer to delete it and create a new one. You may want to use the self-service ssl docs . If the site is in a Site Factory realm, follow the steps to create an ELB for Site Factory . Deprovision the existing one. As a last step, move the contents of the customer's home directory using the commands we generated above before the site move and copied to JIRA ticket. Note: We will also need to move the customer's RA site into the dedicated VPC, if it exists. Since there is no shared RA hardware in a dedicated VPC, you should use the customer's non-prod hardware as the destination for the RA site. Verification Verify there are no alerts for any of the hardware or sites affected by the site move. All tasks and/or workflows should be done. Also check that the web rotation status looks like you expect. site-check ${SITE} site-getwebrotationstatus ${SITE} site-checkwebs ${SITE} If no more sites remain on the source server(s) then verify if they can be deprovisioned and file a TSR ticket to deprovision the instances in seven days. Use the FIPS runbook to check that all of the servers have FIPS enabled. IPv6 Support All ELB back-end instances must have IPv6 addresses. You can verify this with the following: ELB_URL= host dualstack.${ELB_URL} | grep IPv6 If there are no IPv6 addresses in the host output, you can enable IPv6 with the following command: ELB_NAME= # the short name of the elb aws elb modify-load-balancer-attributes --load-balancer-name ${ELB_NAME} --load-balancer-attributes '{\"AdditionalAttributes\":[{\"Key\":\"elb.vpcipv6policy.enabled\",\"Value\":\"true\"}] }' TLSv1.2 Support The customer's balancers must use an SSL security policy with only TLSv1.2 enabled. This is the Acquia standard today, but you can enforce it. To do so, use the following commands: BALS= ah-server edit $BALS --config nginx.conf:ssl_security_policy=\"TLS-1-2-Ext-2018-06\" You can verify with: fpdsh -l $BALS -c \"sudo grep -i tls /etc/nginx/nginx.conf\" Network Boundaries All of the FedRAMP customers will have access to a new feature called \u201cShield Access Control\u201d. To enable it, follow the VPC Network Boundaries runbook to provision a VPC network boundary for their dedicated VPC. Site Factory post-steps If Site Factory: Create a DG ticket in JIRA and link to the site move ticket. The site move ticket is not done until the DG ticket is done. The ACSF engineering team will perform a cleanup as needed on the new hardware. There are typically some caches that need refreshing on the factory, and some files are not brought over during the regular process. Recovery If the workflow ever reaches error_pause , then you must determine what went wrong during the site move. There are two major points which the task can fail: migrating data from /vol/ebs1 , or migrating data from /mnt/gfs . Check the task status and the step at which it paused to determine which part of the site move failed. Databases: follow the procedure for ssh-ing between servers , and restore the data on the destination DB's. File System: Follow the ssh-between-servers runbook to sync the remaining files. Make sure to run the rsync on screen session. An example is below. WARNING: Always use a trailing slash with rsync paths!! sv-screen screen_name rsync -avPe 'ssh -i /root/.ssh/path_of_key\u2019 /mnt/gfs/${SITE}/ ${DST_FS_SERVER}:/mnt/gfs/${SITE}/ fssh ${DST_FS_SERVER} \"sudo chown -Rh ${SITEGROUP_UID}:${SITEGROUP_UID} /mnt/gfs/${SITE}\" If you do not have a clear path forward to recover the workflow and complete it, DO NOT abort the workflow . Instead, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership","title":"Moving a FedRAMP Site with Acquia Cloud Shield"},{"location":"standard_maintenance/moving_a_fedramp_site_with_acquia_shield/#moving-a-fedramp-site-with-acquia-cloud-shield","text":"This procedure guides you through moving a site from one stack of servers to another.","title":"Moving a FedRAMP Site with Acquia Cloud Shield"},{"location":"standard_maintenance/moving_a_fedramp_site_with_acquia_shield/#requirements","text":"In order for FedRAMP customer sites to meet all of the latest requirements, the following things are all necessary: The site must be in a dedicated VPC for customers with Acquia Cloud Shield. All instances must be 4-series hardware. All servers must have FIPS mode enabled. Note: while webs, bals, and fs-only servers can have FIPS mode enabled during a relaunch, database servers cannot. A site move is mandatory to move onto new database servers that are launched with FIPS mode from the very start. Check if the hardware is already FIPS enabled with this runbook . If the customer has an ELB, the ELB's back-end instances must have IPv6 addresses. See the Verification section to check this. If the customer does not have an ELB, one must be added. The customer must have dedicated balancers. Balancers must be configured to use TLSv1.2 only. See the Verification section to check this. Shield Access Control needs to be enabled. See the Verification section to check this under \u201cNetwork Boundaries\u201d.","title":"Requirements"},{"location":"standard_maintenance/moving_a_fedramp_site_with_acquia_shield/#vpc","text":"FedRAMP customers must be in a dedicated VPC. The customer should fill out the VPC questionnaire to provide you with the information that you need to provision their dedicated VPC. Follow the VPC provision instructions .","title":"VPC"},{"location":"standard_maintenance/moving_a_fedramp_site_with_acquia_shield/#site-factory-site-layout","text":"Site Factory site moves, such as in the enterprise-g1 realm, have some noteworthy differences from site moves in ACE: Site Factory sites are comprised of several sitegroups which cannot be moved independently of one another ELBs in Site Factory have extra requirements Create a DG ticket after the site move is completed. Since it is required to move all sites in a Site Factory, it is helpful to understand the sitegroup/sites on a typical site factory: https://ops.acquia.com/doc/index.php/Procedures/Provision_%26_Deprovision/Provisioning_Gardens . esl ${CUSTOMERNAME}% Each Site Factory has three sitegroups, ${CUSTOMERNAME} , ${CUSTOMERNAME}sf , and ${CUSTOMERNAME}theme . These sitegroups are often on separate stacks, so spend time tracking down all of the hardware. Within those sitegroups you will see sitenames such as ${CUSTOMERNAME}01live , ${CUSTOMERNAME}01update , ${CUSTOMERNAME}01theme , etc. Note some older site factories may add an underscore, i.e. ${CUSTOMERNAME}_sf . Identify all sitegroups, sites, and hardware before beginning the site move.","title":"Site Factory site layout"},{"location":"standard_maintenance/moving_a_fedramp_site_with_acquia_shield/#provisioning-new-hardware","text":"In order to be FIPS compliant, all servers must be on series 4 hardware. If you are not provided with an existing list of ami types for the new hardware, find equivalent series 4 ami's: https://ec2instances.info/?filter=c4|m4 . Follow the FIPS server provisioning runbook to provision FIPS-mode servers to move the site to.","title":"Provisioning New Hardware"},{"location":"standard_maintenance/moving_a_fedramp_site_with_acquia_shield/#preparation","text":"The following prep work should be completed before the site move is executed: Verify that the site and destination servers are in the same region. If the regions differ, then balancers and VCS repos must move to the new region as well. SRC_SITE= DST_FS_SERVER= DST_DB_SERVER= SRC_SRV=$(ah-server list site:${SRC_SITE} -w type!=svn| tail -1) ah-server list ${SRC_SRV},${DST_FS_SERVER} -c ec2_region --no-name | paste -s \\ | awk '$1 != $2 { exit 1; }' && echo \"Regions match\" || echo \"WARNING: Regions do not match\" Verify that the destination server has enough disk space to accommodate the new site. This is a hard stop point if this check does not pass. site-movevolusage ${SRC_SITE} ${DST_FS_SERVER} ${DST_DB_SERVER} Additionally, if the destination hardware does not exist yet, run the above as follows (with destination sizes): site-movevolusage ${SRC_SITE} ${DST_FS_SIZE} [e.g. 10G or 10240M] ${DST_DB_SIZE} [e.g. 10G or 10240M] If the site is moving to servers in a different region and it has an ELB then verify that the key and cert are on the gluster volume at SITE= SITE_ENV= SITEGROUP=$(ah-site list ${SITE} --no-name -c sitegroup) /home/${SITEGROUP}/${SITE_ENV}/ssl If they are not, assign the ticket to the reporter, set to Waiting for Feedback, and ask that the files be provided at that path. EIPs cannot move between regions, so the customer needs to whitelist any new webnode EIPs before the site move can go forward.","title":"Preparation"},{"location":"standard_maintenance/moving_a_fedramp_site_with_acquia_shield/#procedure","text":"Use the site move workflow to move the site to the new hardware. There is now a pre-sync step to minimize downtime.","title":"Procedure"},{"location":"standard_maintenance/moving_a_fedramp_site_with_acquia_shield/#important-note","text":"Do not abort workflows! If you are unable to resolve a problem with a workflow, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership","title":"Important Note"},{"location":"standard_maintenance/moving_a_fedramp_site_with_acquia_shield/#syncing-data-prior-to-downtime","text":"The site move workflow can be used in such a way that the majority of a site's data can be rsynced onto the new hardware before the site is actually transferred. This \"pre-rsync\" does not require downtime and can shorten the total required downtime for switching hardware. To do this, simply pause the workflow at the step update_site_location_within_the_hosting_api . --pause-at-step=update_site_location_within_the_hosting_api The step which executes the pre-rsync is called pre_migrate_site_files .","title":"Syncing Data Prior to Downtime"},{"location":"standard_maintenance/moving_a_fedramp_site_with_acquia_shield/#variables","text":"Set variables for the SITE to be moved, the lowest-numbered destination DB server, space-separated lists of destination WEBS and BALS , and the OP ticket. SITE= DB= WEBS=() BALS=() OP= WEBS_CSV=$(array-csv ${WEBS[@]}) BALS_CSV=$(array-csv ${BALS[@]})","title":"Variables"},{"location":"standard_maintenance/moving_a_fedramp_site_with_acquia_shield/#home-directory-copy-commands","text":"These commands are generated now but executed later after site-move for moving customer's home directory contents. Copy these to the OP ticket to be run after the site-move is done while true; do SRC=$(ah-server list site:${SITE} -w typeINded,fs,fsdb,fsdbmesh,staging | head -1) DST_FS_CLUSTER_ID=$(ah-server list ${WEBS_CSV} --no-name -c fs_cluster_id | head -1) DST=$(ah-server list % -w typeINded,fs,fsdb,fsdbmesh,staging fs_cluster_id=${DST_FS_CLUSTER_ID} | head -1) SITEGROUP=$(ah-site list ${SITE} --no-name -c sitegroup) SITEGROUP_UID=$(ah-sitegroup list ${SITEGROUP} --no-name -c unix_uid) echo \"{code:title= Move $SITE home directory content from $SRC to $DST}\" echo \"fssh ${DST} 'sudo mkdir -m755 /mnt/gfs/home'\" echo \"sv-rsyncfile -o avPu ${SRC}:/mnt/gfs/home/${SITEGROUP}/ ${WEBS[0]}:/mnt/gfs/home/${SITEGROUP}/\" echo \"fssh ${DST} 'sudo chown -Rh ${SITEGROUP_UID}:${SITEGROUP_UID} /mnt/gfs/home/${SITEGROUP}'\" echo \"{code}\" echo echo 'COPY THE ABOVE OUTPUT TO JIRA TICKET AND EXECUTE THEM LATER AFTER THE SITE MOVE AS LAST STEP' break done","title":"Home directory copy commands"},{"location":"standard_maintenance/moving_a_fedramp_site_with_acquia_shield/#site-move","text":"Start the workflow to move the site. Omit any parameters which are not being changed (i.e. if the site is keeping its current balancers). Add a pause if desired. ah-site move ${SITE} --webs ${WEBS[@]} --bals ${BALS[@]} --db ${DB} --force Once the workflow is completed, if the old webs or deds have EIPs, move them to the new webs/deds. ah-server help migrate-eip Usage: ah-server migrate-eip --destination-server-name=DESTINATION_SERVER_NAME --source-server-name=SOURCE_SERVER_NAME # Note. Classic Elastic IPs need to be allocated 24 hours before moving them which is a hard AWS restriction. If the site has an ELB, work with support and the customer to delete it and create a new one. You may want to use the self-service ssl docs . If the site is in a Site Factory realm, follow the steps to create an ELB for Site Factory . Deprovision the existing one. As a last step, move the contents of the customer's home directory using the commands we generated above before the site move and copied to JIRA ticket. Note: We will also need to move the customer's RA site into the dedicated VPC, if it exists. Since there is no shared RA hardware in a dedicated VPC, you should use the customer's non-prod hardware as the destination for the RA site.","title":"Site Move"},{"location":"standard_maintenance/moving_a_fedramp_site_with_acquia_shield/#verification","text":"Verify there are no alerts for any of the hardware or sites affected by the site move. All tasks and/or workflows should be done. Also check that the web rotation status looks like you expect. site-check ${SITE} site-getwebrotationstatus ${SITE} site-checkwebs ${SITE} If no more sites remain on the source server(s) then verify if they can be deprovisioned and file a TSR ticket to deprovision the instances in seven days. Use the FIPS runbook to check that all of the servers have FIPS enabled.","title":"Verification"},{"location":"standard_maintenance/moving_a_fedramp_site_with_acquia_shield/#ipv6-support","text":"All ELB back-end instances must have IPv6 addresses. You can verify this with the following: ELB_URL= host dualstack.${ELB_URL} | grep IPv6 If there are no IPv6 addresses in the host output, you can enable IPv6 with the following command: ELB_NAME= # the short name of the elb aws elb modify-load-balancer-attributes --load-balancer-name ${ELB_NAME} --load-balancer-attributes '{\"AdditionalAttributes\":[{\"Key\":\"elb.vpcipv6policy.enabled\",\"Value\":\"true\"}] }'","title":"IPv6 Support"},{"location":"standard_maintenance/moving_a_fedramp_site_with_acquia_shield/#tlsv12-support","text":"The customer's balancers must use an SSL security policy with only TLSv1.2 enabled. This is the Acquia standard today, but you can enforce it. To do so, use the following commands: BALS= ah-server edit $BALS --config nginx.conf:ssl_security_policy=\"TLS-1-2-Ext-2018-06\" You can verify with: fpdsh -l $BALS -c \"sudo grep -i tls /etc/nginx/nginx.conf\"","title":"TLSv1.2 Support"},{"location":"standard_maintenance/moving_a_fedramp_site_with_acquia_shield/#network-boundaries","text":"All of the FedRAMP customers will have access to a new feature called \u201cShield Access Control\u201d. To enable it, follow the VPC Network Boundaries runbook to provision a VPC network boundary for their dedicated VPC.","title":"Network Boundaries"},{"location":"standard_maintenance/moving_a_fedramp_site_with_acquia_shield/#site-factory-post-steps","text":"If Site Factory: Create a DG ticket in JIRA and link to the site move ticket. The site move ticket is not done until the DG ticket is done. The ACSF engineering team will perform a cleanup as needed on the new hardware. There are typically some caches that need refreshing on the factory, and some files are not brought over during the regular process.","title":"Site Factory post-steps"},{"location":"standard_maintenance/moving_a_fedramp_site_with_acquia_shield/#recovery","text":"If the workflow ever reaches error_pause , then you must determine what went wrong during the site move. There are two major points which the task can fail: migrating data from /vol/ebs1 , or migrating data from /mnt/gfs . Check the task status and the step at which it paused to determine which part of the site move failed. Databases: follow the procedure for ssh-ing between servers , and restore the data on the destination DB's. File System: Follow the ssh-between-servers runbook to sync the remaining files. Make sure to run the rsync on screen session. An example is below. WARNING: Always use a trailing slash with rsync paths!! sv-screen screen_name rsync -avPe 'ssh -i /root/.ssh/path_of_key\u2019 /mnt/gfs/${SITE}/ ${DST_FS_SERVER}:/mnt/gfs/${SITE}/ fssh ${DST_FS_SERVER} \"sudo chown -Rh ${SITEGROUP_UID}:${SITEGROUP_UID} /mnt/gfs/${SITE}\" If you do not have a clear path forward to recover the workflow and complete it, DO NOT abort the workflow . Instead, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership","title":"Recovery"},{"location":"standard_maintenance/moving_a_fedramp_site_without_acquia_shield/","text":"Moving a FedRAMP Site without Acquia Cloud Shield This procedure guides you through moving a site from one stack of servers to another. Requirements In order for FedRAMP customer sites to meet all of the latest requirements, the following things are all necessary: The site must be in a shared FedRAMP VPC. All instances must be 4-series hardware. All servers must have FIPS mode enabled. Note: while webs, bals, and fs-only servers can have FIPS mode enabled during a relaunch, database servers cannot. A site move is mandatory to move onto new database servers that are launched with FIPS mode from the very start. Check if the hardware is already FIPS enabled with this runbook . If the customer has an ELB, the ELB's back-end instances must have IPv6 addresses. See the Verification section to check this. If the customer does not have an ELB, one must be added. The customer must have dedicated balancers. Balancers must be configured to use TLSv1.2 only. See the Verification section to check this. Shield Access Control needs to be enabled. See the Verification section to check this under \u201cNetwork Boundaries\u201d. VPC FedRAMP customers must be in a shared FedRAMP VPC, unless they have Acquia Cloud Shield . Site Factory site layout Site Factory site moves, such as in the enterprise-g1 realm, have some noteworthy differences from site moves in ACE: Site Factory sites are comprised of several sitegroups which cannot be moved independently of one another. ELBs in Site Factory have extra requirements Create a DG ticket after the site move is completed. Since it is required to move all sites in a Site Factory, it is helpful to understand the sitegroup/sites on a typical site factory: https://ops.acquia.com/doc/index.php/Procedures/Provision_%26_Deprovision/Provisioning_Gardens . esl ${CUSTOMERNAME}% Each Site Factory has three sitegroups, ${CUSTOMERNAME} , ${CUSTOMERNAME}sf , and ${CUSTOMERNAME}theme . These sitegroups are often on separate stacks, so spend time tracking down all of the hardware. Within those sitegroups you will see sitenames such as ${CUSTOMERNAME}01live , ${CUSTOMERNAME}01update , ${CUSTOMERNAME}01theme , etc. Note some older site factories may add an underscore, i.e. ${CUSTOMERNAME}_sf . Identify all sitegroups, sites, and hardware before beginning the site move. Provisioning New Hardware In order to be FIPS compliant, all servers must be on series 4 hardware. If you are not provided with an existing list of ami types for the new hardware, find equivalent series 4 ami's: https://ec2instances.info/?filter=c4|m4 . Follow the FIPS server provisioning runbook to provision FIPS-mode servers to move the site to. Preparation The following prep work should be completed before the site move is executed: Verify that the site and destination servers are in the same region. If the regions differ, then balancers and VCS repos must move to the new region as well. SRC_SITE= DST_FS_SERVER= DST_DB_SERVER= SRC_SRV=$(ah-server list site:${SRC_SITE} -w type!=svn| tail -1) ah-server list ${SRC_SRV},${DST_FS_SERVER} -c ec2_region --no-name | paste -s \\ | awk '$1 != $2 { exit 1; }' && echo \"Regions match\" || echo \"WARNING: Regions do not match\" Verify that the destination server has enough disk space to accommodate the new site. This is a hard stop point if this check does not pass. site-movevolusage ${SRC_SITE} ${DST_FS_SERVER} ${DST_DB_SERVER} Additionally, if the destination hardware does not exist yet, run the above as follows (with destination sizes): site-movevolusage ${SRC_SITE} ${DST_FS_SIZE} [e.g. 10G or 10240M] ${DST_DB_SIZE} [e.g. 10G or 10240M] If the site is moving to servers in a different region and it has an ELB then verify that the key and cert are on the gluster volume at /mnt/gfs/${SITE}/ssl . If they are not, assign the ticket to the reporter, set to Waiting for Feedback, and ask that the files be provided at that path. EIPs cannot move between regions, so the customer needs to whitelist any new webnode EIPs before the site move can go forward. Procedure Use the site move workflow to move the site to the new hardware. There is now a pre-sync step to minimize downtime. Important Note Do not abort workflows! If you are unable to resolve a problem with a workflow, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership Syncing Data Prior to Downtime The site move workflow can be used in such a way that the majority of a site's data can be rsynced onto the new hardware before the site is actually transferred. This \"pre-rsync\" does not require downtime and can shorten the total required downtime for switching hardware. To do this, simply pause the workflow at the step update_site_location_within_the_hosting_api . --pause-at-step=update_site_location_within_the_hosting_api The step which executes the pre-rsync is called pre_migrate_site_files . Varriables Set variables for the SITE to be moved, the lowest-numbered destination DB server, space-separated lists of destination WEBS and BALS , and the OP ticket. SITE= DB= WEBS=() BALS=() OP= WEBS_CSV=$(array-csv ${WEBS[@]}) BALS_CSV=$(array-csv ${BALS[@]}) Migrating EIP of dedicated bals - PLEASE READ THIS CAREFULLY This section only applies for Non-ELB sites which have dedicated bals: bals which host only have one prod site or more than one prod site for the same customer and all of these sites will be moved to new bal pair in FedRamp VPC. If the maintenance is for sites having ELB/s or sites that live on shared bals or for sites for which old bals will still have some sites that are not going to be moved to the new hardware in FedRamp VPC after this maintenance, there should already be a separate plan in place that you should have knowledge of before proceeding with the maintenance. This runbook does not yet have instructions for these cases so figure the DNS update part out before proceeding for the cases just mentioned. The following variables should be set before the site move is done. OLD_BALS=<CSV Current Bals for the Site/s> OLD_BAL_EIP=$(ah-server list $OLD_BALS -w eip_id!=nil --no-name -c external_ip) OLD_BAL_WITH_EIP=$(ah-server list $OLD_BALS -w eip_id!=nil) NEW_BALS=${BALS_CSV} NEW_BAL_EIP=$(ah-server list $NEW_BALS -w eip_id!=nil --no-name -c external_ip) NEW_BAL_WITH_EIP=$(ah-server list $NEW_BALS -w eip_id!=nil) Copy the output of the following into the OP ticket and use these for variable re-population if you have to do that later after site-move. echo -e \" {code:title=variables for bal eip switch over} OLD_BAL_EIP=${OLD_BAL_EIP} OLD_BAL_WITH_EIP=${OLD_BAL_WITH_EIP} NEW_BAL_EIP=${NEW_BAL_EIP} NEW_BAL_WITH_EIP=${NEW_BAL_WITH_EIP} {code}\" The commands below will be used later for the EIP switch-over. Copy the output of the following to the OP ticket echo -e \" {code:title=EIP switch over commands - run them after them site moves} ah-elastic-ip remove $OLD_BAL_EIP $OLD_BAL_WITH_EIP ah-elastic-ip remove $NEW_BAL_EIP $NEW_BAL_WITH_EIP ah-elastic-ip add $OLD_BAL_EIP $NEW_BAL_WITH_EIP ah-elastic-ip add $NEW_BAL_EIP $OLD_BAL_WITH_EIP {code}\" Home directory copy commands These commands are generated now but executed later after site-move for moving customer's home directory contents. Copy these to the OP ticket to be run after the site-move is done while true; do SRC=$(ah-server list site:${SITE} -w typeINded,fs,fsdb,fsdbmesh,staging | head -1) DST_FS_CLUSTER_ID=$(ah-server list ${WEBS_CSV} --no-name -c fs_cluster_id | head -1) DST=$(ah-server list % -w typeINded,fs,fsdb,fsdbmesh,staging fs_cluster_id=${DST_FS_CLUSTER_ID} | head -1) SITEGROUP=$(ah-site list ${SITE} --no-name -c sitegroup) SITEGROUP_UID=$(ah-sitegroup list ${SITEGROUP} --no-name -c unix_uid) echo \"{code:title= Move $SITE home directory content from $SRC to $DST}\" echo \"fssh ${DST} 'sudo mkdir -m755 /mnt/gfs/home'\" echo \"sv-rsyncfile -o avPu ${SRC}:/mnt/gfs/home/${SITEGROUP}/ ${WEBS[0]}:/mnt/gfs/home/${SITEGROUP}/\" echo \"fssh ${DST} 'sudo chown -Rh ${SITEGROUP_UID}:${SITEGROUP_UID} /mnt/gfs/home/${SITEGROUP}'\" echo \"{code}\" echo echo 'COPY THE ABOVE OUTPUT TO JIRA TICKET AND EXECUTE THEM LATER AFTER THE SITE MOVE AS LAST STEP' break done Site Move Start the workflow to move the site. Omit any parameters which are not being changed (i.e. if the site is keeping its current balancers). Add a pause if desired. ah-site move ${SITE} --webs ${WEBS[@]} --bals ${BALS[@]} --db ${DB} --force Once the workflow is completed, if the old webs or deds have EIPs, move them to the new webs/deds. ah-server help migrate-eip Usage: ah-server migrate-eip --destination-server-name=DESTINATION_SERVER_NAME --source-server-name=SOURCE_SERVER_NAME # Note. Classic Elastic IPs need to be allocated 24 hours before moving them which is a hard AWS restriction. Switch over the bal EIPs using commands that we got from the Migrating EIP of dedicated bals section above. As a last step, move the contents of the customer's home directory using the commands we generated above before the site move and copied to JIRA ticket. Note: We will also need to move the customer's RA site into the dedicated VPC, if it exists. Since there is no shared RA hardware in a dedicated VPC, you should use the customer's non-prod hardware as the destination for the RA site. Create an ELB FedRAMP customers require an ELB. Follow the ELB provision runbook to provision one (For creating self-signed certificate ELB, you can just use the command at the end of this paragraph). If they have an existing ELB, grab the cert and key from it before deprovisioning it. If they do not have an existing ELB, just use a self signed certificate for now. To create ELB with self-signed certificate, you can use the following command site-create-elb-with-self-signed-cert $SITE If the site is in a Site Factory realm, follow the steps to create an ELB for Site Factory . Deprovision the existing one. After creating the ELB, you must configure the ELB to support TLSv1.2 only. Until this is supported by the platform, it must be done manually in the AWS UI. Login to the AWS console. Select EC2 under services. Select Load Balancers on the left menu. Search for the customer's ELB in the search bar. For example \"mc-12555\". Click the Listeners tab at the bottom, then Cipher . Click \"Custom Security Policy\", and then ensure that only Protocol-TLSv1.2 is selected on the right under SSL Protocols. Save. Verification Verify there are no alerts for any of the hardware or sites affected by the site move. All tasks and/or workflows should be done. Also check that the web rotation status looks like you expect. site-check ${SITE} site-getwebrotationstatus ${SITE} site-checkwebs ${SITE} If no more sites remain on the source server(s) then verify if they can be deprovisioned and file a TSR ticket to deprovision the instances in seven days. Use the FIPS runbook to check that all of the servers have FIPS enabled. IPv6 Support All ELB back-end instances must have IPv6 addresses. You can verify this with the following: ELB_URL= host dualstack.${ELB_URL} | grep IPv6 If there are no IPv6 addresses in the host output, you can enable IPv6 with the following command: ELB_NAME= # the short name of the elb aws elb modify-load-balancer-attributes --load-balancer-name ${ELB_NAME} --load-balancer-attributes '{\"AdditionalAttributes\":[{\"Key\":\"elb.vpcipv6policy.enabled\",\"Value\":\"true\"}] }' TLSv1.2 Support The customer's balancers must have TLSv1.2 enabled. This is the Acquia standard today, but you can enforce it. To do so, use the following commands: BALS= ah-server edit $BALS --config nginx.conf:ssl_security_policy=\"TLS-1-2-Ext-2018-06\" You can verify with: fpdsh -l $BALS -c \"sudo grep -i tls /etc/nginx/nginx.conf\" Site Factory post-steps If Site Factory: Create a DG ticket in JIRA and link to the site move ticket. The site move ticket is not done until the DG ticket is done. The ACSF engineering team will perform a cleanup as needed on the new hardware. There are typically some caches that need refreshing on the factory, and some files are not brought over during the regular process. Recovery If the workflow ever reaches error_pause , then you must determine what went wrong during the site move. There are two major points which the task can fail: migrating data from /vol/ebs1 , or migrating data from /mnt/gfs . Check the task status and the step at which it paused to determine which part of the site move failed. Databases: follow the procedure for ssh-ing between servers , and restore the data on the destination DB's. File System: Follow the ssh-between-servers runbook to sync the remaining files. Make sure to run the rsync on screen session. An example is below. WARNING: Always use a trailing slash with rsync paths!! sv-screen screen_name rsync -avPe 'ssh -i /root/.ssh/path_of_key\u2019 /mnt/gfs/${SITE}/ ${DST_FS_SERVER}:/mnt/gfs/${SITE}/ fssh ${DST_FS_SERVER} \"sudo chown -Rh ${SITEGROUP_UID}:${SITEGROUP_UID} /mnt/gfs/${SITE}\" If you do not have a clear path forward to recover the workflow and complete it, DO NOT abort the workflow . Instead, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership","title":"Moving a FedRAMP Site without Acquia Cloud Shield"},{"location":"standard_maintenance/moving_a_fedramp_site_without_acquia_shield/#moving-a-fedramp-site-without-acquia-cloud-shield","text":"This procedure guides you through moving a site from one stack of servers to another.","title":"Moving a FedRAMP Site without Acquia Cloud Shield"},{"location":"standard_maintenance/moving_a_fedramp_site_without_acquia_shield/#requirements","text":"In order for FedRAMP customer sites to meet all of the latest requirements, the following things are all necessary: The site must be in a shared FedRAMP VPC. All instances must be 4-series hardware. All servers must have FIPS mode enabled. Note: while webs, bals, and fs-only servers can have FIPS mode enabled during a relaunch, database servers cannot. A site move is mandatory to move onto new database servers that are launched with FIPS mode from the very start. Check if the hardware is already FIPS enabled with this runbook . If the customer has an ELB, the ELB's back-end instances must have IPv6 addresses. See the Verification section to check this. If the customer does not have an ELB, one must be added. The customer must have dedicated balancers. Balancers must be configured to use TLSv1.2 only. See the Verification section to check this. Shield Access Control needs to be enabled. See the Verification section to check this under \u201cNetwork Boundaries\u201d.","title":"Requirements"},{"location":"standard_maintenance/moving_a_fedramp_site_without_acquia_shield/#vpc","text":"FedRAMP customers must be in a shared FedRAMP VPC, unless they have Acquia Cloud Shield .","title":"VPC"},{"location":"standard_maintenance/moving_a_fedramp_site_without_acquia_shield/#site-factory-site-layout","text":"Site Factory site moves, such as in the enterprise-g1 realm, have some noteworthy differences from site moves in ACE: Site Factory sites are comprised of several sitegroups which cannot be moved independently of one another. ELBs in Site Factory have extra requirements Create a DG ticket after the site move is completed. Since it is required to move all sites in a Site Factory, it is helpful to understand the sitegroup/sites on a typical site factory: https://ops.acquia.com/doc/index.php/Procedures/Provision_%26_Deprovision/Provisioning_Gardens . esl ${CUSTOMERNAME}% Each Site Factory has three sitegroups, ${CUSTOMERNAME} , ${CUSTOMERNAME}sf , and ${CUSTOMERNAME}theme . These sitegroups are often on separate stacks, so spend time tracking down all of the hardware. Within those sitegroups you will see sitenames such as ${CUSTOMERNAME}01live , ${CUSTOMERNAME}01update , ${CUSTOMERNAME}01theme , etc. Note some older site factories may add an underscore, i.e. ${CUSTOMERNAME}_sf . Identify all sitegroups, sites, and hardware before beginning the site move.","title":"Site Factory site layout"},{"location":"standard_maintenance/moving_a_fedramp_site_without_acquia_shield/#provisioning-new-hardware","text":"In order to be FIPS compliant, all servers must be on series 4 hardware. If you are not provided with an existing list of ami types for the new hardware, find equivalent series 4 ami's: https://ec2instances.info/?filter=c4|m4 . Follow the FIPS server provisioning runbook to provision FIPS-mode servers to move the site to.","title":"Provisioning New Hardware"},{"location":"standard_maintenance/moving_a_fedramp_site_without_acquia_shield/#preparation","text":"The following prep work should be completed before the site move is executed: Verify that the site and destination servers are in the same region. If the regions differ, then balancers and VCS repos must move to the new region as well. SRC_SITE= DST_FS_SERVER= DST_DB_SERVER= SRC_SRV=$(ah-server list site:${SRC_SITE} -w type!=svn| tail -1) ah-server list ${SRC_SRV},${DST_FS_SERVER} -c ec2_region --no-name | paste -s \\ | awk '$1 != $2 { exit 1; }' && echo \"Regions match\" || echo \"WARNING: Regions do not match\" Verify that the destination server has enough disk space to accommodate the new site. This is a hard stop point if this check does not pass. site-movevolusage ${SRC_SITE} ${DST_FS_SERVER} ${DST_DB_SERVER} Additionally, if the destination hardware does not exist yet, run the above as follows (with destination sizes): site-movevolusage ${SRC_SITE} ${DST_FS_SIZE} [e.g. 10G or 10240M] ${DST_DB_SIZE} [e.g. 10G or 10240M] If the site is moving to servers in a different region and it has an ELB then verify that the key and cert are on the gluster volume at /mnt/gfs/${SITE}/ssl . If they are not, assign the ticket to the reporter, set to Waiting for Feedback, and ask that the files be provided at that path. EIPs cannot move between regions, so the customer needs to whitelist any new webnode EIPs before the site move can go forward.","title":"Preparation"},{"location":"standard_maintenance/moving_a_fedramp_site_without_acquia_shield/#procedure","text":"Use the site move workflow to move the site to the new hardware. There is now a pre-sync step to minimize downtime.","title":"Procedure"},{"location":"standard_maintenance/moving_a_fedramp_site_without_acquia_shield/#important-note","text":"Do not abort workflows! If you are unable to resolve a problem with a workflow, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership","title":"Important Note"},{"location":"standard_maintenance/moving_a_fedramp_site_without_acquia_shield/#syncing-data-prior-to-downtime","text":"The site move workflow can be used in such a way that the majority of a site's data can be rsynced onto the new hardware before the site is actually transferred. This \"pre-rsync\" does not require downtime and can shorten the total required downtime for switching hardware. To do this, simply pause the workflow at the step update_site_location_within_the_hosting_api . --pause-at-step=update_site_location_within_the_hosting_api The step which executes the pre-rsync is called pre_migrate_site_files .","title":"Syncing Data Prior to Downtime"},{"location":"standard_maintenance/moving_a_fedramp_site_without_acquia_shield/#varriables","text":"Set variables for the SITE to be moved, the lowest-numbered destination DB server, space-separated lists of destination WEBS and BALS , and the OP ticket. SITE= DB= WEBS=() BALS=() OP= WEBS_CSV=$(array-csv ${WEBS[@]}) BALS_CSV=$(array-csv ${BALS[@]})","title":"Varriables"},{"location":"standard_maintenance/moving_a_fedramp_site_without_acquia_shield/#migrating-eip-of-dedicated-bals-please-read-this-carefully","text":"This section only applies for Non-ELB sites which have dedicated bals: bals which host only have one prod site or more than one prod site for the same customer and all of these sites will be moved to new bal pair in FedRamp VPC. If the maintenance is for sites having ELB/s or sites that live on shared bals or for sites for which old bals will still have some sites that are not going to be moved to the new hardware in FedRamp VPC after this maintenance, there should already be a separate plan in place that you should have knowledge of before proceeding with the maintenance. This runbook does not yet have instructions for these cases so figure the DNS update part out before proceeding for the cases just mentioned. The following variables should be set before the site move is done. OLD_BALS=<CSV Current Bals for the Site/s> OLD_BAL_EIP=$(ah-server list $OLD_BALS -w eip_id!=nil --no-name -c external_ip) OLD_BAL_WITH_EIP=$(ah-server list $OLD_BALS -w eip_id!=nil) NEW_BALS=${BALS_CSV} NEW_BAL_EIP=$(ah-server list $NEW_BALS -w eip_id!=nil --no-name -c external_ip) NEW_BAL_WITH_EIP=$(ah-server list $NEW_BALS -w eip_id!=nil) Copy the output of the following into the OP ticket and use these for variable re-population if you have to do that later after site-move. echo -e \" {code:title=variables for bal eip switch over} OLD_BAL_EIP=${OLD_BAL_EIP} OLD_BAL_WITH_EIP=${OLD_BAL_WITH_EIP} NEW_BAL_EIP=${NEW_BAL_EIP} NEW_BAL_WITH_EIP=${NEW_BAL_WITH_EIP} {code}\" The commands below will be used later for the EIP switch-over. Copy the output of the following to the OP ticket echo -e \" {code:title=EIP switch over commands - run them after them site moves} ah-elastic-ip remove $OLD_BAL_EIP $OLD_BAL_WITH_EIP ah-elastic-ip remove $NEW_BAL_EIP $NEW_BAL_WITH_EIP ah-elastic-ip add $OLD_BAL_EIP $NEW_BAL_WITH_EIP ah-elastic-ip add $NEW_BAL_EIP $OLD_BAL_WITH_EIP {code}\"","title":"Migrating EIP of dedicated bals - PLEASE READ THIS CAREFULLY"},{"location":"standard_maintenance/moving_a_fedramp_site_without_acquia_shield/#home-directory-copy-commands","text":"These commands are generated now but executed later after site-move for moving customer's home directory contents. Copy these to the OP ticket to be run after the site-move is done while true; do SRC=$(ah-server list site:${SITE} -w typeINded,fs,fsdb,fsdbmesh,staging | head -1) DST_FS_CLUSTER_ID=$(ah-server list ${WEBS_CSV} --no-name -c fs_cluster_id | head -1) DST=$(ah-server list % -w typeINded,fs,fsdb,fsdbmesh,staging fs_cluster_id=${DST_FS_CLUSTER_ID} | head -1) SITEGROUP=$(ah-site list ${SITE} --no-name -c sitegroup) SITEGROUP_UID=$(ah-sitegroup list ${SITEGROUP} --no-name -c unix_uid) echo \"{code:title= Move $SITE home directory content from $SRC to $DST}\" echo \"fssh ${DST} 'sudo mkdir -m755 /mnt/gfs/home'\" echo \"sv-rsyncfile -o avPu ${SRC}:/mnt/gfs/home/${SITEGROUP}/ ${WEBS[0]}:/mnt/gfs/home/${SITEGROUP}/\" echo \"fssh ${DST} 'sudo chown -Rh ${SITEGROUP_UID}:${SITEGROUP_UID} /mnt/gfs/home/${SITEGROUP}'\" echo \"{code}\" echo echo 'COPY THE ABOVE OUTPUT TO JIRA TICKET AND EXECUTE THEM LATER AFTER THE SITE MOVE AS LAST STEP' break done","title":"Home directory copy commands"},{"location":"standard_maintenance/moving_a_fedramp_site_without_acquia_shield/#site-move","text":"Start the workflow to move the site. Omit any parameters which are not being changed (i.e. if the site is keeping its current balancers). Add a pause if desired. ah-site move ${SITE} --webs ${WEBS[@]} --bals ${BALS[@]} --db ${DB} --force Once the workflow is completed, if the old webs or deds have EIPs, move them to the new webs/deds. ah-server help migrate-eip Usage: ah-server migrate-eip --destination-server-name=DESTINATION_SERVER_NAME --source-server-name=SOURCE_SERVER_NAME # Note. Classic Elastic IPs need to be allocated 24 hours before moving them which is a hard AWS restriction. Switch over the bal EIPs using commands that we got from the Migrating EIP of dedicated bals section above. As a last step, move the contents of the customer's home directory using the commands we generated above before the site move and copied to JIRA ticket. Note: We will also need to move the customer's RA site into the dedicated VPC, if it exists. Since there is no shared RA hardware in a dedicated VPC, you should use the customer's non-prod hardware as the destination for the RA site.","title":"Site Move"},{"location":"standard_maintenance/moving_a_fedramp_site_without_acquia_shield/#create-an-elb","text":"FedRAMP customers require an ELB. Follow the ELB provision runbook to provision one (For creating self-signed certificate ELB, you can just use the command at the end of this paragraph). If they have an existing ELB, grab the cert and key from it before deprovisioning it. If they do not have an existing ELB, just use a self signed certificate for now. To create ELB with self-signed certificate, you can use the following command site-create-elb-with-self-signed-cert $SITE If the site is in a Site Factory realm, follow the steps to create an ELB for Site Factory . Deprovision the existing one. After creating the ELB, you must configure the ELB to support TLSv1.2 only. Until this is supported by the platform, it must be done manually in the AWS UI. Login to the AWS console. Select EC2 under services. Select Load Balancers on the left menu. Search for the customer's ELB in the search bar. For example \"mc-12555\". Click the Listeners tab at the bottom, then Cipher . Click \"Custom Security Policy\", and then ensure that only Protocol-TLSv1.2 is selected on the right under SSL Protocols. Save.","title":"Create an ELB"},{"location":"standard_maintenance/moving_a_fedramp_site_without_acquia_shield/#verification","text":"Verify there are no alerts for any of the hardware or sites affected by the site move. All tasks and/or workflows should be done. Also check that the web rotation status looks like you expect. site-check ${SITE} site-getwebrotationstatus ${SITE} site-checkwebs ${SITE} If no more sites remain on the source server(s) then verify if they can be deprovisioned and file a TSR ticket to deprovision the instances in seven days. Use the FIPS runbook to check that all of the servers have FIPS enabled.","title":"Verification"},{"location":"standard_maintenance/moving_a_fedramp_site_without_acquia_shield/#ipv6-support","text":"All ELB back-end instances must have IPv6 addresses. You can verify this with the following: ELB_URL= host dualstack.${ELB_URL} | grep IPv6 If there are no IPv6 addresses in the host output, you can enable IPv6 with the following command: ELB_NAME= # the short name of the elb aws elb modify-load-balancer-attributes --load-balancer-name ${ELB_NAME} --load-balancer-attributes '{\"AdditionalAttributes\":[{\"Key\":\"elb.vpcipv6policy.enabled\",\"Value\":\"true\"}] }'","title":"IPv6 Support"},{"location":"standard_maintenance/moving_a_fedramp_site_without_acquia_shield/#tlsv12-support","text":"The customer's balancers must have TLSv1.2 enabled. This is the Acquia standard today, but you can enforce it. To do so, use the following commands: BALS= ah-server edit $BALS --config nginx.conf:ssl_security_policy=\"TLS-1-2-Ext-2018-06\" You can verify with: fpdsh -l $BALS -c \"sudo grep -i tls /etc/nginx/nginx.conf\"","title":"TLSv1.2 Support"},{"location":"standard_maintenance/moving_a_fedramp_site_without_acquia_shield/#site-factory-post-steps","text":"If Site Factory: Create a DG ticket in JIRA and link to the site move ticket. The site move ticket is not done until the DG ticket is done. The ACSF engineering team will perform a cleanup as needed on the new hardware. There are typically some caches that need refreshing on the factory, and some files are not brought over during the regular process.","title":"Site Factory post-steps"},{"location":"standard_maintenance/moving_a_fedramp_site_without_acquia_shield/#recovery","text":"If the workflow ever reaches error_pause , then you must determine what went wrong during the site move. There are two major points which the task can fail: migrating data from /vol/ebs1 , or migrating data from /mnt/gfs . Check the task status and the step at which it paused to determine which part of the site move failed. Databases: follow the procedure for ssh-ing between servers , and restore the data on the destination DB's. File System: Follow the ssh-between-servers runbook to sync the remaining files. Make sure to run the rsync on screen session. An example is below. WARNING: Always use a trailing slash with rsync paths!! sv-screen screen_name rsync -avPe 'ssh -i /root/.ssh/path_of_key\u2019 /mnt/gfs/${SITE}/ ${DST_FS_SERVER}:/mnt/gfs/${SITE}/ fssh ${DST_FS_SERVER} \"sudo chown -Rh ${SITEGROUP_UID}:${SITEGROUP_UID} /mnt/gfs/${SITE}\" If you do not have a clear path forward to recover the workflow and complete it, DO NOT abort the workflow . Instead, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership","title":"Recovery"},{"location":"standard_maintenance/relaunch_bastion/","text":"Relaunching WARNING!! Only relaunch a bastion if you have bastion sudo. Post launch steps require root access. Escalate early with any bastion issues. If a bastion goes down due to unforeseen consequences then the normal crit procedure should be followed. The impact of a bastion outage only affects Acquia employees, but is still a serious issue. If maintenance needs to be performed that requires a relaunch then advanced notice must be sent to: ops-team@acuqia.com tech@acquia.com Rebooting If you are rebooting a bastion, you only need to verify that all the necessary repositories and crons listed below are still there post reboot. You still need to perform the Unison Syncs step at the bottom. Pre-Flight Check Ensure you are a sudoer. sudo /bin/true if [[ $? -ne 0 ]]; then echo \"ERROR: You are not a sudoer. ABORT.\" fi Ahrabot runs crons on bastion-22. If you are relaunching bastion-22, gather a copy of ahrabot's cron jobs and save it somewhere safe crontab -u ahrabot -l Ahopsbot runs crons on bastion-21. If you are relaunching bastion-21, gather a copy of ahopsbot's cron jobs and save it somewhere safe crontab -u ahopsbot -l Ensure you have the file $SECURE/ec2/bastion_fields_deployment_key . If you don't, grab it from the Ops KPX Archive.Its entry is named 'Bastion Git Deployment Key' in Ops KPX archive.Once you have it, ensure it has the correct permissions and chmod. if [[ -e ${SECURE}/ec2/bastion_fields_deployment_key ]]; then sudo chown ${USER}:${USER} ${SECURE}/ec2/bastion_fields_deployment_key; sudo chmod 0400 ${SECURE}/ec2/bastion_fields_deployment_key; else echo \"ERROR: You need the bastion_fields_deployment_key from Ops KPX. ABORT.\" fi Set a variable for the bastion you are relaunching. BASTION= if [[ \"$BASTION\" == \"bastion-21\" ]]; then BASTION_EIP=107.20.238.9 elif [[ \"$BASTION\" == \"bastion-22\" ]]; then BASTION_EIP=46.137.113.132 elif [[ \"$BASTION\" == \"bastion-133\" ]]; then BASTION_EIP=54.252.90.180 fi Add your public key to /root/.ssh/authorized_keys2 on the bastion you are relaunching incase you get locked out post relaunch and need to troubleshoot. Make sure to test to see if you can ssh into the bastion as the root user. ssh root@bastion-$$$.network.hosting.acquia.com Suspending Rather than use the \"relaunch\" command directly, the best practice with bastions is to do a suspend followed by a launch. Because of the complexity of suspending a bastion, you should always suspend it with --debug . This will show you extra information that you'll need during launch, plus help with diagnosing issues. ah-server suspend $BASTION --SUSPEND-PRODUCTION-SERVERS --debug Launching Bastions are like other servers. They are part of fields in the .network realm, they have an encrypted EBS volume and they have an EIP. Because of the complexity of launching a bastion, you should always launch it with --debug . This will show you extra information that you'll need during launch, plus help with diagnosing issues. While relaunch is going on, open a terminal and log into the launching bastion using steps following the launch step ah-server launch $BASTION --debug Closely follow the launcher output and look for lines similar to: [2016-04-11 00:46:36] DEBUG: Entering Aq::Hosting::ServerLauncher::Steps::EnableRootLogin [2016-04-11 00:46:36] DEBUG: Memory used before: 131660 kB [2016-04-11 00:46:41] DEBUG: Socket open failed to 54.252.90.180:22. [0/16] [2016-04-11 00:46:47] DEBUG: Socket open failed to 54.252.90.180:22. [0/16] [2016-04-11 00:47:02] DEBUG: Successfully opened a socket to 54.252.90.180:22. [1/16] [2016-04-11 00:47:03] DEBUG: Successfully opened a socket to 54.252.90.180:22. [2/16] ... [2016-04-11 00:47:21] DEBUG: Successfully opened a socket to 54.252.90.180:22. [16/16] [2016-04-11 00:47:21] DEBUG: Connection to 54.252.90.180:22 succeeded 16 in a row. [2016-04-11 00:47:21] DEBUG: ssh ubuntu@54.252.90.180 sudo cp /home/ubuntu/.ssh/authorized_keys /root/.ssh/ [2016-04-11 00:47:25] DEBUG: ssh ubuntu@54.252.90.180 sudo chown root:root /root/.ssh/authorized_keys [2016-04-11 00:47:25] DEBUG: ssh ubuntu@54.252.90.180 rm -f /home/ubuntu/.ssh/authorized_keys [2016-04-11 00:47:26] DEBUG: Memory used after: 133028 kB [2016-04-11 00:47:26] DEBUG: Exiting Aq::Hosting::ServerLauncher::Steps::EnableRootLogin Once this step is complete, you can log in to the server as root on port 22 on a new terminal while true; do ssh root@${BASTION_EIP} -p 22 -i $SECURE/ec2/acquia-internal/ssh/default; done We log in nice and early to ensure we have access should there be an issue. You must be logged in before puppet starts to avoid being locked out until launch completion. Post Relaunch Setup Everything in this section needs to be automated away. If you can make an improvement, please do so and update this doc. The following sections must be actioned in order and be executed as you, not root . Open a session as your user with the following command (not with sudo su - $USER): su $USER Fields Because the initial fields checkout will need to build and install a plethora of gems, this process can take longer than one minute to complete. This means that subsequent minutely runs will collide and overwrite each other - this is a known issue. To get around this issue you must comment out the fields cron entry for a couple of minutes until gems have been properly installed. sudo crontab -u ahgit -e Run the fields-checkout script by hand to ensure that all current branches were successfully cloned and installed sudo su -c \"/usr/local/sbin/fields-checkout\" ahgit If this fails, check that ahgit has a valid ssh key: sudo su - ahgit ssh -T git@github.com If you do not get a greeting for the user ac-ops, get the ac-ops ssh key from keepass. Ops-misc Ops-misc is checked out to /mnt/apps/ops-misc/ by /usr/local/sbin/ops-misc-checkout If it has not been checked out yet, you can do it as follows sudo su - ahgit /usr/local/sbin/ops-misc-checkout logout Storing ops-misc in /mnt is new behavior, so we must put in a backwards compatible link. sudo ln -s /mnt/apps/ops-misc/master /usr/local/ops Initialise Ops' working directories. # USERS_CSV should be populated by running 'ops-getahopsusers' as your own user USERS_CSV=$(/mnt/apps/ops-misc/master/bin/ops-getahopsusers) sudo /mnt/apps/ops-misc/master/bin/ops-mkdir ${USERS_CSV} Test by sourcing the symlinked ops-misc source /usr/local/ops/lib/bash/profile.d/ops-env.sh Ops-API (Otto) sudo ln -s /mnt/apps/ops-api/master /usr/local/ops-api pushd /mnt/apps/ops-api/master sudo gem2.6 install typhoeus --version=1.0.2 sudo gem2.6 install popen4 --version=0.1.2 sudo gem2.6 install thor --version=1.0.1 popd The cron job for the ahgit user will run bundle2.6 install every minute so no need to run it manually. Ahrabot If this is bastion-22, retrieve your copy of ahrabot's crontab and put it in the new ahrabot's crontab: crontab -u ahrabot -e Ahopsbot If this is bastion-21, retrieve your copy of ahopsbot's crontab and put it in the new ahopsbot's crontab: crontab -u ahopsbot -e AHT Support is working to get this formalised in puppet - see CL-10912 Test. If there are errors with this process please contact Support Engineering . sudo su -c /vol/ebs1/ahsupport/bin/cron.sh ahsupportbot Install the cron job: sudo crontab -u ahsupportbot -e Add: # OP-28131 */5 * * * * /vol/ebs1/ahsupport/bin/cron.sh ops-incidents Install some packages before doing the ops-incidents setup sudo apt-cache policy libncurses5-dev sudo apt-get install libncurses5-dev ops-incidents after-relaunch installation Restore the crontab Restore the commented out fields-checkout line in crontab sudo crontab -u ahgit -e Unison Sync To ensure that /vol/ebs1/keys is synced post reboot/relaunch, you will need to use Unison to sync the bastions. All Unison commands need to be run on bastion-21. Ensure that you are logged in as root in bastion-21 with $HOME set to /root . You will need sudo as root rights to run this sudo -i root If you are rebooting or relaunching bastion-21, run following commands as root : unison bastion-133 -prefer /vol/ebs1/ unison bastion-22 -prefer /vol/ebs1/ Before syncing bastion-22 or bastion-133, ensure that the public key for bastion-21 exists in /root/.ssh/authorized_keys2. If it is missing, copy the authorized_keys2 file from the other bastion (not bastion-21 as it does not have its own public key there). If bastion-21 is relaunched, then a new key needs to be generated and added to the other bastions. If you are rebooting or relaunching bastion-22, run following as root : unison bastion-22 -prefer /vol/ebs1/ If you are rebooting or relaunching bastion-133, run following as root : unison bastion-133 -prefer /vol/ebs1/ If the sync gets stuck on /vol/ebs1/ahsupport/logs/aht-* or another file that is currently being modified, wait a minute and try again. Try syncing a few times before escalating to Cloud. If you run into any other issues with Unison syncing, please escalate to the Cloud Platform team. Cleanup Be sure to remove your public key from /root/.ssh/authorized_keys2 if you added it before relaunching. Notification Gather the new rsa key hash ssh-keygen -f /etc/ssh/ssh_host_rsa_key -l Update the Bastion Host Guide on Confluence with the new key hash. Email tech@acquia.com to notify people of the relaunch and change in SSH key.","title":"Relaunching"},{"location":"standard_maintenance/relaunch_bastion/#relaunching","text":"WARNING!! Only relaunch a bastion if you have bastion sudo. Post launch steps require root access. Escalate early with any bastion issues. If a bastion goes down due to unforeseen consequences then the normal crit procedure should be followed. The impact of a bastion outage only affects Acquia employees, but is still a serious issue. If maintenance needs to be performed that requires a relaunch then advanced notice must be sent to: ops-team@acuqia.com tech@acquia.com","title":"Relaunching"},{"location":"standard_maintenance/relaunch_bastion/#rebooting","text":"If you are rebooting a bastion, you only need to verify that all the necessary repositories and crons listed below are still there post reboot. You still need to perform the Unison Syncs step at the bottom.","title":"Rebooting"},{"location":"standard_maintenance/relaunch_bastion/#pre-flight-check","text":"Ensure you are a sudoer. sudo /bin/true if [[ $? -ne 0 ]]; then echo \"ERROR: You are not a sudoer. ABORT.\" fi Ahrabot runs crons on bastion-22. If you are relaunching bastion-22, gather a copy of ahrabot's cron jobs and save it somewhere safe crontab -u ahrabot -l Ahopsbot runs crons on bastion-21. If you are relaunching bastion-21, gather a copy of ahopsbot's cron jobs and save it somewhere safe crontab -u ahopsbot -l Ensure you have the file $SECURE/ec2/bastion_fields_deployment_key . If you don't, grab it from the Ops KPX Archive.Its entry is named 'Bastion Git Deployment Key' in Ops KPX archive.Once you have it, ensure it has the correct permissions and chmod. if [[ -e ${SECURE}/ec2/bastion_fields_deployment_key ]]; then sudo chown ${USER}:${USER} ${SECURE}/ec2/bastion_fields_deployment_key; sudo chmod 0400 ${SECURE}/ec2/bastion_fields_deployment_key; else echo \"ERROR: You need the bastion_fields_deployment_key from Ops KPX. ABORT.\" fi Set a variable for the bastion you are relaunching. BASTION= if [[ \"$BASTION\" == \"bastion-21\" ]]; then BASTION_EIP=107.20.238.9 elif [[ \"$BASTION\" == \"bastion-22\" ]]; then BASTION_EIP=46.137.113.132 elif [[ \"$BASTION\" == \"bastion-133\" ]]; then BASTION_EIP=54.252.90.180 fi Add your public key to /root/.ssh/authorized_keys2 on the bastion you are relaunching incase you get locked out post relaunch and need to troubleshoot. Make sure to test to see if you can ssh into the bastion as the root user. ssh root@bastion-$$$.network.hosting.acquia.com","title":"Pre-Flight Check"},{"location":"standard_maintenance/relaunch_bastion/#suspending","text":"Rather than use the \"relaunch\" command directly, the best practice with bastions is to do a suspend followed by a launch. Because of the complexity of suspending a bastion, you should always suspend it with --debug . This will show you extra information that you'll need during launch, plus help with diagnosing issues. ah-server suspend $BASTION --SUSPEND-PRODUCTION-SERVERS --debug","title":"Suspending"},{"location":"standard_maintenance/relaunch_bastion/#launching","text":"Bastions are like other servers. They are part of fields in the .network realm, they have an encrypted EBS volume and they have an EIP. Because of the complexity of launching a bastion, you should always launch it with --debug . This will show you extra information that you'll need during launch, plus help with diagnosing issues. While relaunch is going on, open a terminal and log into the launching bastion using steps following the launch step ah-server launch $BASTION --debug Closely follow the launcher output and look for lines similar to: [2016-04-11 00:46:36] DEBUG: Entering Aq::Hosting::ServerLauncher::Steps::EnableRootLogin [2016-04-11 00:46:36] DEBUG: Memory used before: 131660 kB [2016-04-11 00:46:41] DEBUG: Socket open failed to 54.252.90.180:22. [0/16] [2016-04-11 00:46:47] DEBUG: Socket open failed to 54.252.90.180:22. [0/16] [2016-04-11 00:47:02] DEBUG: Successfully opened a socket to 54.252.90.180:22. [1/16] [2016-04-11 00:47:03] DEBUG: Successfully opened a socket to 54.252.90.180:22. [2/16] ... [2016-04-11 00:47:21] DEBUG: Successfully opened a socket to 54.252.90.180:22. [16/16] [2016-04-11 00:47:21] DEBUG: Connection to 54.252.90.180:22 succeeded 16 in a row. [2016-04-11 00:47:21] DEBUG: ssh ubuntu@54.252.90.180 sudo cp /home/ubuntu/.ssh/authorized_keys /root/.ssh/ [2016-04-11 00:47:25] DEBUG: ssh ubuntu@54.252.90.180 sudo chown root:root /root/.ssh/authorized_keys [2016-04-11 00:47:25] DEBUG: ssh ubuntu@54.252.90.180 rm -f /home/ubuntu/.ssh/authorized_keys [2016-04-11 00:47:26] DEBUG: Memory used after: 133028 kB [2016-04-11 00:47:26] DEBUG: Exiting Aq::Hosting::ServerLauncher::Steps::EnableRootLogin Once this step is complete, you can log in to the server as root on port 22 on a new terminal while true; do ssh root@${BASTION_EIP} -p 22 -i $SECURE/ec2/acquia-internal/ssh/default; done We log in nice and early to ensure we have access should there be an issue. You must be logged in before puppet starts to avoid being locked out until launch completion.","title":"Launching"},{"location":"standard_maintenance/relaunch_bastion/#post-relaunch-setup","text":"Everything in this section needs to be automated away. If you can make an improvement, please do so and update this doc. The following sections must be actioned in order and be executed as you, not root . Open a session as your user with the following command (not with sudo su - $USER): su $USER","title":"Post Relaunch Setup"},{"location":"standard_maintenance/relaunch_bastion/#fields","text":"Because the initial fields checkout will need to build and install a plethora of gems, this process can take longer than one minute to complete. This means that subsequent minutely runs will collide and overwrite each other - this is a known issue. To get around this issue you must comment out the fields cron entry for a couple of minutes until gems have been properly installed. sudo crontab -u ahgit -e Run the fields-checkout script by hand to ensure that all current branches were successfully cloned and installed sudo su -c \"/usr/local/sbin/fields-checkout\" ahgit If this fails, check that ahgit has a valid ssh key: sudo su - ahgit ssh -T git@github.com If you do not get a greeting for the user ac-ops, get the ac-ops ssh key from keepass.","title":"Fields"},{"location":"standard_maintenance/relaunch_bastion/#ops-misc","text":"Ops-misc is checked out to /mnt/apps/ops-misc/ by /usr/local/sbin/ops-misc-checkout If it has not been checked out yet, you can do it as follows sudo su - ahgit /usr/local/sbin/ops-misc-checkout logout Storing ops-misc in /mnt is new behavior, so we must put in a backwards compatible link. sudo ln -s /mnt/apps/ops-misc/master /usr/local/ops Initialise Ops' working directories. # USERS_CSV should be populated by running 'ops-getahopsusers' as your own user USERS_CSV=$(/mnt/apps/ops-misc/master/bin/ops-getahopsusers) sudo /mnt/apps/ops-misc/master/bin/ops-mkdir ${USERS_CSV} Test by sourcing the symlinked ops-misc source /usr/local/ops/lib/bash/profile.d/ops-env.sh","title":"Ops-misc"},{"location":"standard_maintenance/relaunch_bastion/#ops-api-otto","text":"sudo ln -s /mnt/apps/ops-api/master /usr/local/ops-api pushd /mnt/apps/ops-api/master sudo gem2.6 install typhoeus --version=1.0.2 sudo gem2.6 install popen4 --version=0.1.2 sudo gem2.6 install thor --version=1.0.1 popd The cron job for the ahgit user will run bundle2.6 install every minute so no need to run it manually.","title":"Ops-API (Otto)"},{"location":"standard_maintenance/relaunch_bastion/#ahrabot","text":"If this is bastion-22, retrieve your copy of ahrabot's crontab and put it in the new ahrabot's crontab: crontab -u ahrabot -e","title":"Ahrabot"},{"location":"standard_maintenance/relaunch_bastion/#ahopsbot","text":"If this is bastion-21, retrieve your copy of ahopsbot's crontab and put it in the new ahopsbot's crontab: crontab -u ahopsbot -e","title":"Ahopsbot"},{"location":"standard_maintenance/relaunch_bastion/#aht","text":"Support is working to get this formalised in puppet - see CL-10912 Test. If there are errors with this process please contact Support Engineering . sudo su -c /vol/ebs1/ahsupport/bin/cron.sh ahsupportbot Install the cron job: sudo crontab -u ahsupportbot -e Add: # OP-28131 */5 * * * * /vol/ebs1/ahsupport/bin/cron.sh","title":"AHT"},{"location":"standard_maintenance/relaunch_bastion/#ops-incidents","text":"Install some packages before doing the ops-incidents setup sudo apt-cache policy libncurses5-dev sudo apt-get install libncurses5-dev ops-incidents after-relaunch installation","title":"ops-incidents"},{"location":"standard_maintenance/relaunch_bastion/#restore-the-crontab","text":"Restore the commented out fields-checkout line in crontab sudo crontab -u ahgit -e","title":"Restore the crontab"},{"location":"standard_maintenance/relaunch_bastion/#unison-sync","text":"To ensure that /vol/ebs1/keys is synced post reboot/relaunch, you will need to use Unison to sync the bastions. All Unison commands need to be run on bastion-21. Ensure that you are logged in as root in bastion-21 with $HOME set to /root . You will need sudo as root rights to run this sudo -i root If you are rebooting or relaunching bastion-21, run following commands as root : unison bastion-133 -prefer /vol/ebs1/ unison bastion-22 -prefer /vol/ebs1/ Before syncing bastion-22 or bastion-133, ensure that the public key for bastion-21 exists in /root/.ssh/authorized_keys2. If it is missing, copy the authorized_keys2 file from the other bastion (not bastion-21 as it does not have its own public key there). If bastion-21 is relaunched, then a new key needs to be generated and added to the other bastions. If you are rebooting or relaunching bastion-22, run following as root : unison bastion-22 -prefer /vol/ebs1/ If you are rebooting or relaunching bastion-133, run following as root : unison bastion-133 -prefer /vol/ebs1/ If the sync gets stuck on /vol/ebs1/ahsupport/logs/aht-* or another file that is currently being modified, wait a minute and try again. Try syncing a few times before escalating to Cloud. If you run into any other issues with Unison syncing, please escalate to the Cloud Platform team.","title":"Unison Sync"},{"location":"standard_maintenance/relaunch_bastion/#cleanup","text":"Be sure to remove your public key from /root/.ssh/authorized_keys2 if you added it before relaunching.","title":"Cleanup"},{"location":"standard_maintenance/relaunch_bastion/#notification","text":"Gather the new rsa key hash ssh-keygen -f /etc/ssh/ssh_host_rsa_key -l Update the Bastion Host Guide on Confluence with the new key hash. Email tech@acquia.com to notify people of the relaunch and change in SSH key.","title":"Notification"},{"location":"standard_maintenance/replace_volumes/","text":"Replacing a Bad Volume Manually In certain cases, a volume may become corrupted, and you may have to manually replace it. If this is due to a failed workflow, then make sure you clean up as necessary. DO NOT ABORT WORKFLOWS. Escalate the issue to cloud via Ops Portal . Then you can clean up the rest (detach the temp volume, delete it, clean up the volume id in fields, etc). Diagnosing a Bad Volume If you suspect that a server has a bad volume, check available resources to diagnose the problem: Search /var/log/kern.log and /var/log/syslog for relevant errors (i.e. I/O errors, data corruption, unmountable/unreadable/unwriteable volumes or blocks, XFS errors, etc.) Run dmesg on the server From the bastion, check the AWS volume status ( REGION and EBS_ID can be found with sv-vollist ): aws ec2 describe-volume-status --region ${REGION} --volume-id ${EBS_ID} If the above steps show nothing relevant, try checking for bad blocks: badblocks -v -s ${DEVICE_PATH} Read the section on xfs_repair if you suspect there is something wrong with the integrity of the filesystem. It is more likely that there is something wrong with the file system. If the underlying volume is corrupted you will almost certainly need to restore it on a new volume from a good backup. Repairing the File System If there is something wrong with the underlying file system, running xfs_repair will attempt to identify problems and repair them. Remove the -n option from the command to let xfs_repair attempt repairs. DEVICE_PATH= umount ${DEVICE_PATH} xfs_repair -n ${DEVICE_PATH} Once xfs_repair has completed successfully, mount the volume (use puppet or do it manually) and check for problems again. If xfs_repair throws an error, or did not resolve the problem, then you will need to restore the volume from a backup. Replacing the Volume with a Snapshot If the bad volume is the backup volume, the easiest resolution is to replace it with a blank volume . After the workflow is done, you should manually run the backup script to populate the volume: fssh ${SERVER} 'sudo /usr/local/sbin/fields-backup-fileserver.php' Otherwise, for FS or DB volumes, we can replace the corrupt volume with one of its snapshots. Avoid this if at all possible because the customer will suffer downtime and will almost certainly lose data. This option only works if the server with the corrupted volume can be suspended and has snapshots available to restore from. Run sv-vollist and save the output to Jira. Record some variables: SERVER= sv-vollist ${SERVER} REGION= EC2_VOL_ID= FIELDS_VOL_ID= Find the last known good snapshot: ah-backup list-runs ${SERVER} -s SNAPSHOT_ID= Suspend the server if it isn't already. If the server is part of a HA setup, you should follow any failover steps as appropriate to prevent customer downtime. ah-server suspend ${SERVER} Edit the server's volume in fields to use the snapshot volume instead. ah-volume edit ${FIELDS_VOL_ID} -s ebs_id=${SNAPSHOT_ID} Launch the server sv-taskrelaunch server -m1 ${SERVER} Once the server is launched, verify that the volume is mounted and working appropriately. Since we just restored a volume with old customer data, we need to take steps to restore data replication if the volume was part of an HA pair. If the bad volume was a... ...DB volume, perform a dump restore from the other database server . ...FS volume, force a Gluster heal by stat'ing all the files: site-fsremount on:${SERVER} fssh ${SERVER} \"sudo ls -lahR /mnt/gfs\" > /dev/null Check the gluster logs for errors. If something is wrong, you may need to manually rsync data from the good brick . Verify that the snapshot volume works and no data is missing before cleaning up. If further investigation is needed, create a ticket in Jira. If everything looks ok, clean up the old volume. aws ec2 detach-volume --region ${REGION} --volume-id ${EC2_VOL_ID} aws ec2 delete-volume --region ${REGION} --volume-id ${EC2_VOL_ID}","title":"Replacing a Bad Volume Manually"},{"location":"standard_maintenance/replace_volumes/#replacing-a-bad-volume-manually","text":"In certain cases, a volume may become corrupted, and you may have to manually replace it. If this is due to a failed workflow, then make sure you clean up as necessary. DO NOT ABORT WORKFLOWS. Escalate the issue to cloud via Ops Portal . Then you can clean up the rest (detach the temp volume, delete it, clean up the volume id in fields, etc).","title":"Replacing a Bad Volume Manually"},{"location":"standard_maintenance/replace_volumes/#diagnosing-a-bad-volume","text":"If you suspect that a server has a bad volume, check available resources to diagnose the problem: Search /var/log/kern.log and /var/log/syslog for relevant errors (i.e. I/O errors, data corruption, unmountable/unreadable/unwriteable volumes or blocks, XFS errors, etc.) Run dmesg on the server From the bastion, check the AWS volume status ( REGION and EBS_ID can be found with sv-vollist ): aws ec2 describe-volume-status --region ${REGION} --volume-id ${EBS_ID} If the above steps show nothing relevant, try checking for bad blocks: badblocks -v -s ${DEVICE_PATH} Read the section on xfs_repair if you suspect there is something wrong with the integrity of the filesystem. It is more likely that there is something wrong with the file system. If the underlying volume is corrupted you will almost certainly need to restore it on a new volume from a good backup.","title":"Diagnosing a Bad Volume"},{"location":"standard_maintenance/replace_volumes/#repairing-the-file-system","text":"If there is something wrong with the underlying file system, running xfs_repair will attempt to identify problems and repair them. Remove the -n option from the command to let xfs_repair attempt repairs. DEVICE_PATH= umount ${DEVICE_PATH} xfs_repair -n ${DEVICE_PATH} Once xfs_repair has completed successfully, mount the volume (use puppet or do it manually) and check for problems again. If xfs_repair throws an error, or did not resolve the problem, then you will need to restore the volume from a backup.","title":"Repairing the File System"},{"location":"standard_maintenance/replace_volumes/#replacing-the-volume-with-a-snapshot","text":"If the bad volume is the backup volume, the easiest resolution is to replace it with a blank volume . After the workflow is done, you should manually run the backup script to populate the volume: fssh ${SERVER} 'sudo /usr/local/sbin/fields-backup-fileserver.php' Otherwise, for FS or DB volumes, we can replace the corrupt volume with one of its snapshots. Avoid this if at all possible because the customer will suffer downtime and will almost certainly lose data. This option only works if the server with the corrupted volume can be suspended and has snapshots available to restore from. Run sv-vollist and save the output to Jira. Record some variables: SERVER= sv-vollist ${SERVER} REGION= EC2_VOL_ID= FIELDS_VOL_ID= Find the last known good snapshot: ah-backup list-runs ${SERVER} -s SNAPSHOT_ID= Suspend the server if it isn't already. If the server is part of a HA setup, you should follow any failover steps as appropriate to prevent customer downtime. ah-server suspend ${SERVER} Edit the server's volume in fields to use the snapshot volume instead. ah-volume edit ${FIELDS_VOL_ID} -s ebs_id=${SNAPSHOT_ID} Launch the server sv-taskrelaunch server -m1 ${SERVER} Once the server is launched, verify that the volume is mounted and working appropriately. Since we just restored a volume with old customer data, we need to take steps to restore data replication if the volume was part of an HA pair. If the bad volume was a... ...DB volume, perform a dump restore from the other database server . ...FS volume, force a Gluster heal by stat'ing all the files: site-fsremount on:${SERVER} fssh ${SERVER} \"sudo ls -lahR /mnt/gfs\" > /dev/null Check the gluster logs for errors. If something is wrong, you may need to manually rsync data from the good brick . Verify that the snapshot volume works and no data is missing before cleaning up. If further investigation is needed, create a ticket in Jira. If everything looks ok, clean up the old volume. aws ec2 detach-volume --region ${REGION} --volume-id ${EC2_VOL_ID} aws ec2 delete-volume --region ${REGION} --volume-id ${EC2_VOL_ID}","title":"Replacing the Volume with a Snapshot"},{"location":"standard_maintenance/resize_volumes/","text":"Resize volumes EBS volumes can be resized to any of the supported sizes , provided the data fits. The supported sizes are a business restriction, not a technical restriction. Volumes must be either magnetic or SSD except for backup volume. Backup volume type should be magnetic for ACE/ACP customers and SSD for ACSF (EG1/WMG/TREX). Below table lists the recommended storage type for volumes: | Volume | Storage type | |--------------|------------------------------------------------------------| | Database | SSD (gp3) | | Filesystem | SSD (gp3) | | Database | SSD (gp2) | | Filesystem | SSD (gp2) | | Backup | Magnetic (standard for ACE/ACP) . | | Backup | SSD (gp3 for ACSF) | Note While upsizing existing volumes, keep the same storage type as existing unless it is specified to change the storage type in the ticket. Note This runbook is also applicable for ACP volume resizes now. The sizes of ephemeral volumes ('/dev/xvda' and '/dev/xvdb') are tied to the ami_type and can not be changed. Only mntfs volumes can be resized directly, see Mntfs (xvbd) . For all other purpose EBS volumes (FS,DB), we create new EBS volumes, copy the data, and exchange the volumes. Creating the volumes and copying the data is done in two phases with a prep phase and a maintenance window phase. Copying the data is typically done with the XFS tools for Gluster bricks and rsync for MySQL volumes. Exchanging the volumes requires a maintenance window. During this window, services are stopped and an incremental copy is made before volumes are exchanged. Note : In fields, volume devices are referred to as '/dev/sda', etc, even if the devices are really '/dev/xvda' on the server itself. This is because of the device handler used by the kernel on the instance. sd = SCSI Disk driver and xvd = Xen Virtualisation Disk driver. man sd for some extra low level info. Note : SSD's are supported for database volumes but cost extra so existing volumes should be resized to the same type unless specifically requested and approved. Note : All magnetic (standard) volumes will have a size of less than 38 Gb or greater than 125 Gb. Most of them 125Gb. Note this is the size of the volume not the partition. Emergency upsize guidelines (ACE & ACSF only) Start emergency upsizing the volumes (DB/FS) if the volume filling rate has been high or reached 100% and customer/support isn't able to clear any data. Proceed with emergency upsize if customer has been non-responsive over 3 or more crits to clear the data. Proceed for an emergency conversion to gp3 if IOPs usage is very high and disk usage is less. If IOPs and usage both are high and creating DB replication lag then proceed with emergency upsize to gp2 or gp3. For ACP - we don't perform emergency upsize. File an SL ticket if customer is unresponsive over 3 crits or more and get confirmation for removing them from monitoring. File an AM ticket after upsize from the ops portal If the upsize is running over your shift, please include handoff notes mentioning all what has been done and what is left to make it easy for the next engineer to pick it up. We can refer this Flowchart to decide on whether to do an Emergency Upsize or some other step to deal with a Disk Partition Alert : Scope of Flowchart : Gluster and DB file system Volumes of ACE , ACSF and ACP Gluster Prep Dumps It is possible that doing multiple gluster dumps at once (rsync or xfsdump) will cause an outage. You can create and mount the new volumes in parallel, but unless you are very sure that there is enough CPU, memory, and i/o bandwidth available to do two gluster dumps at once, you should do one at a time. Preparatory steps To be completed before the maintenance window opens. If downsizing, make sure the space currently used is less than 95% of the new volume size. SERVER= SIZE= JIRA_TICKET= Create and attach the new volume Gather volume volume information and put it in the ticket. sv-vollist ${SERVER} Get the volume id The volume id is the number after id: in the output of sv-vollist. It does not start with vol-. VOLUME_ID= VOLUME_TYPE=(gp3 gp2 or standard) If you need to start at a specific time, calculate the UNIX_START_TIME variable: UNIX_START_TIME=$(date -d '2018/03/22 20:00 UTC' +\"%s\") add the following flag to your ah-volume resize command: --scheduled-time ${UNIX_START_TIME} If you want to resume a workflow task at a specific time, calculate UNIX_START_TIME as above, then schedule it to resume (you must do this after starting the workflow with ah-volume resize below): WORKFLOW_ID= ah-workflow schedule-resume ${WORKFLOW_ID} \\ --scheduled-time ${UNIX_START_TIME} WARNING: This is not safe for HA pairs since there is no mechanism in place to ensure clean failover. To Find/Check scheduled maintenance information and status, run scheduled_task=$(ah-workflow get ${WORKFLOW_ID} | grep -w \"scheduled_task_ids.0\"|cut -d: -f2) wf-scheduled or ah-scheduled-task get $scheduled_task To Cancel/Remove the scheduled task in case if your maintenance will be cancelled, Run ah-scheduled-task kill $scheduled_task Beware: Always check the last hrs update in your maintenance ticket for cancellation updates if any. Add a runbook entry. VOLUME=[mysql|gfs|backup] fssh $SERVER \"sudo ah-runbook \\ '${JIRA_TICKET} - ${USER} - ${VOLUME} to ${SIZE}'\" Adding encryption to volumes: Encryption is required add --set-encryption to the resize command. Encryption is only supported for the following ami_types Type Instance type sizes c4 c4.large c4.xlarge c4.2xlarge c4.4xlarge c4.8xlarge c4.16xlarge c5 c5.large c5.xlarge c5.2xlarge c5.4xlarge c5.9xlarge c5.18xlarge cr1 cr1.8xlarge d2 d2.xlarge d2.2xlarge d2.4xlarge d2.8xlarge g2 g2.2xlarge g2.8xlarge m4 m4.large m4.xlarge m4.2xlarge m4.4xlarge m4.10xlarge m4.16xlarge m5 m5.large m5.xlarge m5.2xlarge m5.4xlarge m5.12xlarge m5.24xlarge r4 r4.large r4.xlarge r4.2xlarge r4.4xlarge r4.8xlarge r4.16xlarge t2 t2.large List based on Aq Gem Instance Features aq/aws_helpers/ec2/instance_features.rb Copy data: rsync method Important Note Do not abort workflows! If you are unable to resolve a problem with a workflow, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership Note : Unless the customer wants their FS (gluster) volumes to be a 'standard' volume type, the gluster bricks must always be set to SSD i.e. 'gp3' or 'gp2'. Be sure to check the ticket description. Note : Please do not purge binlogs during DB volume upsize even if the site is down. Purging binlogs during a DB volume upsize might corrupt that DB upon finishing. All volumes must be encrypted by default now. Please ensure that instance type supports encrypted ebs volumes before starting the workflow. Disclaimer Before initiating a rsync workflow for db cluster, make sure to check if the following condition is met: New volume size > (Current_Disk_Size + Biggest_File_on_the_Current_Disk/particularly ibdata1 file) If the above condition doesn't met or if the size of a particular file like ibdata1 file is huge, then we should use 'xfsdump' method to upsize the volume. However if you face any issue with 'xfsdump' method then escalate the issue to DBA. NOTE: After resizing the volume on each server, make sure to remount Gluster server. This is a mandatory step and applicable to FS volumes only. Typically used for MySQL, but also works with Gluster bricks. ah-volume resize ${VOLUME_ID} --new-size ${SIZE} --method rsync \\ --pause-at-step disable_backups --set-encryption \\ --pause-description \"${JIRA_TICKET} - ${USER}\" \\ --send-notifications false Note : In order to receive workflow failure notifications --send-notications false flag can be avoided. If this is a scheduled workflow with no pause and add encryption, on one of supported instance types listed on the table above, use: NOTE: After resizing the volume on each server, make sure to remount Gluster server. This is a mandatory step and applicable to FS volumes only. ah-volume resize ${VOLUME_ID} --new-size ${SIZE} --method rsync \\ --set-encryption --scheduled-time ${UNIX_START_TIME} \\ --send-notifications false Ops can use below command for MySQL volumes resize only for DEDs/FSDBs/DBMASTERs PRIMARY_DB_SERVER= ah-db-cluster resize-storage $PRIMARY_DB_SERVER --new-size ${SIZE} --method rsync \\ --set-encryption --scheduled-time ${UNIX_START_TIME} \\ --send-notifications false Note : In order to receive workflow failure notifications --send-notications false flag can be avoided. Copy data: XFS dump-restore method Important Note Do not abort workflows! If you are unable to resolve a problem with a workflow, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership Note : Unless the customer wants their FS (gluster) volumes to be a 'standard' volume type, the gluster bricks must always be set to SSD i.e. 'gp3' or 'gp2'. Be sure to check the ticket description. This also works for MySQL volumes. For gluster xfsdumps: If this is the second server you are doing an xfsdump on, make sure the first one is finished, or there is more than enough I/O bandwidth to spare. Two gluster dumps at once can cause an outage. Note : Please do not purge binlogs during DB volume upsize even if the site is down. Purging binlogs during a DB volume upsize might corrupt that DB upon finishing. All volumes must be encrypted by default now. Please ensure that instance type supports encrypted ebs volumes before starting the workflow. For GlusterFS bricks set the type to gp3 : NOTE: After resizing the volume on each server, make sure to remount Gluster server. This is a mandatory step and applicable to FS volumes only. ah-volume resize ${VOLUME_ID} --new-size ${SIZE} --method xfsdump \\ --ebs-volume-type ${VOLUME_TYPE} \\ --set-encryption \\ --pause-at-step disable_backups \\ --pause-description \"${JIRA_TICKET} - ${USER}\" \\ --send-notifications false For other volumes: NOTE: After resizing the volume on each server, make sure to remount Gluster server. This is a mandatory step and applicable to FS volumes only. ah-volume resize ${VOLUME_ID} --new-size ${SIZE} --method xfsdump \\ --set-encryption \\ --pause-at-step disable_backups \\ --pause-description \"${JIRA_TICKET} - ${USER}\" \\ --send-notifications false Note : In order to receive workflow failure notifications --send-notications false flag can be avoided. Note : There is a bug due to which a workflow fails if the volume has been upsized previously using xfsdump. In that case, please remove xfsrestorehousekeepingdir and orphanage directories from /mnt/gfs before starting the workflow. Also, check if /mnt/brickXXXX has these directories and cleanup them if they exist from there too. No data copy: no_data_migration method Warning : this method will create empty volumes discarding any existing data . It is usefull for backup volumes where we don't need to wait for data copy. It should NEVER be used on gfs or mysql volumes! If this is a scheduled workflow with no pause and add encryption on supported instances use: ah-volume resize ${VOLUME_ID} --new-size ${SIZE} --method no_data_migration \\ --set-encryption --scheduled-time ${UNIX_START_TIME} \\ --send-notifications false Note : In order to receive workflow failure notifications --send-notications false flag can be avoided. Also keep in mind, backup volume type should be magnetic for ACE/ACP customers and SSD for ACSF (EG1/WMG/TREX). Gp2 to Gp3 conversion If IOPs usage is very high and disk usage is less for FS or DB volume or DB replication is very high due to high IOPs then procced with conversion from standard or gp2 to gp3 using a worklfow. ah-volume resize ${VOLUME_ID} --new-size ${SIZE} --method xfsdump \\ --ebs-volume-type ${VOLUME_TYPE} \\ --set-encryption \\ --send-notifications false Maintenance window steps These steps must be completed during the assigned maintenance window. Verify the prep work completed properly WORKFLOW_ID= ah-workflow get ${WORKFLOW_ID} The status field should be set to user_pause. If it's in an error state, debug the workflow ah-workflow get ${WORKFLOW_ID} --show-logs Verify the person actioning the previous steps left an ah-runbook entry. Create an entry if they forgot to. ah-runbook For HA clusters, follow the procedure to work on one server at a time in the section on volume specifics below. Resume the workflow to complete the resize ah-workflow resume ${WORKFLOW_ID} If the volume was Gluster Resize the backup volume to match. Volume and service specifics MySQL (xvdm) Backup (xvdn) Gluster (xvdo) Mntfs (xvdb) MySQL volumes (xvdm) In an HA cluster, upsize one server at a time. Check that replication is in sync and the primary (first) server is active. ah-db-cluster status ${SERVER} Lock replication to the primary. ah-db-cluster lock ${SERVER} When the secondary is resized and workflow has completed, check that replication is in sync. ah-db-cluster status ${SERVER} When it is, unlock and fail over. Otherwise, fix it, or escalate to a DBA. ah-db-cluster unlock ${SERVER} dns-update $CLUSTER $SECONDARY On the primary (but now inactive) server, resize the volume as with the secondary. After upsizing, check replication, unlock, and fail back as before. Backup (xvdn) This volume matches the Gluster brick in size on staging servers and the primary server in HA FS clusters. Note : The volume on the secondary FS server is always 1G in size. Note for encryption : If you have encrypted the FS volumes (gluster bricks), both the backup-ebs volumes will need encryption as well. Set variables. SIZE= SDN_VOLUME_ID= Check volume-type is magnetic, reported as standard. sv-vollist $server For ACE/ACP, if not magnetic, please specify new volume as magnetic simultaneous with the resize. ah-volume resize ${SDN_VOLUME_ID} --new-size ${SIZE} --method rsync --ebs-volume-type=standard --send-notifications false For ACSF (EG1/WMG/TREX), if not SSD, please specify new volume as gp3 simultaneous with the resize. ah-volume resize ${SDN_VOLUME_ID} --new-size ${SIZE} --method rsync --ebs-volume-type=gp3 --send-notifications false If already encryption is supported, resize to an empty backup volume after setting the appropriate EBS volume type. ah-volume resize ${SDN_VOLUME_ID} --new-size ${SIZE} --set-encryption \\ --method no_data_migration --send-notifications false Gluster (xvdo) After resizing the volume on each server, remount Gluster server. Make sure it properly remounts on every server. (Often, remounting twice will take care of this). The reason we remount gluster first is that during the time the gluster service has been offline the clients may have completely timed out retrying their connections; this starts up the retry loop so that when the firewall rule is removed they sanely reconnect. site-fsremount ${SITE} Mntfs (xvdb) Volumes mounted to /mnt/ on EBS-backed instances, so called mntfs volumes, can be upsized with the ah-volume upsize-mntfs subcommand by defining the server name and the target size in GiB: ah-volume upsize-mntfs --server-name=${SERVER_NAME} --target-size=${TARGET_SIZE} Note : In order to receive workflow failure notifications --send-notications false can be avoided. It triggers a workflow in the background that first increases the EBS volume size to the given target size via AWS API. Then it expands the xfs partition to the maximum size of the volume with xfs_growfs . The workflow operates on the fly without unmounting or detaching the volume. NO backup will be saved by the workflow. The filesystem remains readable and writable during the operation. The additional space becomes available after the worklow finishes. Note : The command works only on Current Generation intance types and on some of the Previous Generation instance types. For more detailed info check the AWS documentation Note : Amazon doesn't allow you to change the size of a volume within 6 hours more than once. So a consecutive call of upsize-mntfs will fail. In this case the workflow will be suspended, but it can be resumed after the resize limit period expired. Note : The subcommand can only increase volumes. It does not allow volume downsize. Livedev-enabled sites If the site has livedev enabled, audit the webs post-resize to make sure that livedev exists, has a docroot, and belongs to the correct user and group. SERVERS=($(ah-server list site:$SITE -w typeINded,staging,web)) for srv in ${SERVERS[@]}; do echo echo \"SERVER: $srv\" fssh $srv \"sudo ls -lah /mnt/gfs/${SITE}/livedev/\" 2>/dev/null done If livedev is in broken state on any of the webs, do another site-fsremount and check again. Remounting the filesystem should fix the problem, but if the filesystem is not successfully remounted, the customer may see staging task failures down the road. Troubleshooting Reset XFS dump-restore If for any reason you have to reset the process and start again, you only need to modify the destination: rm -Rf /mnt/${DEV}/{orphanage,xfsrestorehousekeepingdir} Gluster 3.4 ID If Gluster 3.4 complains it lost the ID, do the following to fix it. export BRICK=/mnt/brick12312/brick export FSCLUSTER=ded-sitename export VOL_ID=$(grep volume-id /var/lib/glusterd/vols/${FSCLUSTER}/info \\ | cut -d= -f2 \\ | sed 's/-//g') setfattr -n trusted.glusterfs.volume-id -v 0x${VOL_ID} ${BRICK} gluster volume start ${FSCLUSTER} ah-config-gluster Volume Cleanup This procedure is only to be used if you are cleaning up volumes from a failed workflow. Get the volume details and set variables: sv-vollist $SERVER DEVICE=[/dev/xvdx | /dev/xvdy | /dev/xvdz] EBS_ID= VOL_ID= REGION= Here EBS_ID is the AWS volume identifier that starts with vol- (under heading ebs_id) and VOL_ID is the fields volume identifier under the heading id in the output of sv-vollist $SERVER . Unmount the volume: fssh $SERVER \"sudo umount -f $DEVICE\" Detach this volume from server: aws ec2 detach-volume --region $REGION --volume-id $EBS_ID Once detached successfully, delete this volume: aws ec2 delete-volume --region $REGION --volume-id $EBS_ID Update fields record for this deleted volume: ah-volume edit $VOL_ID -s server_id=0","title":"Resize volumes"},{"location":"standard_maintenance/resize_volumes/#resize-volumes","text":"EBS volumes can be resized to any of the supported sizes , provided the data fits. The supported sizes are a business restriction, not a technical restriction. Volumes must be either magnetic or SSD except for backup volume. Backup volume type should be magnetic for ACE/ACP customers and SSD for ACSF (EG1/WMG/TREX). Below table lists the recommended storage type for volumes: | Volume | Storage type | |--------------|------------------------------------------------------------| | Database | SSD (gp3) | | Filesystem | SSD (gp3) | | Database | SSD (gp2) | | Filesystem | SSD (gp2) | | Backup | Magnetic (standard for ACE/ACP) . | | Backup | SSD (gp3 for ACSF) | Note While upsizing existing volumes, keep the same storage type as existing unless it is specified to change the storage type in the ticket. Note This runbook is also applicable for ACP volume resizes now. The sizes of ephemeral volumes ('/dev/xvda' and '/dev/xvdb') are tied to the ami_type and can not be changed. Only mntfs volumes can be resized directly, see Mntfs (xvbd) . For all other purpose EBS volumes (FS,DB), we create new EBS volumes, copy the data, and exchange the volumes. Creating the volumes and copying the data is done in two phases with a prep phase and a maintenance window phase. Copying the data is typically done with the XFS tools for Gluster bricks and rsync for MySQL volumes. Exchanging the volumes requires a maintenance window. During this window, services are stopped and an incremental copy is made before volumes are exchanged. Note : In fields, volume devices are referred to as '/dev/sda', etc, even if the devices are really '/dev/xvda' on the server itself. This is because of the device handler used by the kernel on the instance. sd = SCSI Disk driver and xvd = Xen Virtualisation Disk driver. man sd for some extra low level info. Note : SSD's are supported for database volumes but cost extra so existing volumes should be resized to the same type unless specifically requested and approved. Note : All magnetic (standard) volumes will have a size of less than 38 Gb or greater than 125 Gb. Most of them 125Gb. Note this is the size of the volume not the partition.","title":"Resize volumes"},{"location":"standard_maintenance/resize_volumes/#emergency-upsize-guidelines-ace-acsf-only","text":"Start emergency upsizing the volumes (DB/FS) if the volume filling rate has been high or reached 100% and customer/support isn't able to clear any data. Proceed with emergency upsize if customer has been non-responsive over 3 or more crits to clear the data. Proceed for an emergency conversion to gp3 if IOPs usage is very high and disk usage is less. If IOPs and usage both are high and creating DB replication lag then proceed with emergency upsize to gp2 or gp3. For ACP - we don't perform emergency upsize. File an SL ticket if customer is unresponsive over 3 crits or more and get confirmation for removing them from monitoring. File an AM ticket after upsize from the ops portal If the upsize is running over your shift, please include handoff notes mentioning all what has been done and what is left to make it easy for the next engineer to pick it up. We can refer this Flowchart to decide on whether to do an Emergency Upsize or some other step to deal with a Disk Partition Alert : Scope of Flowchart : Gluster and DB file system Volumes of ACE , ACSF and ACP","title":"Emergency upsize guidelines (ACE &amp; ACSF only)"},{"location":"standard_maintenance/resize_volumes/#gluster-prep-dumps","text":"It is possible that doing multiple gluster dumps at once (rsync or xfsdump) will cause an outage. You can create and mount the new volumes in parallel, but unless you are very sure that there is enough CPU, memory, and i/o bandwidth available to do two gluster dumps at once, you should do one at a time.","title":"Gluster Prep Dumps"},{"location":"standard_maintenance/resize_volumes/#preparatory-steps","text":"To be completed before the maintenance window opens. If downsizing, make sure the space currently used is less than 95% of the new volume size. SERVER= SIZE= JIRA_TICKET=","title":"Preparatory steps"},{"location":"standard_maintenance/resize_volumes/#create-and-attach-the-new-volume","text":"Gather volume volume information and put it in the ticket. sv-vollist ${SERVER} Get the volume id The volume id is the number after id: in the output of sv-vollist. It does not start with vol-. VOLUME_ID= VOLUME_TYPE=(gp3 gp2 or standard) If you need to start at a specific time, calculate the UNIX_START_TIME variable: UNIX_START_TIME=$(date -d '2018/03/22 20:00 UTC' +\"%s\") add the following flag to your ah-volume resize command: --scheduled-time ${UNIX_START_TIME} If you want to resume a workflow task at a specific time, calculate UNIX_START_TIME as above, then schedule it to resume (you must do this after starting the workflow with ah-volume resize below): WORKFLOW_ID= ah-workflow schedule-resume ${WORKFLOW_ID} \\ --scheduled-time ${UNIX_START_TIME} WARNING: This is not safe for HA pairs since there is no mechanism in place to ensure clean failover. To Find/Check scheduled maintenance information and status, run scheduled_task=$(ah-workflow get ${WORKFLOW_ID} | grep -w \"scheduled_task_ids.0\"|cut -d: -f2) wf-scheduled or ah-scheduled-task get $scheduled_task To Cancel/Remove the scheduled task in case if your maintenance will be cancelled, Run ah-scheduled-task kill $scheduled_task Beware: Always check the last hrs update in your maintenance ticket for cancellation updates if any. Add a runbook entry. VOLUME=[mysql|gfs|backup] fssh $SERVER \"sudo ah-runbook \\ '${JIRA_TICKET} - ${USER} - ${VOLUME} to ${SIZE}'\" Adding encryption to volumes: Encryption is required add --set-encryption to the resize command. Encryption is only supported for the following ami_types Type Instance type sizes c4 c4.large c4.xlarge c4.2xlarge c4.4xlarge c4.8xlarge c4.16xlarge c5 c5.large c5.xlarge c5.2xlarge c5.4xlarge c5.9xlarge c5.18xlarge cr1 cr1.8xlarge d2 d2.xlarge d2.2xlarge d2.4xlarge d2.8xlarge g2 g2.2xlarge g2.8xlarge m4 m4.large m4.xlarge m4.2xlarge m4.4xlarge m4.10xlarge m4.16xlarge m5 m5.large m5.xlarge m5.2xlarge m5.4xlarge m5.12xlarge m5.24xlarge r4 r4.large r4.xlarge r4.2xlarge r4.4xlarge r4.8xlarge r4.16xlarge t2 t2.large List based on Aq Gem Instance Features aq/aws_helpers/ec2/instance_features.rb","title":"Create and attach the new volume"},{"location":"standard_maintenance/resize_volumes/#copy-data-rsync-method","text":"","title":"Copy data: rsync method"},{"location":"standard_maintenance/resize_volumes/#important-note","text":"Do not abort workflows! If you are unable to resolve a problem with a workflow, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership Note : Unless the customer wants their FS (gluster) volumes to be a 'standard' volume type, the gluster bricks must always be set to SSD i.e. 'gp3' or 'gp2'. Be sure to check the ticket description. Note : Please do not purge binlogs during DB volume upsize even if the site is down. Purging binlogs during a DB volume upsize might corrupt that DB upon finishing. All volumes must be encrypted by default now. Please ensure that instance type supports encrypted ebs volumes before starting the workflow.","title":"Important Note"},{"location":"standard_maintenance/resize_volumes/#disclaimer","text":"Before initiating a rsync workflow for db cluster, make sure to check if the following condition is met: New volume size > (Current_Disk_Size + Biggest_File_on_the_Current_Disk/particularly ibdata1 file) If the above condition doesn't met or if the size of a particular file like ibdata1 file is huge, then we should use 'xfsdump' method to upsize the volume. However if you face any issue with 'xfsdump' method then escalate the issue to DBA. NOTE: After resizing the volume on each server, make sure to remount Gluster server. This is a mandatory step and applicable to FS volumes only. Typically used for MySQL, but also works with Gluster bricks. ah-volume resize ${VOLUME_ID} --new-size ${SIZE} --method rsync \\ --pause-at-step disable_backups --set-encryption \\ --pause-description \"${JIRA_TICKET} - ${USER}\" \\ --send-notifications false Note : In order to receive workflow failure notifications --send-notications false flag can be avoided. If this is a scheduled workflow with no pause and add encryption, on one of supported instance types listed on the table above, use: NOTE: After resizing the volume on each server, make sure to remount Gluster server. This is a mandatory step and applicable to FS volumes only. ah-volume resize ${VOLUME_ID} --new-size ${SIZE} --method rsync \\ --set-encryption --scheduled-time ${UNIX_START_TIME} \\ --send-notifications false Ops can use below command for MySQL volumes resize only for DEDs/FSDBs/DBMASTERs PRIMARY_DB_SERVER= ah-db-cluster resize-storage $PRIMARY_DB_SERVER --new-size ${SIZE} --method rsync \\ --set-encryption --scheduled-time ${UNIX_START_TIME} \\ --send-notifications false Note : In order to receive workflow failure notifications --send-notications false flag can be avoided.","title":"Disclaimer"},{"location":"standard_maintenance/resize_volumes/#copy-data-xfs-dump-restore-method","text":"","title":"Copy data: XFS dump-restore method"},{"location":"standard_maintenance/resize_volumes/#important-note_1","text":"Do not abort workflows! If you are unable to resolve a problem with a workflow, raise the incident to Ops Management for approval to escalate it to Cloud through Ops Portal: https://portal.ais.acquia.io/form/clescalate Use this list of components to identify which Cloud team to assign it to: https://confluence.acquia.com/display/CL/Cloud+Workflow+Ownership Note : Unless the customer wants their FS (gluster) volumes to be a 'standard' volume type, the gluster bricks must always be set to SSD i.e. 'gp3' or 'gp2'. Be sure to check the ticket description. This also works for MySQL volumes. For gluster xfsdumps: If this is the second server you are doing an xfsdump on, make sure the first one is finished, or there is more than enough I/O bandwidth to spare. Two gluster dumps at once can cause an outage. Note : Please do not purge binlogs during DB volume upsize even if the site is down. Purging binlogs during a DB volume upsize might corrupt that DB upon finishing. All volumes must be encrypted by default now. Please ensure that instance type supports encrypted ebs volumes before starting the workflow. For GlusterFS bricks set the type to gp3 : NOTE: After resizing the volume on each server, make sure to remount Gluster server. This is a mandatory step and applicable to FS volumes only. ah-volume resize ${VOLUME_ID} --new-size ${SIZE} --method xfsdump \\ --ebs-volume-type ${VOLUME_TYPE} \\ --set-encryption \\ --pause-at-step disable_backups \\ --pause-description \"${JIRA_TICKET} - ${USER}\" \\ --send-notifications false For other volumes: NOTE: After resizing the volume on each server, make sure to remount Gluster server. This is a mandatory step and applicable to FS volumes only. ah-volume resize ${VOLUME_ID} --new-size ${SIZE} --method xfsdump \\ --set-encryption \\ --pause-at-step disable_backups \\ --pause-description \"${JIRA_TICKET} - ${USER}\" \\ --send-notifications false Note : In order to receive workflow failure notifications --send-notications false flag can be avoided. Note : There is a bug due to which a workflow fails if the volume has been upsized previously using xfsdump. In that case, please remove xfsrestorehousekeepingdir and orphanage directories from /mnt/gfs before starting the workflow. Also, check if /mnt/brickXXXX has these directories and cleanup them if they exist from there too.","title":"Important  Note"},{"location":"standard_maintenance/resize_volumes/#no-data-copy-no_data_migration-method","text":"Warning : this method will create empty volumes discarding any existing data . It is usefull for backup volumes where we don't need to wait for data copy. It should NEVER be used on gfs or mysql volumes! If this is a scheduled workflow with no pause and add encryption on supported instances use: ah-volume resize ${VOLUME_ID} --new-size ${SIZE} --method no_data_migration \\ --set-encryption --scheduled-time ${UNIX_START_TIME} \\ --send-notifications false Note : In order to receive workflow failure notifications --send-notications false flag can be avoided. Also keep in mind, backup volume type should be magnetic for ACE/ACP customers and SSD for ACSF (EG1/WMG/TREX).","title":"No data copy: no_data_migration method"},{"location":"standard_maintenance/resize_volumes/#gp2-to-gp3-conversion","text":"If IOPs usage is very high and disk usage is less for FS or DB volume or DB replication is very high due to high IOPs then procced with conversion from standard or gp2 to gp3 using a worklfow. ah-volume resize ${VOLUME_ID} --new-size ${SIZE} --method xfsdump \\ --ebs-volume-type ${VOLUME_TYPE} \\ --set-encryption \\ --send-notifications false","title":"Gp2 to Gp3 conversion"},{"location":"standard_maintenance/resize_volumes/#maintenance-window-steps","text":"These steps must be completed during the assigned maintenance window. Verify the prep work completed properly WORKFLOW_ID= ah-workflow get ${WORKFLOW_ID} The status field should be set to user_pause. If it's in an error state, debug the workflow ah-workflow get ${WORKFLOW_ID} --show-logs Verify the person actioning the previous steps left an ah-runbook entry. Create an entry if they forgot to. ah-runbook For HA clusters, follow the procedure to work on one server at a time in the section on volume specifics below. Resume the workflow to complete the resize ah-workflow resume ${WORKFLOW_ID} If the volume was Gluster Resize the backup volume to match.","title":"Maintenance window steps"},{"location":"standard_maintenance/resize_volumes/#volume-and-service-specifics","text":"MySQL (xvdm) Backup (xvdn) Gluster (xvdo) Mntfs (xvdb)","title":"Volume and service specifics"},{"location":"standard_maintenance/resize_volumes/#mysql-volumes-xvdm","text":"In an HA cluster, upsize one server at a time. Check that replication is in sync and the primary (first) server is active. ah-db-cluster status ${SERVER} Lock replication to the primary. ah-db-cluster lock ${SERVER} When the secondary is resized and workflow has completed, check that replication is in sync. ah-db-cluster status ${SERVER} When it is, unlock and fail over. Otherwise, fix it, or escalate to a DBA. ah-db-cluster unlock ${SERVER} dns-update $CLUSTER $SECONDARY On the primary (but now inactive) server, resize the volume as with the secondary. After upsizing, check replication, unlock, and fail back as before.","title":"MySQL volumes (xvdm)"},{"location":"standard_maintenance/resize_volumes/#backup-xvdn","text":"This volume matches the Gluster brick in size on staging servers and the primary server in HA FS clusters. Note : The volume on the secondary FS server is always 1G in size. Note for encryption : If you have encrypted the FS volumes (gluster bricks), both the backup-ebs volumes will need encryption as well. Set variables. SIZE= SDN_VOLUME_ID= Check volume-type is magnetic, reported as standard. sv-vollist $server For ACE/ACP, if not magnetic, please specify new volume as magnetic simultaneous with the resize. ah-volume resize ${SDN_VOLUME_ID} --new-size ${SIZE} --method rsync --ebs-volume-type=standard --send-notifications false For ACSF (EG1/WMG/TREX), if not SSD, please specify new volume as gp3 simultaneous with the resize. ah-volume resize ${SDN_VOLUME_ID} --new-size ${SIZE} --method rsync --ebs-volume-type=gp3 --send-notifications false If already encryption is supported, resize to an empty backup volume after setting the appropriate EBS volume type. ah-volume resize ${SDN_VOLUME_ID} --new-size ${SIZE} --set-encryption \\ --method no_data_migration --send-notifications false","title":"Backup (xvdn)"},{"location":"standard_maintenance/resize_volumes/#gluster-xvdo","text":"After resizing the volume on each server, remount Gluster server. Make sure it properly remounts on every server. (Often, remounting twice will take care of this). The reason we remount gluster first is that during the time the gluster service has been offline the clients may have completely timed out retrying their connections; this starts up the retry loop so that when the firewall rule is removed they sanely reconnect. site-fsremount ${SITE}","title":"Gluster (xvdo)"},{"location":"standard_maintenance/resize_volumes/#mntfs-xvdb","text":"Volumes mounted to /mnt/ on EBS-backed instances, so called mntfs volumes, can be upsized with the ah-volume upsize-mntfs subcommand by defining the server name and the target size in GiB: ah-volume upsize-mntfs --server-name=${SERVER_NAME} --target-size=${TARGET_SIZE} Note : In order to receive workflow failure notifications --send-notications false can be avoided. It triggers a workflow in the background that first increases the EBS volume size to the given target size via AWS API. Then it expands the xfs partition to the maximum size of the volume with xfs_growfs . The workflow operates on the fly without unmounting or detaching the volume. NO backup will be saved by the workflow. The filesystem remains readable and writable during the operation. The additional space becomes available after the worklow finishes. Note : The command works only on Current Generation intance types and on some of the Previous Generation instance types. For more detailed info check the AWS documentation Note : Amazon doesn't allow you to change the size of a volume within 6 hours more than once. So a consecutive call of upsize-mntfs will fail. In this case the workflow will be suspended, but it can be resumed after the resize limit period expired. Note : The subcommand can only increase volumes. It does not allow volume downsize.","title":"Mntfs (xvdb)"},{"location":"standard_maintenance/resize_volumes/#livedev-enabled-sites","text":"If the site has livedev enabled, audit the webs post-resize to make sure that livedev exists, has a docroot, and belongs to the correct user and group. SERVERS=($(ah-server list site:$SITE -w typeINded,staging,web)) for srv in ${SERVERS[@]}; do echo echo \"SERVER: $srv\" fssh $srv \"sudo ls -lah /mnt/gfs/${SITE}/livedev/\" 2>/dev/null done If livedev is in broken state on any of the webs, do another site-fsremount and check again. Remounting the filesystem should fix the problem, but if the filesystem is not successfully remounted, the customer may see staging task failures down the road.","title":"Livedev-enabled sites"},{"location":"standard_maintenance/resize_volumes/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"standard_maintenance/resize_volumes/#reset-xfs-dump-restore","text":"If for any reason you have to reset the process and start again, you only need to modify the destination: rm -Rf /mnt/${DEV}/{orphanage,xfsrestorehousekeepingdir}","title":"Reset XFS dump-restore"},{"location":"standard_maintenance/resize_volumes/#gluster-34-id","text":"If Gluster 3.4 complains it lost the ID, do the following to fix it. export BRICK=/mnt/brick12312/brick export FSCLUSTER=ded-sitename export VOL_ID=$(grep volume-id /var/lib/glusterd/vols/${FSCLUSTER}/info \\ | cut -d= -f2 \\ | sed 's/-//g') setfattr -n trusted.glusterfs.volume-id -v 0x${VOL_ID} ${BRICK} gluster volume start ${FSCLUSTER} ah-config-gluster","title":"Gluster 3.4 ID"},{"location":"standard_maintenance/resize_volumes/#volume-cleanup","text":"This procedure is only to be used if you are cleaning up volumes from a failed workflow. Get the volume details and set variables: sv-vollist $SERVER DEVICE=[/dev/xvdx | /dev/xvdy | /dev/xvdz] EBS_ID= VOL_ID= REGION= Here EBS_ID is the AWS volume identifier that starts with vol- (under heading ebs_id) and VOL_ID is the fields volume identifier under the heading id in the output of sv-vollist $SERVER . Unmount the volume: fssh $SERVER \"sudo umount -f $DEVICE\" Detach this volume from server: aws ec2 detach-volume --region $REGION --volume-id $EBS_ID Once detached successfully, delete this volume: aws ec2 delete-volume --region $REGION --volume-id $EBS_ID Update fields record for this deleted volume: ah-volume edit $VOL_ID -s server_id=0","title":"Volume Cleanup"},{"location":"standard_maintenance/resize_volumes_manual/","text":"Resize volumes manually Note you can resize volumes via workflows. Only use these instructions if there is bug or missing feature with the workflow Resize volumes via workflow EBS volumes can be resized to any of the supported sizes , provided the data fits. The supported sizes are a business restriction, not a technical restriction. Volumes must be either magnetic or SSD except for backup volume. Backup volume type should be magnetic for ACE/ACP customers and SSD for ACSF (EG1/WMG/TREX). Below table lists the recommended storage type for volumes: | Volume | Storage type | |--------------|------------------------------------------------------------| | Database | SSD (gp3) | | Filesystem | SSD (gp3) | | Backup | Magnetic (standard for ACE/ACP) | | Backup | SSD (gp3 for ACSF) | Note While upsizing existing volumes other than Backup volumes, keep the same storage type as existing unless it is specified to change the storage type in the ticket. The sizes of ephemeral volumes ('/dev/xvda' and '/dev/xvdb') are tied to the ami_type and can not be changed. EBS volumes can not be resized directly. Instead, we create new EBS volumes, copy the data, and exchange the volumes. Creating the volumes and copying the data is done in two phases with a prep phase and a maintenance window phase. Copying the data is typically done with the XFS tools for Gluster bricks and rsync for MySQL volumes. Exchanging the volumes requires a maintenance window. During this window, services are stopped and an incremental copy is made before volumes are exchanged. Note : In fields, volume devices are referred to as '/dev/sda', etc, even if the devices are really '/dev/xvda' on the server itself. This is because of the device handler used by the kernel on the instance. sd = SCSI Disk driver and xvd = Xen Virtualisation Disk driver. man sd for some extra low level info. Note : SSD's are supported for database volumes but cost extra so existing volumes should be resized to the same type unless specifically requested and approved. Emergency upsize guidelines (ACE & ACSF only) Start emergency upsizing the volumes (DB/FS) if the volume filling rate has been high or reached 100% and customer/support isn't able to clear any data. Proceed with emergency upsize if customer has been non-responsive over 3 or more crits to clear the data. For ACP - we don't perform emergency upsize. File an SL ticket if customer is unresponsive over 3 crits or more and get confirmation for removing them from monitoring. File an AM ticket after upsize from the ops portal If the upsize is running over your shift, please include handoff notes mentioning all what has been done and what is left to make it easy for the next engineer to pick it up. Gluster Prep Dumps It is possible that doing multiple gluster dumps at once (rsync or xfsdump) will cause an outage. You can create and mount the new volumes in parallel, but unless you are very sure that there is enough CPU, memory, and i/o bandwidth available to do two gluster dumps at once, you should do one at a time. Preparatory steps To be completed before the maintenance window opens. If downsizing, make sure the space currently used is less than 95% of the new volume size. SERVER= SIZE= TYPE= INSTANCE=$(ah-server list $SERVER --no-name -c ec2_id) REGION=$(ah-server list $SERVER --no-name -c ec2_region) AZ=$(ah-server list $SERVER --no-name -c ec2_availability_zone) Create and attach the new volume Gather volume volume information and put it in the ticket. sv-vollist $SERVER Create a new volume of the new size. As a reminder, database volumes need to stay the same type unless specifically requested and approved. For a MySQL volume, do this: aws ec2 create-volume \\ --region $REGION \\ --availability-zone $AZ \\ --size $SIZE \\ --volume-type $TYPE For a gluster volume, add the flag for an SSD volume: aws ec2 create-volume \\ --region $REGION \\ --availability-zone $AZ \\ --size $SIZE \\ --volume-type gp3 Set variables of the old and new volumes. OLD_VOL= NEW_VOL= View the tags from the current volume. aws ec2 describe-volumes \\ --region $REGION \\ --volume-ids $OLD_VOL \\ --output text Set more variables. Only DEVICE needs to be specified here, since FIELDS_STAGE , USER and SERVER should already be defined. DEVICE is the full path that fields knows about, such as /dev/sdm . Fields is the only place that uses \"sd X \" instead of \"xvd X \". NOTE : /dev/sdm => /dev/sdx, /dev/sdn => /dev/sdy and /dev/sdo => /dev/sdz DEVICE= TMP_DEVICE= Tag the new volume. The launching user is you, not the original person. aws ec2 create-tags \\ --region $REGION \\ --resources $NEW_VOL \\ --tags Key=ah_stage,Value=$FIELDS_STAGE \\ Key=ah_server_name,Value=$SERVER \\ Key=ah_attach_to_device,Value=$DEVICE \\ Key=ah_launching_user,Value=$USER Attach the volume at the temporary device. aws ec2 attach-volume \\ --region $REGION \\ --volume-id $NEW_VOL \\ --instance-id $INSTANCE \\ --device $TMP_DEVICE Format and mount the new volume Add a runbook entry. JIRA_TICKET= fssh $SERVER \"sudo ah-runbook \\ '$JIRA_TICKET - $USER - $DEVICE resize to $SIZE'\" On the server, set DEV to just \"xvd X \". Replace X with the correct letter. Export it so it is usable from a Screen session. export DEV=xvdX Create the filesystem. (We do not partition volumes.) mkfs -t xfs /dev/$DEV Create the mountpoint. This may exist from a previous resize. As long as nothing is mounted, that is fine. mkdir -p /mnt/$DEV Mount. mount /dev/$DEV /mnt/$DEV Copy data: rsync method Typically used for MySQL, but also works with Gluster bricks. Start screen. screen -S rsync-$DEV For MySQL : Run rsync. Ensure there are trailing slashes on these paths. (date; rsync -avP /vol/ebs1/ /mnt/${DEV}/; date) \\ | tee -a /mnt/tmp/vol-resize-${DEV}-rsync-0.log For Gluster bricks : Run rsync. The -X and -H flags are very important Ensure there are trailing slashes on these paths. If this is the second server you are doing an rsync on, make sure the first one is finished, or there is more than enough I/O bandwidth to spare. Two gluster dumps at once can cause an outage. BRICK=/mnt/brick##### (date; rsync -avHPX ${BRICK}/ /mnt/${DEV}/; date) \\ | tee -a /mnt/tmp/vol-resize-${DEV}-rsync-0.log Copy data: XFS dump-restore method This also works for MySQL volumes. Change the paths appropriately. For gluster xfsdumps: If this is the second server you are doing an rsync on, make sure the first one is finished, or there is more than enough I/O bandwidth to spare. Two gluster dumps at once can cause an outage. Start screen. screen -S xfsdump-$DEV Create the initial, level-zero dump, which is a complete dump of the entire filesystem. Note : Paths do not have a trailing slash. BRICK=/mnt/brick##### (date; xfsdump -l 0 - $BRICK 2>/mnt/tmp/xfsdump_l0.stderr.log \\ | xfsrestore -r - /mnt/$DEV 2>&1; date) \\ | tee -a /mnt/tmp/xfsdump_l0.log Resize the backup volume , /dev/xvdn , to match. Maintenance window steps These steps must be completed during the assigned maintenance window. Set these variables on the bastion. Note : Set DEV to just \"xvdX\". Replace X with the correct letter. SITE= SERVER= OLD_VOL= NEW_VOL= DEV= INSTANCE=$(ah-server list $SERVER --no-name -c ec2_id) REGION=$(ah-server list $SERVER --no-name -c ec2_region) AZ=$(ah-server list $SERVER --no-name -c ec2_availability_zone) Set these variables on the server. JIRA_TICKET= DEV= MOUNTPOINT= Check that the preparatory steps are complete. For the XFS dump-restore method, check in the log that both xfsdump and xfsrestore reported they were successful - /mnt/tmp/xfsdump_l0{,.stderr}.log . Verify the person actioning the previous steps left an ah-runbook entry. Create an entry if they forgot to. ah-runbook For HA clusters, follow the procedure to work on one server at a time in the section on volume specifics below. Disable Puppet and stop cron. puppet agent --disable \"$JIRA_TICKET - $USER - /dev/$DEV resize.\" service cron stop Stop volume-specific services. See the section for your volume below. Verify nothing is using the volume. meh or other services may need to be stopped. lsof | grep $MOUNTPOINT For the XFS dump-restore method : Check that 'xfsrestorehousekeepingdir' exists on the destination ('/mnt/$DEV'). If it does not, rename the 'orphanage' directory on the destination, and omit the '-r' option from xfsrestore below. Run the next level xfsdump . BRICK=/mnt/brick##### (date; xfsdump -l 1 - $BRICK 2>/mnt/tmp/xfsdump_l1.stderr.log \\ | xfsrestore -r - /mnt/$DEV 2>&1; date) \\ | tee -a /mnt/tmp/xfsdump_l1.log Note : After resize when its done successfully, do not forget to remove the xfsrestorehousekeepingdir and orphanage directories new volume which is mounted under temporary mount point /mnt/$DEV. To avoid future resize workflow failures. rm -rf /mnt/$DEV/xfsrestorehousekeepingdir For the rsync method : For MySQL : Run the final rsync. (date; rsync -avP --delete /vol/ebs1/ /mnt/${DEV}/; date) \\ | tee -a /mnt/tmp/vol-resize-${DEV}-rsync-1.log For Gluster bricks : Run the final rsync. BRICK=/mnt/brick##### (date; rsync -avHPX --delete ${BRICK}/ /mnt/${DEV}/; date) \\ | tee -a /mnt/tmp/vol-resize-${DEV}-rsync-1.log For both methods : Run it again. It should make no changes since services using the volume are stopped. Unmount the current and replacement volumes. umount $MOUNTPOINT umount /dev/$DEV Detach both volumes. aws ec2 detach-volume --region $REGION --volume-id $OLD_VOL aws ec2 detach-volume --region $REGION --volume-id $NEW_VOL Attach the new volume, no longer at the temporary location. aws ec2 attach-volume \\ --region $REGION \\ --volume-id $NEW_VOL \\ --instance-id $INSTANCE \\ --device /dev/$DEV Mount the new volume, no longer at the temporary mount point. mount $MOUNTPOINT Enable and run Puppet to start any services stopped earlier. puppet agent --enable; puppet agent --test If it was a Gluster brick that was resized, remount Gluster for the entire site. Make sure it properly remounts on every server. site-fsremount $SITE Update the fields volume record. Note : When you modify a volume with ah-server , a brand new volume ID is created. You must run sv-vollist again if you need to know the new volume id. For MySQL volumes (xvdm): ah-server edit $SERVER -s ebs_id=$NEW_VOL For Backup volumes (xvdn): ah-server edit $SERVER -s ebs2_id=$NEW_VOL For Gluster bricks (xvdo): ah-volume edit $BRICKID -s \\ ebs_id=$NEW_VOL \\ size=$SIZE \\ ec2_availability_zone=$AZ \\ status=in_use Tag the old volumes as having been replaced. (Remove some unused tags to make room.) aws ec2 delete-tags \\ --region $REGION \\ --resources $OLD_VOL \\ --tags Key=title Key=active aws ec2 create-tags \\ --region $REGION \\ --resources $OLD_VOL \\ --tags Key=ops_replaced_in,Value=$JIRA_TICKET \\ Key=ah_resize_info,Value=${OLD_VOL}/$(date +%Y%m%d%H%M -d \"+7 days\") The replaced volumes will be deleted in 1 week by the cronjob on the master Volume and service specifics MySQL (xvdm) Backup (xvdn) Gluster (xvdo) MySQL volumes (sdm) Mountpoint: '/vol/ebs1' In an HA cluster, upsize one server at a time. Check that replication is in sync and the primary (first) server is active. ah-db-cluster status $SERVER Lock replication to the primary. ah-db-cluster lock $SERVER Stop Puppet, cron, and MySQL as above on the secondary. Stop MySQL with the following command. Never force MySQL to stop. Escalate to a DB if it refuses to stop gracefully. Note Some databases have very large data sets and use quite a lot of RAM. These can take many minutes to safely shutdown. Flushing caches to disk can take a long time with EBS. mysqladmin shutdown When the secondary is resized and services have been restarted, check that replication is in sync. ah-db-cluster status $SERVER When it is, unlock and fail over. Otherwise, fix it, or escalate to a DBA. ah-db-cluster unlock $SERVER dns-update $CLUSTER $SECONDARY On the primary (but now inactive) server, stop services and resize the volume as with the secondary. After upsizing, check replication, unlock, and fail back as before. Backup (sdn) Mountpoint: '/vol/backup-ebs' This volume can be replaced with a blank one of volume-type magnetic and fields-backup-fileserver.php will replace the contents from the Gluster volume. This volume matches the Gluster brick in size on staging servers and the primary server in HA FS clusters. For ACE/ACP, some prior backup-volumes may have been made as SSD volumes, reported as gp3 by sv-vollist. To match policy for new provisions, it is okay during this resize to replace with magnetic, reported as standard by sv-vollist. However in case of ACSF (EG1/WMG/TREX), some prior backup-volumes may have been made as Magnetic volumes, reported as standard by sv-vollist. To match policy for new provisions, it is okay during this resize to replace with SSD, reported as gp3 by sv-vollist. IMPORTANT : Ensure you resize the backup volume on the primary FS server FIRST. It is vital that the primary has the lowest number volume id. Note : The volume on the secondary FS server is always 1G in size. Set variables. SERVER= SIZE= OLD_VOL= INSTANCE=$(ah-server list $SERVER --no-name -c ec2_id) REGION=$(ah-server list $SERVER --no-name -c ec2_region) AZ=$(ah-server list $SERVER --no-name -c ec2_availability_zone) Create a new volume. aws ec2 create-volume \\ --region $REGION \\ --availability-zone $AZ \\ --size $SIZE View the tags from the current volume. aws ec2 describe-volumes --region $REGION --volume-ids $OLD_VOL Set more variables. NEW_VOL= Tag the new volume. Only 'SERVER' needs to be specified here, since 'FIELDS_STAGE' and 'USER' should already be defined. The launching user is you, not the original person. aws ec2 create-tags \\ --region $REGION \\ --resources $NEW_VOL \\ --tags \\ Key=ah_stage,Value=$FIELDS_STAGE \\ Key=ah_server_name,Value=$SERVER \\ Key=ah_attach_to_device,Value=/dev/sdn \\ Key=ah_launching_user,Value=$USER Unmount the old volume. fssh $SERVER sudo umount /vol/backup-ebs Detach the old volume. aws ec2 detach-volume --region $REGION --volume-id $OLD_VOL Attach the new volume. aws ec2 attach-volume \\ --region $REGION \\ --volume-id $NEW_VOL \\ --instance-id $INSTANCE \\ --device /dev/sdn Format the new volume. fssh $SERVER sudo mkfs -t xfs /dev/xvdn Mount the new volume. fssh $SERVER sudo mount /vol/backup-ebs Update the fields volume record. Note when setting ebs2_id with ah-server the id of the volume changes ah-server edit $SERVER -s ebs2_id=$NEW_VOL sv-vollist $SERVER Gluster (sdo) Mountpoint: '/mnt/brick#####', where ##### is the fields volume ID. (There is only one '/mnt/brick#####' per fs class server.) Stop the Gluster service: service glusterfs-server stop Stop any gluster processes: pkill glusterfsd Puppet does not start the Gluster service. Run fields-config-fs-server.php to start it, or ah-config-gluster for gluster version >3.0. After resizing the volume on each server, remount Gluster server. Make sure it properly remounts on every server. (Often, remounting twice will take care of this). The reason we remount gluster first is that during the time the gluster service has been offline the clients may have completely timed out retrying their connections; this starts up the retry loop so that when the firewall rule is removed they sanely reconnect. site-fsremount $SITE Troubleshooting Reset XFS dump-restore If for any reason you have to reset the process and start again, you only need to modify the destination: rm -Rf /mnt/$DEV/{orphanage,xfsrestorehousekeepingdir} Gluster 3.4 ID If Gluster 3.4 complains it lost the ID, do the following to fix it. export BRICK=/mnt/brick12312/brick export FSCLUSTER=ded-sitename export VOL_ID=$(grep volume-id /var/lib/glusterd/vols/$FSCLUSTER/info \\ | cut -d= -f2 \\ | sed 's/-//g') setfattr -n trusted.glusterfs.volume-id -v 0x$VOL_ID $BRICK gluster volume start $FSCLUSTER ah-config-gluster Deleting a volume When deleting a volume, make sure it is \"available\". (Here, $VOLUMES is space-separated.) aws ec2 describe-volumes --region $REGION --volume-ids $VOLUMES | grep State To delete a volume: aws ec2 delete-volume --region $REGION --volume-id $VOLUME Volume Cleanup This procedure is only to be used if you are cleaning up volumes from a failed resize. Get the volume details and set variables: sv-vollist $SERVER DEVICE=[/dev/xvdx | /dev/xvdy | /dev/xvdz] EBS_ID= VOL_ID= REGION= Here EBS_ID is the AWS volume identifier that starts with vol- (under heading ebs_id) and VOL_ID is the fields volume identifier under the heading id in the output of sv-vollist $SERVER . Unmount the volume: fssh $SERVER \"sudo umount -f $DEVICE\" Detach this volume from server: aws ec2 detach-volume --region $REGION --volume-id $EBS_ID Once detached successfully, delete this volume: aws ec2 delete-volume --region $REGION --volume-id $EBS_ID Update fields record for this deleted volume: ah-volume edit $VOL_ID -s server_id=0","title":"Resize volumes manually"},{"location":"standard_maintenance/resize_volumes_manual/#resize-volumes-manually","text":"Note you can resize volumes via workflows. Only use these instructions if there is bug or missing feature with the workflow Resize volumes via workflow EBS volumes can be resized to any of the supported sizes , provided the data fits. The supported sizes are a business restriction, not a technical restriction. Volumes must be either magnetic or SSD except for backup volume. Backup volume type should be magnetic for ACE/ACP customers and SSD for ACSF (EG1/WMG/TREX). Below table lists the recommended storage type for volumes: | Volume | Storage type | |--------------|------------------------------------------------------------| | Database | SSD (gp3) | | Filesystem | SSD (gp3) | | Backup | Magnetic (standard for ACE/ACP) | | Backup | SSD (gp3 for ACSF) | Note While upsizing existing volumes other than Backup volumes, keep the same storage type as existing unless it is specified to change the storage type in the ticket. The sizes of ephemeral volumes ('/dev/xvda' and '/dev/xvdb') are tied to the ami_type and can not be changed. EBS volumes can not be resized directly. Instead, we create new EBS volumes, copy the data, and exchange the volumes. Creating the volumes and copying the data is done in two phases with a prep phase and a maintenance window phase. Copying the data is typically done with the XFS tools for Gluster bricks and rsync for MySQL volumes. Exchanging the volumes requires a maintenance window. During this window, services are stopped and an incremental copy is made before volumes are exchanged. Note : In fields, volume devices are referred to as '/dev/sda', etc, even if the devices are really '/dev/xvda' on the server itself. This is because of the device handler used by the kernel on the instance. sd = SCSI Disk driver and xvd = Xen Virtualisation Disk driver. man sd for some extra low level info. Note : SSD's are supported for database volumes but cost extra so existing volumes should be resized to the same type unless specifically requested and approved.","title":"Resize volumes manually"},{"location":"standard_maintenance/resize_volumes_manual/#emergency-upsize-guidelines-ace-acsf-only","text":"Start emergency upsizing the volumes (DB/FS) if the volume filling rate has been high or reached 100% and customer/support isn't able to clear any data. Proceed with emergency upsize if customer has been non-responsive over 3 or more crits to clear the data. For ACP - we don't perform emergency upsize. File an SL ticket if customer is unresponsive over 3 crits or more and get confirmation for removing them from monitoring. File an AM ticket after upsize from the ops portal If the upsize is running over your shift, please include handoff notes mentioning all what has been done and what is left to make it easy for the next engineer to pick it up.","title":"Emergency upsize guidelines (ACE &amp; ACSF only)"},{"location":"standard_maintenance/resize_volumes_manual/#gluster-prep-dumps","text":"It is possible that doing multiple gluster dumps at once (rsync or xfsdump) will cause an outage. You can create and mount the new volumes in parallel, but unless you are very sure that there is enough CPU, memory, and i/o bandwidth available to do two gluster dumps at once, you should do one at a time.","title":"Gluster Prep Dumps"},{"location":"standard_maintenance/resize_volumes_manual/#preparatory-steps","text":"To be completed before the maintenance window opens. If downsizing, make sure the space currently used is less than 95% of the new volume size. SERVER= SIZE= TYPE= INSTANCE=$(ah-server list $SERVER --no-name -c ec2_id) REGION=$(ah-server list $SERVER --no-name -c ec2_region) AZ=$(ah-server list $SERVER --no-name -c ec2_availability_zone)","title":"Preparatory steps"},{"location":"standard_maintenance/resize_volumes_manual/#create-and-attach-the-new-volume","text":"Gather volume volume information and put it in the ticket. sv-vollist $SERVER Create a new volume of the new size. As a reminder, database volumes need to stay the same type unless specifically requested and approved. For a MySQL volume, do this: aws ec2 create-volume \\ --region $REGION \\ --availability-zone $AZ \\ --size $SIZE \\ --volume-type $TYPE For a gluster volume, add the flag for an SSD volume: aws ec2 create-volume \\ --region $REGION \\ --availability-zone $AZ \\ --size $SIZE \\ --volume-type gp3 Set variables of the old and new volumes. OLD_VOL= NEW_VOL= View the tags from the current volume. aws ec2 describe-volumes \\ --region $REGION \\ --volume-ids $OLD_VOL \\ --output text Set more variables. Only DEVICE needs to be specified here, since FIELDS_STAGE , USER and SERVER should already be defined. DEVICE is the full path that fields knows about, such as /dev/sdm . Fields is the only place that uses \"sd X \" instead of \"xvd X \". NOTE : /dev/sdm => /dev/sdx, /dev/sdn => /dev/sdy and /dev/sdo => /dev/sdz DEVICE= TMP_DEVICE= Tag the new volume. The launching user is you, not the original person. aws ec2 create-tags \\ --region $REGION \\ --resources $NEW_VOL \\ --tags Key=ah_stage,Value=$FIELDS_STAGE \\ Key=ah_server_name,Value=$SERVER \\ Key=ah_attach_to_device,Value=$DEVICE \\ Key=ah_launching_user,Value=$USER Attach the volume at the temporary device. aws ec2 attach-volume \\ --region $REGION \\ --volume-id $NEW_VOL \\ --instance-id $INSTANCE \\ --device $TMP_DEVICE","title":"Create and attach the new volume"},{"location":"standard_maintenance/resize_volumes_manual/#format-and-mount-the-new-volume","text":"Add a runbook entry. JIRA_TICKET= fssh $SERVER \"sudo ah-runbook \\ '$JIRA_TICKET - $USER - $DEVICE resize to $SIZE'\" On the server, set DEV to just \"xvd X \". Replace X with the correct letter. Export it so it is usable from a Screen session. export DEV=xvdX Create the filesystem. (We do not partition volumes.) mkfs -t xfs /dev/$DEV Create the mountpoint. This may exist from a previous resize. As long as nothing is mounted, that is fine. mkdir -p /mnt/$DEV Mount. mount /dev/$DEV /mnt/$DEV","title":"Format and mount the new volume"},{"location":"standard_maintenance/resize_volumes_manual/#copy-data-rsync-method","text":"Typically used for MySQL, but also works with Gluster bricks. Start screen. screen -S rsync-$DEV For MySQL : Run rsync. Ensure there are trailing slashes on these paths. (date; rsync -avP /vol/ebs1/ /mnt/${DEV}/; date) \\ | tee -a /mnt/tmp/vol-resize-${DEV}-rsync-0.log For Gluster bricks : Run rsync. The -X and -H flags are very important Ensure there are trailing slashes on these paths. If this is the second server you are doing an rsync on, make sure the first one is finished, or there is more than enough I/O bandwidth to spare. Two gluster dumps at once can cause an outage. BRICK=/mnt/brick##### (date; rsync -avHPX ${BRICK}/ /mnt/${DEV}/; date) \\ | tee -a /mnt/tmp/vol-resize-${DEV}-rsync-0.log","title":"Copy data: rsync method"},{"location":"standard_maintenance/resize_volumes_manual/#copy-data-xfs-dump-restore-method","text":"This also works for MySQL volumes. Change the paths appropriately. For gluster xfsdumps: If this is the second server you are doing an rsync on, make sure the first one is finished, or there is more than enough I/O bandwidth to spare. Two gluster dumps at once can cause an outage. Start screen. screen -S xfsdump-$DEV Create the initial, level-zero dump, which is a complete dump of the entire filesystem. Note : Paths do not have a trailing slash. BRICK=/mnt/brick##### (date; xfsdump -l 0 - $BRICK 2>/mnt/tmp/xfsdump_l0.stderr.log \\ | xfsrestore -r - /mnt/$DEV 2>&1; date) \\ | tee -a /mnt/tmp/xfsdump_l0.log Resize the backup volume , /dev/xvdn , to match.","title":"Copy data: XFS dump-restore method"},{"location":"standard_maintenance/resize_volumes_manual/#maintenance-window-steps","text":"These steps must be completed during the assigned maintenance window. Set these variables on the bastion. Note : Set DEV to just \"xvdX\". Replace X with the correct letter. SITE= SERVER= OLD_VOL= NEW_VOL= DEV= INSTANCE=$(ah-server list $SERVER --no-name -c ec2_id) REGION=$(ah-server list $SERVER --no-name -c ec2_region) AZ=$(ah-server list $SERVER --no-name -c ec2_availability_zone) Set these variables on the server. JIRA_TICKET= DEV= MOUNTPOINT= Check that the preparatory steps are complete. For the XFS dump-restore method, check in the log that both xfsdump and xfsrestore reported they were successful - /mnt/tmp/xfsdump_l0{,.stderr}.log . Verify the person actioning the previous steps left an ah-runbook entry. Create an entry if they forgot to. ah-runbook For HA clusters, follow the procedure to work on one server at a time in the section on volume specifics below. Disable Puppet and stop cron. puppet agent --disable \"$JIRA_TICKET - $USER - /dev/$DEV resize.\" service cron stop Stop volume-specific services. See the section for your volume below. Verify nothing is using the volume. meh or other services may need to be stopped. lsof | grep $MOUNTPOINT For the XFS dump-restore method : Check that 'xfsrestorehousekeepingdir' exists on the destination ('/mnt/$DEV'). If it does not, rename the 'orphanage' directory on the destination, and omit the '-r' option from xfsrestore below. Run the next level xfsdump . BRICK=/mnt/brick##### (date; xfsdump -l 1 - $BRICK 2>/mnt/tmp/xfsdump_l1.stderr.log \\ | xfsrestore -r - /mnt/$DEV 2>&1; date) \\ | tee -a /mnt/tmp/xfsdump_l1.log Note : After resize when its done successfully, do not forget to remove the xfsrestorehousekeepingdir and orphanage directories new volume which is mounted under temporary mount point /mnt/$DEV. To avoid future resize workflow failures. rm -rf /mnt/$DEV/xfsrestorehousekeepingdir For the rsync method : For MySQL : Run the final rsync. (date; rsync -avP --delete /vol/ebs1/ /mnt/${DEV}/; date) \\ | tee -a /mnt/tmp/vol-resize-${DEV}-rsync-1.log For Gluster bricks : Run the final rsync. BRICK=/mnt/brick##### (date; rsync -avHPX --delete ${BRICK}/ /mnt/${DEV}/; date) \\ | tee -a /mnt/tmp/vol-resize-${DEV}-rsync-1.log For both methods : Run it again. It should make no changes since services using the volume are stopped. Unmount the current and replacement volumes. umount $MOUNTPOINT umount /dev/$DEV Detach both volumes. aws ec2 detach-volume --region $REGION --volume-id $OLD_VOL aws ec2 detach-volume --region $REGION --volume-id $NEW_VOL Attach the new volume, no longer at the temporary location. aws ec2 attach-volume \\ --region $REGION \\ --volume-id $NEW_VOL \\ --instance-id $INSTANCE \\ --device /dev/$DEV Mount the new volume, no longer at the temporary mount point. mount $MOUNTPOINT Enable and run Puppet to start any services stopped earlier. puppet agent --enable; puppet agent --test If it was a Gluster brick that was resized, remount Gluster for the entire site. Make sure it properly remounts on every server. site-fsremount $SITE Update the fields volume record. Note : When you modify a volume with ah-server , a brand new volume ID is created. You must run sv-vollist again if you need to know the new volume id. For MySQL volumes (xvdm): ah-server edit $SERVER -s ebs_id=$NEW_VOL For Backup volumes (xvdn): ah-server edit $SERVER -s ebs2_id=$NEW_VOL For Gluster bricks (xvdo): ah-volume edit $BRICKID -s \\ ebs_id=$NEW_VOL \\ size=$SIZE \\ ec2_availability_zone=$AZ \\ status=in_use Tag the old volumes as having been replaced. (Remove some unused tags to make room.) aws ec2 delete-tags \\ --region $REGION \\ --resources $OLD_VOL \\ --tags Key=title Key=active aws ec2 create-tags \\ --region $REGION \\ --resources $OLD_VOL \\ --tags Key=ops_replaced_in,Value=$JIRA_TICKET \\ Key=ah_resize_info,Value=${OLD_VOL}/$(date +%Y%m%d%H%M -d \"+7 days\") The replaced volumes will be deleted in 1 week by the cronjob on the master","title":"Maintenance window steps"},{"location":"standard_maintenance/resize_volumes_manual/#volume-and-service-specifics","text":"MySQL (xvdm) Backup (xvdn) Gluster (xvdo)","title":"Volume and service specifics"},{"location":"standard_maintenance/resize_volumes_manual/#mysql-volumes-sdm","text":"Mountpoint: '/vol/ebs1' In an HA cluster, upsize one server at a time. Check that replication is in sync and the primary (first) server is active. ah-db-cluster status $SERVER Lock replication to the primary. ah-db-cluster lock $SERVER Stop Puppet, cron, and MySQL as above on the secondary. Stop MySQL with the following command. Never force MySQL to stop. Escalate to a DB if it refuses to stop gracefully. Note Some databases have very large data sets and use quite a lot of RAM. These can take many minutes to safely shutdown. Flushing caches to disk can take a long time with EBS. mysqladmin shutdown When the secondary is resized and services have been restarted, check that replication is in sync. ah-db-cluster status $SERVER When it is, unlock and fail over. Otherwise, fix it, or escalate to a DBA. ah-db-cluster unlock $SERVER dns-update $CLUSTER $SECONDARY On the primary (but now inactive) server, stop services and resize the volume as with the secondary. After upsizing, check replication, unlock, and fail back as before.","title":"MySQL volumes (sdm)"},{"location":"standard_maintenance/resize_volumes_manual/#backup-sdn","text":"Mountpoint: '/vol/backup-ebs' This volume can be replaced with a blank one of volume-type magnetic and fields-backup-fileserver.php will replace the contents from the Gluster volume. This volume matches the Gluster brick in size on staging servers and the primary server in HA FS clusters. For ACE/ACP, some prior backup-volumes may have been made as SSD volumes, reported as gp3 by sv-vollist. To match policy for new provisions, it is okay during this resize to replace with magnetic, reported as standard by sv-vollist. However in case of ACSF (EG1/WMG/TREX), some prior backup-volumes may have been made as Magnetic volumes, reported as standard by sv-vollist. To match policy for new provisions, it is okay during this resize to replace with SSD, reported as gp3 by sv-vollist. IMPORTANT : Ensure you resize the backup volume on the primary FS server FIRST. It is vital that the primary has the lowest number volume id. Note : The volume on the secondary FS server is always 1G in size. Set variables. SERVER= SIZE= OLD_VOL= INSTANCE=$(ah-server list $SERVER --no-name -c ec2_id) REGION=$(ah-server list $SERVER --no-name -c ec2_region) AZ=$(ah-server list $SERVER --no-name -c ec2_availability_zone) Create a new volume. aws ec2 create-volume \\ --region $REGION \\ --availability-zone $AZ \\ --size $SIZE View the tags from the current volume. aws ec2 describe-volumes --region $REGION --volume-ids $OLD_VOL Set more variables. NEW_VOL= Tag the new volume. Only 'SERVER' needs to be specified here, since 'FIELDS_STAGE' and 'USER' should already be defined. The launching user is you, not the original person. aws ec2 create-tags \\ --region $REGION \\ --resources $NEW_VOL \\ --tags \\ Key=ah_stage,Value=$FIELDS_STAGE \\ Key=ah_server_name,Value=$SERVER \\ Key=ah_attach_to_device,Value=/dev/sdn \\ Key=ah_launching_user,Value=$USER Unmount the old volume. fssh $SERVER sudo umount /vol/backup-ebs Detach the old volume. aws ec2 detach-volume --region $REGION --volume-id $OLD_VOL Attach the new volume. aws ec2 attach-volume \\ --region $REGION \\ --volume-id $NEW_VOL \\ --instance-id $INSTANCE \\ --device /dev/sdn Format the new volume. fssh $SERVER sudo mkfs -t xfs /dev/xvdn Mount the new volume. fssh $SERVER sudo mount /vol/backup-ebs Update the fields volume record. Note when setting ebs2_id with ah-server the id of the volume changes ah-server edit $SERVER -s ebs2_id=$NEW_VOL sv-vollist $SERVER","title":"Backup (sdn)"},{"location":"standard_maintenance/resize_volumes_manual/#gluster-sdo","text":"Mountpoint: '/mnt/brick#####', where ##### is the fields volume ID. (There is only one '/mnt/brick#####' per fs class server.) Stop the Gluster service: service glusterfs-server stop Stop any gluster processes: pkill glusterfsd Puppet does not start the Gluster service. Run fields-config-fs-server.php to start it, or ah-config-gluster for gluster version >3.0. After resizing the volume on each server, remount Gluster server. Make sure it properly remounts on every server. (Often, remounting twice will take care of this). The reason we remount gluster first is that during the time the gluster service has been offline the clients may have completely timed out retrying their connections; this starts up the retry loop so that when the firewall rule is removed they sanely reconnect. site-fsremount $SITE","title":"Gluster (sdo)"},{"location":"standard_maintenance/resize_volumes_manual/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"standard_maintenance/resize_volumes_manual/#reset-xfs-dump-restore","text":"If for any reason you have to reset the process and start again, you only need to modify the destination: rm -Rf /mnt/$DEV/{orphanage,xfsrestorehousekeepingdir}","title":"Reset XFS dump-restore"},{"location":"standard_maintenance/resize_volumes_manual/#gluster-34-id","text":"If Gluster 3.4 complains it lost the ID, do the following to fix it. export BRICK=/mnt/brick12312/brick export FSCLUSTER=ded-sitename export VOL_ID=$(grep volume-id /var/lib/glusterd/vols/$FSCLUSTER/info \\ | cut -d= -f2 \\ | sed 's/-//g') setfattr -n trusted.glusterfs.volume-id -v 0x$VOL_ID $BRICK gluster volume start $FSCLUSTER ah-config-gluster","title":"Gluster 3.4 ID"},{"location":"standard_maintenance/resize_volumes_manual/#deleting-a-volume","text":"When deleting a volume, make sure it is \"available\". (Here, $VOLUMES is space-separated.) aws ec2 describe-volumes --region $REGION --volume-ids $VOLUMES | grep State To delete a volume: aws ec2 delete-volume --region $REGION --volume-id $VOLUME","title":"Deleting a volume"},{"location":"standard_maintenance/resize_volumes_manual/#volume-cleanup","text":"This procedure is only to be used if you are cleaning up volumes from a failed resize. Get the volume details and set variables: sv-vollist $SERVER DEVICE=[/dev/xvdx | /dev/xvdy | /dev/xvdz] EBS_ID= VOL_ID= REGION= Here EBS_ID is the AWS volume identifier that starts with vol- (under heading ebs_id) and VOL_ID is the fields volume identifier under the heading id in the output of sv-vollist $SERVER . Unmount the volume: fssh $SERVER \"sudo umount -f $DEVICE\" Detach this volume from server: aws ec2 detach-volume --region $REGION --volume-id $EBS_ID Once detached successfully, delete this volume: aws ec2 delete-volume --region $REGION --volume-id $EBS_ID Update fields record for this deleted volume: ah-volume edit $VOL_ID -s server_id=0","title":"Volume Cleanup"},{"location":"standard_maintenance/fips-140-2/fips_check/","text":"Check whether a server is already FIPS compliant Check kernel release Kernel release should be marked with fips: SERVER_NAME= fssh $SERVER_NAME uname -r 4.4.0-1002-fips Check crypto setting: SERVER_NAME= fssh $SERVER_NAME sudo sysctl crypto crypto.fips_enabled = 1 Check package pin On FIPS enabled servers the following packages are expected to be pinned to the LP-PPA-ubuntu-advantage-fips remote: SERVER_NAME= fssh $SERVER_NAME sudo apt-cache policy | grep fips 500 https://private-ppa.launchpad.net/ubuntu-advantage/fips/ubuntu xenial/main amd64 Packages release v=16.04,o=LP-PPA-ubuntu-advantage-fips,a=xenial,n=xenial,l=FIPS,c=main,b=amd64 strongswan-hmac -> 5.3.5-1ubuntu3.fips.3.3 with priority 1001 openssl -> 1.0.2g-1ubuntu4.fips.4.6.3 with priority 1001 linux-fips -> 4.4.0.1002.3 with priority 1001 strongswan -> 5.3.5-1ubuntu3.fips.3.3 with priority 1001 fips-initramfs -> 0.0.3 with priority 1001 libssl1.0.0-hmac -> 1.0.2g-1ubuntu4.fips.4.6.3 with priority 1001 openssh-server-hmac -> 1:7.2p2-4ubuntu2.fips.2.2.1 with priority 1001 openssh-client-hmac -> 1:7.2p2-4ubuntu2.fips.2.2.1 with priority 1001 libssl1.0.0 -> 1.0.2g-1ubuntu4.fips.4.6.3 with priority 1001 Check mysql version on DB servers Mysql version has to be atleast 5.6.41 or later, check config settings: ah-server get SERVER_NAME ... server_settings: server_settings.puppet: server_settings.puppet.fips_enabled: 1 ... server_settings.puppet.mysql_version: 5.6.41 ...","title":"Check whether a server is already FIPS compliant"},{"location":"standard_maintenance/fips-140-2/fips_check/#check-whether-a-server-is-already-fips-compliant","text":"","title":"Check whether a server is already FIPS compliant"},{"location":"standard_maintenance/fips-140-2/fips_check/#check-kernel-release","text":"Kernel release should be marked with fips: SERVER_NAME= fssh $SERVER_NAME uname -r 4.4.0-1002-fips Check crypto setting: SERVER_NAME= fssh $SERVER_NAME sudo sysctl crypto crypto.fips_enabled = 1","title":"Check kernel release"},{"location":"standard_maintenance/fips-140-2/fips_check/#check-package-pin","text":"On FIPS enabled servers the following packages are expected to be pinned to the LP-PPA-ubuntu-advantage-fips remote: SERVER_NAME= fssh $SERVER_NAME sudo apt-cache policy | grep fips 500 https://private-ppa.launchpad.net/ubuntu-advantage/fips/ubuntu xenial/main amd64 Packages release v=16.04,o=LP-PPA-ubuntu-advantage-fips,a=xenial,n=xenial,l=FIPS,c=main,b=amd64 strongswan-hmac -> 5.3.5-1ubuntu3.fips.3.3 with priority 1001 openssl -> 1.0.2g-1ubuntu4.fips.4.6.3 with priority 1001 linux-fips -> 4.4.0.1002.3 with priority 1001 strongswan -> 5.3.5-1ubuntu3.fips.3.3 with priority 1001 fips-initramfs -> 0.0.3 with priority 1001 libssl1.0.0-hmac -> 1.0.2g-1ubuntu4.fips.4.6.3 with priority 1001 openssh-server-hmac -> 1:7.2p2-4ubuntu2.fips.2.2.1 with priority 1001 openssh-client-hmac -> 1:7.2p2-4ubuntu2.fips.2.2.1 with priority 1001 libssl1.0.0 -> 1.0.2g-1ubuntu4.fips.4.6.3 with priority 1001","title":"Check package pin"},{"location":"standard_maintenance/fips-140-2/fips_check/#check-mysql-version-on-db-servers","text":"Mysql version has to be atleast 5.6.41 or later, check config settings: ah-server get SERVER_NAME ... server_settings: server_settings.puppet: server_settings.puppet.fips_enabled: 1 ... server_settings.puppet.mysql_version: 5.6.41 ...","title":"Check mysql version on DB servers"},{"location":"standard_maintenance/fips-140-2/fips_disable/","text":"Disable FIPS Important!: DB servers running on FIPS cannot be relaunched simply with FIPS disabled. For disabling FIPS on the following server types api, dbmaster, dbmesh, ded, free, fsdb, fsdbmesh, srv, staging follow the specific DB migration steps . This runbook describes how to: Disable FIPS on servers individually Bulk disable FIPS on servers with the same type Disable FIPS on a server Suspend the server SERVER_NAME= ah-server suspend $SERVER_NAME Edit FIPS server config: ah-server edit $SERVER_NAME -c puppet:fips_enabled=0 Launch server ah-server launch $SERVER_NAME Bulk disable FIPS on servers Important!: Bulk disable FIPS on DB servers is not supported. For enabling FIPS on api, dbmaster, dbmesh, ded, free, fsdb, fsdbmesh, srv, or staging server types follow the DB-specific runbook . SERVER_NAMES=() ah-server bulk-relaunch ${SERVER_NAMES[@]} -c puppet:fips_enabled=0","title":"Disable FIPS"},{"location":"standard_maintenance/fips-140-2/fips_disable/#disable-fips","text":"Important!: DB servers running on FIPS cannot be relaunched simply with FIPS disabled. For disabling FIPS on the following server types api, dbmaster, dbmesh, ded, free, fsdb, fsdbmesh, srv, staging follow the specific DB migration steps . This runbook describes how to: Disable FIPS on servers individually Bulk disable FIPS on servers with the same type","title":"Disable FIPS"},{"location":"standard_maintenance/fips-140-2/fips_disable/#disable-fips-on-a-server","text":"Suspend the server SERVER_NAME= ah-server suspend $SERVER_NAME Edit FIPS server config: ah-server edit $SERVER_NAME -c puppet:fips_enabled=0 Launch server ah-server launch $SERVER_NAME","title":"Disable FIPS on a server"},{"location":"standard_maintenance/fips-140-2/fips_disable/#bulk-disable-fips-on-servers","text":"Important!: Bulk disable FIPS on DB servers is not supported. For enabling FIPS on api, dbmaster, dbmesh, ded, free, fsdb, fsdbmesh, srv, or staging server types follow the DB-specific runbook . SERVER_NAMES=() ah-server bulk-relaunch ${SERVER_NAMES[@]} -c puppet:fips_enabled=0","title":"Bulk disable FIPS on servers"},{"location":"standard_maintenance/fips-140-2/fips_enable/","text":"Enable FIPS Important!: DB servers cannot be relaunched simply with FIPS enabled. For enabling FIPS on the following server types api, dbmaster, dbmesh, ded, free, fsdb, fsdbmesh, srv, staging follow the specific DB migration steps . This runbook describes how to: Enable FIPS on servers individually Bulk enable FIPS on servers with the same type FIPS kernel is supported EXCLUSIVELY by the following AWS instance types: - SERIES 4 instance types Other instance types are not supported yet. Enable FIPS on a server Suspend the server SERVER_NAME= ah-server suspend $SERVER_NAME Adjust instance type If the server is not in VPC, select a VPC_ID from the output of ah-vpc list % -c id . Series 4 is only available in VPC. VPC_ID= # ID from output of ah-vpc list % -c id ah-server edit $SERVER_NAME -s vpc_id=$VPC_ID Only series 4 instance types are supported for FIPS enabling. So change the ami_type if that does not match this criteria. AMI_TYPE= # series 4 instance type, e.g.: c4.large ah-server edit $SERVER_NAME -s ami_type=$AMI_TYPE Set fips_enabled to 1 ah-server edit $SERVER_NAME -c puppet:fips_enabled=1 Launch server ah-server launch $SERVER_NAME Bulk enable FIPS on servers Important!: Bulk enable FIPS on DB servers is not supported. For enabling FIPS on api, dbmaster, dbmesh, ded, free, fsdb fsdbmesh, srv, or staging server types, follow the specific DB migration steps . bulk-relaunch allows to relaunch multiple servers on FIPS because it supports server config setting changes by using option -c . The servers must be the same type. Note: Since only series 4 instances are supported with current FIPS configuration use option -a to change the instance type if it is needed. Bulk relaunch servers If the server is not in VPC, select a VPC_ID from the output of ah-vpc list % -c id . Series 4 is only available in VPC. VPC_ID= # ID from output of ah-vpc list % -c id ah-server edit $(array-csv ${SERVER_NAMES[@]}) -s vpc_id=$VPC_ID Relaunch servers: SERVER_NAMES=() AMI_TYPE= # only series 4 ah-server bulk-relaunch ${SERVER_NAMES[@]} -a ${AMI_TYPE} -c puppet:fips_enabled=1","title":"Enable FIPS"},{"location":"standard_maintenance/fips-140-2/fips_enable/#enable-fips","text":"Important!: DB servers cannot be relaunched simply with FIPS enabled. For enabling FIPS on the following server types api, dbmaster, dbmesh, ded, free, fsdb, fsdbmesh, srv, staging follow the specific DB migration steps . This runbook describes how to: Enable FIPS on servers individually Bulk enable FIPS on servers with the same type FIPS kernel is supported EXCLUSIVELY by the following AWS instance types: - SERIES 4 instance types Other instance types are not supported yet.","title":"Enable FIPS"},{"location":"standard_maintenance/fips-140-2/fips_enable/#enable-fips-on-a-server","text":"Suspend the server SERVER_NAME= ah-server suspend $SERVER_NAME Adjust instance type If the server is not in VPC, select a VPC_ID from the output of ah-vpc list % -c id . Series 4 is only available in VPC. VPC_ID= # ID from output of ah-vpc list % -c id ah-server edit $SERVER_NAME -s vpc_id=$VPC_ID Only series 4 instance types are supported for FIPS enabling. So change the ami_type if that does not match this criteria. AMI_TYPE= # series 4 instance type, e.g.: c4.large ah-server edit $SERVER_NAME -s ami_type=$AMI_TYPE Set fips_enabled to 1 ah-server edit $SERVER_NAME -c puppet:fips_enabled=1 Launch server ah-server launch $SERVER_NAME","title":"Enable FIPS on a server"},{"location":"standard_maintenance/fips-140-2/fips_enable/#bulk-enable-fips-on-servers","text":"Important!: Bulk enable FIPS on DB servers is not supported. For enabling FIPS on api, dbmaster, dbmesh, ded, free, fsdb fsdbmesh, srv, or staging server types, follow the specific DB migration steps . bulk-relaunch allows to relaunch multiple servers on FIPS because it supports server config setting changes by using option -c . The servers must be the same type. Note: Since only series 4 instances are supported with current FIPS configuration use option -a to change the instance type if it is needed.","title":"Bulk enable FIPS on servers"},{"location":"standard_maintenance/fips-140-2/fips_enable/#bulk-relaunch-servers","text":"If the server is not in VPC, select a VPC_ID from the output of ah-vpc list % -c id . Series 4 is only available in VPC. VPC_ID= # ID from output of ah-vpc list % -c id ah-server edit $(array-csv ${SERVER_NAMES[@]}) -s vpc_id=$VPC_ID Relaunch servers: SERVER_NAMES=() AMI_TYPE= # only series 4 ah-server bulk-relaunch ${SERVER_NAMES[@]} -a ${AMI_TYPE} -c puppet:fips_enabled=1","title":"Bulk relaunch servers"},{"location":"standard_maintenance/fips-140-2/fips_migrate_db/","text":"Enable FIPS on DB servers Existing DB servers cannot be simply relaunched in FIPS mode. For FIPS compliancy a specifc mysql version needs to be installed. The ah-db-cluster upgrade-mysql tool must be used to upgrade MySQL to 5.6.41 prior to enabling FIPS. The list of server types involved are: api, dbmaster, dbmesh, ded, free, fdsb, fsdbmesh, srv, staging An upgrade command would look like, ah-db-cluster upgrade-mysql $DBSERVER --version=5.6.41","title":"Enable FIPS on DB servers"},{"location":"standard_maintenance/fips-140-2/fips_migrate_db/#enable-fips-on-db-servers","text":"Existing DB servers cannot be simply relaunched in FIPS mode. For FIPS compliancy a specifc mysql version needs to be installed. The ah-db-cluster upgrade-mysql tool must be used to upgrade MySQL to 5.6.41 prior to enabling FIPS. The list of server types involved are: api, dbmaster, dbmesh, ded, free, fdsb, fsdbmesh, srv, staging An upgrade command would look like, ah-db-cluster upgrade-mysql $DBSERVER --version=5.6.41","title":"Enable FIPS on DB servers"},{"location":"standard_maintenance/fips-140-2/fips_mysql_upgrade/","text":"Upgrading mysql tier to be FIPS 140-2 compliant As part of FIPS initiative, customers who are on non-fips compliant hardware will have to be migrated to a fips compliant hardware. This runbook will indicate the steps to be followed for the process. Pre-requisites (must be known before you begin) Site or sites Gathering a list of servers If a customer has multiple sites set the SITES variable to an array of sites: SITES=( ) SERVERS_CSV=$(ah-server list $(printf 'site:%s\\n' ${SITES[@]} | paste -sd,) -w type!=svn | paste -sd,) Create lists of database servers for the customer List NON-HA database servers. NON_HA_DB_SERVERS=( $(ah-server list % -w status=0 typeINsrv,staging,api,free \"name IN ${SERVERS_CSV}\") ) NON_HA_DB_SERVERS_CSV=$(array-csv ${NON_HA_DB_SERVERS[@]}) List HA database servers. HA_DB_SERVERS=( $(ah-server list % -w status=0 typeINded,fsdb,dbmaster,fsdbmesh,dbmesh \"name IN ${SERVERS_CSV}\") ) HA_DB_SERVERS_CSV=$(array-csv ${HA_DB_SERVERS[@]}) Verify the MySQL Versions before starting Check NON-HA database servers versions. fpdsh -l ${NON_HA_DB_SERVERS_CSV} -c \"mysql --version\" staging-123: mysql Ver 14.14 Distrib 5.6.32-78.1, for debian-linux-gnu (x86_64) using 6.3 Check HA database servers versions. fpdsh -l ${HA_DB_SERVERS_CSV} -c \"mysql --version\" fsdb-123: mysql Ver 14.14 Distrib 5.6.32-78.1, for debian-linux-gnu (x86_64) using 6.3 If any servers are already running 5.6.41 they do not need to be upgraded. (Workflows to upgrade them again will fail.) Find all active and passive database servers Separate active and primary database servers from all HA servers. echo ${HA_DB_SERVERS[@]} | sort -V > ${OPSTMP}/all_dbs eval $(sv-dbprisec $(paste -sd, ${OPSTMP}/all_dbs)) echo ${PRIMARY_DBS[@]} | sort -V > ${OPSTMP}/active_dbs echo ${SECONDARY_DBS[@]} | sort -V > ${OPSTMP}/passive_dbs Upgrade database servers to use FIPS compliant mysql version Upgrade mysql on all NON-HA database servers. for DB_SERVER in ${NON_HA_DB_SERVERS[@]}; do ah-db-cluster upgrade-mysql --version=5.6.41 ${DB_SERVER}; done Run pre-flight checks on all HA database servers. for DB_SERVER in ${PRIMARY_DBS[@]}; do ${OPSROOT}/scripts/mysql56-upgrade-check.sh ${DB_SERVER}; done Paste the output of the script into the Jira ticket. If any check fails refer to the relevant section here . Upgrade mysql on all HA servers. for DB_SERVER in ${PRIMARY_DBS[@]}; do ah-db-cluster upgrade-mysql --version=5.6.41 ${DB_SERVER} done If you are doing mysql upgrade on multi-region servers, then you need an extra parameter --active-region for the above command. This will kick-off tungsten_mysql_upgrade_workflow . ACTIVE_REGION= for DB_SERVER in ${PRIMARY_DBS[@]}; do ah-db-cluster upgrade-mysql --active-region=${ACTIVE_REGION} --version=5.6.41 ${DB_SERVER}; done Verify workflow has been successfully completed ah-workflow get <workflow id> --show-logs Verification step Ensure NON-HA database servers have been successfully upgraded. fpdsh -l ${NON_HA_DB_SERVERS_CSV} -c \"mysql --version\" staging-123: mysql Ver 14.14 Distrib 5.6.41-84.1, for debian-linux-gnu (x86_64) using 6.3 Ensure HA database servers have been successfully upgraded. fpdsh -l ${HA_DB_SERVERS_CSV} -c \"mysql --version\" fsdb-123: mysql Ver 14.14 Distrib 5.6.41-84.1, for debian-linux-gnu (x86_64) using 6.3 Suspend, Enable FIPS, Relaunch to New VPC Ops will be completing these setps of the runbook in a separate [ticket][2].","title":"Upgrading mysql tier to be FIPS 140-2 compliant"},{"location":"standard_maintenance/fips-140-2/fips_mysql_upgrade/#upgrading-mysql-tier-to-be-fips-140-2-compliant","text":"As part of FIPS initiative, customers who are on non-fips compliant hardware will have to be migrated to a fips compliant hardware. This runbook will indicate the steps to be followed for the process.","title":"Upgrading mysql tier to be FIPS 140-2 compliant"},{"location":"standard_maintenance/fips-140-2/fips_mysql_upgrade/#pre-requisites-must-be-known-before-you-begin","text":"Site or sites","title":"Pre-requisites (must be known before you begin)"},{"location":"standard_maintenance/fips-140-2/fips_mysql_upgrade/#gathering-a-list-of-servers","text":"If a customer has multiple sites set the SITES variable to an array of sites: SITES=( ) SERVERS_CSV=$(ah-server list $(printf 'site:%s\\n' ${SITES[@]} | paste -sd,) -w type!=svn | paste -sd,)","title":"Gathering a list of servers"},{"location":"standard_maintenance/fips-140-2/fips_mysql_upgrade/#create-lists-of-database-servers-for-the-customer","text":"List NON-HA database servers. NON_HA_DB_SERVERS=( $(ah-server list % -w status=0 typeINsrv,staging,api,free \"name IN ${SERVERS_CSV}\") ) NON_HA_DB_SERVERS_CSV=$(array-csv ${NON_HA_DB_SERVERS[@]}) List HA database servers. HA_DB_SERVERS=( $(ah-server list % -w status=0 typeINded,fsdb,dbmaster,fsdbmesh,dbmesh \"name IN ${SERVERS_CSV}\") ) HA_DB_SERVERS_CSV=$(array-csv ${HA_DB_SERVERS[@]})","title":"Create lists of database servers for the customer"},{"location":"standard_maintenance/fips-140-2/fips_mysql_upgrade/#verify-the-mysql-versions-before-starting","text":"Check NON-HA database servers versions. fpdsh -l ${NON_HA_DB_SERVERS_CSV} -c \"mysql --version\" staging-123: mysql Ver 14.14 Distrib 5.6.32-78.1, for debian-linux-gnu (x86_64) using 6.3 Check HA database servers versions. fpdsh -l ${HA_DB_SERVERS_CSV} -c \"mysql --version\" fsdb-123: mysql Ver 14.14 Distrib 5.6.32-78.1, for debian-linux-gnu (x86_64) using 6.3 If any servers are already running 5.6.41 they do not need to be upgraded. (Workflows to upgrade them again will fail.)","title":"Verify the MySQL Versions before starting"},{"location":"standard_maintenance/fips-140-2/fips_mysql_upgrade/#find-all-active-and-passive-database-servers","text":"Separate active and primary database servers from all HA servers. echo ${HA_DB_SERVERS[@]} | sort -V > ${OPSTMP}/all_dbs eval $(sv-dbprisec $(paste -sd, ${OPSTMP}/all_dbs)) echo ${PRIMARY_DBS[@]} | sort -V > ${OPSTMP}/active_dbs echo ${SECONDARY_DBS[@]} | sort -V > ${OPSTMP}/passive_dbs","title":"Find all active and passive database servers"},{"location":"standard_maintenance/fips-140-2/fips_mysql_upgrade/#upgrade-database-servers-to-use-fips-compliant-mysql-version","text":"Upgrade mysql on all NON-HA database servers. for DB_SERVER in ${NON_HA_DB_SERVERS[@]}; do ah-db-cluster upgrade-mysql --version=5.6.41 ${DB_SERVER}; done Run pre-flight checks on all HA database servers. for DB_SERVER in ${PRIMARY_DBS[@]}; do ${OPSROOT}/scripts/mysql56-upgrade-check.sh ${DB_SERVER}; done Paste the output of the script into the Jira ticket. If any check fails refer to the relevant section here . Upgrade mysql on all HA servers. for DB_SERVER in ${PRIMARY_DBS[@]}; do ah-db-cluster upgrade-mysql --version=5.6.41 ${DB_SERVER} done If you are doing mysql upgrade on multi-region servers, then you need an extra parameter --active-region for the above command. This will kick-off tungsten_mysql_upgrade_workflow . ACTIVE_REGION= for DB_SERVER in ${PRIMARY_DBS[@]}; do ah-db-cluster upgrade-mysql --active-region=${ACTIVE_REGION} --version=5.6.41 ${DB_SERVER}; done Verify workflow has been successfully completed ah-workflow get <workflow id> --show-logs","title":"Upgrade database servers to use FIPS compliant mysql version"},{"location":"standard_maintenance/fips-140-2/fips_mysql_upgrade/#verification-step","text":"Ensure NON-HA database servers have been successfully upgraded. fpdsh -l ${NON_HA_DB_SERVERS_CSV} -c \"mysql --version\" staging-123: mysql Ver 14.14 Distrib 5.6.41-84.1, for debian-linux-gnu (x86_64) using 6.3 Ensure HA database servers have been successfully upgraded. fpdsh -l ${HA_DB_SERVERS_CSV} -c \"mysql --version\" fsdb-123: mysql Ver 14.14 Distrib 5.6.41-84.1, for debian-linux-gnu (x86_64) using 6.3","title":"Verification step"},{"location":"standard_maintenance/fips-140-2/fips_mysql_upgrade/#suspend-enable-fips-relaunch-to-new-vpc","text":"Ops will be completing these setps of the runbook in a separate [ticket][2].","title":"Suspend, Enable FIPS, Relaunch to New VPC"},{"location":"standard_maintenance/fips-140-2/fips_provision/","text":"FIPS 140-2 compliant server provisioning FIPS server config needs to be enabled after allocation and before launch: Allocate server Note: Only series 4 instance types are supported for FIPS enabling. SERVER_TYPE= REGION= AVAIL_ZONE= AMI_TYPE= # only series 4 SERVER_NAME=$(ah-server allocate $SERVER_TYPE -r $REGION -z $AVAIL_ZONE -t $AMI_TYPE) FIPS server config setting Note: For internal server types this server configuration is unneccesary, because the following server types are allocated by default with FIPS: backup, task, dns, ossec, mon, sitemon, monui, bastion ah-server edit $SERVER_NAME -c puppet:fips_enabled=1 Mysql version server config setting Note: A specific version of mysql is required to be used on FIPS compliant servers. Therefore activating FIPS on server types api, dbmaster, dbmesh, ded, free, fsdb, fsdbmesh, srv, staging, web requires an additional server config setting: MYSQL_VERSION=5.7.29 ah-server edit $SERVER_NAME -c puppet:mysql_version=$MYSQL_VERSION Launch server ah-server launch $SERVER_NAME","title":"FIPS 140-2 compliant server provisioning"},{"location":"standard_maintenance/fips-140-2/fips_provision/#fips-140-2-compliant-server-provisioning","text":"FIPS server config needs to be enabled after allocation and before launch: Allocate server Note: Only series 4 instance types are supported for FIPS enabling. SERVER_TYPE= REGION= AVAIL_ZONE= AMI_TYPE= # only series 4 SERVER_NAME=$(ah-server allocate $SERVER_TYPE -r $REGION -z $AVAIL_ZONE -t $AMI_TYPE) FIPS server config setting Note: For internal server types this server configuration is unneccesary, because the following server types are allocated by default with FIPS: backup, task, dns, ossec, mon, sitemon, monui, bastion ah-server edit $SERVER_NAME -c puppet:fips_enabled=1 Mysql version server config setting Note: A specific version of mysql is required to be used on FIPS compliant servers. Therefore activating FIPS on server types api, dbmaster, dbmesh, ded, free, fsdb, fsdbmesh, srv, staging, web requires an additional server config setting: MYSQL_VERSION=5.7.29 ah-server edit $SERVER_NAME -c puppet:mysql_version=$MYSQL_VERSION Launch server ah-server launch $SERVER_NAME","title":"FIPS 140-2 compliant server provisioning"}]}